{"meta":{"title":"Eli's Blog","subtitle":null,"description":null,"author":"Eli He","url":"https://elihe2011.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-11-19T08:24:36.000Z","updated":"2021-06-22T10:50:49.750Z","comments":true,"path":"categories/index.html","permalink":"https://elihe2011.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Fiber 框架学习","slug":"Fiber 框架学习","date":"2021-10-24T05:29:45.000Z","updated":"2021-10-28T12:36:18.454Z","comments":true,"path":"2021/10/24/Fiber 框架学习/","link":"","permalink":"https://elihe2011.github.io/2021/10/24/Fiber%20%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/","excerpt":"1. 入门1go get github.com/gofiber/fiber/v2 编写主函数： 123456789func main() &#123; app := fiber.New() app.Get(&quot;/&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;Hello World!&quot;) &#125;) app.Listen(&quot;:3000&quot;)&#125;","text":"1. 入门1go get github.com/gofiber/fiber/v2 编写主函数： 123456789func main() &#123; app := fiber.New() app.Get(&quot;/&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;Hello World!&quot;) &#125;) app.Listen(&quot;:3000&quot;)&#125; 2. 配置1234567891011121314func main() &#123; app := fiber.New(fiber.Config&#123; AppName: &quot;It&#x27;s a go fiber web frame&quot;, ServerHeader: &quot;gofiber.io&quot;, // Response.Header.Server ReadTimeout: 5 * time.Second, WriteTimeout: 5 * time.Second, &#125;) app.Get(&quot;/&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;OK&quot;) &#125;) log.Fatalln(app.Listen(&quot;:3000&quot;))&#125; 3. 路由3.1 参数12345678910111213141516171819202122232425func main() &#123; app := fiber.New() app.Get(&quot;/about&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;about&quot;) &#125;) // ?: 允许username不输入 app.Get(&quot;/hello/:username?&quot;, func(c *fiber.Ctx) error &#123; msg := fmt.Sprintf(&quot;hello %s&quot;, c.Params(&quot;username&quot;)) return c.SendString(msg) &#125;) // 复杂路由 app.Get(&quot;/fights/:from-:to&quot;, func(c *fiber.Ctx) error &#123; fmt.Fprintf(c, &quot;%s-%s\\n&quot;, c.Params(&quot;from&quot;), c.Params(&quot;to&quot;)) return nil &#125;) // 路由注册信息 data, _ := json.MarshalIndent(app.Stack(), &quot;&quot;, &quot; &quot;) fmt.Println(string(data)) log.Fatalln(app.Listen(&quot;:3000&quot;))&#125; 3.2 Add &amp; AllFiber 路由支持额外的方法： Add：所有 HTTP Method 对应的底层实现 1234// Fiber 自动添加 Head 方法func (app *App) Get(path string, handlers ...Handler) Router &#123; return app.Add(MethodHead, path, handlers...).Add(MethodGet, path, handlers...)&#125; All：支持任意的 HTTP Method 请求 3.3 Mount &amp; GroupMount: 可以将一个 Fiber 实例挂载到另一个实例 1234567891011func main() &#123; micro := fiber.New() micro.Get(&quot;/micro&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;micro&quot;) &#125;) app := fiber.New() app.Mount(&quot;/app&quot;, micro) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; Group: 路由分组 1234567891011121314151617181920212223242526func calc(c *fiber.Ctx) error &#123; start := time.Now() c.Next() elapse := time.Since(start) log.Printf(&quot;it takes %.2f seconds\\n&quot;, elapse.Seconds()) return nil&#125;func main() &#123; app := fiber.New() api := app.Group(&quot;/api&quot;) v1 := api.Group(&quot;/v1&quot;) v1.Get(&quot;/about&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;hello 1&quot;) &#125;) v2 := api.Group(&quot;/v2&quot;, calc) v2.Get(&quot;/about&quot;, func(c *fiber.Ctx) error &#123; time.Sleep(3 * time.Second) return c.SendString(&quot;hello 2&quot;) &#125;) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; 4. 静态资源1app.Static(&quot;/images&quot;, `/data/images`, fiber.Static&#123;Browse: true&#125;) 5. 使用模板pug 模板: index.pug 12345html head title #&#123;.Title&#125; body p #&#123;.Message&#125; 解析： 1234567891011121314151617func main() &#123; // 初始化 pug 模板引擎 engine := pug.New(&quot;./views&quot;, &quot;.pug&quot;) app := fiber.New(fiber.Config&#123; Views: engine, &#125;) app.Get(&quot;/&quot;, func(c *fiber.Ctx) error &#123; return c.Render(&quot;index&quot;, fiber.Map&#123; &quot;Title&quot;: &quot;hello&quot;, &quot;Message&quot;: &quot;This is the index pug template&quot;, &#125;) &#125;) app.Listen(&quot;:3000&quot;)&#125; 6. fiber.Ctx 方法6.1 c.BodyParser12345678910111213141516171819202122type User struct &#123; Name string `json:&quot;name&quot; xml:&quot;name&quot; form:&quot;name&quot;` Pass string `json:&quot;pass&quot; xml:&quot;pass&quot; form:&quot;pass&quot;`&#125;func main() &#123; app := fiber.New() app.Post(&quot;/login&quot;, func(c *fiber.Ctx) error &#123; user := new(User) err := c.BodyParser(user) if err != nil &#123; return err &#125; log.Printf(&quot;name %s, pass: %s\\n&quot;, user.Name, user.Pass) return c.SendString(&quot;OK&quot;) &#125;) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; 测试： 123456789curl -X POST -H &quot;Content-Type: application/json&quot; --data &quot;&#123;\\&quot;name\\&quot;:\\&quot;john\\&quot;,\\&quot;pass\\&quot;:\\&quot;doe\\&quot;&#125;&quot; localhost:3000/logincurl -X POST -H &quot;Content-Type: application/xml&quot; --data &quot;&lt;login&gt;&lt;name&gt;john&lt;/name&gt;&lt;pass&gt;doe&lt;/pass&gt;&lt;/login&gt;&quot; localhost:3000/logincurl -X POST -H &quot;Content-Type: application/x-www-form-urlencoded&quot; --data &quot;name=john&amp;pass=doe&quot; localhost:3000/logincurl -X POST -F name=john -F pass=doe http://localhost:3000/logincurl -X POST &quot;http://localhost:3000/login?name=john&amp;pass=doe&quot; 6.2 c.Query()12345678910111213func main() &#123; app := fiber.New() app.Get(&quot;/users&quot;, func(c *fiber.Ctx) error &#123; pageIndex := c.Query(&quot;page_index&quot;) pageSize := c.Query(&quot;page_size&quot;) body := fmt.Sprintf(&quot;page index: %s\\npage size: %s&quot;, pageIndex, pageSize) return c.SendString(body) &#125;) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; 7. 中间件7.1 自定义123456789app.Use(func(c *fiber.Ctx) error &#123; start := time.Now() c.Next() elapse := time.Since(start) log.Printf(&quot;it takes %.2f seconds\\n&quot;, elapse.Seconds()) return nil&#125;) 7.2 内置中间件https://docs.gofiber.io/api/middleware 123456789101112func main() &#123; app := fiber.New() // 使用内置中间件 app.Use(recover.New()) app.Get(&quot;/&quot;, func(c *fiber.Ctx) error &#123; panic(&quot;I&#x27;m an error&quot;) &#125;) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; 7.2.1 签名1func New(config ...Config) fiber.Handler 7.2.2 配置12345678910111213141516171819202122type Config struct &#123; // Next defines a function to skip this middleware when returned true. // // Optional. Default: nil Next func(c *fiber.Ctx) bool // EnableStackTrace enables handling stack trace // // Optional. Default: false EnableStackTrace bool // StackTraceHandler defines a function to handle stack trace // // Optional. Default: defaultStackTraceHandler StackTraceHandler func(e interface&#123;&#125;)&#125;var ConfigDefault = Config&#123; Next: nil, EnableStackTrace: false, StackTraceHandler: defaultStackTraceHandler,&#125; 7.3 自建中间件123456789101112131415161718192021222324// 响应headers中设置如下参数func Security(c *fiber.Ctx) error &#123; c.Set(&quot;X-XSS-Protection&quot;, &quot;1; mode=block&quot;) c.Set(&quot;X-Content-Type-Options&quot;, &quot;nosniff&quot;) c.Set(&quot;X-Download-Options&quot;, &quot;noopen&quot;) c.Set(&quot;Strict-Transport-Security&quot;, &quot;max-age=5184000&quot;) c.Set(&quot;X-Frame-Options&quot;, &quot;SAMEORIGIN&quot;) c.Set(&quot;X-DNS-Prefetch-Control&quot;, &quot;off&quot;) return c.Next()&#125;func main() &#123; app := fiber.New() // 使用内置中间件 app.Use(Security) app.Get(&quot;/&quot;, func(c *fiber.Ctx) error &#123; return c.JSON(map[string]string&#123;&quot;msg&quot;: &quot;ok&quot;&#125;) &#125;) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; 8. 单元测试Fiber 提供专门的测试方法： 123// Test is used for internal debugging by passing a *http.Request.// Timeout is optional and defaults to 1s, -1 will disable it completely.func (app *App) Test(req *http.Request, msTimeout ...int) (resp *http.Response, err error) 待测试程序： 12345678910111213func setupRouters(app *fiber.App) &#123; app.Get(&quot;/hello&quot;, func(c *fiber.Ctx) error &#123; return c.SendString(&quot;Hello World!&quot;) &#125;)&#125;func main() &#123; app := fiber.New() setupRouters(app) log.Fatal(app.Listen(&quot;:3000&quot;))&#125; 测试代码： 123456789101112131415161718192021222324252627func TestHelloRoute(t *testing.T) &#123; app := fiber.New() setupRouters(app) cases := []struct &#123; description string route string expectedCode int &#125;&#123; &#123; description: &quot;get HTTP status 200&quot;, route: &quot;/hello&quot;, expectedCode: 200, &#125;, &#123; description: &quot;get HTTP status 404&quot;, route: &quot;/notfound&quot;, expectedCode: 404, &#125;, &#125; for _, c := range cases &#123; req := httptest.NewRequest(&quot;GET&quot;, c.route, nil) resp, _ := app.Test(req, 1) assert.Equalf(t, c.expectedCode, resp.StatusCode, c.description) &#125;&#125;","categories":[{"name":"golang","slug":"golang","permalink":"https://elihe2011.github.io/categories/golang/"}],"tags":[]},{"title":"Golang 加密和签名","slug":"Golang 加密和签名.md","date":"2021-10-09T11:05:31.000Z","updated":"2021-10-28T12:36:18.452Z","comments":true,"path":"2021/10/09/Golang 加密和签名.md/","link":"","permalink":"https://elihe2011.github.io/2021/10/09/Golang%20%E5%8A%A0%E5%AF%86%E5%92%8C%E7%AD%BE%E5%90%8D.md/","excerpt":"1. 存储格式密钥、密文、签名字符串的存储格式 12345678910// hex：转为十六进制字符串表示hex.EncodeToString(src []byte) stringhex.DecodeString(s string) ([]byte, error)// base64base64.StdEncoding.EncodeToString(src []byte) stringbase64.StdEncoding.DecodeString(s string) ([]byte, error)// pem: 密钥解析pem.Decode(data []byte) (p *Block, rest []byte)","text":"1. 存储格式密钥、密文、签名字符串的存储格式 12345678910// hex：转为十六进制字符串表示hex.EncodeToString(src []byte) stringhex.DecodeString(s string) ([]byte, error)// base64base64.StdEncoding.EncodeToString(src []byte) stringbase64.StdEncoding.DecodeString(s string) ([]byte, error)// pem: 密钥解析pem.Decode(data []byte) (p *Block, rest []byte) 2. 生成密钥12345# 私钥openssl genrsa -out rsa_private_key.pem 2048# 公钥openssl rsa -in rsa_private_key.pem -pubout -out rsa_public_key.pem 3. 私钥格式12345// PKCS1x509.ParsePKCS1PrivateKey(der []byte) (key interface&#123;&#125;, err error)// PKCS2x509.ParsePKCS8PrivateKey(der []byte) (key interface&#123;&#125;, err error) 4. SHA算法123456// sha1 or sha256h := sha1.New()h := sha256.New()h.Write([]byte(data))hash := h.Sum(nil) 5. RSA类型 公钥加密、私钥解密 私钥签名、公钥验签 1234567891011// 加密rsa.EncryptPKCS1v15(rand io.Reader, pub *PublicKey, msg []byte) ([]byte, error)// 解密rsa.DecryptPKCS1v15(rand io.Reader, priv *PrivateKey, ciphertext []byte) ([]byte, error)// 签名rsa.SignPKCS1v15(rand io.Reader, priv *PrivateKey, hash crypto.Hash, hashed []byte) ([]byte, error)// 验签rsa.VerifyPKCS1v15(pub *PublicKey, hash crypto.Hash, hashed []byte, sig []byte) error 5.1 加密和解密12345678910111213141516171819202122232425262728293031323334func RsaEncrypt(plainText, publicKey string) (string, error) &#123; block, _ := pem.Decode([]byte(publicKey)) pubKey, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil &#123; return &quot;&quot;, err &#125; cipherText, err := rsa.EncryptPKCS1v15(rand.Reader, pubKey.(*rsa.PublicKey), []byte(plainText)) if err != nil &#123; return &quot;&quot;, err &#125; return base64.StdEncoding.EncodeToString(cipherText), nil&#125;func RsaDecrypt(cipherText, privateKey string) (string, error) &#123; block, _ := pem.Decode([]byte(privateKey)) priKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil &#123; return &quot;&quot;, err &#125; cipherTextData, err := base64.StdEncoding.DecodeString(cipherText) if err != nil &#123; return &quot;&quot;, err &#125; plainTextData, err := rsa.DecryptPKCS1v15(rand.Reader, priKey, cipherTextData) if err != nil &#123; return &quot;&quot;, err &#125; return string(plainTextData), nil&#125; 5.2 签名和验签12345678910111213141516171819202122232425262728293031323334func RsaSign(originalData, privateKey string) (string, error) &#123; block, _ := pem.Decode([]byte(privateKey)) priKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil &#123; return &quot;&quot;, err &#125; h := sha256.New() h.Write([]byte(originalData)) hash := h.Sum(nil) signature, err := rsa.SignPKCS1v15(rand.Reader, priKey, crypto.SHA256, hash[:]) if err != nil &#123; return &quot;&quot;, err &#125; return hex.EncodeToString(signature), nil&#125;func RsaVerify(originalData, SignatureData, publicKey string) error &#123; block, _ := pem.Decode([]byte(publicKey)) pubKey, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil &#123; return err &#125; signature, err := hex.DecodeString(SignatureData) h := sha256.New() h.Write([]byte(originalData)) hash := h.Sum(nil) return rsa.VerifyPKCS1v15(pubKey.(*rsa.PublicKey), crypto.SHA256, hash[:], signature)&#125; 6. AES123456789aes.NewCipher(key []byte) (cipher.Block, error)cipher.NewCBCEncrypter(b Block, iv []byte) BlockModecipherTextData := make([]byte, len(originalData))blockMode.CryptBlocks(cipherTextData, originalData)cipher.NewCBCDecrypter(b Block, iv []byte) BlockModeoriginalData := make([]byte, len(cipherTextData))blockMode.CryptBlocks(originalData, cipherTextData) 实例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func AesEncrypt(plainText, key, iv string) (string, error) &#123; // 密钥: 长度必须为16, 24, 32 block, err := aes.NewCipher([]byte(key)) if err != nil &#123; return &quot;&quot;, err &#125; // 加密模式: IV长度和KEY保持一致 blockMode := cipher.NewCBCEncrypter(block, []byte(iv)) // 填充内容 blockSize := block.BlockSize() left := blockSize - len(plainText)%blockSize padding := bytes.Repeat([]byte&#123;byte(left)&#125;, left) originalData := append([]byte(plainText), padding...) // 加密 cipherTextData := make([]byte, len(originalData)) blockMode.CryptBlocks(cipherTextData, originalData) return base64.StdEncoding.EncodeToString(cipherTextData), nil&#125;func AesDecrypt(cipherText, key, iv string) (string, error) &#123; // 密钥: 长度必须为16, 24, 32 block, err := aes.NewCipher([]byte(key)) if err != nil &#123; return &quot;&quot;, err &#125; // 加密模式: IV长度和KEY保持一致 blockMode := cipher.NewCBCDecrypter(block, []byte(iv)) // 密文 cipherTextData, err := base64.StdEncoding.DecodeString(cipherText) // 解密 originalData := make([]byte, len(cipherTextData)) blockMode.CryptBlocks(originalData, cipherTextData) // 去除填充 length := len(originalData) left := int(originalData[length-1]) plainTextData := originalData[:(length - left)] return string(plainTextData), nil&#125;","categories":[{"name":"golang","slug":"golang","permalink":"https://elihe2011.github.io/categories/golang/"}],"tags":[]},{"title":"Kubernetes 核心组件","slug":"Kubernetes 核心组件","date":"2021-07-13T06:28:35.000Z","updated":"2021-07-13T06:28:48.588Z","comments":true,"path":"2021/07/13/Kubernetes 核心组件/","link":"","permalink":"https://elihe2011.github.io/2021/07/13/Kubernetes%20%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/","excerpt":"1. API-Server1.1 工作原理核心功能：资源操作入口 提供集群管理的 REST API 接口，包括认证授权、准入控制、数据校验以及集群状态变更等 提供其他模块之间的数据交互和通信的枢纽（其他模块通过 API Server 查询或修改数据，只有 API Server 能够直接操作 etcd）","text":"1. API-Server1.1 工作原理核心功能：资源操作入口 提供集群管理的 REST API 接口，包括认证授权、准入控制、数据校验以及集群状态变更等 提供其他模块之间的数据交互和通信的枢纽（其他模块通过 API Server 查询或修改数据，只有 API Server 能够直接操作 etcd） 1.2 访问1.2.1 访问端口12345678vi /etc/kubernetes/kube-apiserver.conf--insecure-bind-address=127.0.0.1 \\--insecure-port=8080 \\--bind-address=192.168.80.11 \\--secure-port=6443 \\curl http://localhost:8080curl https://192.168.80.11:6443 1.2.2 访问方式12345678910111213141516171819202122232425262728293031323334353637383940# 1. sdkgo get k8s.io/client-go@latest# 2. kubectlkubectl get --raw /api/v1/namespaces | python -m json.toolkubectl get --raw /apis/metrics.k8s.io/v1beta1/nodeskubectl get --raw /apis/metrics.k8s.io/v1beta1/pods# 3. kubectl proxykubectl proxy --port=8081 &amp;curl http://localhost:8081/api/&#123; &quot;kind&quot;: &quot;APIVersions&quot;, &quot;versions&quot;: [ &quot;v1&quot; ], &quot;serverAddressByClientCIDRs&quot;: [ &#123; &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;, &quot;serverAddress&quot;: &quot;192.168.80.45:6443&quot; &#125; ]&#125;# 4. curlTOKEN=$(kubectl describe secrets $(kubectl get secrets -n kube-system |grep admin |cut -f1 -d &#x27; &#x27;) -n kube-system |grep -E &#x27;^token&#x27; |cut -f2 -d&#x27;:&#x27;|tr -d &#x27;\\t&#x27;|tr -d &#x27; &#x27;)APISERVER=$(kubectl config view |grep server|cut -f 2- -d &quot;:&quot; | tr -d &quot; &quot;)curl -H &quot;Authorization: Bearer $TOKEN&quot; $APISERVER/api --insecure&#123; &quot;kind&quot;: &quot;APIVersions&quot;, &quot;versions&quot;: [ &quot;v1&quot; ], &quot;serverAddressByClientCIDRs&quot;: [ &#123; &quot;clientCIDR&quot;: &quot;0.0.0.0/0&quot;, &quot;serverAddress&quot;: &quot;192.168.80.45:6443&quot; &#125; ]&#125;r 1.3 API 资源123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143# 所有支持的资源$ kubectl api-resourcesNAME SHORTNAMES APIGROUP NAMESPACED KINDbindings true Bindingcomponentstatuses cs false ComponentStatusconfigmaps cm true ConfigMapendpoints ep true Endpointsevents ev true Eventlimitranges limits true LimitRangenamespaces ns false Namespacenodes no false Nodepersistentvolumeclaims pvc true PersistentVolumeClaimpersistentvolumes pv false PersistentVolumepods po true Podpodtemplates true PodTemplatereplicationcontrollers rc true ReplicationControllerresourcequotas quota true ResourceQuotasecrets true Secretserviceaccounts sa true ServiceAccountservices svc true Servicemutatingwebhookconfigurations admissionregistration.k8s.io false MutatingWebhookConfigurationvalidatingwebhookconfigurations admissionregistration.k8s.io false ValidatingWebhookConfigurationcustomresourcedefinitions crd,crds apiextensions.k8s.io false CustomResourceDefinitionapiservices apiregistration.k8s.io false APIServicecontrollerrevisions apps true ControllerRevisiondaemonsets ds apps true DaemonSetdeployments deploy apps true Deploymentreplicasets rs apps true ReplicaSetstatefulsets sts apps true StatefulSettokenreviews authentication.k8s.io false TokenReviewlocalsubjectaccessreviews authorization.k8s.io true LocalSubjectAccessReviewselfsubjectaccessreviews authorization.k8s.io false SelfSubjectAccessReviewselfsubjectrulesreviews authorization.k8s.io false SelfSubjectRulesReviewsubjectaccessreviews authorization.k8s.io false SubjectAccessReviewhorizontalpodautoscalers hpa autoscaling true HorizontalPodAutoscalercronjobs cj batch true CronJobjobs batch true Jobcertificatesigningrequests csr certificates.k8s.io false CertificateSigningRequestleases coordination.k8s.io true Leaseendpointslices discovery.k8s.io true EndpointSliceevents ev events.k8s.io true Eventingresses ing extensions true Ingressingressclasses networking.k8s.io false IngressClassingresses ing networking.k8s.io true Ingressnetworkpolicies netpol networking.k8s.io true NetworkPolicyruntimeclasses node.k8s.io false RuntimeClasspoddisruptionbudgets pdb policy true PodDisruptionBudgetpodsecuritypolicies psp policy false PodSecurityPolicyclusterrolebindings rbac.authorization.k8s.io false ClusterRoleBindingclusterroles rbac.authorization.k8s.io false ClusterRolerolebindings rbac.authorization.k8s.io true RoleBindingroles rbac.authorization.k8s.io true Rolepriorityclasses pc scheduling.k8s.io false PriorityClasscsidrivers storage.k8s.io false CSIDrivercsinodes storage.k8s.io false CSINodestorageclasses sc storage.k8s.io false StorageClassvolumeattachments storage.k8s.io false VolumeAttachment# 获取特定组 apps 的资源$ kubectl api-resources --api-group appskubectl api-resources --api-group appsNAME SHORTNAMES APIGROUP NAMESPACED KINDcontrollerrevisions apps true ControllerRevisiondaemonsets ds apps true DaemonSetdeployments deploy apps true Deploymentreplicasets rs apps true ReplicaSetstatefulsets sts apps true StatefulSet# 资源详细解释$ kubectl explain svcKIND: ServiceVERSION: v1DESCRIPTION: Service is a named abstraction of software service (for example, mysql) consisting of local port (for example 3306) that the proxy listens on, and the selector that determines which pods will answer requests sent through the proxy.FIELDS: apiVersion &lt;string&gt; APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources kind &lt;string&gt; Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds metadata &lt;Object&gt; Standard object&#x27;s metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata spec &lt;Object&gt; Spec defines the behavior of a service. https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status status &lt;Object&gt; Most recently observed status of the service. Populated by the system. Read-only. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status # 集群支持的API版本$ kubectl api-versionsadmissionregistration.k8s.io/v1admissionregistration.k8s.io/v1beta1apiextensions.k8s.io/v1apiextensions.k8s.io/v1beta1apiregistration.k8s.io/v1apiregistration.k8s.io/v1beta1apps/v1authentication.k8s.io/v1authentication.k8s.io/v1beta1authorization.k8s.io/v1authorization.k8s.io/v1beta1autoscaling/v1autoscaling/v2beta1autoscaling/v2beta2batch/v1batch/v1beta1certificates.k8s.io/v1certificates.k8s.io/v1beta1coordination.k8s.io/v1coordination.k8s.io/v1beta1discovery.k8s.io/v1beta1events.k8s.io/v1events.k8s.io/v1beta1extensions/v1beta1networking.k8s.io/v1networking.k8s.io/v1beta1node.k8s.io/v1beta1policy/v1beta1rbac.authorization.k8s.io/v1rbac.authorization.k8s.io/v1beta1scheduling.k8s.io/v1scheduling.k8s.io/v1beta1storage.k8s.io/v1storage.k8s.io/v1beta1v1 1.4 示例https://v1-19.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#read-pod-v1-core 1234567891011121314151617cat &gt; pod.yml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: pod-examplespec: containers: - name: alpine image: alpine:latest command: [&quot;echo&quot;] args: [&quot;Hello World&quot;]EOFkubectl apply -f pod.ymlkubectl get podcurl http://localhost:8080/api/v1/namespaces/default/pods/pod-example 2. Controller-ManagerController Manager 由 kube-controller-manager 和 cloud-controller-manager 组成，是 Kubernetes 的大脑，它通过 apiserver 监控整个集群的状态，并确保集群处于预期的工作状态。 Controller Manager作为集群内部的管理控制中心，负责集群内的Node、Pod副本、服务端点（Endpoint）、命名空间（Namespace）、服务账号（ServiceAccount）、资源定额（ResourceQuota）的管理，当某个Node意外宕机时，Controller Manager会及时发现并执行自动化修复流程，确保集群始终处于预期的工作状态。 2.1 控制器分类kube-controller-manager: Replication Controller Node Controller CronJob Controller Daemon Controller Deployment Controller Endpoint Controller Garbage Collector Namespace Controller Job Controller Pod AutoScaler RelicaSet Service Controller ServiceAccount Controller StatefulSet Controller Volume Controller Resource quota Controller cloud-controller-manager: 在 Kubernetes 启用 Cloud Provider 的时候才需要，用来配合云服务提供商的控制 Node Controller Route Controller Service Controller 2.2 Replication Controller (RC)简称RC，即副本控制器，它的作用是保证集群中一个RC所关联的Pod副本数始终保持预设值 只有当Pod的重启策略RestartPolicy=Always时，RC才会管理该Pod的操作（创建、销毁、重启等） 创建Pod的RC模板，只在创建Pod时有效，一旦Pod创建完成，模板的变化，不会影响到已创建好的Pod 可通过修改Pod的Label，使该Pod脱离RC的管理。该方法可用于Pod从集群中迁移，数据修复等调试 删除一个RC不影响它所创建的Pod，如果要删除Pod，需要将RC的副本数属性设置为0 不要越过RC创建Pod，因为RC实现了自动化管理Pod，提高容灾能力 2.2.1 RC 的职责 维护集群中Pod的副本数 通过调整RC中的spec.replicas属性值来实现系统的扩容或缩容 通过改变RC中的Pod模板来实现系统的滚动升级 2.2.2 存活探针Kubemetes有以下三种探测容器的机制： HTTPGET探针：对容器的地址http://ip:port/path执行HTTPGET请求 成功：探测器收到响应，且响应状态码不代表错误（2xx、3xx) 失败：未收到响应，或收到错误响应状态码 TCP套接字探针：尝试与容器指定端口建立TCP连接。如果连接成功建立，则探测成功；否则，容器重新启动。 Exec探针：在容器内执行任意命令，并检查命令的退出状态码。如果状态码是0, 则探测成功；其他状态码都被认为失败。 1234567891011spec: containers: - name: nginx image: nginx:latest # 一个基于HTTP GET的存活探针 livenessProbe: # 第一次检测在容器启动15秒后 initialDelaySeconds: 15 httpGet: port: 8080 path: / 2.3 ReplicaSet (RS)RS 是RC的替代者，它使用Deployment管理，比RC更强大 2.4 Node Controllerkubelet 在启动时，会通过API Server注册自身的节点信息，并定时向API Server汇报状态信息；API Server接收到信息后，将信息更新到etcd中。 Controller Manager 在启动时，如果设置了--cluster-cidr 参数，对于没有设置Sepc.PodCIDR的Node节点生成一个CIDR地址，并用该CIDR地址设置节点的Spec.PodCIDR属性，防止不同的节点的CIDR地址发生冲突。 2.4.1 Node EvictionNode 控制器在节点异常后，会按照默认的速率（--node-eviction-rate=0.1，即每10秒一个节点的速率）进行 Node 的驱逐。Node 控制器按照 Zone 将节点划分为不同的组，再跟进 Zone 的状态进行速率调整： Normal：所有节点都 Ready，默认速率驱逐。 PartialDisruption：即超过33% 的节点 NotReady 的状态。当异常节点比例大于--unhealthy-zone-threshold=0.55时开始减慢速率： 小集群（即节点数量小于 --large-cluster-size-threshold=50）：停止驱逐 大集群，减慢速率为 --secondary-node-eviction-rate=0.01 FullDisruption：所有节点都 NotReady，返回使用默认速率驱逐。但当所有 Zone 都处在 FullDisruption 时，停止驱逐。 2.5 ResourceQuota Controller资源配额管理，确保指定的资源对象在任何适合都不会超量占用系统物理资源。 支持三个级别的资源配置管理： 容器级别：对CPU和Memory进行限制 Pod级别：对一个Pod内所有容器的可用资源进行限制 Namespace级别： Pod数量 RS 数量 SVC 数量 ResourceQuota 数量 Secret 数量 可持有的PV（Persistent Volume）数量 说明： 配额管理通过 Admission Control (准入控制) 来管理 Admission Control 提供两针配额约束方式 LimitRanger：作用于Pod和Container ResourceQuota：作用于Namespace，限定一个Namespace中的各种资源的使用总额 ResourceQuota Controller流程图： 2.6 Namespace Controller用户通过API Server创建新的Namespace并保存在etcd中，Namespace Controller定时通过API Server 读取这些Namespace信息。 如果Namespace被API标记为优雅删除(即设置删除期限，DeletionTimestamp)，则将该Namespace状态设置为”Terminating”，并保存到etcd中，同时Namespace Controller删除该Namespace下的ServiceAccount, RS, Pod等资源对象。 2.7 Endpoint ControllerService, Endpoint, Pod的关系： Endpoints 表示一个Service对应的所有Pod副本的访问地址，而Endpoints Controller负责生成和维护所有Endpoints对象的控制器，它负责监听Service和对应的Pod副本变化： Service被删除，则删除和该Service同名的Endpoints对象 Service被创建或修改，则根据该Service信息获得相关的Pod列表，然后创建或更新Service对应的Endpoints对象 Pod事件，则更它对应的Service的Endpoints对象 kube-proxy 进程获取每个Service的Endpoints，实现Service的负载均衡功能 2.8 Service ControllerService Controller 属于kubernetes集群与外部云平台之间的一个接口控制器。它监听Service变化，如果一个LoadBalancer类型的Service，则确保外部的云平台上对该Service对应的Load Balancer实例相应地创建、删除及更新路由转发表。 3. SchedulerScheduler负责Pod调度，在整个系统中起“承上启下”作用 承上：负责接收Controller Manager 创建的新的Pod，并为其选择合适的Node 启下：Node上的kubelet接管Pod的生命周期 Scheduler 集群分发调度器: 1) 通过调度算法，选择合适的Node，将待调度的Pod在该Node上创建，并将信息写入etcd中 2) kubelet 通过API Server监听到 Scheduler 产生的Pod绑定信息，然后获取对应的Pod清单，下载image，并启动容器 3.1 调度流程 预选调度过程：即遍历所有目标Node，筛选出符合要求的候选节点。k8s 内置了多种预选策略(Predicates) 供用户选择 确定最优节点：采用优选策略（Priority）计算出每个候选节点的积分，取最高分 调度流程通过插件式加载的调度算法提供者(Algorithm Provider) 具体实现，一个调度算法提供者就是包括一组预选策略与一组优选策略的结构体。 3.2 预选策略1234567891011121314151617181920CheckNodeCondition：检查节点是否正常（如ip，磁盘等）GeneralPredicates HostName：检查Pod对象是否定义了pod.spec.hostname PodFitsHostPorts：pod要能适配node的端口 pods.spec.containers.ports.hostPort（指定绑定在节点的端口上） MatchNodeSelector：检查节点的NodeSelector的标签 pods.spec.nodeSelector PodFitsResources：检查Pod的资源需求是否能被节点所满足NoDiskConflict: 检查Pod依赖的存储卷是否能满足需求（默认未使用）PodToleratesNodeTaints：检查Pod上的spec.tolerations可容忍的污点是否完全包含节点上的污点PodToleratesNodeNoExecuteTaints：不能执行（NoExecute）的污点（默认未使用）CheckNodeLabelPresence：检查指定的标签再上节点是否存在CheckServiceAffinity：将相同services相同的pod尽量放在一起（默认未使用）MaxEBSVolumeCount： 检查EBS（AWS存储）存储卷的最大数量MaxGCEPDVolumeCount GCE存储最大数MaxAzureDiskVolumeCount: AzureDisk 存储最大数CheckVolumeBinding：检查节点上已绑定或未绑定的pvcNoVolumeZoneConflict：检查存储卷对象与pod是否存在冲突CheckNodeMemoryPressure：检查节点内存是否存在压力过大CheckNodePIDPressure：检查节点上的PID数量是否过大CheckNodeDiskPressure： 检查内存、磁盘IO是否过大MatchInterPodAffinity: 检查节点是否能满足pod的亲和性或反亲和性 3.3 优选策略12345678910111213LeastRequested： 空闲量越高得分越高(cpu((capacity-sum(requested))*10/capacity)+memory((capacity-sum(requested))*10/capacity))/2BalancedResourceAllocation：CPU和内存资源被占用率相近的胜出NodePreferAvoidPods: 节点注解信息“scheduler.alpha.kubernetes.io/preferAvoidPods”TaintToleration：将Pod对象的spec.tolerations列表项与节点的taints列表项进行匹配度检查，匹配条目越，得分越低SeletorSpreading：标签选择器分散度，（与当前pod对象通选的标签，所选其它pod越多的得分越低）InterPodAffinity：遍历pod对象的亲和性匹配项目，项目越多得分越高NodeAffinity：节点亲和性 、MostRequested：空闲量越小得分越高，和LeastRequested相反 （默认未启用）NodeLabel：节点是否存在对应的标签 （默认未启用）ImageLocality：根据满足当前Pod对象需求的已有镜像的体积大小之和（默认未启用） 3.4 高级调度3.4.1 nodeSelector123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 1. 创建 redis 集群cat &gt; redis-deploy.yml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: redisspec: selector: matchLabels: app: redis replicas: 2 template: metadata: labels: app: redis spec: containers: - name: redis image: redis:6.2.3 resources: requests: cpu: 100m memory: 100Mi ports: - containerPort: 6379 nodeSelector: disk: ssd # 限定磁盘类型EOFkubetcl apply -f redis-deploy.yml# 检查pod状态kubectl get podNAME READY STATUS RESTARTS AGEredis-9fc84569-2jlxh 0/1 Pending 0 60sredis-9fc84569-q78jd 0/1 Pending 0 60skubectl describe pod redis-9fc84569-2jlxhEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 20s (x3 over 76s) default-scheduler 0/4 nodes are available: 4 node(s) didn&#x27;t match node selector.# k8s-node2 增加标签 disk=ssd kubectl label node k8s-node2 disk=ssd kubectl get nodes --show-labels | grep disk=ssdk8s-node2 Ready node 4d21h v1.19.11 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disk=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node2,kubernetes.io/os=linux,node-role.kubernetes.io/node=# 再次检查 pod 是否创建成功kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESredis-9fc84569-2jlxh 1/1 Running 0 5m20s 10.244.1.8 k8s-node2 &lt;none&gt; &lt;none&gt;redis-9fc84569-q78jd 1/1 Running 0 5m20s 10.244.1.7 k8s-node2 &lt;none&gt; &lt;none&gt; 3.4.2 亲和性 (affinity)1. 软亲和preferredDuringSchedulingIgnoredDuringExecution软亲和：选择条件匹配多的，就算都不满足条件，还是会生成pod 123456789101112131415161718192021222324252627282930313233cat &gt; preferred-affinity-pod.yml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: preferred-affinity-pod labels: app: my-podspec: containers: - name: preferred-affinity-pod image: nginx ports: - name: http containerPort: 80 affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: apps # 标签键名 operator: In values: - mysql # apps=mysql - redis # apps=redis weight: 60 # 匹配相应nodeSelectorTerm相关联的权重,1-100EOFkubectl apply -f preferred-affinity-pod.yml# 不满足依旧创建成功kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpreferred-affinity-pod 1/1 Running 0 61s 10.244.2.18 k8s-node1 &lt;none&gt; &lt;none&gt; 2. 硬亲和requiredDuringSchedulingIgnoredDuringExecution 硬亲和：选择条件匹配多的，必须满足一项，才会生成pod 12345678910111213141516171819202122232425262728293031323334353637383940cat &gt; required-affinity-pod.yml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: required-affinity-pod labels: app: my-podspec: containers: - name: required-affinity-pod image: nginx ports: - name: http containerPort: 80 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: apps # 标签键名 operator: In values: - mysql # apps=mysql - redis # apps=redis EOFkubectl apply -f required-affinity-pod.yml# 不满足无法创建成功kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESrequired-affinity-pod 0/1 Pending 0 18s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;# 修改 k8s-node1 的标签kubectl label node k8s-node1 apps=mysql # 创建成功kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESrequired-affinity-pod 1/1 Running 0 2m31s 10.244.2.19 k8s-node1 &lt;none&gt; &lt;none&gt; 3.4.3 反亲和性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849cat &gt; anti-affinity.yml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: myapp1 labels: app: myapp1 spec: containers: - name: myapp1 image: nginx ports: - name: http containerPort: 80---apiVersion: v1kind: Podmetadata: name: myapp2 labels: app: myapp2 spec: containers: - name: myapp2 image: nginx ports: - name: http containerPort: 80 affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - myapp1 # app=myapp1 topologyKey: kubernetes.io/hostname #kubernetes.io/hostname的值一样代表pod不处于同一位置 EOFkubectl apply -f anti-affinity.yml# 分属不同的节点上kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyapp1 1/1 Running 0 43s 10.244.2.20 k8s-node1 &lt;none&gt; &lt;none&gt;myapp2 1/1 Running 0 43s 10.244.1.9 k8s-node2 &lt;none&gt; &lt;none&gt; 3.5 污点和容忍taint的effect定义对Pod排斥效果： NoSchedule：只影响调度过程，对现存的Pod对象不产生影响，即不驱离 NoExecute：既影响调度过程，也影响现在的Pod对象，即现存的Pod对象将被驱离 PreferNoSchedule： 最好不部署Pod，但如果实在找不到节点，也可以在此节点上部署 3.5.1 污点管理1234567891011121314kubectl describe node k8s-master1 | grep TaintsTaints: node-role.kubernetes.io/master:NoSchedulekubectl describe node k8s-node1 | grep TaintsTaints: &lt;none&gt;# 打污点kubectl taint node k8s-node1 node-role.kubernetes.io/node=:NoSchedulekubectl describe node k8s-node1 | grep TaintsTaints: node-role.kubernetes.io/node:NoSchedule# 去除污点kubectl taint node k8s-node1 node-role.kubernetes.io/node- 3.5.2 容忍123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 节点全部加上node-type污点kubectl taint node k8s-node1 node-type=:NoSchedulekubectl taint node k8s-node2 node-type=:NoSchedulecat &gt; toleration-pod.yml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: toleration-pod labels: app: toleration-pod spec: containers: - name: toleration-pod image: nginx ports: - name: http containerPort: 80 tolerations: - key: &quot;node-type&quot; # 污点名称 operator: &quot;Equal&quot; # Exists/Equal value: &quot;PreferNoSchedule&quot; # 污点值 effect: &quot;NoSchedule&quot; # #tolerationSeconds: 3600 # 如果被驱逐的话，容忍时间 effect和tolerationSeconds不能同时存在EOFkubectl apply -f toleration-pod.yml# 无法正常创建kubectl get podNAME READY STATUS RESTARTS AGEtoleration-pod 0/1 Pending 0 5skubectl describe pod toleration-podEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 26s (x2 over 26s) default-scheduler 0/4 nodes are available: 1 node(s) had taint &#123;node-role.kubernetes.io/master: &#125;, that the pod didn&#x27;t tolerate, 3 node(s) had taint &#123;node-type: &#125;, that the pod didn&#x27;t tolerate.# k8s-node1 污点增加 PreferNoSchedule，并删除NoSchedulekubectl taint node k8s-node1 node-type=:PreferNoSchedulekubectl taint node k8s-node1 node-type=:NoSchedule- # 调度成功kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStoleration-pod 1/1 Running 0 11m 10.244.2.21 k8s-node1 &lt;none&gt; &lt;none&gt; 4. Kubelet每个Node节点上都运行一个 Kubelet 服务进程，默认监听 10250 端口，接收并执行 Master 发来的指令，管理 Pod 及 Pod 中的容器。每个 Kubelet 进程会在 API Server 上注册所在Node节点的信息，定期向 Master 节点汇报该节点的资源使用情况，并通过 cAdvisor 监控节点和容器的资源。可以把kubelet理解成【Server-Agent】架构中的agent，是Node上的Pod管家。 4.1 节点管理节点管理主要是节点自注册和节点状态更新： 通过启动参数“-register-node” 来确定是否向API Server注册自己 没有选择自注册模式，则需要用户自己配置Node资源信息，同时配置API Server的地址 启动时，通过API Server注册节点信息，并定时向API Server发送节点新消息，API Server在接收到新消息后，将信息写入 etcd 主要参数： --kubeconfig: 指定kubeconfig的路径，该文件常用来指定证书 --hostname-override: 配置该节点在集群中显示的主机名 --node-status-update-frequency: kubelet向API Server上报心跳的频率，默认10s 4.2 Pod 管理4.2.1 获取 Pod 清单 kubelet 通过 API Server Client 使用Watch加List的方式，监听 “/registry/csinodes” 和 “/registry/pods” 目录，将获取到的信息同步到本地缓存中 1234567891011121314151617181920212223242526272829etcdctl get /registry/csinodes --prefix --keys-only/registry/csinodes/k8s-master1/registry/csinodes/k8s-master2/registry/csinodes/k8s-node1/registry/csinodes/k8s-node2# 节点详细信息etcdctl get /registry/csinodes/k8s-master1/registry/csinodes/k8s-master1k8sstorage.k8s.io/v1CSINode⚌⚌k8s-master1&quot;*$cc45d1d2-dde9-4740-ac49-878a971ef0852⚌⚌⚌j=Node k8s-master1&quot;$5e851f78-5bfc-4acb-b5c3-4a10cf353237*v1z⚌⚌kubeletUpdatestorage.k8s.io/v⚌⚌⚌FieldsV1:⚌⚌&#123;&quot;f:metadata&quot;:&#123;&quot;f:ownerReferences&quot;:&#123;&quot;.&quot;:&#123;&#125;,&quot;k:&#123;\\&quot;uid\\&quot;:\\&quot;5e851f78-5bfc-4acb-b5c3-4a10cf353237\\&quot;&#125;&quot;:&#123;&quot;.&quot;:&#123;&#125;,&quot;f:apiVersion&quot;:&#123;&#125;,&quot;f:kind&quot;:&#123;&#125;,&quot;f:name&quot;:&#123;&#125;,&quot;f:uid&quot;:&#123;&#125;&#125;&#125;&#125;&#125;&quot;# pods信息etcdctl get /registry/pods --prefix --keys-only/registry/pods/kube-system/coredns-867bfd96bd-264bb/registry/pods/kube-system/kube-flannel-ds-48kz2/registry/pods/kube-system/kube-flannel-ds-bsfpp/registry/pods/kube-system/kube-flannel-ds-h5shb/registry/pods/kube-system/kube-flannel-ds-qpvlt/registry/pods/kubernetes-dashboard/dashboard-metrics-scraper-79c5968bdc-62hlk/registry/pods/kubernetes-dashboard/kubernetes-dashboard-9f9799597-b8hfr 所有针对 Pod 的操作都将会被 kubelet 监听到，kubelet会根据监听到的指令，创建、修改或删除本节点的Pod。 4.2.2 Pod 创建流程 kubelet 读取监听到的信息，如果是创建或修改 Pod，则执行如下处理： 为Pod创建一个数据目录 从API Server读取该 Pod 清单 为该 Pod 挂载外部卷 下载 Pod 用到的 Secret 检查节点上是否已运行Pod，如果 Pod 没有容器或 Pause容器 没有启动，则先停止 Pod 里的所有容器进程。如果在Pod中有需要删除的容器，则删除这些容器 用 “kubernetes/pause” 镜像为每个Pod创建一个容器。Pause容器用于接管 Pod 中所有其他容器的网络。没创建一个新的Pod，kubelet 都会先创建一个 Pause容器，然后再创建其他容器。 Pod 中每个容器的处理： 为容器计算一个hash值，然后用容器名字去docker查询对应容器的hash值。若查找到容器，但两者hash值不同，则停止docker中的容器进程，并停止与之管理的Pause容器；若两者相同，则不做任何处理 如果容器被终止了，且容器未指定 restartPolicy，则不做任何处理 调用 Docker Client 下载容器镜像，然后运行容器 4.2.3 容器状态检查Pod 通过两类探针检查容器的监控状态： LivenessProbe: 生存检查。如果检查到容器不健康，则删除该容器，并根据容器的重启策略做响应处理。 ReadinessProbe: 就绪检查。如果检查的容器未就绪，将删除关联 Service 的 Endpoints 中关联条目。 LivenessProbe 的三种实现方式： ExecAction：容器中执行命令，如果命令退出状态码是0，则表示容器健康 TCPSocketAction: 通过容器的 IP:PORT 执行 TCP 检查，如果端口能够被访问，则表示容器健康 HTTPGetAction：通过容器的 http://IP:PORT/path 调用HTTP GET方法，如果响应状态码表示成功(2xx, 3xx)，则认为容器健康 4.2.4 Static Pod所有以非 API Server 方式创建的 Pod 都叫 Static Pod。Kubelet 将 Static Pod 的状态汇报给 API Server，API Server 为该 Static Pod 创建一个 Mirror Pod 和其相匹配。Mirror Pod 的状态将真实反映 Static Pod 的状态。当 Static Pod 被删除时，与之相对应的 Mirror Pod 也会被删除。 4.3 cAdvisor 资源监控资源监控级别：容器，Pod，Service，整个集群 Heapster: 为k8s提供了一个级别的监控平台，它是集群级别的监控和事件数据集成器(Aggregator)。它以Pod方式运行在集群中，并通过 kubelet 发现所有运行在集群中的节点，查看来自这些节点的资源使用情况。kubelet 通过 cAdvisor 获取其所在节点即容器的数据。Heapster通过带着关联标签的 Pod 分组信息，它们被推送到一个可配置的后端，用于存储和可视化展示。 cAdvisor: 一个开源的分析容器资源使用率和性能特征的代理工具，集成到 kubelet，当 kubelet 启动时会同时启动 cAdvisor，且一个cAdvidsor 只监控一个Node节点的信息。cAdvisor 自动查找所有在其节点上的容器，自动采集 CPU、内存、文件系统和网络使用的统计信息。cAdvisor 通过它所在节点的 Root 容器，采集并分析该节点的全面使用情况。 cAdvisor 通过其所在节点的 4149 端口暴露一个简单的 UI。 4.4 工作原理 kubelet 内部组件： kubelet API：认证API (10250)，cAdvisor API (4194)，只读 API (10255)，健康检查API (10248) syncLoop: 从 API 或者 manifest 目录接收 Pod 跟新，发送到 podWorkers 处理，大量使用 channel 来处理异步请求 辅助的 Manager: cAdvisor, PLEG, Volume Manager等，处理 syncLoop 以外的工作 CRI：容器执行引擎接口，负责与 container runtime shim 通信 容器执行引擎：dockershim, rkt等 网络插件：CNI， kubenet 4.5 Kubelet Evictionkubelet 会健康资源的使用情况，并通过驱逐机制防止计算和存储资源耗尽。在驱逐时，Pod中的容器全部停止，并将 PodPhase 设置为 Failed 定期 (housekeeping-interval) 检查系统的资源是否达到了预先配置的驱逐阈值： Eviction Signal Condition Description memory.available MemoryPressue memory.available := node.status.capacity[memory] - node.stats.memory.workingSet nodefs.available DiskPressure nodefs.available := node.stats.fs.available（Kubelet Volume以及日志等） nodefs.inodesFree DiskPressure nodefs.inodesFree := node.stats.fs.inodesFree imagefs.available DiskPressure imagefs.available := node.stats.runtime.imagefs.available（镜像以及容器可写层等） imagefs.inodesFree DiskPressure imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree 驱逐阈值可以使用百分比，也可以使用绝对值: 123--eviction-hard=memory.available&lt;500Mi,nodefs.available&lt;1Gi,imagefs.available&lt;100Gi--eviction-minimum-reclaim=&quot;memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi&quot;`--system-reserved=memory=1.5Gi 驱逐信号分类： 软驱逐 (Soft Eviction): 配合驱逐宽限期 (eviction-soft-grace-period 和 eviction-max-pod-grace-period) 一起使用。系统资源达到软驱逐阈值且超过宽限期之后才会执行驱逐动作 硬驱逐 (Hard Eviction): 系统资源达到硬驱逐阈值时理解执行驱逐动作 驱逐动作： 回收节点资源 配置了 imagefs 阈值 达到 nodefs 阈值：删除已停止的 Pod 达到 imagefs 阈值：删除未使用的镜像 未配置 imagefs 阈值 达到 nodefs 阈值：先删除已停止的 Pod，后删除未使用的镜像，顺序清理 驱逐用户 Pod 驱逐顺序：BestEffort, Burstable, Guaranteed 配置了 imagefs 阈值 达到 nodefs 阈值：基于nodefs用量驱逐 (local volume + logs) 达到 imagefs 阈值：基于imagefs用量驱逐 (容器可写层) 未配置 imagefs 阈值 达到 nodefs 阈值：安装总磁盘使用驱逐 (local volume + logs + 容器可写层) 其他容器和镜像垃圾回收选项： 垃圾回收参数 驱逐参数 解释 --image-gc-high-threshold --eviction-hard 或 --eviction-soft 现存的驱逐回收信号可以触发镜像垃圾回收 --image-gc-low-threshold --eviction-minimum-reclaim 驱逐回收实现相同行为 --minimum-image-ttl-duration 由于驱逐不包括TTL配置，所以它还会继续支持 --maximum-dead-containers 一旦旧日志存储在容器上下文之外，就会被弃用 --maximum-dead-containers-per-container 一旦旧日志存储在容器上下文之外，就会被弃用 --minimum-container-ttl-duration 一旦旧日志存储在容器上下文之外，就会被弃用 --low-diskspace-threshold-mb --eviction-hard or eviction-soft 驱逐回收将磁盘阈值泛化到其他资源 --outofdisk-transition-frequency --eviction-pressure-transition-period 驱逐回收将磁盘压力转换到其他资源 4.6 容器运行时容器运行时 (Container Runtime)，负责真正管理镜像和容器的生命周期。kubelet 通过容器运行时接口 (Container Runtime Interface, CRI) 与容器运行时交互，以管理镜像和容器。 CRI 容器引擎： Docker：dockershim OCI (Open Container Initiative) 开放容器标准 Containerd CRI-O runc, OCI 标准容器引擎 PouchContainer：阿里巴巴开源的胖容器引擎 4.7 Node 汇总指标 集群内部：curl http://k8s-master1:10255/stats/summary 集群外部：（暂未成功） 12kubectl proxy &amp;curl http://localhost:8001/api/v1/proxy/csinodes/k8s-master1:10255/stats/summary 5. Kube-proxy5.1 简介kube-proxy 监听 API server 中 service 和 endpoint 的变化情况，并通过 userspace、iptables、ipvs 或 winuserspace 等 proxier 来为服务配置负载均衡（仅支持 TCP &amp; UDP） kube-proxy 可以直接运行在物理机上，也可以以 static pod 或者daemonset的方式运行 kube-proxy 的实现： userspace： 早期方案，它在用户空间监听一个端口，所有服务通过 iptables 转发到这个端口，然后再其内部负载均衡器到实际的Pod。该方式最主要的问题时效率低，有明显的性能瓶颈。 iptables: 推荐方案，完全以iptables规则的方式来实现 service 负载均衡。该方式的最主要问题是创建了太多的 iptables 规则，非增量式更新会引入一定的时延，大规模情况下有明显的性能问题 ipvs: 解决了 iptables 的性能问题，采用增量式更新，可以保证 service 更新期间连接保持不断开 123456789101112# ipvs 模式需要加载内核模块modprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4# to check loaded modules, uselsmod | grep -e ip_vs -e nf_conntrack_ipv4# orcut -f1 -d &quot; &quot; /proc/modules | grep -e ip_vs -e nf_conntrack_ipv4 5.2 Iptables 示例 5.3 ipvs 示例 5.4 kube-proxy 的不足只支持 TCP 和 UDP，不支持 HTTP 路由，也没有健康检查机制。这些可以通过自定义 Ingress Controller 的方法来解决。 6. Kube-DNS6.1 kube-dns6.1.1 工作原理 kube-dns 由三个容器构成： kube-dns: 核心组件 KubeDNS：负责监听 Service 和 Endpoint 的变化情况，并将相关信息更新到 Sky DNS 中 SkyDNS: 负责 DNS 解析，监听在 10053 端口，同时也监听在 10055 端口提供 metrics 服务 kube-dns 还监听在 8081 端口，提供健康检查使用 dnsmasq-nanny: 负责启动 dnsmasq，配置发生变化时，重启 dnsmasq dnsmasq 的 upstream 为 SkyDNS，即集群内部的 DNS 解析由 SkyDNS 负责 sidecar: 负责健康检查和 提供 DNS metrics （10054端口） 6.1.2 使用 kube-dns123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235cat &gt; kube-dns.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: kube-dns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: &quot;true&quot; addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: &quot;KubeDNS&quot;spec: selector: k8s-app: kube-dns clusterIP: 10.0.0.2 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP---apiVersion: v1kind: ServiceAccountmetadata: name: kube-dns namespace: kube-system labels: kubernetes.io/cluster-service: &quot;true&quot; addonmanager.kubernetes.io/mode: Reconcile---apiVersion: v1kind: ConfigMapmetadata: name: kube-dns namespace: kube-system labels: addonmanager.kubernetes.io/mode: EnsureExists---apiVersion: apps/v1kind: Deploymentmetadata: name: kube-dns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: &quot;true&quot; addonmanager.kubernetes.io/mode: Reconcilespec: # replicas: not specified here: # 1. In order to make Addon Manager do not reconcile this replicas parameter. # 2. Default is 1. # 3. Will be tuned in real time if DNS horizontal auto-scaling is turned on. strategy: rollingUpdate: maxSurge: 10% maxUnavailable: 0 selector: matchLabels: k8s-app: kube-dns template: metadata: labels: k8s-app: kube-dns annotations: prometheus.io/port: &quot;10054&quot; prometheus.io/scrape: &quot;true&quot; spec: priorityClassName: system-cluster-critical securityContext: seccompProfile: type: RuntimeDefault supplementalGroups: [ 65534 ] fsGroup: 65534 affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: k8s-app operator: In values: [&quot;kube-dns&quot;] topologyKey: kubernetes.io/hostname tolerations: - key: &quot;CriticalAddonsOnly&quot; operator: &quot;Exists&quot; volumes: - name: kube-dns-config configMap: name: kube-dns optional: true nodeSelector: kubernetes.io/os: linux containers: - name: kubedns image: k8s.gcr.io/dns/k8s-dns-kube-dns:1.17.3 resources: # TODO: Set memory limits when we&#x27;ve profiled the container for large # clusters, then set request = limit to keep this container in # guaranteed class. Currently, this container falls into the # &quot;burstable&quot; category so the kubelet doesn&#x27;t backoff from restarting it. limits: memory: 170Mi requests: cpu: 100m memory: 70Mi livenessProbe: httpGet: path: /healthcheck/kubedns port: 10054 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: httpGet: path: /readiness port: 8081 scheme: HTTP # we poll on pod startup for the Kubernetes master service and # only setup the /readiness HTTP server once that&#x27;s available. initialDelaySeconds: 3 timeoutSeconds: 5 args: - --domain=cluster.local. - --dns-port=10053 - --config-dir=/kube-dns-config - --v=2 env: - name: PROMETHEUS_PORT value: &quot;10055&quot; ports: - containerPort: 10053 name: dns-local protocol: UDP - containerPort: 10053 name: dns-tcp-local protocol: TCP - containerPort: 10055 name: metrics protocol: TCP volumeMounts: - name: kube-dns-config mountPath: /kube-dns-config securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 1001 - name: dnsmasq image: k8s.gcr.io/dns/k8s-dns-dnsmasq-nanny:1.17.3 livenessProbe: httpGet: path: /healthcheck/dnsmasq port: 10054 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 args: - -v=2 - -logtostderr - -configDir=/etc/k8s/dns/dnsmasq-nanny - -restartDnsmasq=true - -- - -k - --cache-size=1000 - --no-negcache - --dns-loop-detect - --log-facility=- - --server=/cluster.local/127.0.0.1#10053 - --server=/in-addr.arpa/127.0.0.1#10053 - --server=/ip6.arpa/127.0.0.1#10053 ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP # see: https://github.com/kubernetes/kubernetes/issues/29055 for details resources: requests: cpu: 150m memory: 20Mi volumeMounts: - name: kube-dns-config mountPath: /etc/k8s/dns/dnsmasq-nanny securityContext: capabilities: drop: - all add: - NET_BIND_SERVICE - SETGID - name: sidecar image: k8s.gcr.io/dns/k8s-dns-sidecar:1.17.3 livenessProbe: httpGet: path: /metrics port: 10054 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 args: - --v=2 - --logtostderr - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV ports: - containerPort: 10054 name: metrics protocol: TCP resources: requests: memory: 20Mi cpu: 10m securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 1001 dnsPolicy: Default # Don&#x27;t use cluster DNS. serviceAccountName: kube-dnsEOFkubectl apply -f kube-dns.yamlkubectl get pod -n kube-system 6.1.3 相关问题1. 问题定位1234567891011121314151617# 发现问题kubectl describe pod kube-dns-594c5b5cb5-mdxp6 -n kube-system... Normal Pulled 13m kubelet Container image &quot;k8s.gcr.io/dns/k8s-dns-kube-dns:1.17.3&quot; already present on machine Warning Unhealthy 12m (x2 over 13m) kubelet Liveness probe failed: HTTP probe failed with statuscode: 503 Warning Unhealthy 9m32s (x25 over 13m) kubelet Readiness probe failed: Get &quot;http://10.244.2.28:8081/readiness&quot;: dial tcp 10.244.2.28:8081: connect: connection refused Warning BackOff 4m30s (x19 over 10m) kubelet Back-off restarting failed container# 查看容器日志kubectl logs kube-dns-594c5b5cb5-mdxp6 kubedns -n kube-system...I0520 05:59:53.947378 1 server.go:195] Skydns metrics enabled (/metrics:10055)I0520 05:59:53.947996 1 log.go:172] skydns: ready for queries on cluster.local. for tcp://0.0.0.0:10053 [rcache 0]I0520 05:59:53.948005 1 log.go:172] skydns: ready for queries on cluster.local. for udp://0.0.0.0:10053 [rcache 0]E0520 05:59:53.957842 1 reflector.go:125] pkg/mod/k8s.io/client-go@v0.0.0-20190620085101-78d2af792bab/tools/cache/reflector.go:98: Failed to list *v1.Service: services is forbidden: User &quot;system:serviceaccount:kube-system:kube-dns&quot; cannot list resource &quot;services&quot; in API group &quot;&quot; at the cluster scope: RBAC: clusterrole.rbac.authorization.k8s.io &quot;system:kube-dns&quot; not foundE0520 05:59:53.957894 1 reflector.go:125] pkg/mod/k8s.io/client-go@v0.0.0-20190620085101-78d2af792bab/tools/cache/reflector.go:98: Failed to list *v1.Endpoints: endpoints is forbidden: User &quot;system:serviceaccount:kube-system:kube-dns&quot; cannot list resource &quot;endpoints&quot; in API group &quot;&quot; at the cluster scope: RBAC: clusterrole.rbac.authorization.k8s.io &quot;system:kube-dns&quot; not foundI0520 05:59:54.447988 1 dns.go:220] Waiting for [endpoints services] to be initialized from apiserver... 问题根因：rbac “system:kube-dns” 未找到，导致无法访问apiserver 2. 解决办法1234567891011121314151617181920212223242526272829303132333435363738394041# 创建 rbaccat &gt; kube-dns-rbac.yaml &lt;&lt;EOFapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-dnsrules: - apiGroups: - &quot;&quot; resources: - endpoints - services verbs: - get - list - watch---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-dnsroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-dnssubjects:- kind: ServiceAccount name: kube-dns namespace: kube-systemEOFkubectl apply -f kube-dns-rbac.yamlkubectl describe clusterrole system:kube-dnskubectl describe clusterrolebinding system:kube-dns 3. 验证成功123456789101112131415161718192021kubectl apply -f kube-dns.yamlkubectl apply -f kube-dns.yamlkubectl get pod -n kube-system -o wide | grep kube-dnskube-dns-594c5b5cb5-6wttp 3/3 Running 0 13m 10.244.2.29 k8s-node1 &lt;none&gt; &lt;none&gt;kubectl describe pod kube-dns-594c5b5cb5-mdxp6 -n kube-system...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 48s default-scheduler Successfully assigned kube-system/kube-dns-594c5b5cb5-6wttp to k8s-node1 Normal Pulled 47s kubelet Container image &quot;k8s.gcr.io/dns/k8s-dns-kube-dns:1.17.3&quot; already present on machine Normal Created 47s kubelet Created container kubedns Normal Started 47s kubelet Started container kubedns Normal Pulled 47s kubelet Container image &quot;k8s.gcr.io/dns/k8s-dns-dnsmasq-nanny:1.17.3&quot; already present on machine Normal Created 47s kubelet Created container dnsmasq Normal Started 47s kubelet Started container dnsmasq Normal Pulled 47s kubelet Container image &quot;k8s.gcr.io/dns/k8s-dns-sidecar:1.17.3&quot; already present on machine Normal Created 47s kubelet Created container sidecar Normal Started 47s kubelet Started container sidecar 6.2 CoreDNSkube-dns 的升级版。CoreDNS 的效率更高，资源占用更小 6.2.1 安装 coredns1234567891011wget https://github.com/coredns/deployment/archive/refs/tags/coredns-1.14.0.tar.gztar zxvf coredns-1.14.0.tar.gzcd deployment-coredns-1.14.0/kubernetes# 部署./deploy.sh | kubectl apply -f -kubectl delete --namespace=kube-system deployment kube-dns# 卸载./rollback.sh | kubectl apply -f -kubectl delete --namespace=kube-system deployment coredns 6.2.2 支持的 DNS 格式 Service A record：$&#123;my-svc&#125;.$&#123;my-namespace&#125;.svc.cluster.local，解析分两种情况 普通 Service 解析为 Cluster IP Headless Service 解析为指定的 Pod IP 列表 SRV record: _$&#123;my-port-name&#125;._$&#123;my-port-protocol&#125;$&#123;my-svc&#125;.$&#123;my-namespace&#125;.svc.cluster.local Pod A record: $&#123;pod-ip-address&#125;.$&#123;my-namespace&#125;.pod.cluster.local 指定 hostname 和 subdomain: $&#123;hostname&#125;.$&#123;custom-subdomain&#125;.default.svc.cluster.local 示例： 1234567891011121314151617181920212223242526272829303132333435cat &gt; dns-test.yaml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: nginx labels: name: nginxspec: hostname: nginx subdomain: default-subdomain containers: - name: nginx image: nginx ports: - name: http containerPort: 80 ---apiVersion: v1kind: Podmetadata: name: dnsutils labels: name: dnsutilsspec: containers: - image: tutum/dnsutils command: - sleep - &quot;7200&quot; name: dnsutilsEOFkubectl apply -f nginx-pod.yamlkubectl exec -it dnsutils /bin/sh 6.3 私有和上游 DNS 服务器12345678910apiVersion: v1kind: ConfigMapmetadata: name: kube-dns namespace: kube-systemdata: stubDomains: | &#123;“acme.local”: [“1.2.3.4”]&#125; upstreamNameservers: | [“8.8.8.8”, “8.8.4.4”] 查询请求首先会被发送到 kube-dns 的 DNS 缓存层 (Dnsmasq 服务器)。Dnsmasq 服务器会先检查请求的后缀，带有集群后缀（例如：”.cluster.local”）的请求会被发往 kube-dns，拥有存根域后缀的名称（例如：”.acme.local”）将会被发送到配置的私有 DNS 服务器 [“1.2.3.4”]。最后，不满足任何这些后缀的请求将会被发送到上游 DNS [“8.8.8.8”, “8.8.4.4”] 里。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://elihe2011.github.io/categories/kubernetes/"}],"tags":[]},{"title":"Kubernetes 集群二进制安装","slug":"Kubernetes 集群二进制安装","date":"2021-06-20T02:46:12.000Z","updated":"2021-10-09T11:02:01.741Z","comments":true,"path":"2021/06/20/Kubernetes 集群二进制安装/","link":"","permalink":"https://elihe2011.github.io/2021/06/20/Kubernetes%20%E9%9B%86%E7%BE%A4%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/","excerpt":"1. 环境准备1.1 安装规划 角色 IP 组件 k8s-master1 192.168.80.45 etcd, api-server, controller-manager, scheduler, docker k8s-node01 192.168.80.46 etcd, kubelet, kube-proxy, docker k8s-node02 192.168.80.47 etcd, kubelet, kube-proxy, docker 软件版本： 软件 版本 备注 OS Ubuntu 16.04.6 LTS Kubernetes 1.21.4 Etcd v3.5.0 Docker 19.03.9","text":"1. 环境准备1.1 安装规划 角色 IP 组件 k8s-master1 192.168.80.45 etcd, api-server, controller-manager, scheduler, docker k8s-node01 192.168.80.46 etcd, kubelet, kube-proxy, docker k8s-node02 192.168.80.47 etcd, kubelet, kube-proxy, docker 软件版本： 软件 版本 备注 OS Ubuntu 16.04.6 LTS Kubernetes 1.21.4 Etcd v3.5.0 Docker 19.03.9 1.2 系统设置12345678910111213141516171819202122232425262728# 1. 修改主机名hostnamectl set-hostname k8s-masterhostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02# 2. 主机名解析cat &gt;&gt; /etc/hosts &lt;&lt;EOF192.168.80.45 k8s-master192.168.80.46 k8s-node01192.168.80.47 k8s-node02EOF# 3. 禁用 swapswapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab# 4. 将桥接的IPv4流量传递到iptables的链 cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOFsysctl --system # 5. 时间同步 apt install ntpdate -y ntpdate ntp1.aliyun.comcrontab -e*/30 * * * * /usr/sbin/ntpdate-u ntp1.aliyun.com &gt;&gt; /var/log/ntpdate.log 2&gt;&amp;1 2. 安装 docker123456789101112131415161718192021222324252627282930313233343536373839mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-install# 1. 下载安装包wget https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgztar zxvf docker-19.03.9.tgzmv docker/* /usr/bindocker version# 2. 开机启动配置cat &gt; /lib/systemd/system/docker.service &lt;&lt; EOF[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.targetWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP \\$MAINPIDLimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityTimeoutStartSec=0Delegate=yesKillMode=processRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.targetEOF# 3. 启动systemctl daemon-reloadsystemctl start dockersystemctl status dockersystemctl enable docker 3. TLS 证书3.1 证书工具12345678910mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-installwget https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl_1.5.0_linux_amd64wget https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssljson_1.5.0_linux_amd64wget https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl-certinfo_1.5.0_linux_amd64mv cfssl_1.5.0_linux_amd64 /usr/local/bin/cfsslmv cfssljson_1.5.0_linux_amd64 /usr/local/bin/cfssljsonmv cfssl-certinfo_1.5.0_linux_amd64 /usr/bin/cfssl-certinfochmod /usr/local/bin/cfssl* 3.2 证书归类生成的 CA 证书和秘钥文件如下： 组件 证书 密钥 备注 etcd ca.pem、etcd.pem etcd-key.pem apiserver ca.pem、apiserver.pem apiserver-key.pem controller-manager ca.pem、kube-controller-manager.pem ca-key.pem、kube-controller-manager-key.pem kubeconfig scheduler ca.pem、kube-scheduler.pem kube-scheduler-key.pem kubeconfig kubelet ca.pem kubeconfig+token kube-proxy ca.pem、kube-proxy.pem kube-proxy-key.pem kubeconfig kubectl ca.pem、admin.pem admin-key.pem 3.3 CA 证书CA: Certificate Authority 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152mkdir -p /root/ssl &amp;&amp; cd /root/ssl# 1. CA 配置文件cat &gt; ca-config.json &lt;&lt;EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;kubernetes&quot;: &#123; &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ], &quot;expiry&quot;: &quot;87600h&quot; &#125; &#125; &#125;&#125;EOF# 2. CA 证书签名请求文件cat &gt; ca-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ], &quot;ca&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;&#125;EOF# 3. 生成CA证书和密钥cfssl gencert -initca ca-csr.json | cfssljson -bare cals ca*ca-config.json ca.csr ca-csr.json ca-key.pem ca.pem 3.4 etcd 证书注意：hosts 中的IP地址，分别指定了 etcd 集群的主机 IP 1234567891011121314151617181920212223242526272829# 1. 证书签名请求文件cat &gt; etcd-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;127.0.0.1&quot;, &quot;localhost&quot;, &quot;192.168.80.45&quot;, &quot;192.168.80.46&quot;, &quot;192.168.80.47&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;etcd&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes etcd-csr.json | cfssljson -bare etcd 3.5 kube-apiserver 证书注意：hosts 中的IP地址，分别指定了 kubernetes master 集群的主机 IP 和 kubernetes 服务的服务 IP（一般是 kube-apiserver 指定的 service-cluster-ip-range 网段的第一个IP，如 10.96.0.1） 12345678910111213141516171819202122232425262728293031323334353637# 1. 证书签名请求文件cat &gt; kube-apiserver-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;127.0.0.1&quot;, &quot;localhost&quot;, &quot;192.168.80.1&quot;, &quot;192.168.80.2&quot;, &quot;192.168.80.45&quot;, &quot;192.168.80.46&quot;, &quot;192.168.80.47&quot;, &quot;10.96.0.1&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver 3.6 kube-controller-manager 证书1234567891011121314151617181920212223# 1. 证书签名请求文件cat &gt; kube-controller-manager-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;system:kube-controller-manager&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;system:masters&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager 3.8 kube-scheduler 证书1234567891011121314151617181920212223# 1. 证书签名请求文件cat &gt; kube-scheduler-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;system:kube-scheduler&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;system:masters&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler 3.9 admin 证书 后续 kube-apiserver 使用 RBAC 对客户端(如 kubelet、kube-proxy、Pod)请求进行授权； kube-apiserver 预定义了一些 RBAC 使用的 RoleBindings，如 cluster-admin 将 Group system:masters 与 Role cluster-admin 绑定，该 Role 授予了调用kube-apiserver 的所有 API的权限； O 指定该证书的 Group 为 system:masters，kubelet 使用该证书访问 kube-apiserver 时 ，由于证书被 CA 签名，所以认证通过，同时由于证书用户组为经过预授权的 system:masters，所以被授予访问所有 API 的权限； 1234567891011121314151617181920212223242526# 1. 证书签名请求文件cat &gt; admin-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;admin&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;system:masters&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书 cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare adminls admin*admin.csr admin-csr.json admin-key.pem admin.pem 搭建完 kubernetes 集群后，可以通过命令: kubectl get clusterrolebinding cluster-admin -o yaml ,查看到 clusterrolebinding cluster-admin 的 subjects 的 kind 是 Group，name 是 system:masters。 roleRef 对象是 ClusterRole cluster-admin。 即 system:masters Group 的 user 或者 serviceAccount 都拥有 cluster-admin 的角色。 因此在使用 kubectl 命令时候，才拥有整个集群的管理权限。 123456789101112131415161718192021kubectl get clusterrolebinding cluster-admin -o yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot; creationTimestamp: 2017-04-11T11:20:42Z labels: kubernetes.io/bootstrapping: rbac-defaults name: cluster-admin resourceVersion: &quot;52&quot; selfLink: /apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin uid: e61b97b2-1ea8-11e7-8cd7-f4e9d49f8ed0roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- apiGroup: rbac.authorization.k8s.io kind: Group name: system:masters 3.10 kube-proxy 证书 CN 指定该证书的 User 为 system:kube-proxy； kube-apiserver 预定义的 RoleBinding system:node-proxier 将User system:kube-proxy 与 Role system:node-proxier 绑定，该 Role 授予了调用 kube-apiserver Proxy 相关 API 的权限； 1234567891011121314151617181920212223# 1. 证书签名请求文件cat &gt; kube-proxy-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;system:kube-proxy&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 3.11 证书信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657cfssl-certinfo -cert apiserver.pem&#123; &quot;subject&quot;: &#123; &quot;common_name&quot;: &quot;kubernetes&quot;, &quot;country&quot;: &quot;CN&quot;, &quot;organization&quot;: &quot;k8s&quot;, &quot;organizational_unit&quot;: &quot;System&quot;, &quot;locality&quot;: &quot;BeiJing&quot;, &quot;province&quot;: &quot;BeiJing&quot;, &quot;names&quot;: [ &quot;CN&quot;, &quot;BeiJing&quot;, &quot;BeiJing&quot;, &quot;k8s&quot;, &quot;System&quot;, &quot;kubernetes&quot; ] &#125;, &quot;issuer&quot;: &#123; &quot;common_name&quot;: &quot;kubernetes&quot;, &quot;country&quot;: &quot;CN&quot;, &quot;organization&quot;: &quot;k8s&quot;, &quot;organizational_unit&quot;: &quot;System&quot;, &quot;locality&quot;: &quot;BeiJing&quot;, &quot;province&quot;: &quot;BeiJing&quot;, &quot;names&quot;: [ &quot;CN&quot;, &quot;BeiJing&quot;, &quot;BeiJing&quot;, &quot;k8s&quot;, &quot;System&quot;, &quot;kubernetes&quot; ] &#125;, &quot;serial_number&quot;: &quot;275867496157961939649344217740970264800633176866&quot;, &quot;sans&quot;: [ &quot;localhost&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot;, &quot;127.0.0.1&quot;, &quot;192.168.80.1&quot;, &quot;192.168.80.2&quot;, &quot;192.168.80.45&quot;, &quot;192.168.80.46&quot;, &quot;192.168.80.47&quot;, &quot;10.96.0.1&quot; ], &quot;not_before&quot;: &quot;2021-06-09T05:20:00Z&quot;, &quot;not_after&quot;: &quot;2031-06-07T05:20:00Z&quot;, &quot;sigalg&quot;: &quot;SHA256WithRSA&quot;, &quot;authority_key_id&quot;: &quot;&quot;, &quot;subject_key_id&quot;: &quot;E3:84:0F:9C:00:07:4A:8F:5C:B2:35:45:A0:50:4D:3E:9D:C0:B4:D0&quot;, &quot;pem&quot;: &quot;-----BEGIN CERTIFICATE-----\\nMIIEezCCA2OgAwIBAgIUMFJTjEXe9sDDDpPXcAiUBt5+QyIwDQYJKoZIhvcNAQEL\\nBQAwZTELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0Jl\\naUppbmcxDDAKBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMwEQYDVQQDEwpr\\ndWJlcm5ldGVzMB4XDTIxMDYwOTA1MjAwMFoXDTMxMDYwNzA1MjAwMFowZTELMAkG\\nA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0JlaUppbmcxDDAK\\nBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMwEQYDVQQDEwprdWJlcm5ldGVz\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAw0BpjZQNEd6Oqu8ubEWG\\nhbdwJecOTCfdbY+VLIKEm0Tys8ZBlu7OrtZ8Rj5OAZTXil0ZJz+hvHo8YTNJJ16g\\njHV88VSpfoXD5DE59PITSFwfY1lWHVctC3Ddo9CM9cU9Ty+Kf29XcrLbc/VNGZTB\\ncvKXoM3b6NkBKOdKphVjUvafhKC6ls2ac5uub3uqZTpPgBs/1PvINKNZkP5U6lUV\\noTBMAT+qbQ9aggA+bA+WegL3jHU78ngo1XMnsb1HfAjwKDOf66smNJ/K+YjD+Cul\\ngjpyqOQKGlz5xqXUcBgIMO9djI4f5hvaMsSje1aSJ/oh5AfQbxQsGjajlS80ED08\\nxwIDAQABo4IBITCCAR0wDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUF\\nBwMBBggrBgEFBQcDAjAMBgNVHRMBAf8EAjAAMB0GA1UdDgQWBBTjhA+cAAdKj1yy\\nNUWgUE0+ncC00DCBvgYDVR0RBIG2MIGzgglsb2NhbGhvc3SCCmt1YmVybmV0ZXOC\\nEmt1YmVybmV0ZXMuZGVmYXVsdIIWa3ViZXJuZXRlcy5kZWZhdWx0LnN2Y4Iea3Vi\\nZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVygiRrdWJlcm5ldGVzLmRlZmF1bHQu\\nc3ZjLmNsdXN0ZXIubG9jYWyHBH8AAAGHBMCoUAGHBMCoUAKHBMCoUC2HBMCoUC6H\\nBMCoUC+HBAr+AAEwDQYJKoZIhvcNAQELBQADggEBAG+RUKp4cxz4EOqmAPiczkl2\\nHciAg01RbCavoLoUWmoDDAQf7PIhQF2pLewFCwR5w6SwvCJAVdg+eHdefJ2MBtJr\\nKQgbmEOBXd4Z5ZqBeSP6ViHvb1pKtRSldznZLfxjsVd0bN3na/JmS4TZ90SqLLtL\\nN4CgGfTs2AfrtbtWIqewDMS9aWjBK8VePzLBmsdLddD4WYQOnl+QjdrX9bbqYRCG\\nQo3CKvJ3JZqh6AJHcgKsm0702uMU/TCJwe1M8I8SpYrwA74uCBy3O9jXed1rZlrp\\nRVURB6Ro7SMLjiadTJyf6AbLPMmZcPKHhZ1XG07q8Od2Kd+KVx1PxF3et6OOteE=\\n-----END CERTIFICATE-----\\n&quot;&#125; 3.12 分发证书12mkdir -p /etc/kubernetes/pkicp *.pem /etc/kubernetes/pki 4. 安装 etcd (多节点)4.1 节点 etcd-1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-install# 1. 下载并安装wget https://github.com/etcd-io/etcd/releases/download/v3.5.0/etcd-v3.5.0-linux-amd64.tar.gztar zxvf etcd-v3.5.0-linux-amd64.tar.gzmv etcd-v3.5.0-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin/# 2. 配置文件mkdir -p /etc/etcdcat &gt; /etc/etcd/etcd.conf.yml &lt;&lt; EOF# This is the configuration file for the etcd server.# Human-readable name for this member.name: &#x27;etcd-1&#x27;# Path to the data directory.data-dir: /var/lib/etcd/default.etcd# Path to the dedicated wal directory.wal-dir:# Number of committed transactions to trigger a snapshot to disk.snapshot-count: 10000# Time (in milliseconds) of a heartbeat interval.heartbeat-interval: 100# Time (in milliseconds) for an election to timeout.election-timeout: 1000# Raise alarms when backend size exceeds the given quota. 0 means use the# default quota.quota-backend-bytes: 0# List of comma separated URLs to listen on for peer traffic.listen-peer-urls: &#x27;https://localhost:2380,https://192.168.80.45:2380&#x27;# List of comma separated URLs to listen on for client traffic.listen-client-urls: &#x27;https://localhost:2379,https://192.168.80.45:2379&#x27;# Maximum number of snapshot files to retain (0 is unlimited).max-snapshots: 5# Maximum number of wal files to retain (0 is unlimited).max-wals: 5# Comma-separated white list of origins for CORS (cross-origin resource sharing).cors:# List of this member&#x27;s peer URLs to advertise to the rest of the cluster.# The URLs needed to be a comma-separated list.initial-advertise-peer-urls: &#x27;https://localhost:2380,https://192.168.80.45:2380&#x27;# List of this member&#x27;s client URLs to advertise to the public.# The URLs needed to be a comma-separated list.advertise-client-urls: &#x27;https://localhost:2379,https://192.168.80.45:2379&#x27;# Discovery URL used to bootstrap the cluster.discovery:# Valid values include &#x27;exit&#x27;, &#x27;proxy&#x27;discovery-fallback: &#x27;proxy&#x27;# HTTP proxy to use for traffic to discovery service.discovery-proxy:# DNS domain used to bootstrap initial cluster.discovery-srv:# Initial cluster configuration for bootstrapping.initial-cluster: &#x27;etcd-1=https://192.168.80.45:2380,etcd-2=https://192.168.80.46:2380,etcd-3=https://192.168.80.47:2380&#x27;# Initial cluster token for the etcd cluster during bootstrap.initial-cluster-token: &#x27;etcd-cluster&#x27;# Initial cluster state (&#x27;new&#x27; or &#x27;existing&#x27;).initial-cluster-state: &#x27;new&#x27;# Reject reconfiguration requests that would cause quorum loss.strict-reconfig-check: false# Accept etcd V2 client requestsenable-v2: true# Enable runtime profiling data via HTTP serverenable-pprof: true# Valid values include &#x27;on&#x27;, &#x27;readonly&#x27;, &#x27;off&#x27;proxy: &#x27;off&#x27;# Time (in milliseconds) an endpoint will be held in a failed state.proxy-failure-wait: 5000# Time (in milliseconds) of the endpoints refresh interval.proxy-refresh-interval: 30000# Time (in milliseconds) for a dial to timeout.proxy-dial-timeout: 1000# Time (in milliseconds) for a write to timeout.proxy-write-timeout: 5000# Time (in milliseconds) for a read to timeout.proxy-read-timeout: 0client-transport-security: # Path to the client server TLS cert file. cert-file: /etc/kubernetes/pki/etcd.pem # Path to the client server TLS key file. key-file: /etc/kubernetes/pki/etcd-key.pem # Enable client cert authentication. client-cert-auth: true # Path to the client server TLS trusted CA cert file. trusted-ca-file: /etc/kubernetes/pki/ca.pem # Client TLS using generated certificates auto-tls: truepeer-transport-security: # Path to the peer server TLS cert file. cert-file: /etc/kubernetes/pki/etcd.pem # Path to the peer server TLS key file. key-file: /etc/kubernetes/pki/etcd-key.pem # Enable peer client cert authentication. client-cert-auth: true # Path to the peer server TLS trusted CA cert file. trusted-ca-file: /etc/kubernetes/pki/ca.pem # Peer TLS using generated certificates. auto-tls: true# Enable debug-level logging for etcd.log-level: debuglogger: zap# Specify &#x27;stdout&#x27; or &#x27;stderr&#x27; to skip journald logging even when running under systemd.log-outputs: [stderr]# Force to create a new one member cluster.force-new-cluster: falseauto-compaction-mode: periodicauto-compaction-retention: &quot;1&quot;EOF# 3. 开机启动cat &gt; /lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network-online.targetWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/etcd --config-file=/etc/etcd/etcd.conf.ymlRestart=on-failureRestartSec=5LimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 4.2 其他节点123456# 1. 解压克隆文件sudo -icd / &amp;&amp; mv /home/ubuntu/etcd-clone.tar / &amp;&amp; tar xvf etcd-clone.tar &amp;&amp; rm -f etcd-clone.tar# 2. 修改配置文件, 改成各自对应的IP和名称vi /etc/etcd/etcd.conf.yml 4.3 启动12345678910111213141516171819202122232425# 1. 开机启动systemctl daemon-reloadsystemctl start etcdsystemctl status etcdsystemctl enable etcd# 2. 运行状态etcdctl member list --cacert=/etc/kubernetes/pki/ca.pem --cert=/etc/kubernetes/pki/etcd.pem --key=/etc/kubernetes/pki/etcd-key.pem --write-out=table+------------------+---------+--------+----------------------------+----------------------------+------------+| ID | STATUS | NAME | PEER ADDRS | CLIENT ADDRS | IS LEARNER |+------------------+---------+--------+----------------------------+----------------------------+------------+| 46bc5ad35e418584 | started | etcd-1 | https://192.168.80.45:2380 | https://192.168.80.45:2379 | false || 8f347c1327049bc8 | started | etcd-3 | https://192.168.80.47:2380 | https://192.168.80.47:2379 | false || b01e7a29099f3eb8 | started | etcd-2 | https://192.168.80.46:2380 | https://192.168.80.46:2379 | false |+------------------+---------+--------+----------------------------+----------------------------+------------+# 3. 健康状态etcdctl endpoint health --cacert=/etc/kubernetes/pki/ca.pem --cert=/etc/kubernetes/pki/etcd.pem --key=/etc/kubernetes/pki/etcd-key.pem --cluster --write-out=table+----------------------------+--------+-------------+-------+| ENDPOINT | HEALTH | TOOK | ERROR |+----------------------------+--------+-------------+-------+| https://192.168.80.47:2379 | true | 20.973639ms | || https://192.168.80.46:2379 | true | 29.842299ms | || https://192.168.80.45:2379 | true | 30.564766ms | |+----------------------------+--------+-------------+-------+ 4. 安装 etcd (单节点)4.1 节点 etcd-1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-install# 1. 下载并安装wget https://github.com/etcd-io/etcd/releases/download/v3.5.0/etcd-v3.5.0-linux-amd64.tar.gztar zxvf etcd-v3.5.0-linux-amd64.tar.gzmv etcd-v3.5.0-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin/# 2. 配置文件mkdir -p /etc/etcdcat &gt; /etc/etcd/etcd.conf.yml &lt;&lt; EOFname: &#x27;etcd-1&#x27;data-dir: /var/lib/etcd/default.etcdwal-dir:snapshot-count: 10000heartbeat-interval: 100election-timeout: 1000quota-backend-bytes: 0listen-peer-urls: &#x27;https://localhost:2380,https://192.168.80.45:2380&#x27;listen-client-urls: &#x27;https://localhost:2379,https://192.168.80.45:2379&#x27;max-snapshots: 5max-wals: 5cors:initial-advertise-peer-urls: &#x27;https://localhost:2380,https://192.168.80.45:2380&#x27;advertise-client-urls: &#x27;https://localhost:2379,https://192.168.80.45:2379&#x27;discovery:discovery-fallback: &#x27;proxy&#x27;discovery-proxy:discovery-srv:strict-reconfig-check: falseenable-v2: trueenable-pprof: trueproxy: &#x27;off&#x27;proxy-failure-wait: 5000proxy-refresh-interval: 30000proxy-dial-timeout: 1000proxy-write-timeout: 5000proxy-read-timeout: 0client-transport-security: cert-file: /etc/kubernetes/pki/etcd.pem key-file: /etc/kubernetes/pki/etcd-key.pem client-cert-auth: true trusted-ca-file: /etc/kubernetes/pki/ca.pem auto-tls: truepeer-transport-security: cert-file: /etc/kubernetes/pki/etcd.pem key-file: /etc/kubernetes/pki/etcd-key.pem client-cert-auth: true trusted-ca-file: /etc/kubernetes/pki/ca.pem auto-tls: truelog-level: debuglogger: zaplog-outputs: [stderr]force-new-cluster: falseauto-compaction-mode: periodicauto-compaction-retention: &quot;1&quot;EOF# 3. 开机启动cat &gt; /lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network-online.targetWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/etcd --config-file=/etc/etcd/etcd.conf.ymlRestart=on-failureRestartSec=5LimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF# 4. 启动systemctl daemon-reloadsystemctl start etcdsystemctl status etcdsystemctl enable etcd# 5. 运行状态etcdctl member list --cacert=/etc/kubernetes/pki/ca.pem --cert=/etc/kubernetes/pki/etcd.pem --key=/etc/kubernetes/pki/etcd-key.pem --write-out=table# 6. 健康状态etcdctl endpoint health --cacert=/etc/kubernetes/pki/ca.pem --cert=/etc/kubernetes/pki/etcd.pem --key=/etc/kubernetes/pki/etcd-key.pem --cluster --write-out=table 5. Master 节点kubernetes master 节点组件： kube-apiserver kube-scheduler kube-controller-manager kubelet （非必须，但必要） kube-proxy（非必须，但必要） 5.1 安装准备https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.21.md 123456mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-installwget https://dl.k8s.io/v1.21.4/kubernetes-server-linux-amd64.tar.gztar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kube-apiserver kube-scheduler kube-controller-manager kubectl kubelet kube-proxy /usr/bin 5.2 apiserver5.2.1 TLS Bootstrapping Token启用 TLS Bootstrapping 机制： TLS Bootstraping：Master apiserver启用TLS认证后，Node节点kubelet和kube-proxy要与kube-apiserver进行通信，必须使用CA签发的有效证书才可以，当Node节点很多时，这种客户端证书颁发需要大量工作，同样也会增加集群扩展复杂度。为了简化流程，Kubernetes引入了TLS bootstraping机制来自动颁发客户端证书，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。所以强烈建议在Node上使用这种方式，目前主要用于kubelet，kube-proxy还是由我们统一颁发一个证书。 TLS bootstraping 工作流程： 123456BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d &#x27; &#x27;)# 格式：token，用户名，UID，用户组cat &gt; /etc/kubernetes/token.csv &lt;&lt;EOF$&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,&quot;system:node-bootstrapper&quot;EOF 5.2.2 开机启动--service-cluster-ip-range=10.96.0.0/16: Service IP 段 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152KUBE_APISERVER_OPTS=&quot;--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\ --anonymous-auth=false \\ --bind-address=192.168.80.45 \\ --secure-port=6443 \\ --advertise-address=192.168.80.45 \\ --authorization-mode=Node,RBAC \\ --runtime-config=api/all=true \\ --enable-bootstrap-token-auth \\ --service-cluster-ip-range=10.96.0.0/16 \\ --token-auth-file=/etc/kubernetes/token.csv \\ --service-node-port-range=30000-50000 \\ --tls-cert-file=/etc/kubernetes/pki/kube-apiserver.pem \\ --tls-private-key-file=/etc/kubernetes/pki/kube-apiserver-key.pem \\ --client-ca-file=/etc/kubernetes/pki/ca.pem \\ --kubelet-client-certificate=/etc/kubernetes/pki/kube-apiserver.pem \\ --kubelet-client-key=/etc/kubernetes/pki/kube-apiserver-key.pem \\ --service-account-key-file=/etc/kubernetes/pki/ca-key.pem \\ --service-account-signing-key-file=/etc/kubernetes/pki/ca-key.pem \\ --service-account-issuer=https://kubernetes.default.svc.cluster.local \\ --etcd-cafile=/etc/kubernetes/pki/ca.pem \\ --etcd-certfile=/etc/kubernetes/pki/etcd.pem \\ --etcd-keyfile=/etc/kubernetes/pki/etcd-key.pem \\ --etcd-servers=https://192.168.80.45:2379 \\ --allow-privileged=true \\ --audit-log-maxage=30 \\ --audit-log-maxbackup=3 \\ --audit-log-maxsize=100 \\ --audit-log-path=/var/log/kubernetes/kube-apiserver-audit.log \\ --event-ttl=1h \\ --alsologtostderr=true \\ --logtostderr=false \\ --log-dir=/var/log/kubernetes \\ --v=2&quot;cat &gt; /lib/systemd/system/kube-apiserver.service &lt;&lt; EOF[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]ExecStart=/usr/bin/kube-apiserver $KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF# 2. 启动systemctl daemon-reloadsystemctl start kube-apiserver systemctl status kube-apiserver systemctl enable kube-apiserver 5.2.3 kubectl 管理集群1234567891011121314151617181920mkdir -p /root/.kubeKUBE_CONFIG=/root/.kube/configKUBE_APISERVER=&quot;https://192.168.80.45:6443&quot;kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/pki/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-credentials cluster-admin \\ --client-certificate=/etc/kubernetes/pki/admin.pem \\ --client-key=/etc/kubernetes/pki/admin-key.pem \\ --embed-certs=true \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-context default \\ --cluster=kubernetes \\ --user=cluster-admin \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config use-context default --kubeconfig=$&#123;KUBE_CONFIG&#125; 5.2.4 授权 kubelet-bootstrap 用户允许请求证书防止错误：failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User &quot;kubelet-bootstrap&quot; cannot create resource &quot;certificatesigningrequests&quot; in API group &quot;certificates.k8s.io&quot; at the cluster scope 123kubectl create clusterrolebinding kubelet-bootstrap \\--clusterrole=system:node-bootstrapper \\--user=kubelet-bootstrap 5.2.5 授权 apiserver 访问 kubelet12345678910111213141516171819202122232425262728293031323334353637383940mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-installcat &gt; apiserver-to-kubelet-rbac.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubeletrules: - apiGroups: - &quot;&quot; resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics - pods/log verbs: - &quot;*&quot;---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: system:kube-apiserver namespace: &quot;&quot;roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubeletsubjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetesEOFkubectl apply -f apiserver-to-kubelet-rbac.yaml 5.3 controller-manager5.3.1 kubeconfig123456789101112131415161718KUBE_CONFIG=&quot;/etc/kubernetes/kube-controller-manager.kubeconfig&quot;KUBE_APISERVER=&quot;https://192.168.80.45:6443&quot;kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/pki/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-credentials kube-controller-manager \\ --client-certificate=/etc/kubernetes/pki/kube-controller-manager.pem \\ --client-key=/etc/kubernetes/pki/kube-controller-manager-key.pem \\ --embed-certs=true \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-controller-manager \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config use-context default --kubeconfig=$&#123;KUBE_CONFIG&#125; 5.3.2 开机启动--cluster-cidr=10.244.0.0/16: Pod IP 段 --service-cluster-ip-range=10.96.0.0/16: Service IP 段 123456789101112131415161718192021222324252627282930313233KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/var/log/kubernetes \\--leader-elect=true \\--kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\--bind-address=127.0.0.1 \\--allocate-node-cidrs=true \\--cluster-cidr=10.244.0.0/16 \\--service-cluster-ip-range=10.96.0.0/16 \\--cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \\--cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \\--root-ca-file=/etc/kubernetes/pki/ca.pem \\--service-account-private-key-file=/etc/kubernetes/pki/ca-key.pem \\--cluster-signing-duration=87600h0m0s&quot;cat &gt; /lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]ExecStart=/usr/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl start kube-controller-managersystemctl status kube-controller-managersystemctl enable kube-controller-manager 5.4 scheduler5.4.1 kubeconfig123456789101112131415161718KUBE_CONFIG=&quot;/etc/kubernetes/kube-scheduler.kubeconfig&quot;KUBE_APISERVER=&quot;https://192.168.80.45:6443&quot;kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/pki/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-credentials kube-scheduler \\ --client-certificate=/etc/kubernetes/pki/kube-scheduler.pem \\ --client-key=/etc/kubernetes/pki/kube-scheduler-key.pem \\ --embed-certs=true \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-scheduler \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config use-context default --kubeconfig=$&#123;KUBE_CONFIG&#125; 5.4.2 开机启动12345678910111213141516171819202122232425KUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/var/log/kubernetes \\--leader-elect \\--kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\--bind-address=127.0.0.1&quot;cat &gt; /lib/systemd/system/kube-scheduler.service &lt;&lt; EOF[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]ExecStart=/usr/bin/kube-scheduler $KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl start kube-schedulersystemctl status kube-schedulersystemctl enable kube-scheduler 5.5 kubelet5.5.1 参数配置1234567891011121314151617181920212223242526272829303132cat &gt; /etc/kubernetes/kubelet-config.yml &lt;&lt; EOFkind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 0.0.0.0port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS:- 10.96.0.2clusterDomain: cluster.local failSwapOn: falseauthentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.pem authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30sevictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5%maxOpenFiles: 1000000maxPods: 110EOF 5.5.2 kubeconfig12345678910111213141516171819BOOTSTRAP_TOKEN=$(cat /etc/kubernetes/token.csv | awk -F, &#x27;&#123;print $1&#125;&#x27;)KUBE_CONFIG=&quot;/etc/kubernetes/bootstrap.kubeconfig&quot;KUBE_APISERVER=&quot;https://192.168.80.45:6443&quot; # 生成 kubelet bootstrap kubeconfig 配置文件kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/pki/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-credentials &quot;kubelet-bootstrap&quot; \\ --token=$&#123;BOOTSTRAP_TOKEN&#125; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-context default \\ --cluster=kubernetes \\ --user=&quot;kubelet-bootstrap&quot; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config use-context default --kubeconfig=$&#123;KUBE_CONFIG&#125; 5.5.3 开机启动其中：--kubeconfig=/etc/kubernetes/kubelet.kubeconfig 在加入集群时自动生成 1234567891011121314151617181920212223242526272829KUBELET_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/var/log/kubernetes \\--hostname-override=k8s-master1 \\--network-plugin=cni \\--kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\--config=/etc/kubernetes/kubelet-config.yml \\--cert-dir=/etc/kubernetes/pki \\--pod-infra-container-image=mirrorgooglecontainers/pause-amd64:3.1&quot;cat &gt; /lib/systemd/system/kubelet.service &lt;&lt; EOF[Unit]Description=Kubernetes KubeletAfter=docker.service[Service]ExecStart=/usr/bin/kubelet $KUBELET_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl start kubeletsystemctl status kubeletsystemctl enable kubelet 5.5.4 加入集群1234567891011121314151617# 查看kubelet证书请求kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONnode-csr-ghWG-AWFM9sxJbr5A-BIq9puVIRxfFHrQlwDjYbHba8 25s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending# 批准申请kubectl certificate approve node-csr-ghWG-AWFM9sxJbr5A-BIq9puVIRxfFHrQlwDjYbHba8# 再次查看证书kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONnode-csr-ghWG-AWFM9sxJbr5A-BIq9puVIRxfFHrQlwDjYbHba8 53m kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Approved,Issued# 查看节点（由于网络插件还没有部署，节点会没有准备就绪 NotReady）kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master1 NotReady &lt;none&gt; 4m8s v1.21.4 5.6 kube-proxy5.6.1 参数配置clusterCIDR: 10.96.0.0/16: Service IP 段，与apiserver &amp; controller-manager 的--service-cluster-ip-range 一致 12345678910cat &gt; /etc/kubernetes/kube-proxy-config.yml &lt;&lt; EOFkind: KubeProxyConfigurationapiVersion: kubeproxy.config.k8s.io/v1alpha1bindAddress: 0.0.0.0metricsBindAddress: 0.0.0.0:10249clientConnection: kubeconfig: /etc/kubernetes/kube-proxy.kubeconfighostnameOverride: k8s-master1clusterCIDR: 10.96.0.0/16EOF 5.6.2 kubeconfig 文件123456789101112131415161718KUBE_CONFIG=&quot;/etc/kubernetes/kube-proxy.kubeconfig&quot;KUBE_APISERVER=&quot;https://192.168.80.45:6443&quot;kubectl config set-cluster kubernetes \\ --certificate-authority=/etc/kubernetes/pki/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-credentials kube-proxy \\ --client-certificate=/etc/kubernetes/pki/kube-proxy.pem \\ --client-key=/etc/kubernetes/pki/kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=$&#123;KUBE_CONFIG&#125;kubectl config use-context default --kubeconfig=$&#123;KUBE_CONFIG&#125; 5.6.3 开机启动123456789101112131415161718192021222324KUBE_PROXY_OPTS=&quot;--logtostderr=false \\--v=2 \\--proxy-mode=iptables \\--log-dir=/var/log/kubernetes \\--config=/etc/kubernetes/kube-proxy-config.yml&quot;cat &gt; /lib/systemd/system/kube-proxy.service &lt;&lt; EOF[Unit]Description=Kubernetes ProxyAfter=network.target[Service]ExecStart=/usr/bin/kube-proxy $KUBE_PROXY_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl start kube-proxysystemctl status kube-proxysystemctl enable kube-proxy 5.7 集群管理5.7.1 集群配置信息123456789101112131415161718192021kubectl config viewapiVersion: v1clusters:- cluster: certificate-authority-data: DATA+OMITTED server: https://192.168.80.45:6443 name: kubernetescontexts:- context: cluster: kubernetes user: cluster-admin name: defaultcurrent-context: defaultkind: Configpreferences: &#123;&#125;users:- name: cluster-admin user: client-certificate-data: REDACTED client-key-data: REDACTED 5.7.2 集群状态12345678kubectl get csWarning: v1 ComponentStatus is deprecated in v1.19+NAME STATUS MESSAGE ERRORscheduler Healthy okcontroller-manager Healthy oketcd-1 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;etcd-2 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 5.8 命令补全1234apt install -y bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc 6. 网络插件其中涉及的IP段，要与 kube-controller-manager中 “–cluster-cidr” 一致 6.1 CNI Plugins所有节点都要操作 12345mkdir -p $HOME/k8s-install/network &amp;&amp; cd $_wget https://github.com/containernetworking/plugins/releases/download/v0.9.1/cni-plugins-linux-amd64-v0.9.1.tgzmkdir -p /opt/cni/bintar zxvf cni-plugins-linux-amd64-v0.9.1.tgz -C /opt/cni/bin 6.2 calicoCalico是一个纯三层的数据中心网络方案，是目前Kubernetes主流的网络方案。 123456789101112131415161718192021222324252627282930mkdir -p $HOME/k8s-install/network &amp;&amp; cd $HOME/k8s-install/network# 1. 下载插件wget https://docs.projectcalico.org/manifests/calico.yaml# CIDR的值，与 kube-controller-manager中“--cluster-cidr=10.244.0.0/16” 一致vi calico.yaml 3680 # The default IPv4 pool to create on startup if none exists. Pod IPs will be 3681 # chosen from this range. Changing this value after installation will have 3682 # no effect. This should fall within `--cluster-cidr`. 3683 - name: CALICO_IPV4POOL_CIDR 3684 value: &quot;10.244.0.0/16&quot;# 2. 安装网络插件kubectl apply -f calico.yaml# 3. 检查是否启动kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEcalico-kube-controllers-7f4f5bf95d-tgklk 1/1 Running 0 2m7scalico-node-fwv5x 1/1 Running 0 2m8scalico-node-ttt2c 1/1 Running 0 2m8scalico-node-xjvjf 1/1 Running 0 2m8s# 4. 节点状态正常kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 65m v1.21.4k8s-node01 Ready node 20m v1.21.4k8s-node02 Ready node 20m v1.21.4 6.3 flannel12345678910111213141516171819mkdir -p $HOME/k8s-install/network &amp;&amp; cd $HOME/k8s-install/networkwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.ymlvi kube-flannel.yml &quot;Network&quot;: &quot;10.244.0.0/16&quot;,kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkube-flannel-ds-8qnnx 1/1 Running 0 10skube-flannel-ds-979lc 1/1 Running 0 16mkube-flannel-ds-kgmgg 1/1 Running 0 16mkubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 85m v1.21.4k8s-node01 Ready node 40m v1.21.4k8s-node02 Ready node 40m v1.21.4 6.4 ovs-cni6.4.1 安装 open-vswitch1apt install openvswitch-switch 6.4.2 安装 multusmultus创建的crd资源network-attachment-definitions来定义ovs配置 123wget https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/images/multus-daemonset.ymlkubectl apply -f multus-daemonset.yml 6.4.3 安装 ovs-cni123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106wget https://github.com/k8snetworkplumbingwg/ovs-cni/blob/main/manifests/ovs-cni.yml.in# 参照配置cat &gt; ovs-cni.yml &lt;&lt;EOFapiVersion: apps/v1kind: DaemonSetmetadata: name: ovs-cni-amd64 namespace: kube-system labels: tier: node app: ovs-cnispec: selector: matchLabels: app: ovs-cni template: metadata: labels: tier: node app: ovs-cni annotations: description: OVS CNI allows users to attach their Pods/VMs to Open vSwitch bridges available on nodes spec: serviceAccountName: ovs-cni-marker hostNetwork: true nodeSelector: beta.kubernetes.io/arch: amd64 tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule initContainers: - name: ovs-cni-plugin image: quay.io/kubevirt/ovs-cni-plugin:latest command: [&#x27;cp&#x27;, &#x27;/ovs&#x27;, &#x27;/host/opt/cni/bin/ovs&#x27;] imagePullPolicy: IfNotPresent securityContext: privileged: true volumeMounts: - name: cnibin mountPath: /host/opt/cni/bin containers: - name: ovs-cni-marker image: quay.io/kubevirt/ovs-cni-marker:latest imagePullPolicy: IfNotPresent securityContext: privileged: true args: - -node-name - $(NODE_NAME) - -ovs-socket - /host/var/run/openvswitch/db.sock volumeMounts: - name: ovs-var-run mountPath: /host/var/run/openvswitch env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName volumes: - name: cnibin hostPath: path: /opt/cni/bin - name: ovs-var-run hostPath: path: /var/run/openvswitch---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: ovs-cni-marker-crrules:- apiGroups: - &quot;&quot; resources: - nodes - nodes/status verbs: - get - update - patch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: ovs-cni-marker-crbroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: ovs-cni-marker-crsubjects:- kind: ServiceAccount name: ovs-cni-marker namespace: kube-system---apiVersion: v1kind: ServiceAccountmetadata: name: ovs-cni-marker namespace: kube-systemEOF# 2. 安装 ovs-cnikubectl apply -f ovs-cni.yaml 6.4.4 网桥123456789101112# 1. 创建网桥ovs-vsctl add-br br1ovs-vsctl show# 2. 查看node是否使用了网桥kubectl describe node k8s-master...Capacity: ovs-cni.network.kubevirt.io/br1: 1k # 默认写死 1k...Allocatable: ovs-cni.network.kubevirt.io/br1: 1k # 默认写死 1k 6.4.5 网络扩展1234567891011121314151617181920cat &gt; ovs-ipam-net.yml &lt;&lt;EOFapiVersion: &quot;k8s.cni.cncf.io/v1&quot;kind: NetworkAttachmentDefinitionmetadata: name: ovs-ipam-net annotations: k8s.v1.cni.cncf.io/resourceName: ovs-cni.network.kubevirt.io/br1spec: config: &#x27;&#123; &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;type&quot;: &quot;ovs&quot;, &quot;bridge&quot;: &quot;br1&quot;, &quot;vlan&quot;: 100, &quot;ipam&quot;: &#123; &quot;type&quot;: &quot;static&quot; &#125; &#125;&#x27;EOFkubectl apply -f ovs-ipam-net.yml 6.4.6 验证1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 1. 创建podcat &gt; ovs-test.yml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: samplepod-1 annotations: k8s.v1.cni.cncf.io/networks: &#x27;[ &#123; &quot;name&quot;: &quot;ovs-ipam-net&quot;, &quot;ips&quot;: [&quot;10.10.10.1/24&quot;] &#125;]&#x27;spec: containers: - name: pod-1 command: [&quot;sleep&quot;, &quot;99999&quot;] image: alpine---apiVersion: v1kind: Podmetadata: name: samplepod-2 annotations: k8s.v1.cni.cncf.io/networks: &#x27;[ &#123; &quot;name&quot;: &quot;ovs-ipam-net&quot;, &quot;ips&quot;: [&quot;10.10.10.2/24&quot;] &#125;]&#x27;spec: containers: - name: pod-2 command: [&quot;sleep&quot;, &quot;99999&quot;] image: alpineEOF# 2. zhickubectl apply -f ovs-test.yml# 3. 通信测试kubectl exec -it samplepod-1 -- ping 10.10.10.2 -c 5PING 10.10.10.2 (10.10.10.2): 56 data bytes64 bytes from 10.10.10.2: seq=0 ttl=127 time=10.266 ms64 bytes from 10.10.10.2: seq=1 ttl=127 time=7.423 ms64 bytes from 10.10.10.2: seq=2 ttl=127 time=7.265 ms64 bytes from 10.10.10.2: seq=3 ttl=127 time=14.498 7. Node 节点Kubernetes node节点组件： kubelet kube-proxy 6.1 克隆准备 (master节点执行)123456mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-installtar cvf worker-node-clone.tar /usr/bin/&#123;kubelet,kube-proxy&#125; /lib/systemd/system/&#123;kubelet,kube-proxy&#125;.service /etc/kubernetes/kubelet* /etc/kubernetes/kube-proxy* /etc/kubernetes/pki /etc/kubernetes/bootstrap.kubeconfigscp worker-node-clone.tar ubuntu@192.168.80.46:/home/ubuntuscp worker-node-clone.tar ubuntu@192.168.80.47:/home/ubuntu 6.2 克隆节点12345678cd / &amp;&amp; mv /home/ubuntu/worker-node-clone.tar / &amp;&amp; tar xvf worker-node-clone.tar &amp;&amp; rm -f worker-node-clone.tar# 删除证书申请审批后自动生成的文件，后面重新生成rm -f /etc/kubernetes/kubelet.kubeconfig rm -f /etc/kubernetes/pki/kubelet*# 日志目录mkdir -p /var/log/kubernetes 6.3 修改配置按实际节点名称修改 1234567# kubeletvi /lib/systemd/system/kubelet.service--hostname-override=k8s-node01# kube-proxyvi /etc/kubernetes/kube-proxy-config.ymlhostnameOverride: k8s-node01 6.4 开机启动1234systemctl daemon-reloadsystemctl start kubelet kube-proxysystemctl status kubelet kube-proxysystemctl enable kubelet kube-proxy 6.5 加入集群 (master节点执行)1234567891011121314151617181920212223242526272829303132333435# 1. 节点信息kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONnode-csr-ghWG-AWFM9sxJbr5A-BIq9puVIRxfFHrQlwDjYbHba8 94m kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Approved,Issuednode-csr-r2GF_8R3zuUe9BCf6eHeijWnzyPDDy-6WQUFOrOAQjA 34s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pendingnode-csr-wvcKDHm38jQgjyaLiA_G2ycc2Qvmecf_iRRd9IqlSEw 97s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending# 2. 批准加入kubectl certificate approve node-csr-r2GF_8R3zuUe9BCf6eHeijWnzyPDDy-6WQUFOrOAQjA kubectl certificate approve node-csr-wvcKDHm38jQgjyaLiA_G2ycc2Qvmecf_iRRd9IqlSEw# 3. 集群节点kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master1 NotReady &lt;none&gt; 45m v1.21.4k8s-node01 NotReady &lt;none&gt; 6s v1.21.4k8s-node02 NotReady &lt;none&gt; 10s v1.21.4# 4. 设置标签，即更改节点角色kubectl label node k8s-master1 node-role.kubernetes.io/master=kubectl label node k8s-node01 node-role.kubernetes.io/node=kubectl label node k8s-node02 node-role.kubernetes.io/node=kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master1 NotReady master 49m v1.21.4k8s-node01 NotReady node 3m45s v1.21.4k8s-node02 NotReady node 3m49s v1.21.4# 5. 设置污点：是master节点无法创建podkubectl taint nodes k8s-master1 node-role.kubernetes.io/master=:NoSchedulekubectl describe node k8s-master1Taints: node-role.kubernetes.io/master:NoSchedule node.kubernetes.io/not-ready:NoSchedule 8. Addons8.1 CoreDNSCoreDNS用于集群内部Service名称解析 12345678910111213141516171819202122232425mkdir -p $HOME/k8s-install/coredns &amp;&amp; cd $HOME/k8s-install/corednswget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sedwget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.shchmod +x deploy.shexport CLUSTER_DNS_SVC_IP=&quot;10.96.0.2&quot;export CLUSTER_DNS_DOMAIN=&quot;cluster.local&quot;./deploy.sh -i $&#123;CLUSTER_DNS_SVC_IP&#125; -d $&#123;CLUSTER_DNS_DOMAIN&#125; | kubectl apply -f -# 查询状态kubectl get pods -n kube-system | grep corednscoredns-746fcb4bc5-nts2k 1/1 Running 0 6m2s# 验证 busybox1.33.1有问题kubectl run -it --rm dns-test --image=busybox:1.28.4 /bin/shIf you don&#x27;t see a command prompt, try pressing enter./ # nslookup kubernetesServer: 10.96.0.2Address: 10.96.0.2:53Name: kubernetes.default.svc.cluster.localAddress: 10.0.0.1 DNS问题排查： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# dns servicekubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkube-dns ClusterIP 10.96.0.2 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 13m# endpoints 是否正常kubectl get endpoints kube-dns -n kube-systemNAME ENDPOINTS AGEkube-dns 10.244.85.194:53,10.244.85.194:53,10.244.85.194:9153 13m# coredns 增加解析日志CoreDNS 配置参数说明：errors: 输出错误信息到控制台。health：CoreDNS 进行监控检测，检测地址为 http://localhost:8080/health 如果状态为不健康则让 Pod 进行重启。ready: 全部插件已经加载完成时，将通过 endpoints 在 8081 端口返回 HTTP 状态 200。kubernetes：CoreDNS 将根据 Kubernetes 服务和 pod 的 IP 回复 DNS 查询。prometheus：是否开启 CoreDNS Metrics 信息接口，如果配置则开启，接口地址为 http://localhost:9153/metricsforward：任何不在Kubernetes 集群内的域名查询将被转发到预定义的解析器 (/etc/resolv.conf)。cache：启用缓存，30 秒 TTL。loop：检测简单的转发循环，如果找到循环则停止 CoreDNS 进程。reload：监听 CoreDNS 配置，如果配置发生变化则重新加载配置。loadbalance：DNS 负载均衡器，默认 round_robin。# 编辑 coredns 配置kubectl edit configmap coredns -n kube-systemapiVersion: v1data: Corefile: | .:53 &#123; log # new add errors health &#123; lameduck 5s &#125; ready kubernetes cluster.local in-addr.arpa ip6.arpa &#123; fallthrough in-addr.arpa ip6.arpa &#125; prometheus :9153 forward . /etc/resolv.conf &#123; max_concurrent 1000 &#125; cache 30 loop reload loadbalance &#125;kind: ConfigMapmetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:&#123;&quot;Corefile&quot;:&quot;.:53 &#123;\\n errors\\n health &#123;\\n lameduck 5s\\n &#125;\\n ready\\n kubernetes cluster.local in-addr.arpa ip6.arpa &#123;\\n fallthrough in-addr.arpa ip6.arpa\\n &#125;\\n prometheus :9153\\n forward . /etc/resolv.conf &#123;\\n max_concurrent 1000\\n &#125;\\n cache 30\\n loop\\n reload\\n loadbalance\\n&#125;\\n&quot;&#125;,&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;coredns&quot;,&quot;namespace&quot;:&quot;kube-system&quot;&#125;&#125; creationTimestamp: &quot;2021-05-13T11:57:45Z&quot; name: coredns namespace: kube-system resourceVersion: &quot;38460&quot; selfLink: /api/v1/namespaces/kube-system/configmaps/coredns uid: c62a856d-1fc3-4fe9-b5f1-3ca0dbeb39c1 回滚操作： 123456789wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/rollback.shchmod +x rollback.shexport CLUSTER_DNS_SVC_IP=&quot;10.96.0.2&quot;export CLUSTER_DNS_DOMAIN=&quot;cluster.local&quot;./rollback.sh -i $&#123;CLUSTER_DNS_SVC_IP&#125; -d $&#123;CLUSTER_DNS_DOMAIN&#125; | kubectl apply -f -kubectl delete --namespace=kube-system deployment coredns 8.2 Dashboard123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051mkdir -p $HOME/k8s-install/dashboard &amp;&amp; cd $HOME/k8s-install/dashboard# 1. 下载并安装curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml -o dashboard.yamlkubectl apply -f dashboard.yaml# 2. 检查运行状态kubectl get pods -n kubernetes-dashboard -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESdashboard-metrics-scraper-79c5968bdc-xkm78 1/1 Running 0 23m 10.244.159.129 k8s-master1 &lt;none&gt; &lt;none&gt;kubernetes-dashboard-9f9799597-d8g8t 1/1 Running 0 23m 10.244.58.193 k8s-node02 &lt;none&gt; &lt;none&gt;# 3. 检查服务状态kubectl get svc -n kubernetes-dashboard -o wideNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORdashboard-metrics-scraper ClusterIP 10.96.14.1 &lt;none&gt; 8000/TCP 24m k8s-app=dashboard-metrics-scraperkubernetes-dashboard ClusterIP 10.96.219.125 &lt;none&gt; 443/TCP 24m k8s-app=kubernetes-dashboard# 4. 服务改为NodePort方式kubectl edit svc kubernetes-dashboard -n kubernetes-dashboardtype: ClusterIP =&gt; type: NodePort kubectl get svc -n kubernetes-dashboard -o wideNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORdashboard-metrics-scraper ClusterIP 10.96.14.1 &lt;none&gt; 8000/TCP 3h30m k8s-app=dashboard-metrics-scraperkubernetes-dashboard NodePort 10.96.219.125 &lt;none&gt; 443:31639/TCP 3h30m k8s-app=kubernetes-dashboard# 5. 创建service account并绑定默认cluster-admin管理员集群角色：kubectl create serviceaccount dashboard-admin -n kube-systemkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin# 6. 获取访问 tokenkubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &#x27;/dashboard-admin/&#123;print $1&#125;&#x27;)Name: dashboard-admin-token-xwd72Namespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: dashboard-admin kubernetes.io/service-account.uid: 013e9f84-827f-4dc7-81b3-874a28bfebc6Type: kubernetes.io/service-account-tokenData====ca.crt: 1310 bytesnamespace: 11 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6InNQRElCQTlPRUZ5SU54STQ1QWllLXlKMTFCcmZieG0wVTJnRlpzYlBNLXcifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4teHdkNzIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMDEzZTlmODQtODI3Zi00ZGM3LTgxYjMtODc0YTI4YmZlYmM2Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.O-DI-0IlLFP2pDRKzQYJrZeDAnVvW1IjU-iVwGzvwID7BH0v6kXfWnti07qm8VkuGFJtpuQsmrf6v4sUeRDhr95kZlEVV8Rxnes6oixrkXdk3fR4xreh4lh6ZgCzbER6xI8pMG-j9KNjTRdY6gQPJuOThtI9ab13dpTT5AYpggA2O98DFfgcJ_DzD05hhk6TghOdoro00msHRSUrsEiH0CYa_3PiyPlkvmmY3MlJPsBTdO2pCDzcrjQ2L5EaJAvSh6OodkRY6ymOwfcbfPs3WwSocCEfwkogYOCAQhMC4NU3Jea_hoeFqzLdS1PK5R2rPT-wqemwjDKn0E6jUv6juw# 7. 访问https://192.168.80.45:31639 9. 高可用 角色 IP 组件 备注 k8s-master1 192.168.80.45 etcd, api-server, controller-manager, scheduler, kubelet, kube-proxy, docker k8s-node01 192.168.80.46 etcd, kubelet, kube-proxy, docker k8s-node02 192.168.80.47 etcd, kubelet, kube-proxy, docker k8s-master2 192.168.80.49 etcd, api-server, controller-manager, scheduler, kubelet, kube-proxy, docker 新增节点 9.1 准备操作 (Master-1)9.1.1 kube-apiserver 证书更新在新增节点的IP段未在证书中时需要如下操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455mkdir -p /root/ssl &amp;&amp; cd /root/ssl# 1. 证书签名请求文件cat &gt; apiserver-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;127.0.0.1&quot;, &quot;localhost&quot;, &quot;192.168.80.1&quot;, &quot;192.168.80.2&quot;, &quot;192.168.80.3&quot;, &quot;192.168.80.45&quot;, &quot;192.168.80.46&quot;, &quot;192.168.80.47&quot;, &quot;192.168.80.48&quot;, &quot;192.168.80.49&quot;, &quot;10.96.0.1&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 2. 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes apiserver-csr.json | cfssljson -bare apiserver# 3. 证书更新cp apiserver*.pem /etc/kubernetes/pkiscp apiserver*.pem ubuntu@192.168.80.46:/home/ubuntuscp apiserver*.pem ubuntu@192.168.80.47:/home/ubuntu# 4. node节点证书更新chown root:root /home/ubuntu/apiserver*.pem mv /home/ubuntu/apiserver*.pem /etc/kubernetes/pki# 5. 重启 apiserversystemctl restart kube-apiserversystemctl status kube-apiserver 9.1.2 增加主机在 k8s-master1, k8s-node01, k8s-node02 上制作 1echo &#x27;192.168.80.49 k8s-master2&#x27; &gt;&gt; /etc/hosts 9.2 扩容 Master9.2.1 初始化123456789101112131415161718192021222324252627282930313233# 1. 修改主机名hostnamectl set-hostname k8s-master2# 2. 主机名解析cat &gt;&gt; /etc/hosts &lt;&lt;EOF192.168.80.45 k8s-master1192.168.80.46 k8s-node01192.168.80.47 k8s-node02192.168.80.49 k8s-master2EOF# 3. 禁用 swapswapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab# 4. 将桥接的IPv4流量传递到iptables的链 cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOFsysctl --system # 5. 域名解析echo &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.conf # 6. 时间同步 apt install ntpdate -y ntpdate ntp1.aliyun.comcrontab -e*/30 * * * * /usr/sbin/ntpdate-u ntp1.aliyun.com &gt;&gt; /var/log/ntpdate.log 2&gt;&amp;1# 7. 日志目录mkdir -p /var/log/kubernetes 9.2.2 克隆1234567891011# 1. k8s-master1 上执行mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-installtar zcvf master-node-clone.tar.gz /usr/bin/kube* /lib/systemd/system/kube*.service /etc/kubernetes /root/.kube/config /usr/bin/docker* /usr/bin/runc /usr/bin/containerd* /usr/bin/ctr /etc/docker /lib/systemd/system/docker.servicescp master-node-clone.tar.gz ubuntu@192.168.80.49:/home/ubuntu# 2. k8s-master2 执行cd / &amp;&amp; mv /home/ubuntu/master-node-clone.tar.gz / &amp;&amp; tar zxvf master-node-clone.tar.gz &amp;&amp; rm -f master-node-clone.tar.gzrm -f /etc/kubernetes/kubelet.kubeconfig rm -f /etc/kubernetes/pki/kubelet* 9.2.3 更新配置12345678910vi /etc/kubernetes/kube-apiserver.conf --bind-address=192.168.80.49 \\--advertise-address=192.168.80.49 \\sed -i &#x27;s#k8s-master1#k8s-master2#&#x27; /etc/kubernetes/*sed -i &#x27;s#192.168.80.45:6443#192.168.80.49:6443#&#x27; /etc/kubernetes/*vi /root/.kube/configserver: https://192.168.80.49:6443 9.2.4 开机启动1234systemctl daemon-reloadsystemctl start docker kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxysystemctl status docker kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxysystemctl enable docker kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy 9.2.5 集群状态12345678kubectl get csWarning: v1 ComponentStatus is deprecated in v1.19+NAME STATUS MESSAGE ERRORcontroller-manager Healthy okscheduler Healthy oketcd-2 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;etcd-1 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 9.2.6 加入集群123456789101112131415kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONnode-csr-HfzAqSEc7sIIG9QFHip4vGFnFZhyZnYjBVGWQyGpz54 7m49s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending# 批准加入kubectl certificate approve node-csr-HfzAqSEc7sIIG9QFHip4vGFnFZhyZnYjBVGWQyGpz54kubectl get nodeNAME STATUS ROLES AGE VERSIONNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 27h v1.21.4k8s-master2 NotReady &lt;none&gt; 11s v1.21.4k8s-node01 Ready node 27h v1.21.4k8s-node02 Ready node 27h v1.21.4 9.2.7 打标和污点12345678910111213# 设置标签kubectl label node k8s-master2 node-role.kubernetes.io/master=# 设置污点：是master节点无法创建podkubectl taint nodes k8s-master2 node-role.kubernetes.io/master=:NoSchedule# 节点信息kubectl get nodes --show-labelsNAME STATUS ROLES AGE VERSION LABELSk8s-master1 Ready master 27h v1.21.4 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master1,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-master2 Ready master 2m13s v1.21.4 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master2,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-node01 Ready node 27h v1.21.4 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linux,node-role.kubernetes.io/node=k8s-node02 Ready node 27h v1.21.4 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linux,node-role.kubernetes.io/node= 9.3 高可用负载均衡 Nginx: 主流Web服务和反向代理服务器，这里用四层实现对apiserver实现负载均衡。 Keepalived: 主流高可用软件，基于VIP绑定实现服务器双机热备。Keepalived主要根据Nginx运行状态判断是否需要故障转移（漂移VIP），例如当Nginx主节点挂掉，VIP会自动绑定在Nginx备节点，从而保证VIP一直可用，实现Nginx高可用。 服务器规划： 角色 IP 组件 k8s-master1 192.168.80.45 kube-apiserver k8s-master2 192.168.80.49 kube-apiserver k8s-loadbalancer1 192.168.80.2 nginx, keepalived k8s-loadbalancer2 192.168.80.3 nginx, keepalived VIP 192.168.80.1 虚拟IP 9.3.1 安装软件1apt install nginx keepalived -y 9.3.2 配置Nginx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354cat &gt; /etc/nginx/nginx.conf &lt;&lt; &quot;EOF&quot;user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;stream &#123; log_format main &#x27;$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent&#x27;; access_log /var/log/nginx/k8s-access.log main; upstream k8s-apiserver &#123; server 192.168.80.45:6443; # Master1 APISERVER IP:PORT server 192.168.80.49:6443; # Master2 APISERVER IP:PORT &#125; server &#123; listen 16443; proxy_pass k8s-apiserver; &#125;&#125;http &#123; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; server &#123; listen 80 default_server; server_name _; location / &#123; &#125; &#125;&#125;EOF 9.3.3 keepalived 配置 (master)12345678910111213141516171819202122232425262728293031323334353637cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOFglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id NGINX_MASTER&#125; # 检查脚本vrrp_script check_nginx &#123; script &quot;/etc/keepalived/check_nginx.sh&quot;&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 # 修改为实际网卡名 virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 priority 100 # 优先级，备服务器设置 90 advert_int 1 # 指定VRRP 心跳包通告间隔时间，默认1秒 authentication &#123; auth_type PASS auth_pass 1111 &#125; # 虚拟IP virtual_ipaddress &#123; 192.168.80.1/24 &#125; track_script &#123; check_nginx &#125; &#125;EOF 9.3.4 keepalived 配置 (slave)12345678910111213141516171819202122232425262728293031323334353637cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOFglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id NGINX_BACKUP&#125; # 检查脚本vrrp_script check_nginx &#123; script &quot;/etc/keepalived/check_nginx.sh&quot;&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 # 修改为实际网卡名 virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 priority 90 # 优先级，备服务器设置 90 advert_int 1 # 指定VRRP 心跳包通告间隔时间，默认1秒 authentication &#123; auth_type PASS auth_pass 1111 &#125; # 虚拟IP virtual_ipaddress &#123; 192.168.80.1/24 &#125; track_script &#123; check_nginx &#125; &#125;EOF 9.3.5 keepalived 检查脚本123456789101112cat &gt; /etc/keepalived/check_nginx.sh &lt;&lt; &quot;EOF&quot;#!/bin/bashcount=$(ss -antp |grep 16443 |egrep -cv &quot;grep|$$&quot;)if [ &quot;$count&quot; -eq 0 ];then exit 1else exit 0fiEOFchmod +x /etc/keepalived/check_nginx.sh 9.3.6 启动服务123systemctl daemon-reloadsystemctl start nginx keepalivedsystemctl enable nginx keepalived 9.3.7 状态检查1234567891011121314ip addrcurl -k https://192.168.80.1:16443/version&#123; &quot;major&quot;: &quot;1&quot;, &quot;minor&quot;: &quot;19&quot;, &quot;gitVersion&quot;: &quot;v1.21.4&quot;, &quot;gitCommit&quot;: &quot;c6a2f08fc4378c5381dd948d9ad9d1080e3e6b33&quot;, &quot;gitTreeState&quot;: &quot;clean&quot;, &quot;buildDate&quot;: &quot;2021-05-12T12:19:22Z&quot;, &quot;goVersion&quot;: &quot;go1.15.12&quot;, &quot;compiler&quot;: &quot;gc&quot;, &quot;platform&quot;: &quot;linux/amd64&quot;&#125; 9.3.8 Worker Node 连接到 LB VIP123456789sed -i &#x27;s#192.168.80.45:6443#192.168.80.1:16443#&#x27; /etc/kubernetes/*systemctl restart kubelet kube-proxykubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 3d17h v1.21.4k8s-master2 Ready master 2d16h v1.21.4k8s-node01 Ready node 3d15h v1.21.4k8s-node02 Ready node 3d15h v1.21.4 10. 删除节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 1. k8s-master2 上，停止kubelet进程systemctl stop kubelet# 2. 检查 k8s-master2 是否已下线kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 40h v1.21.4k8s-master2 NotReady master 12h v1.21.4k8s-node01 Ready node 40h v1.21.4k8s-node02 Ready node 40h v1.21.4# 3. 删除节点kubectl drain k8s-master2node/k8s-master2 cordonederror: unable to drain node &quot;k8s-master2&quot;, aborting command...There are pending nodes to be drained: k8s-master2error: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/calico-node-lwj2r# 4. 强制下线kubectl drain k8s-master2 --ignore-daemonsetsnode/k8s-master2 already cordonedWARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-lwj2rnode/k8s-master2 drained# 5. 下线状态kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 40h v1.21.4k8s-master2 Ready,SchedulingDisabled master 12h v1.21.4k8s-node01 Ready node 39h v1.21.4k8s-node02 Ready node 39h v1.21.4# 6. 恢复操作 (如有必要)kubectl uncordon k8s-master2node/k8s-master2 uncordonedkubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 40h v1.21.4k8s-master2 Ready master 12h v1.21.4k8s-node01 Ready node 39h v1.21.4k8s-node02 Ready node 39h v1.21.4# 7. 彻底删除kubectl delete node k8s-master2 kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s-master1 Ready master 41h v1.21.4k8s-node01 Ready node 40h v1.21.4k8s-node02 Ready node 40h v1.21.4 Z. 补充组件日志级别12345678--v=0 Generally useful for this to ALWAYS be visible to an operator.--v=1 A reasonable default log level if you don’t want verbosity.--v=2 Useful steady state information about the service and important log messages that may correlate to significant changes in the system. This is the recommended default log level for most systems.--v=3 Extended information about changes.--v=4 Debug level verbosity.--v=6 Display requested resources.--v=7 Display HTTP request headers.--v=8 Display HTTP request contents","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://elihe2011.github.io/categories/kubernetes/"}],"tags":[]},{"title":"Kubernetes 集群kubeadmin安装","slug":"Kubernetes 集群kubeadm安装","date":"2021-05-31T12:38:56.000Z","updated":"2021-07-13T06:39:18.708Z","comments":true,"path":"2021/05/31/Kubernetes 集群kubeadm安装/","link":"","permalink":"https://elihe2011.github.io/2021/05/31/Kubernetes%20%E9%9B%86%E7%BE%A4kubeadm%E5%AE%89%E8%A3%85/","excerpt":"1. Kubeadm原理12345# 创建一个 Master 节点$ kubeadm init# 将一个 Node 节点加入到当前集群中$ kubeadm join &lt;Master 节点的 IP 和端口 &gt; 执行 kubeadm init： 自动检查集群机器是否合规 自动生成集群运行所需的各类证书及各类配置，并将Master节点信息保存在名为cluster-info的ConfigMap中。 通过static Pod方式，运行API server, controller manager 、scheduler及etcd组件。 生成Token以便其他节点加入集群 执行 kubeadm join时： 节点通过token访问kube-apiserver，获取cluster-info中信息，主要是apiserver的授权信息（节点信任集群）。 通过授权信息，kubelet可执行TLS bootstrapping，与apiserver真正建立互信任关系（集群信任节点）。 kubeadm做的事就是把大部分组件都容器化，通过StaticPod方式运行，并自动化了大部分的集群配置及认证等工作，简单几步即可搭建一个可用Kubernetes的集群。","text":"1. Kubeadm原理12345# 创建一个 Master 节点$ kubeadm init# 将一个 Node 节点加入到当前集群中$ kubeadm join &lt;Master 节点的 IP 和端口 &gt; 执行 kubeadm init： 自动检查集群机器是否合规 自动生成集群运行所需的各类证书及各类配置，并将Master节点信息保存在名为cluster-info的ConfigMap中。 通过static Pod方式，运行API server, controller manager 、scheduler及etcd组件。 生成Token以便其他节点加入集群 执行 kubeadm join时： 节点通过token访问kube-apiserver，获取cluster-info中信息，主要是apiserver的授权信息（节点信任集群）。 通过授权信息，kubelet可执行TLS bootstrapping，与apiserver真正建立互信任关系（集群信任节点）。 kubeadm做的事就是把大部分组件都容器化，通过StaticPod方式运行，并自动化了大部分的集群配置及认证等工作，简单几步即可搭建一个可用Kubernetes的集群。 2. Haproxy12345678910111213141516171819202122232425262728293031323334353637383940# 安装haproxyyum install haproxy -y # 修改haproxy配置cat &lt;&lt; EOF &gt; /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemondefaults mode tcp log global retries 3 timeout connect 10s timeout client 1m timeout server 1mfrontend kube-apiserver bind *:6443 # 指定前端端口 mode tcp default_backend masterbackend master # 指定后端机器及端口，负载方式为轮询 balance roundrobin server master-1 192.168.41.230:6443 check maxconn 2000 server master-2 192.168.41.231:6443 check maxconn 2000EOF# 开机默认启动haproxy，开启服务systemctl enable haproxysystemctl start haproxy# 检查服务端口情况：# netstat -lntup | grep 6443tcp 0 0 0.0.0.0:6443 0.0.0.0:* LISTEN 3110/haproxy 3. 集群安装 角色 IP 组件 k8s-master 192.168.80.40 kube-apiserver，kube-controller-manager，kube-scheduler，docker, etcd k8s-node1 192.168.80.41 kubelet，kube-proxy，docker，etcd k8s-node2 192.168.80.42 kubelet，kube-proxy，docker，etcd K8S 版本：1.19.11 3.1 准备工作12345678910111213141516171819202122232425262728# 1. 修改主机名hostnamectl set-hostname k8s-masterhostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02# 2. 主机名解析cat &gt;&gt; /etc/hosts &lt;&lt;EOF192.168.80.40 k8s-master192.168.80.41 k8s-node01192.168.80.42 k8s-node02EOF# 3. 禁用 swapswapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab# 4. 将桥接的IPv4流量传递到iptables的链 cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOFsysctl --system # 5. 时间同步 apt install ntpdate -y ntpdate ntp1.aliyun.comcrontab -e*/30 * * * * /usr/sbin/ntpdate-u ntp1.aliyun.com &gt;&gt; /var/log/ntpdate.log 2&gt;&amp;1 3.2 安装 kubeadm1234567891011121314151617181920curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat &gt;/etc/apt/sources.list.d/kubernetes.list &lt;&lt;EOFdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOFapt-get update# 查询可用版本apt-cache policy kubeadm1.19.11-00# 安装 docker 19.03.15~3-0~ubuntu-xenialapt-get install kubeadm=1.19.11-00~ubuntu-xenial -y# masterapt-get install -y kubeadm apt-get install -y kubeadm=1.19.11-00 kubelet=1.19.11-00 kubectl=1.19.11-00# nodeapt-get install -y kubeadm=1.19.11-00 kubelet=1.19.11-00 3.3 Master 节点初始化： 1234567kubeadm init \\ --apiserver-advertise-address=192.168.80.40 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.19.11 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 \\ --ignore-preflight-errors=all 输出结果，用于节点加入集群： 12345678910111213141516Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.80.40:6443 --token a6jcpy.a33lzoxwxs0zx0fr \\ --discovery-token-ca-cert-hash sha256:986154509030b5a816cd6afc796d104c0f3fe24ff1e59bf769cb89b72f904112 kubectl 连接 k8s 认证： 1234567# 不配置kubectl get nodeThe connection to the server localhost:8080 was refused - did you specify the right host or port?mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 3.3 Node 节点加入集群: 12kubeadm join 192.168.80.40:6443 --token a6jcpy.a33lzoxwxs0zx0fr \\ --discovery-token-ca-cert-hash sha256:986154509030b5a816cd6afc796d104c0f3fe24ff1e59bf769cb89b72f904112 3.4 安装网络插件1234567891011# 节点状态kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 7m4s v1.19.11k8s-node01 NotReady &lt;none&gt; 8s v1.19.11k8s-node02 NotReady &lt;none&gt; 4s v1.19.11# 检查日志，发现网络插件未安装journalctl -u kubelet -fJun 02 14:24:29 k8s-master kubelet[75636]: W0602 14:24:29.172144 75636 cni.go:239] Unable to update cni config: no networks found in /etc/cni/net.dJun 02 14:24:32 k8s-master kubelet[75636]: E0602 14:24:32.958021 75636 kubelet.go:2129] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized 安装 calico 网络插件： 1234567891011121314mkdir -p $HOME/k8s-install &amp;&amp; cd $HOME/k8s-installwget https://docs.projectcalico.org/manifests/calico.yaml# CIDR的值，与 kubeadm中“--pod-network-cidr=10.244.0.0/16” 一致vi calico.yaml 3680 # The default IPv4 pool to create on startup if none exists. Pod IPs will be 3681 # chosen from this range. Changing this value after installation will have 3682 # no effect. This should fall within `--cluster-cidr`. 3683 - name: CALICO_IPV4POOL_CIDR 3684 value: &quot;10.244.0.0/16&quot;# 安装网络插件kubectl apply -f calico.yaml 检查 网络插件状态： 123456789101112131415161718192021kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEcalico-kube-controllers-7f4f5bf95d-22gcz 1/1 Running 0 88scalico-node-cj7fv 1/1 Running 0 89scalico-node-n26cx 1/1 Running 0 89scalico-node-rcqrf 1/1 Running 0 89scoredns-6d56c8448f-hn5h4 1/1 Running 0 21mcoredns-6d56c8448f-wfwlf 1/1 Running 0 21metcd-k8s-master 1/1 Running 0 21mkube-apiserver-k8s-master 1/1 Running 0 21mkube-controller-manager-k8s-master 1/1 Running 0 21mkube-proxy-5pvd8 1/1 Running 0 14mkube-proxy-bqfkf 1/1 Running 0 21mkube-proxy-mdc4h 1/1 Running 0 14mkube-scheduler-k8s-master 1/1 Running 0 21mkubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master Ready master 22m v1.19.11k8s-node01 Ready &lt;none&gt; 15m v1.19.11k8s-node02 Ready &lt;none&gt; 15m v1.19.11 3.5 节点角色12345678 kubectl get node --show-labelsNAME STATUS ROLES AGE VERSION LABELSk8s-master Ready master 25m v1.19.11 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s-node01 Ready &lt;none&gt; 18m v1.19.11 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linuxk8s-node02 Ready &lt;none&gt; 18m v1.19.11 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node02,kubernetes.io/os=linuxkubectl label node k8s-node01 node-role.kubernetes.io/node=kubectl label node k8s-node02 node-role.kubernetes.io/node= 3.6 token 过期kubeadm join 加入集群时，需要2个参数，–token与–discovery-token-ca-cert-hash。其中，token有限期一般是24小时，如果超过时间要新增节点，就需要重新生成token。 12345678910111213# tokenkubeadm token creates058gw.c5x6eeze2875sza1# discovery-token-ca-cert-hashopenssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;986154509030b5a816cd6afc796d104c0f3fe24ff1e59bf769cb89b72f904112# 新节点加入kubeadm join api-serverip:port --token s058gw.c5x6eeze28**** --discovery-token-ca-cert-hash 9592464b295699696ce35e5d1dd155580ee29d9bd0884b*****kubeadm join 192.168.80.40:6443 --token s058gw.c5x6eeze2875sza1 \\ --discovery-token-ca-cert-hash sha256:986154509030b5a816cd6afc796d104c0f3fe24ff1e59bf769cb89b72f904112 4. 问题汇总4.1 kubelet 无法正常启动kubelet无法正常启动，导致执行kubeadm时出现如下错误： 123456789101112131415161718192021[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s[kubelet-check] Initial timeout of 40s passed. Unfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - &#x27;systemctl status kubelet&#x27; - &#x27;journalctl -xeu kubelet&#x27; Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - &#x27;docker ps -a | grep kube | grep -v pause&#x27; Once you have found the failing container, you can inspect its logs with: - &#x27;docker logs CONTAINERID&#x27; 解决办法，修改 docker 的cgroupdriver: 123456789101112131415161718cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;storage-opts&quot;: [ &quot;overlay2.override_kernel_check=true&quot; ]&#125;EOFmkdir -p /etc/systemd/system/docker.service.dsystemctl daemon-reloadsystemctl restart docker 重做初始化： 123kubeadm resetkubeadm init xxx 4.2 ubuntu 16 默认内核12345678910111213141516171819202122232425uname -r4.4.0-142-generic# 内核参数告警systemctl status docker● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2021-06-02 14:11:22 CST; 10s ago Docs: https://docs.docker.com Main PID: 52488 (dockerd) Tasks: 10 Memory: 57.5M CPU: 1.767s CGroup: /system.slice/docker.service └─52488 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockJun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.031860026+08:00&quot; level=warning msg=&quot;Your kernel does not support swap memory limit&quot;Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.031910601+08:00&quot; level=warning msg=&quot;Your kernel does not support cgroup rt period&quot;Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.031917871+08:00&quot; level=warning msg=&quot;Your kernel does not support cgroup rt runtime&quot;Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.032178268+08:00&quot; level=info msg=&quot;Loading containers: start.&quot;Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.118451062+08:00&quot; level=info msg=&quot;Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip cJun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.146043534+08:00&quot; level=info msg=&quot;Loading containers: done.&quot;Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.614147613+08:00&quot; level=info msg=&quot;Docker daemon&quot; commit=99e3ed8919 graphdriver(s)=overlay2 version=19.03.15Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.614842390+08:00&quot; level=info msg=&quot;Daemon has completed initialization&quot;Jun 02 14:11:22 k8s-node01 dockerd[52488]: time=&quot;2021-06-02T14:11:22.654911232+08:00&quot; level=info msg=&quot;API listen on /var/run/docker.sock&quot; 5. 结论 ubuntu 16 安装k8s 不需要升级内核 kubelet 启动，docker的 cgroupdriver 必须是 systemd, 否则无法正常启动","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://elihe2011.github.io/categories/kubernetes/"}],"tags":[]},{"title":"TCP","slug":"TCP","date":"2021-03-17T03:17:35.000Z","updated":"2021-07-13T03:17:52.007Z","comments":true,"path":"2021/03/17/TCP/","link":"","permalink":"https://elihe2011.github.io/2021/03/17/TCP/","excerpt":"1. TCP TCP 是面向连接、可靠的、基于字节流的传输层通信协议。 面向连接：一对一的连接。不像 UDP 可以同时向多个主机发送消息。 可靠的：网络链路中出现变化，TCP 可以保证一个报文一定能够到达指定端。","text":"1. TCP TCP 是面向连接、可靠的、基于字节流的传输层通信协议。 面向连接：一对一的连接。不像 UDP 可以同时向多个主机发送消息。 可靠的：网络链路中出现变化，TCP 可以保证一个报文一定能够到达指定端。 1.1 TCP 头 序列号：建立连接时，计算机生成的随机数作为初始值，通过 SYN 包传给接收端主机，每发送一次数据，就累加 1。解决网络包乱序问题 确认应答号：下一次“期望”收到的数据的序列号，发生端收到这个确认应答后，认为这个序列号以前的数据都被正确接收。解决丢包问题 控制位： ACK：确认应答字段有效。除了最初建立连接时的 SYN 包之外该位必须为1 RST：TCP 连接中出现异常，必须强行断开连接 SYN：希望建立连接，在其“序列号”字段初始化后设定 FIN：通信结束，断开连接，不会再发送数据时设定 1.2 TCP 连接用于保证可靠性和流量控制维护的某些状态信息，包括Socket、序列号和窗口大小称为连接 Socket：IP + Port 序列号：解决乱序等问题 窗口大小：流量控制 1.3 唯一确定一个连接通过 TCP 四元组来确定： 源地址 源端口 目标地址 目标端口 源地址和目标地址 (32-bit)：在 IP 头部中，通过 IP 协议发送报文给对方主机 源端口和目标端口 (16-bit)：在 TCP 头部中，通过 TCP 协议把报文发给哪一个进程。 1.4 三次握手 &amp; 四次挥手 TCP 状态： LISTENING: 服务端侦听远端TCP连接请求，等待被连接 SYN_SENT: 客户端调用connect方法，发送一个SYN请求建立连接 SYN_RCVD: 服务端收到连接请求并确认后，调用accept方法 ESTABLISHED: 连接建立 FIN_WAIT_1: 主动关闭连接，调用close方法后 CLOSING: FIN_WAIT_1后，等待对端关闭确认 （较少出现） CLOSE_WAIT: 收到关闭请求，等待关闭 FIN_WAIT_2: 收到关闭ACK确认后 LAST_ACK: 收到关闭请求(CLOSE_WAIT)后，被动关闭连接，调用close方法 TIME_WAIT: 主动关闭连接，收到被动关闭连接(LAST_ACK)后。等待足够的时间，确保远程TCP连接中断确认，最大程度保证双方正常结束，需等待2*MSL时间才能进行下一次连接 CLOSED： 被动关闭端收到ACK后，进入CLOSED，连接结束 总结： TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。 不使用「两次握手」和「四次握手」的原因： 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。 1.4.1 TIME_WAIT主动关闭Socket端会进入TIME_WAIT状态，并持续2MSL时间长度。 MSL (maximum segment lifetime)：表示一个IP数据包在互联网上生存的最长时间，超过这个时间将在网络中消失。MSL建议值为2分钟，但传统上为30s 因此，TIME_WAIT状态一般维持在1-4分钟 TIME_WAIT 作用： 可靠地实现TCP全双工连接终止 允许老的重复连接在网络中消逝 TIME_WAIT 危害： 过多会占用内存，一个TIME_WAIT占用4k 网络差的情况下，如果主动方无TIME_WAIT等待，关闭当前连接后，主动方与被动方又重新建立新的TCP连接，此时被动方重传或延时过来的FIN包会直接影响当前新的TCP连接 如何避免： 设置socket选项为SO_REUSEADDR，端口可重用 由于TIME_WAIT状态是主动关闭一方出现的，所以在协议逻辑设计时，尽量由客户端主动关闭，避免服务端出现TIME_WAIT 1.4.2 SYN 攻击什么是SYN攻击？ 在三次握手过程中，收到客户端SYN，服务端ACK该请求后进入SYN_RCVD状态，该状态称为半连接(half-open connect)，只有等服务端收到ACK再次确认后，才进入ESTABLISHED状态 SYN 攻击，即客户端在短时间内大量伪造不存在的IP地址，向服务端不断地发送SYN包，服务端回复ACK确认包，并等待客户端确认。但由于源地址不存在，服务端需要不断重发ACK包直至超时，大量SYN包长时间占用未连接队列，导致正常SYN请求被丢弃，网络阻塞服务不可用。 DoS/DDoS 是一种典型的SYN攻击 如何检测 SYN 攻击？ 服务器上存在大量半连接状态 (SYN_RCVD) 大量随机的源 IP 地址 如何预防 SYN 攻击? 完全阻止SYN攻击是不可能的，可通过一些方法减轻SYN攻击： 缩短超时时间(SYN Timeout) 增加最大半数连接数 过滤网关防护 SYN cookies 技术 Linux 内核参数： 12345678910111213141516# 队列最大值net.core.netdev_max_backlog# SYN_RCVD 状态连接的最大个数net.ipv4.tcp_max_syn_backlog# 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接net.ipv4.tcp_abort_on_overflow# 启用 cookienet.ipv4.tcp_syncookies = 1# 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；# 计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，# 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。# 最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。 1.5 KeepAliveTCP数据交互完成后，未主动释放连接，在无法知道对端的情况下保持了这个连接，长时间累积导致非常多的半打开连接，造成系统资源浪费。 KeepAlive: 隔一段时间给对端发送一个探测包，如果对方回应ACK，则认为连接还是存活的。在超过一定重试次数之后还是未收到对方的回应，则丢弃该连接。 1.6 如何实现长连接 HeartBeat心跳包 客户端每隔一小段时间向服务器发送一个数据包，通知服务器自己仍然在线。30s 00 00 03 TCP协议的KeepAlive机制 默认不打开，要用setsockopt将SOL_SOCKET.SO_KEEPALIVE设置为1，并且设置参数tcp_keepalive_time/tcp_keepalive_probes/tcp_keepalive_intvl keep-alive机制，可以减少tcp连接建立的次数，也意味着减少TIME_WAIT连接状态，以此来提高服务器性能 但keep-alive也可能导致系统资源被无效占用，合适设置keep-alive timeout时间非常重要 1.7 滑动窗口滑动窗口（Sliding window）是一种流量控制技术，它被用来改善网络吞吐量，即容许发送方在接收任何应答之前传送附加的包，接收方告诉发送方在某一个时刻能送多少包（成为窗口尺寸) 让发送的每一个包都有一个id，接收端必须对每一个包进行确认，这样设备A一次多发送几个片段，而不必等候ACK，同时接收端也要告知它能够收多少，这样发送端发起来也有个限制，当然还需要保证顺序性，不要乱序，对于乱序的状况，我们可以允许等待一定情况下的乱序，比如说先缓存提前到的数据，然后去等待需要的数据，如果一定时间没来就DROP掉，来保证顺序性！ 接收端可以根据自己的状况通告窗口大小，从而控制发送端的发送，进行流量控制。 滑动窗口原理： TCP并不是每一个报文段都会回复ACK确认，可能会对多个报文段发送1个ACK (累积ACK确认)。 比如发送方有1/2/3个报文段，接收方收到2/3报文段后，一直未收到报文段“1”，将会丢弃报文段2/3. 实现滑动窗口： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283var ( limitCount int32 = 10 // 限频总数 limitBucket int = 6 // 滑动窗口个数 curCount int32 = 0 // 当前限频数量 head *ring.Ring // 环形队列 (链表))func main() &#123; addr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, &quot;:3000&quot;) if err != nil &#123; log.Fatal(err) &#125; listener, err := net.ListenTCP(&quot;tcp&quot;, addr) if err != nil &#123; log.Fatal(err) &#125; defer listener.Close() // 初始化滑动窗口 head = ring.New(limitBucket) for i := 0; i &lt; limitBucket; i++ &#123; head.Value = 0 head = head.Next() &#125; // 启动执行器 go func() &#123; ticker := time.NewTicker(time.Second) for &#123; select &#123; case &lt;-ticker.C: subCount := int32(0 - head.Value.(int)) newCount := atomic.AddInt32(&amp;curCount, subCount) // useless, only for print arr := [6]int&#123;&#125; for i := 0; i &lt; limitBucket; i++ &#123; arr[i] = head.Value.(int) head = head.Next() &#125; fmt.Printf(&quot;subCount: %d, newCount: %d, arr: %v\\n&quot;, subCount, newCount, arr) head.Value = 0 head = head.Next() &#125; &#125; &#125;() // 处理请求 for &#123; conn, err := listener.Accept() if err != nil &#123; log.Println(err) continue &#125; go handle(&amp;conn) &#125;&#125;func handle(conn *net.Conn) &#123; defer (*conn).Close() count := atomic.AddInt32(&amp;curCount, 1) if count &gt; limitCount &#123; atomic.AddInt32(&amp;curCount, -1) msg := &quot;HTTP/1.1 404 NOT FOUND\\r\\n\\r\\nError, too many request, please try later.&quot; (*conn).Write([]byte(msg)) &#125; else &#123; mu := sync.Mutex&#123;&#125; mu.Lock() pos := head.Prev() val := pos.Value.(int) val++ pos.Value = val mu.Unlock() time.Sleep(time.Second) msg := &quot;HTTP/1.1 200 OK\\r\\n\\r\\nWell done.&quot; (*conn).Write([]byte(msg)) &#125;&#125; 使用HTTP压测工具hey： https://github.com/rakyll/hey 12345678910111213141516171819202122232425262728293031323334353637383940414243hey -c 6 -n 300 -q 6 -t 80 http://localhost:3000Summary: Total: 11.6708 secs Slowest: 1.0423 secs Fastest: 0.0013 secs Average: 0.0735 secs Requests/sec: 25.7051Response time histogram: 0.001 [1] | 0.105 [279] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 0.210 [0] | 0.314 [0] | 0.418 [0] | 0.522 [0] | 0.626 [0] | 0.730 [0] | 0.834 [0] | 0.938 [0] | 1.042 [20] |■■■Latency distribution: 10% in 0.0033 secs 25% in 0.0052 secs 50% in 0.0065 secs 75% in 0.0076 secs 90% in 0.0091 secs 95% in 1.0066 secs 99% in 1.0417 secsDetails (average, fastest, slowest): DNS+dialup: 0.0052 secs, 0.0013 secs, 1.0423 secs DNS-lookup: 0.0036 secs, 0.0002 secs, 0.0359 secs req write: 0.0001 secs, 0.0000 secs, 0.0023 secs resp wait: 19.8696 secs, 0.0001 secs, 851.1748 secs resp read: 0.0002 secs, 0.0000 secs, 0.0023 secsStatus code distribution: [200] 20 responses [404] 280 responses 1.8 MTU &amp; MSS MTU: 一个网络包的最大长度，以太网一般未 1500 字节 MSS：除去 IP 和 TCP 头部后，一个网络包能容纳的 TCP 数据的最大长度 当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。 但是，如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。 因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。 当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。 因此，可以得知由 IP 层进行分片传输，是非常没有效率的。 所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。 经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。 2. UDP 目标和源端口：告诉 UDP 协议应该把报文发给哪个进程。 包长度： UDP 首部的长度跟数据的长度之和。 校验和：提供可靠的 UDP 首部和数据而设计。 UDP是一个简单的传输层协议，与TCP相比，有如下特征： UDP 缺乏可靠性。不提供确认、序列号、超时重传等机制。 UDP 数据报可能在网络中被复制，被重新排序。即UDP不保证数据一定到达目的地，也不保证数据报的先后顺序，也不保证每个数据报只到达一次 UDP 数据报有长度的。如果一个数据报正确地到达目的地，该数据报的长度也随着随着数据一起传给了接收方。 UDP 面向无连接的。UDP客户端与服务器不存在长期关系，不需要经过三次握手和四次挥手操作 UDP支持多播和广播 3. TCP vs UDP 连接 协议 可靠性 使用场景 TCP 面向连接 流协议，无大小限制 可靠 可靠的通信。使用校验和、确认和重传机制来确保可靠传输 UDP 无连接 数据包协议，有限制 不可靠 1. 包总量较小的通信(DNS, SNMP) 2.视频、音频等流媒体（即时通信）3.广播通信 tcp 传输的是数据流，udp是数据包；tcp要进行三次握手、udp不需要 TCP 和 UDP 区别： 1. 连接 TCP 面向连接，传输数据前先要建立连接。 UDP 不需要连接，即刻传输数据。 2. 服务对象 TCP 是一对一的两点服务。 UDP 支持一对一、一对多、多对多的交互通信 3. 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 4. 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 5. 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 6. 传输方式 TCP 流式传输，没有边界，但保证顺序和可靠。 UDP 一个包一个包的发送，是有边界的，但可能会丢包和乱序。 7. 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。 TCP 和 UDP 应用场景： 由于 TCP 是面向连接，能保证数据的可靠性交付，常用于： FTP 文件传输 HTTP / HTTPS 由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，常用于： 包总量较少的通信，如 DNS 、SNMP 等 视频、音频等多媒体通信 广播通信 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？ 原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。 为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？ TCP 负载数据长度： 1TCP数据总长度 = IP总长度 - IP首部长度 - TCP首部长度 4. 网络包","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"HTTP","slug":"HTTP","date":"2021-01-09T03:19:35.000Z","updated":"2021-07-13T03:21:40.398Z","comments":true,"path":"2021/01/09/HTTP/","link":"","permalink":"https://elihe2011.github.io/2021/01/09/HTTP/","excerpt":"1. HTTP1.1 特性 构建在TCP上的应用层协议 无连接无状态 1.2 状态码 200 OK 301 Moved Permanently 永久重定向，后续请求直接发往新地址 302 Moved Temporarily 临时重定向 304 Not Modified 文件未修改，直接使用缓存文件 400 Bad Request 客户端请求有语法错误 401 Unauthorized 请求未经授权 403 Forbidden 认证通过，但无权限访问资源 404 Not Found 请求的资源不存在 405 Method Not Allowed 500 Internal Server Error 502 Bad Gateway 与upstream建立了连接，但响应超时。可能原因：后端代码执行超时、数据库响应慢等 (received an invalid response from the upstream server) 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。(The server cannot handle the request, because it is overloaded or down for maintenance, generally this is temporary state.) 504 Gateway Time-out 完全无法与upstream建立连接，一般是nginx配置错误 (did not receive a timely response from the upstream server)","text":"1. HTTP1.1 特性 构建在TCP上的应用层协议 无连接无状态 1.2 状态码 200 OK 301 Moved Permanently 永久重定向，后续请求直接发往新地址 302 Moved Temporarily 临时重定向 304 Not Modified 文件未修改，直接使用缓存文件 400 Bad Request 客户端请求有语法错误 401 Unauthorized 请求未经授权 403 Forbidden 认证通过，但无权限访问资源 404 Not Found 请求的资源不存在 405 Method Not Allowed 500 Internal Server Error 502 Bad Gateway 与upstream建立了连接，但响应超时。可能原因：后端代码执行超时、数据库响应慢等 (received an invalid response from the upstream server) 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。(The server cannot handle the request, because it is overloaded or down for maintenance, generally this is temporary state.) 504 Gateway Time-out 完全无法与upstream建立连接，一般是nginx配置错误 (did not receive a timely response from the upstream server) 1.3 持久连接 请求头：Connection: Keep-Alive HTTP/1.1默认 HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。 HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。 1.4 Transfer-Encoding用来标示 HTTP 报文传输格式，默认chunked，表示消息体由数量未定的块组成，并以最后一个大小为0的块为结束。 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF （回车及换行），然后是数据本身，最后块CRLF结束。 1.5 Cookie &amp; Session都是为了解决HTTP无状态问题，发展出来的保存客户端状态的一种机制 1.5.1 Cookie 客户端机制，浏览器存储在用户电脑上的一小段文本文件 http请求时，会将这些信息发生至服务器，服务器可根据这些信息来识别不同的用户 客户端可禁用Cookie 缺点： 不良站点用Cookie收集用户隐私信息 Cookie窃取，黑客可通过Cookie来模拟用户的请求行为（跨站脚本攻击XSS） 1.5.2 Session 服务端机制，服务器使用一种类似散列表的结构来保持信息，当客户端请求时，创建一个session请发给客户端，下一次客户端请求，服务端首先去检查这个请求是否包含了session标识 具体实现方式： Cookie方式：服务器给每个Session分配一个唯一的JSESSIONID，并通过Cookie发送给客户端。当客户端发起新的请求时，将在Cookie头重携带这个JSESSIONID，这样服务器就能够找个这个客户端对应的Session URL回写：服务器在发送给浏览器页面的所有链接中都携带JSESSIONID参数，这样客户端点击任何一个链接都会把JSESSIONID带回服务器 1.6 跨站攻击1.6.1 CSRF （XSRF）Cross-site Request Forgery, 跨站请求伪造 伪造请求，冒充用户在站内的正常操作。用户点击链接时，恶意js伪造请求，比如删除、转账、该密码、发送邮件等操作 预防 CSRF 攻击： 关键操作使用 POST 请求 验证码 检测 Referer，关联的请求地址应该一致 Token 1.6.2 XSSCross Site Scripting， 跨站脚本攻击 客户端提交含有 js 的内容文本，但服务器没有过滤或转义掉这些脚本，当内容发布到了页面上，其他用户访问这个页面的时候就会运行这些脚本。 预防 XSS 攻击： 将用户输入的内容进行 HTML escape 转义 2. HTTPSHTTPS: HTTP over TSL TSL: Transport Layer Security, SSL的后续版本 SSL: Secure Socket Layer 2.1 证书认证 上图为单向认证，双向认证时，需要客户端把自己的证书发回服务端认证 2.2 中间人攻击中间人攻击 (MITM, Man In The Middle Attack): 攻击者与通信的两端分别建立独立的连续，并交换其所收到的数据，使通信的两端都认为他们正在进行一个私密的连接与对方直接对话。 3. HTTP2影响一个HTTP网络请求的因素主要有两个：带宽和延迟 带宽：当前的互联网已解决 延迟： 浏览器阻塞(HOL blocking): 同一个域名，浏览器同时只能有 4 个连接（不同内核可能不同），超过最大连接数限制，后续请求将被阻塞 DNS查询(DNS Lookup): 解析域名为IP需要耗费一定的时间，通常可以利用DNS缓存解决 建立连接(Initial connection): HTTP基于TCP协议，浏览器最快也要进行三次握手才能将HTTP请求报文发往服务器，但建立的连接无法复用。 HTTP2.0新特性： 新的二进制格式 (Binary Format) HTTP1.x的解析基于文本，但文本协议存在多种格式，需要考虑的健壮性问题较多。二进制则不同，只认0和1组合。 多路复用(MultiPlexing) 连接共享，每个request对应一个id，这样一个连接就可以承载多个request header压缩 (HPACK) 使用encoder来减少需要传输的header大小，通信双发各自cache一份header fields表，既避免了重复的header传输，又减小了传输字节数 服务器推送 (server push) 服务器可以向浏览器发生请求之外的内容，比如正在请求一个页面时，服务器会把页面相关的logo，CSS等文件直接推送到客户端。 4. Web 缓存缓存：保存在浏览器中的数据，再次请求服务时，如果相同的URL，直接使用浏览器中的缓存响应访问请求，不会再次向服务器发送请求 三种情况： 未找到缓存（黑色线） 缓存未过期（蓝色线） 缓存已过期（红色线）缓存过期判断服务器文件是否更新的两种方法： 将本地文件的最后修改时间发会服务器，check下文件是否已更新，如果没有，不下载新的文件，只需要更新本地缓存文件的过期时间 客户端文件有版本好，当服务器更新了版本，再次请求时，服务器根据版本判断缓存是否需要更新 通过HTTP-HEADER控制缓存： Expires和Cache-Control: HTTP1.0使用Expires，1.1为Cache-Control:max-age规定了缓存的有效时间 Last-Modified/If-Modified-Since: 缓存过期后，check服务端文件是否更新的第一种方式 ETag/If-None-Match: 缓存过期时check服务端文件是否过期的第二种方式 无法被浏览器缓存的请求： HTTP头中：Cache-Control:no-cache, pragma:no-cache (HTTP1.0), Cache-Control:max-age=0 需要根据Cookie，认证信息等决定输入内容的动态请求不能被缓存 POST请求无法被缓存 5. HTTP &amp; WebSocket5.1 协议 HTTP 1.0: 在一次 TCP 连接中只能完成一个 HTTP 请求 HTTP 1.1: keep-alive，在一次 TCP 连接中完成多个 HTTP 请求 Websocket: 借用HTTP协议来完成握手 12345Connection: UpgradeSec-WebSocket-Extensions: permessage-deflate; client_max_window_bitsSec-WebSocket-Key: km9iqxp+3H2ndD5zXkAczA==Sec-WebSocket-Version: 13Upgrade: websocket 5.2 通信方式比较： ajax轮询：浏览器隔几秒向服务器发起一个请求，询问服务器是否有新信息。需要服务器有很快的处理速度和资源。（速度） long poll：采用阻塞模式，客户端发起连接后，如果没消息，就一直不返回Response给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。需要有很高的并发，也就是说同时接待客户的能力。（场地大小） WebSocket：一次HTTP握手后，整个通讯过程是建立在该连接状态中。服务器可主动推送消息给客户端。 WebSocket和HTTP最大不同： WebSocket是一种双向通信协议。在建立连接后，WebSocket服务器端和客户端都能主动向对方发送或接收数据，就像Socket一样； WebSocket需要像TCP一样，先建立连接，连接成功后才能相互通信。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Linux基础知识","slug":"Linux基础知识","date":"2020-09-21T03:14:32.000Z","updated":"2021-07-13T03:15:08.753Z","comments":true,"path":"2020/09/21/Linux基础知识/","link":"","permalink":"https://elihe2011.github.io/2020/09/21/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"1. 负载均衡1.1 SLBSLB: Server Load Balance 通过设置虚拟服务地址（IP），将位于同一区域（Region）的多台云服务器（Elastic Compute Service，ECS）的资源虚拟成一个高性能、高可用的应用服务池；再根据应用指定的方式，将来自客户端的网络请求分发到云服务器池中 SLB服务会检查云服务器池中ECS的健康状态，自动隔离异常状态的ECS，从而解决了单台ECS的单点问题，同时提高了应用的整体服务能力 负载均衡算法： 轮询 (Round Robin) 最小连接 (Leaster Connections): 优先选择连接数最小的服务器 Source: 根据请求源IP的hash值来选择要转发的服务器，保证特定用户连接到相同服务器","text":"1. 负载均衡1.1 SLBSLB: Server Load Balance 通过设置虚拟服务地址（IP），将位于同一区域（Region）的多台云服务器（Elastic Compute Service，ECS）的资源虚拟成一个高性能、高可用的应用服务池；再根据应用指定的方式，将来自客户端的网络请求分发到云服务器池中 SLB服务会检查云服务器池中ECS的健康状态，自动隔离异常状态的ECS，从而解决了单台ECS的单点问题，同时提高了应用的整体服务能力 负载均衡算法： 轮询 (Round Robin) 最小连接 (Leaster Connections): 优先选择连接数最小的服务器 Source: 根据请求源IP的hash值来选择要转发的服务器，保证特定用户连接到相同服务器 1.2 LVSLVS：Linux Virtual Server 当用户向负载均衡调度器(Director Server)发起请求，调度器将请求发送至内核空间 PREROUTING链首先会接收到用户请求，判断目标IP是否本机IP，将数据包发往INPUT链 IPVS工作在INPUT上，当用户请求到达INPUT时，IPVS会将用户请求和定义好的集群服务进行比对，如果请求时集群服务，那么IPVS将强行修改数据包里的目标IP和端口，并将新数据包发往POSTROUTING链 POSTROUTING链接收数据包后发现目标IP地址刚好时自己的后端服务器，通过选路，将数据包最终发送给后端服务器 LVS 程序组成： ipvs: ip virtual server, 工作在内核空间的一段代码，实现负载均衡调度 ipvsadm: 工作在用户空间，负责ipvs内核框架的编写规则 iptables 内置的4个表: filter: 包过滤 nat: 网络地址转换 mangle: 包重构(修改) raw: 数据跟踪处理 链（chains）: 数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一 条或数条规则 默认包括5种规则链 INPUT：处理入站数据包 OUTPUT：处理出站数据包 FORWARD：处理转发数据包 POSTROUTING链：在进行路由选择后处理数据包（对数据链进行源地址修改转换） PREROUTING链：在进行路由选择前处理数据包（做目标地址转换） 2. 高可用软件 Heartbeat：可实现对服务器资源（IP即程序服务等资源）的监控和管理，并在出现故障的情况下，将资源集合从一台已经故障的计算机快速转移到另一台机器上继续提供服务 Keepalived: 通过IP漂移，实现服务的高可用：服务器集群共享一个虚拟IP，同一时间只有一个服务器占有虚拟IP并对外提供服务，若该服务器不可用，则虚拟IP漂移到另一台服务器并对外提供服务 对LVS应用服务器集群状态进行监控：若应用不可用，则keepalived将其从集群中摘除，若服务器恢复，将其加入集群中 3. 弹性伸缩弹性伸缩（Auto Scaling): 根据业务需求和伸缩策略，自动调整计算机资源。请求高峰时，自动增加业务实例数量，以保证性能不受影响；请求低谷时，自动释放业务实例数量以减低成本 4. 孤儿进程 &amp; 僵尸进程孤儿进程：父进程退出，但它的子进程还在运行，那么这些进程即为孤儿进程。孤儿进程会被init进程（PID=1）接收，并由init进程堆它们完成状态收集工作 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程未调用wait或waitpid获取子进程状态，那么子进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 5. epoll &amp; select epoll 和 select 都是I/O多路复用技术，都实现同时监听多个I/O事件的状态 epoll 比 select 高效，主要基于其操作系统支持的 I/O 事件通知机制，而select是基于轮询机制 epoll 支持水平触发和边缘触发两种模式 6. ping IP 根据目地IP和路由表决定走哪个网卡 根据网卡子网掩码判断目的IP是否在子网内 如果不在子网内，则通过arp缓存查询IP的网卡地址，不存在的话先通过广播询问目的IP的mac地址，该地址会缓存下来 根据获取的mac地址，然后发包 7. 解决hash冲突的办法7.1 开放地址法即 再散列法，基本思想：当关键字key的哈希地址p=H(key) 出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。 线性探测再散列：冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。 二次探测再散列：冲突发生时，在表的左右进行跳跃式探测，比较灵活 （1^2，-1^2， …) 伪随机探测再散列: 建立一个伪随机数发生器，并给定一个随机数做起点 7.2 再哈希法使用不同的哈希函数，直到冲突解决 缺点：耗时较长 7.3 链地址法将哈希值相同的元素构成一个同义词的单链表，并将单链表的头指针存放在哈希表的第i个单元中，查找、插入和删除主要在同义词链表中进行。链表法适用于经常进行插入和删除的情况。 7.4 建立一个公共溢出区将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。 8. Gitgit rebase 1234567891011121314151617# 1. 合并多次提交记录git rebase -i HEAD~4 # 最近四次git rebase --edit-todo # 异常退出vi时执行git rebase --continue # 返回继续编辑# 2. 合并分支 git checkout mastergit pullgit checkout devgit rebase master # 将master最新分支同步到当前分支git rebase --continue # 有冲突，并解决冲突后执行git rebase --abort # 有冲突，放弃，回到rebase前的状态git checkout mastergit merge devgit push git rebase master 做了哪些操作？ 先取消当前dev分支的提交记录 将在当前dev中新开发的代码保存成patch文件，存入.git/rebase目录下 当前dev分支合并最新的master分支 将patch文件应用到当前dev分支 在 dev 分支，使用 git rebase master，然后就会把 dev 接到 master 分支之上。Git 是这么做的： 首先，找到这两条分支的最近公共祖先 LCA 然后，从 master 节点开始，重演 LCA 到 dev 几个 commit 的修改，如果这些修改和 LCA 到 master 的 commit 有冲突，就会提示你手动解决冲突 最后，把 dev 的分支完全接到 master 上面。 9. 进程、线程、协程9.1 进程进程：程序的执行过程，包括了动态创建、调度和消亡的整个过程，是程序资源管理的最小单位 多进程模型：启动多个服务进程。由于多进程地址空间不同，数据不能共享，需要搭建各个进程间的通信桥梁，即IPC (InterProcess Communication) 常见IPC类型 管道 Pipe：一个内核缓冲区，以先进先出FIFO的方式从缓冲区存取数据；以半双工方式通信，数据只能单向流动，且只能在父子进程间通信 命名管道FIFO：以文件形式存于文件系统中 /tmp/fifo, 只要可以访问该文件的进程，均可通信 信号 Signal：用户空间进程和内核直接交互，内核可利用信号来通知用户空间进程发生哪些系统事件 消息队列 Message Queue：存放在内核中的消息链表，每个消息队列由消息队列标识符表示，只在内核重启或主动删除时，消息队列才会被删除 共享内存 Shared memory：多个进程可以直接读写同一块内存空间，是最快的IPC 套接字 Socket：通过网络接口将数据发送到本机的不同进程或远程计算机的进程 9.2 线程线程：进程中，资源调度的最小单位 多线程模型： 线程同步：线程之间的一种直接制约关系，一个线程的执行依赖另一个线程的通知，当它没有得到另一个线程的通知时必须等待，直到消息到达时才被唤醒。 线程互斥：多线程对资源访问的排他性，即多个线程要使用某个共享资源时，任何时刻最多只允许一个线程获得该共享资源的使用权 多线程同步和互斥方法： 互斥锁 条件变量 读写锁 自旋锁：线程反复去获取锁，但这个锁被其他线程占用，此线程将会等待，间隔一段时间后再次尝试获取。这种循环加锁的等待机制被称为自旋锁(spinlock) 信号量 9.3 协程协程：一种比线程更轻量化的微线程 协程优势： 协程在线程内实现，因此始终在一个线程中共享资源，不存在多线程抢占资源和资源同步问题 生产者协程和消费者协程，相互配合协作完成工作，而不是相互抢占 协程的创建和切换开销比线程小的多 9.4 总结进程、线程、协程的关系和区别： 进程拥有独立的堆和栈，既不共享堆，也不共享栈，由操作系统负责调度。 线程拥有独立的栈和共享的堆，由操作系统负责调度（内核线程）。 协程拥有独立的栈和共享的堆，有 golang 的调度器负责调度。 9.5 实现自旋锁12345678910111213141516type SpinLock uint32func NewSpinLock() *SpinLock &#123; var lock SpinLock return &amp;lock&#125;func (sl *SpinLock) Lock() &#123; for !atomic.CompareAndSwapUint32((*uint32)(sl), 0, 1) &#123; runtime.Gosched() &#125;&#125;func (sl *SpinLock) Unlock() &#123; atomic.StoreUint32((*uint32)(sl), 0)&#125; 10. 函数递归问题为什么递归“效率低”？ 函数调用开销问题：函数调用前，需要做许多工作，比如准备函数内局部变量使用的空间、保存函数的参数，记录函数调用位置等，这些操作较为耗资源。 某些递归算法，本身存在低效问题。斐波那契中求某一项，子问题会大量重复出现，产生大量重复计算，效率低下 不断入栈出栈操作 栈容量的限制，可能导致stack overflow 11. 压测工具 vegeta： 高性能http(s)负载测试工具。它是一个负载测试工具而不是基准测试工具。基准测试试图找到系统在峰值容量下所能承受的极限，而负载测试则倾向于讲述系统在不同的负载点和配置下的表现。 1echo &quot;GET http://10.137.8.40&quot; | vegeta attack -rate=20000 -duration=60s | tee test.dat | vegeta report -ouput test-result.dat ​ QPS: query per second goconvey: 集成go test, 支持Web-GUI 关于goconvey，下面说法正确的是（ABC）A. goconvey是一个支持golang的单元测试框架B. goconvey能够自动监控文件修改并启动测试，并可以将测试结果实时输出到web界面C. goconvey提供了丰富的断言简化测试用例的编写D. goconvey无法与go test集成 123456func TestStringSliceEqual(t *testing.T) &#123; Convey(&quot;TestStringSliceEqual should return true when a != nil &amp;&amp; b != nil&quot;, t, func() &#123; a := []string&#123;&quot;hello&quot;, &quot;goconvey&quot;&#125; b := []string&#123;&quot;hello&quot;, &quot;goconvey&quot;&#125; &#125;)&#125; GoStub GoStub框架的使用场景如下：A、为一个全局变量打桩B、为一个函数打桩C、为一个过程打桩D、由任意相同或不同的基本场景组合而成 12. 字符编码大端 (LitteEndian)：高位写左边，从左向右读 小端 (LitteEndian)：高位写右边，从右向左读","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Go 相关概念","slug":"Go 相关概念","date":"2020-07-17T03:42:23.000Z","updated":"2021-06-22T10:50:49.750Z","comments":true,"path":"2020/07/17/Go 相关概念/","link":"","permalink":"https://elihe2011.github.io/2020/07/17/Go%20%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","excerpt":"1. 逃逸分析1.1 堆和栈： 堆（Heap）： 一般情况下，手动申请、分配、释放。内存大小并不定，较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 堆在内存分配中类似于往一个房间里摆放各种家具，家具的尺寸有大有小。 引用类型 (指针、slice、map、chan、interface)的地址对应的数据存储内存通常分配在堆上 栈（Stack）： 由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数，局部变量等等都会存放在栈上 栈是一种拥有特殊规则的线性表数据结构,只允许线性表的一端放入数据,之后再这一端取出数据,按照后进先出(lifo)的顺序 值类型 (整型、浮点型、bool、string、array和struct) 的变量直接存储值，内存通常分配在栈上","text":"1. 逃逸分析1.1 堆和栈： 堆（Heap）： 一般情况下，手动申请、分配、释放。内存大小并不定，较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 堆在内存分配中类似于往一个房间里摆放各种家具，家具的尺寸有大有小。 引用类型 (指针、slice、map、chan、interface)的地址对应的数据存储内存通常分配在堆上 栈（Stack）： 由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数，局部变量等等都会存放在栈上 栈是一种拥有特殊规则的线性表数据结构,只允许线性表的一端放入数据,之后再这一端取出数据,按照后进先出(lifo)的顺序 值类型 (整型、浮点型、bool、string、array和struct) 的变量直接存储值，内存通常分配在栈上 1.2 逃逸分析逃逸分析就是确定一个变量要放堆上还是栈上，规则如下： 是否有在其他地方（非局部）被引用。只要有可能被引用了，那么它一定分配到堆上。否则分配到栈上 即使没有被外部引用，但对象过大，无法存放在栈区上。依然有可能分配到堆上 1.3 需要逃逸的原因频繁申请、分配堆内存是有一定 “代价” 的。会影响应用程序运行的效率，间接影响到整体系统。因此 “按需分配” 最大限度的灵活利用资源，才是正确的治理之道 1.4 查看逃逸分析1.4.1 通过编译器命令，就可以看到详细的逃逸分析过程1234go build -gcflags &#x27;-m -l&#x27; main.go-m: 进行内存分配分析-l: 禁用掉 inline 函数内联, 避免程序内联 1.4.2 通过反编译命令查看1go tool compile -S main.go 1.5 逃逸案例1.5.1 指针1) 外部引用，逃逸 1234567891011121314151617type User struct &#123; ID int Name string Age byte&#125;func GetUser() *User &#123; return &amp;User&#123; ID: 1, Name: &quot;jack&quot;, Age: 12, &#125;&#125;func main() &#123; _ = GetUser()&#125; 12345678$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:10:9: &amp;User literal escapes to heap$ go tool compile -S main.go | grep CALL 0x0028 00040 (main.go:10) CALL runtime.newobject(SB) 0x005f 00095 (main.go:9) CALL runtime.morestack_noctxt(SB) 2）外部未引用，不逃逸 1234func main() &#123; s := new(string) *s = &quot;abc&quot;&#125; 12345$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:4:10: new(string) does not escape$ go tool compile -S main.go | grep CALL 1.5.2 未确定类型1234567func main() &#123; s := new(string) *s = &quot;abc&quot; //fmt.Println(*s) // not escape fmt.Println(s) // escape to heap&#125; 原因：func Println(a ...interface&#123;&#125;) (n int, err error)接收任意类型，在编译时无法确定具体类型，因此产生逃逸 1.5.3 泄漏参数12345678910111213type User struct &#123; ID int Name string Age byte&#125;func GetUser(u *User) *User &#123; return u&#125;func main() &#123; _ = GetUser(&amp;User&#123;ID: 1, Name: &quot;jack&quot;, Age: 12&#125;)&#125; 1234$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:9:14: leaking param: u to result ~r1 level=0./main.go:14:14: &amp;User literal does not escape 使其逃逸：被外部所引用，将分配到堆上 12345678910111213type User struct &#123; ID int Name string Age byte&#125;func GetUser(u User) *User &#123; return &amp;u&#125;func main() &#123; _ = GetUser(User&#123;ID: 1, Name: &quot;jack&quot;, Age: 12&#125;)&#125; 123$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:9:14: moved to heap: u 2. new和make： new： 分配内存 设置零值 返回指针（重要） make: sice, map, chan 分配内存 返回对象 (对象本身为引用类型，不需要返回指针) 3. Go类型断言：1) Type Assertion 12t := o.(T)t, ok := o.(T) 2) Type Switch 123456switch o.(type) &#123;case int:case string:case nil:...&#125; 4. slice4.1 slice扩容的内存管理 翻新扩展：当前元素为 kindNoPointers，将在老 Slice cap 的地址后继续申请空间用于扩容 举家搬迁：重新申请一块内存地址，整体迁移并扩容 cap &lt; 1024: cap = cap * 2cap &gt;= 1024: cap = cap + cap/4 4.2 empty &amp; nil slicelen 和 cap 均等于0 1) empty: arary -&gt; []int&#123;&#125; 指向空数组 12s := []int&#123;&#125;s = make([]int, 0) 2) nil: array -&gt; nil 1var s []int 5. 指针5.1 空指针12345678910func main() &#123; var p1 *int var p2 = new(int) fmt.Println(p1 == nil) // true fmt.Println(p2 == nil) // false fmt.Println(*p1) // panic: nil pointer dereference fmt.Println(*p2) // 0&#125; 6. slice 参数 可通过下标修改原始slice的元素值 append操作，会改变slice指向的底层数组 1234567891011121314151617181920func main() &#123; a := make([]int, 1, 2) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a) foo(a) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a) bar(&amp;a) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a)&#125;func foo(a []int) &#123; a[0] = 9 // slice副本指向的 array 未变，所以能够修改原始 a 的值 a = append(a, 1, 2) // append操作，a指向的地址改变 fmt.Printf(&quot;%p\\n&quot;, &amp;a)&#125;func bar(a *[]int) &#123; *a = append(*a, 5, 6)&#125; 7. 并发读写mapfatal error: concurrent map read and map write 123456789101112131415func mapTest() &#123; m := make(map[int]int) go func() &#123; for &#123; m[0] = 1 &#125; &#125;() go func() &#123; for &#123; _ = m[0] &#125; &#125;()&#125; 解决方案：sync.Map 12345678910111213141516171819202122232425func main() &#123; //mapTest() syncMap() select &#123; case &lt;-time.After(time.Second): break &#125;&#125;func syncMap() &#123; m := sync.Map&#123;&#125; go func() &#123; for &#123; m.Store(0, 1) &#125; &#125;() go func() &#123; for &#123; _, _ = m.Load(0) &#125; &#125;()&#125; 8. Go 接口Go 接口为非侵入式接口 非侵入式接口: 接口的定义者无需知道接口被哪些类型实现了, 而接口的实现者也不需要知道实现了哪些接口, 无需指明已经实现了哪些接口, 只需要关注自己实现的是什么样的接口即可. 编译器会自己识别哪个类型实现哪些接口 侵入式接口: 主要体现是实现接口的类需要很明确的声明自己实现了哪个接口 9. Go 并发CSP: Communicating Sequential Process 通信顺序进程，消息传递模型 Goroutine: 轻量级线程, 简称协程。一个Goroutine 的栈启动很小(2k或者4k)。当Goroutine的栈空间不够的时候,会根据需要动态伸缩栈大小(甚至可到到1G)。 Go 语言线程模型： M: 内核线程（物理线程） P: 执行Go代码所必须的资源（上下文环境） G: 待执行的Go代码，即协程本身 9.1 sync.Mutex 互斥锁解决 goroutine 抢占公共资源问题 12345678910111213141516171819202122232425var m = make(map[int]int)var lock sync.Mutexfunc main() &#123; for i := 1; i &lt;= 10; i++ &#123; go factorial(i) &#125; time.Sleep(time.Second * 2) for k, v := range m &#123; fmt.Printf(&quot;%d!=%d\\n&quot;, k, v) &#125;&#125;func factorial(n int) &#123; res := 1 for i := 1; i &lt;= n; i++ &#123; res *= i &#125; lock.Lock() m[n] = res lock.Unlock()&#125; 9.2 并发数据同步1234567891011121314151617181920212223242526272829303132func add(n int) &#123; defer wg.Done() // method1: Found 1 data race for i := 0; i &lt; n; i++ &#123; runtime.Gosched() c++ &#125; // method2: 正常 /* for i := 0; i &lt; n; i++ &#123; atomic.AddInt64(&amp;c, 1) runtime.Gosched() &#125;*/ // method3: 正常 /* defer lock.Unlock() lock.Lock() for i := 0; i &lt; n; i++ &#123; c++ &#125;*/&#125;func main() &#123; wg.Add(2) go add(3) go add(4) wg.Wait() fmt.Println(&quot;c =&quot;, c)&#125; 检测并发竞争状态：go run --race main.go sync.WaitGroup: 等待组。用于等待一组线程的结束。 123func (wg *WaitGroup) Add(delta int) // 等待个数计数器func (wg *WaitGroup) Done() // 子线程结束，计数器减1func (wg *WaitGroup) Wait() // 阻塞等待所有子线程结束，即计数器为0 sync/atomic: 原子操作包。以底层的加锁机制来同步访问整型变量和指针。 123func AddInt64(addr *int64, delta int64) (new int64)func LoadInt64(addr *int64) (val int64)func StoreInt64(addr *int64, val int64)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Context","slug":"Go Context","date":"2020-07-16T03:20:08.000Z","updated":"2021-06-22T10:50:49.749Z","comments":true,"path":"2020/07/16/Go Context/","link":"","permalink":"https://elihe2011.github.io/2020/07/16/Go%20Context/","excerpt":"1. 简介context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据 1.1 结构图","text":"1. 简介context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据 1.1 结构图 1.2 Context interface12345678910111213type Context interface &#123; // 标识deadline是否已经设置了, 没有设置时, ok的值是false, 并返回初始的time.Time Deadline() (deadline time.Time, ok bool) // 返回一个channel, 当返回关闭的channel时可以执行一些操作 Done() &lt;-chan struct&#123;&#125; // 描述context关闭的原因,通常在Done()收到关闭通知之后才能知道原因 Err() error // 获取上游Goroutine 传递给下游Goroutine的某些数据 Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 方法说明： Deadline: 设置截止时间。第一个参数表示截止时间点，第二个参数是否设置了截止时间。未设置截止时间，需要通过cancel()来取消 Done(): 在被cancel时返回的一个只读通道 Err(): 被cancel的原因 Value(): 绑定到Context上的值 1.3 emptyCtx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// An emptyCtx is never canceled, has no values, and has no deadline. It is not// struct&#123;&#125;, since vars of this type must have distinct addresses.type emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123; return&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil&#125;func (*emptyCtx) Err() error &#123; return nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return nil&#125;func (e *emptyCtx) String() string &#123; switch e &#123; case background: return &quot;context.Background&quot; case todo: return &quot;context.TODO&quot; &#125; return &quot;unknown empty Context&quot;&#125;var ( background = new(emptyCtx) todo = new(emptyCtx))// Background returns a non-nil, empty Context. It is never canceled, has no// values, and has no deadline. It is typically used by the main function,// initialization, and tests, and as the top-level Context for incoming// requests.func Background() Context &#123; return background&#125;// TODO returns a non-nil, empty Context. Code should use context.TODO when// it&#x27;s unclear which Context to use or it is not yet available (because the// surrounding function has not yet been extended to accept a Context// parameter).func TODO() Context &#123; return todo&#125; 1.4 cancelCtx对外暴露了 Err() Done() String() 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// A cancelCtx can be canceled. When canceled, it also cancels any children// that implement canceler.type cancelCtx struct &#123; Context mu sync.Mutex // protects following fields done chan struct&#123;&#125; // created lazily, closed by first cancel call children map[canceler]struct&#123;&#125; // set to nil by the first cancel call err error // set to non-nil by the first cancel call&#125;func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; c.mu.Lock() if c.done == nil &#123; c.done = make(chan struct&#123;&#125;) &#125; d := c.done c.mu.Unlock() return d&#125;func (c *cancelCtx) Err() error &#123; c.mu.Lock() err := c.err c.mu.Unlock() return err&#125;func (c *cancelCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithCancel&quot;, c.Context)&#125;// cancel closes c.done, cancels each of c&#x27;s children, and, if// removeFromParent is true, removes c from its parent&#x27;s children.func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; if err == nil &#123; panic(&quot;context: internal error: missing cancel error&quot;) &#125; c.mu.Lock() if c.err != nil &#123; c.mu.Unlock() return // already canceled &#125; c.err = err if c.done == nil &#123; c.done = closedchan &#125; else &#123; close(c.done) &#125; for child := range c.children &#123; // NOTE: acquiring the child&#x27;s lock while holding parent&#x27;s lock. child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() if removeFromParent &#123; removeChild(c.Context, c) &#125;&#125; 1.5 valueCtx通过 valueCtx 结构知道仅是在Context 的基础上增加了元素 key 和 value 1234567891011121314151617// A valueCtx carries a key-value pair. It implements Value for that key and// delegates all other calls to the embedded Context.type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125;func (c *valueCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithValue(%#v, %#v)&quot;, c.Context, c.key, c.val)&#125;func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; return c.Context.Value(key)&#125; 1.6 timerCtx在cancelCtx 基础上增加了字段 timer 和 deadline 12345678910111213141516171819202122232425262728type timerCtx struct &#123; cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time&#125;func (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123; return c.deadline, true&#125;func (c *timerCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithDeadline(%s [%s])&quot;, c.cancelCtx.Context, c.deadline, time.Until(c.deadline))&#125;func (c *timerCtx) cancel(removeFromParent bool, err error) &#123; c.cancelCtx.cancel(false, err) if removeFromParent &#123; // Remove this timerCtx from its parent cancelCtx&#x27;s children. removeChild(c.cancelCtx.Context, c) &#125; c.mu.Lock() if c.timer != nil &#123; c.timer.Stop() c.timer = nil &#125; c.mu.Unlock()&#125; 2. 使用示例 通过 Background() 和 TODO() 创建最 emptyCtx 实例 ,通常是作为根节点 通过 WithCancel() 创建 cancelCtx 实例 通过 WithValue() 创建 valueCtx 实例 通过 WithDeadline 和 WithTimeout 创建 timerCtx 实例 2.1 WithCancel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func Operate1(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Operate1 done.&quot;) return default: fmt.Println(&quot;Operate1&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func Operate2(ctx context.Context) &#123; fmt.Println(&quot;Operate2&quot;)&#125;func Do1(ctx context.Context) &#123; go Do2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Do1 done.&quot;) fmt.Println(ctx.Err()) return default: fmt.Println(&quot;Do1:&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func Do2(ctx context.Context) &#123; go Operate1(ctx) go Operate2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Do2 done.&quot;) fmt.Println(ctx.Err()) return default: fmt.Println(&quot;Do2:&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) go Do1(ctx) time.Sleep(5 * time.Second) fmt.Println(&quot;Stop all goroutines&quot;) cancel() time.Sleep(2 * time.Second)&#125; 2.2 WithDeadline12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func task1(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(ctx.Err()) return default: fmt.Println(&quot;task1:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func task2(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(ctx.Err()) return default: fmt.Println(&quot;task2:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func main() &#123; after5Sec := time.Now().Add(5 * time.Second) ctx, cancel := context.WithDeadline(context.Background(), after5Sec) defer cancel() go task1(ctx) go task2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Main done:&quot;, ctx.Err()) return &#125; &#125;&#125; 2.3 WithTimeout12345678910111213141516171819202122232425262728293031323334353637func task(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;task is done.&quot;) return default: fmt.Println(&quot;task:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithTimeout(context.Background(), 6*time.Second) defer cancel() go task(ctx) n := 1 for &#123; select &#123; case &lt;-time.Tick(2 * time.Second): if n == 9 &#123; return &#125; fmt.Printf(&quot;n=%d\\n&quot;, n) n++ //case &lt;-ctx.Done(): // fmt.Println(&quot;Main done:&quot;, ctx.Err()) // return &#125; &#125;&#125; 2.4 WithValue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func v1(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;v1 done:&quot;, ctx.Err()) return default: fmt.Println(ctx.Value(&quot;key&quot;)) time.Sleep(3 * time.Second) &#125; &#125;&#125;func v2(ctx context.Context) &#123; fmt.Println(ctx.Value(&quot;key&quot;)) fmt.Println(ctx.Value(&quot;v3&quot;)) ctx = context.WithValue(ctx, &quot;key&quot;, &quot;modify from v2&quot;) go v1(ctx)&#125;func v3(ctx context.Context) &#123; if v := ctx.Value(&quot;key&quot;); v != nil &#123; fmt.Println(&quot;Key =&quot;, v) &#125; ctx = context.WithValue(ctx, &quot;v3&quot;, &quot;value of v3&quot;) go v2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;v3 done:&quot;, ctx.Err()) return default: fmt.Println(&quot;v3&quot;) time.Sleep(2 * time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) ctx = context.WithValue(ctx, &quot;key&quot;, &quot;main&quot;) go v3(ctx) time.Sleep(10 * time.Second) cancel() time.Sleep(3 * time.Second)&#125; 3. 其他示例3.1 关闭协程3.1.1 使用channel1234567891011121314151617181920212223242526272829func main() &#123; c := make(chan bool) for i := 0; i &lt; 5; i++ &#123; go monitor(c, i) &#125; time.Sleep(time.Second) // 关闭channel close(c) time.Sleep(5 * time.Second) fmt.Println(&quot;Done&quot;)&#125;func monitor(c chan bool, num int) &#123; for &#123; select &#123; case v := &lt;-c: fmt.Printf(&quot;Monitor[%d], receive [%v], stopping.\\n&quot;, num, v) return default: fmt.Printf(&quot;Monitor[%d] is running now.\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.1.2 使用Context1234567891011121314151617181920212223242526272829func main() &#123; ctx, cancel := context.WithCancel(context.Background()) for i := 0; i &lt; 5; i++ &#123; go monitor(ctx, i) &#125; time.Sleep(time.Second) // 取消操作 cancel() time.Sleep(5 * time.Second) fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case v := &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d], receive [%v], stopping.\\n&quot;, num, v) return default: fmt.Printf(&quot;Monitor[%d] is running now.\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.2 WithDeadline 和 WithTimeout123456789101112131415161718192021222324252627282930func main() &#123; //ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Second)) ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := 0; i &lt; 5; i++ &#123; go monitor(ctx, i) &#125; time.Sleep(5 * time.Second) if err := ctx.Err(); err != nil &#123; fmt.Printf(&quot;Reason: %v\\n&quot;, err) &#125; fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d] stopped.\\n&quot;, num) return default: fmt.Printf(&quot;Monitor[%d] is running...\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.3 WithValue1234567891011121314151617181920212223242526272829303132func main() &#123; ctx1, cancel := context.WithCancel(context.Background()) ctx2, cancel := context.WithTimeout(ctx1, time.Second) ctx3 := context.WithValue(ctx2, &quot;name&quot;, &quot;jack&quot;) defer cancel() for i := 0; i &lt; 5; i++ &#123; go monitor(ctx3, i) &#125; time.Sleep(5 * time.Second) if err := ctx3.Err(); err != nil &#123; fmt.Printf(&quot;Reason: %v\\n&quot;, err) &#125; fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d] stopped.\\n&quot;, num) return default: value := ctx.Value(&quot;name&quot;) fmt.Printf(&quot;Monitor[%d] is running, value is %v\\n&quot;, num, value) time.Sleep(2 * time.Second) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"MySQL","slug":"MySQL","date":"2020-03-24T05:19:50.000Z","updated":"2021-10-19T11:36:51.268Z","comments":true,"path":"2020/03/24/MySQL/","link":"","permalink":"https://elihe2011.github.io/2020/03/24/MySQL/","excerpt":"1. 简介1.1 架构图 1.2 SQL 执行流程","text":"1. 简介1.1 架构图 1.2 SQL 执行流程 连接器: 处理客户端的连接、获取用户权限、维持和管理连接 查询缓存: 连接器拿到查询SQL后，先通过key-value方式查询缓存，如果缓存存在则直接返回。但是，它非常容易失效，只要表进行了更新，该表相关的所有查询缓存都会被清空。MySQL 8.0 已删除该功能 1SELECT @@query_cache_type; 分析器: 词法分析 (识别关键字，操作，表名，列名) 语法分析 (判断是否符合语法） 优化器: 决定使用哪个索引；有多表关联时，决定表的连接顺序。最后输出执行方案 执行器: 执行SQL时，先判断用户是否对表有查询权限。如果没有，返回没有权限的错误。如果有权限，执行语句扫描表中的数据 1.3 数据类型 DECIMAL：高精度。float/double 浮点数近似值 CHAR：定长，存取效率高；VARCHAR变长，节约磁盘空间。 VARCHAR(50)和VARCHAR(200): 存储相同字符串，所占空间相同，但后者在排序时会消耗更多内存，因为order by采取fixed_length计算col长度。 INT(10): 10表示数据的长度，不是存储数据的大小。 CHAR(10): 10位固定字符串，不足补空格 VARCHAR(10): 10位可变字符串，不补空格 TEXT/BLOB：尽量避免使用，查询时会使用临时表，导致严重性能开销 TIMESTAMP：比 datetime 空间效率高 2. 引擎 MyISAM InnoDB 存储结构 每张表三个文件：表结构(.frm)，表数据(.MYD)，表索引(.MYI) 所有表存储在一个或多个文件中，甚至独立的表空间文件中。 存储空间 可被压缩，存储空间减小 需要更多的内存和存储，会在内存中建立其专用的缓冲池用于高速缓冲数据和索引 备份恢复 通过拷贝表相关的三个文件即可 拷贝数据文件、备份binlog，或使用mysqldump。 文件格式 数据和索引分开存储 .MYD &amp; .MYI 数据和索引集中存储 .idb 存储顺序 按记录插入顺序保存 按主键大小有序插入 外键 不支持 支持 事务 不支持 支持 锁 表锁，不适合高并发 表锁、行锁，适合高并发 SELECT MyIASM 更优 I &amp; U &amp; D InnoDB 更优 索引实现方式 B+树，堆表 B+树，索引组织表 哈希索引 不支持 支持 全文索引 支持 不支持 2.1 聚簇索引 聚簇索引：叶节点存储了行数据、主键及其他索引的列数据。主键索引、覆盖索引都非常高效。 非聚簇索引：叶节点只存储了行数据地址，需要再次寻址才能得到数据 InnoDB: 主键使用聚簇索引 MyISAM: 主键和普通索引，都是非聚合索引 聚簇索引优点：数据检索高效 聚簇索引缺点： 插入速度严重依赖插入顺序 更新主键代价很高，会导致被更新行移动 二级索引访问需要两次索引查找，第一次找主键，第二次根据主键找到数据 2.2 InnoDB支持事务、行锁、外键约束，MyISAM均不支持。 InnoDB 的四大特性： 插入缓冲 (insert buffer) 二次写 (double write) 自适应哈希索引 (ahi) 预读 (read ahead) 3. 索引3.1 什么是索引索引是一种特殊的文件，它采用排序的数据结构，保存表中记录的引用指针。能实现快速检索表数据。底层实现为B树及B+树。 索引原理： 把创建了索引的列进行排序 把排序结果生成倒排表 在倒排表内容上拼上数据地址链 查询时，先拿到倒排表内容，再取出地址链，从而拿到具体数据 索引的优缺点： 优点：提高了数据的检索速度 缺点： 时间方面：创建和维护索引，到要消耗时间。对表数据进行写操作，索引也要进行维护，从而降低了执行效率 空间方面：需要占用额外的磁盘 使用场景： where order by, group by join 覆盖索引：select 的字段，都建立了索引，此时将直接从索引表返回数据，不需要再次扫描数据表。索引覆盖能够很大的提高查询效率。 3.2 数据结构3.2.1 BTree &amp; B+Tree BTree B+Tree 所有节点都有数据指针 只有叶子节点有数据指针 key可能不在叶子节点上，因此搜索需要更多时间 key都在叶子节点上，因此搜索更快，更准 树中没有key的重复项 key重复，所有节点都在叶子上 插入会耗费更多时间 插入容易 内部节点删除非常复杂，树需要进行大量转换 删除任何节点都很容易，因为所有节点都在叶子节点上 叶子节点不存储为结构链表 叶子节点存储为结构链表 没有多余的搜索键 可能存在冗余的搜索键 B+树优于B树的原因： B+树空间利用率更高，可减少IO次数，磁盘读写代价更低。因为B+树内部节点没有指向关键字具体信息的指针，只做索引使用，内部节点相对B树小 B+树的查询效率更加稳定。B+树所有关键字的查询路径长度相同，导致每个关键字的查询效率相当。 B+树增删节点的效率更高。 相关树总结： 平衡二叉树：基于二分法的策略提高数据的查找速度的二叉树的数据结构； 每个节点最多拥有两个子节点 Left-child &lt; Node &lt; Right-child 树的左右两边的层数相差最多一层 BTree: 平衡多路查找树，即查找路径不止两个 B+Tree: 非叶子节点：不保存关键字记录的指针，只进行数据索引 叶子节点：保存父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样 查询方式： 主键索引区：PI, 关联数据的地址，按主键查询 普通索引区：SI, 关联id的地址，然后再到达上面的地址 3.2.2 哈希索引通过hash算法实现，常见hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法等 特点： 仅支持”=”,”IN”和”&lt;=&gt;”查询，不能使用范围 检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引 只有Memory存储引擎显示支持hash索引 3.2.3 全文索引全文索引：搜索引擎使用的一种关键技术，当前 MyISAM 和 InnoDB 均支持 123456789CREATE TABLE tbl_article( `id` INT(11) auto_increment primary key, `title` VARCHAR(64) not null default &#x27;&#x27;, `content` TEXT);# 全文索引ALTER TABLE tbl_article ADD FULLTEXT(content);SELECT * from tbl_article WHERE MATCH(content) AGAINST(&#x27;New York&#x27; IN NATURAL LANGUAGE MODE); 3.3 使用原则 最左前缀匹配严重：联合索引尤为重要 较频繁的查询条件字段，应建立索引 更新频繁的字段，不适合做索引 数量大量重复的字段，不适合做索引 尽量扩展索引，不要新建索引 外键列，一定要建索引 text, blob 不能建立普通索引 NULL值字段不要创建索引，应改为NOT NULL，并设置DEFAULT 索引字段越小越好，key过长会导致间接索引层次增加，性能降低 4. 事务事务：数据库执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。 4.1 ACID 特性 含义 原子性 Atomicity 事务作为一个整体被执行，要么全部成功，要么全部失败 一致性 Consistent 数据库无中间状态，数据库中的数据应满足完整性约束 隔离性 Isolation 多个事务并发执行，相互不影响 持久性 Durability 提交成功的事务，对数据库的修改是永久的，不可逆 4.2 隔离级别12345678SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125;SELECT @@global.tx_isolation;SELECT @@session.tx_isolation;SELECT @@tx_isolation;# 设置为 read uncommittedset session transaction isolation level read uncommitted; 级别 含义 脏读 不可重复读 幻读 读未提交 (Read Uncommitted) 一个事务可以读取到另一个事务还未提交的数据 Y Y Y 读已提交 (Read Committed) 事务中多次读取同一数据，都能读到其他事务提交的数据 N Y Y 可重复读 (Repeatable Read) 事务中多次读取同一数据，即使其他事务提交了该是数据，该数据在本事务中不会改变。 N N Y 可串行化 (Serializable) 事务串行执行，不允许并发 N N N 脏读：一个事务内，读取到了其他事务还没提交的数据。 不可重复读：一个事务内，多次读同一数据，如果另一个事务恰好修改了这个数据，那么在第一个事务中，两次读取的数据就可能不一致。 幻读：一个事务内，第一次查询某条记录，发现没有，但当试图更新这条不存在的记录时，竟然成功，并且再次读取同一条记录，竟然存在。 5. 锁5.1 锁的分类 操作颗粒度 表级锁(偏读)：偏向MyISAM引擎，开销少，加锁快；无死锁；锁定粒度大，锁冲突概率高，并发度低 行级锁(偏写)：偏向InnoDB引擎，开销大，加锁慢；会产生死锁；锁定粒度小，锁冲突概率低，并发度高 页锁：DBD引擎，开销介于行锁和表锁之间，会出现死锁 操作类型： 读锁(共享锁): 多个读操作可同时进行而不相互影响 写锁(排他锁): 写操作未完成前，它会阻断其他写锁和读锁 5.2 表级锁表读锁： 操作 session 1 (lock A read) session X 读A表 YES YES 写A表 NO NO 读写B表 NO YES 表写锁： 操作 session 1 (lock A write) session X 读A表 YES NO 写A表 YES NO 读写B表 NO YES 总结：读锁阻塞写，但不会阻塞读；而写锁会把读和写都阻塞。 123456789101112# 查看是否已加锁 in_use=1show open tables; lock table tbl_A read;lock table tbl_B write; unlock tables;# 表锁分析show status like &#x27;table_locks%&#x27;table_locks_immediate --产生表级锁的次数，每加一次表锁，自动累加1table_locks_waited --表级锁定后，发生等待的次数 5.3 行级锁行锁算法： Record lock: 单行记录上的锁 Gap lock： 间隙锁，锁定一个范围，不包括记录本身 Next-key lock: record+gap 锁定一个范围，包含记录本身 5.3.1 行锁123456789101112131415161718192021222324252627create table tbl_emp ( id int(11) auto_increment primary key, name varchar(20) not null default &#x27;&#x27;, age smallint(4) not null default 0);create index idx_name on tbl_emp(name);insert into tbl_emp values(1, &#x27;eli&#x27;, 34);insert into tbl_emp values(2, &#x27;rania&#x27;, 26);-- session 1set autocommit=0;update tbl_emp set age=32 where id=1;-- session 2set autocommit=0;update tbl_emp set age=33 where id=1; --lockedupdate tbl_emp set age=24 where id=2; --ok---索引失效，行锁变表锁---------- session 1set autocommit=0;update tbl_emp set age=18 where name=123; --索引失效，MySQL8.0直接错误-- session 2set autocommit=0;update tbl_emp set age=19 where name=&#x27;123&#x27;; --lockedupdate tbl_emp set age=28 where name=&#x27;eli&#x27;; --locked 5.3.2 间隙锁：当用范围作为检索条件时，InnoDB会将整个范围锁定，即使该范围内有不存在的记录。这些不存在的记录即为间隙(gap) 1234567891011121314151617create table tbl_gap( a int(10), b varchar(20));insert into tbl_gap values(1, &#x27;a&#x27;);insert into tbl_gap values(3, &#x27;a&#x27;);insert into tbl_gap values(4, &#x27;a&#x27;);insert into tbl_gap values(6, &#x27;a&#x27;);insert into tbl_gap values(7, &#x27;a&#x27;);-- session 1set autocommit=0;update tbl_gap set b=&#x27;x&#x27; where a &gt;=1 and a &lt;= 6;-- session 2set autocommit=0;insert into tbl_gap(a, b) values(2, &#x27;b&#x27;); --locked 5.3.3 锁定一行如何锁定一行： 1234begin;select * from tbl_a where id=5 for update;commit; select ... for update ...where ...的锁行为： 使用了索引，为行锁 未使用索引，为表锁 未查到数据，无锁 5.3.4 行锁总结 尽可能让所有数据检索通过索引来完成，避免无索引升级为表锁 尽可能减少检索条件，避免间隙锁 5.4 死锁死锁: 两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。 解决死锁： 1）如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可大大降低死锁机会。 2）同一事务中，尽可能做的一次锁定所需的所有资源，减少死锁产生的概率。 3）对非常容易产生死锁的业务，可尝试使用升级锁定颗粒度，通过表级锁来减少死锁发生的概率。 5.5 MVVC 悲观锁：想办法避免冲突。每次去拿数据时，都认为别人会修改，所以每次在拿数据时都上锁。 乐观锁：允许冲突，但发生冲突时，有能力解决。乐观的认为冲突不会发生，除非检测到确实产生了冲突 逻辑时钟 (Logical Clock) MVCC：Multi-version Concurrent Control 实现乐观锁： 12345678SELECT data AS old_data, version AS old_version FROM ...;UPDATE ... SET data = new_data, version = new_version WHERE version = old_version;if (updated_row &gt; 0) &#123;// 乐观锁获取成功，操作完成&#125; else &#123;// 乐观锁获取失败，回滚并重试&#125; MVCC 中的版本一般选择使用时间戳或者事务ID来标识。在处理一个写请求时，MVCC不是简单的有新值覆盖旧值，而是为这一项添加一个新版本数据。在读取一个数据项时，要先确定读取的版本，然后根据版本找到对应的数据。MVCC中的读操作永远不会被阻塞。 MVCC两种读形式： 快照读：读取的只是当前事务的可见版本，不用加锁。select * from tablename where id=xxx 即为快照读 当前读：读取当前版本，比如特殊的读操作，更新/插入/删除操作 123456select * from tablename where id=xxx lock in share mode;select * from tablename where id=xxx for update;update tablename set ...insert into tablename(xxx,) values(xxx,)delete from tablename where id=xxx; 6. 视图视图：本质上是一种虚拟表，在物理上不存在，其内容和真实的表相似。它的行和列来自定义视图的查询所引用基本表，在具体引用视图时动态生成。 6.1 特点 视图是由一个或多个实表产生的虚表 视图的建立和删除不影响基本表 对视图内容的更新(增删改)直接影响基本表 当视图来自多个基本表时，不允许添加和删除数据 6.2 使用场景视图的用途：优化SQL查询，提高开发效率 重用SQL语句 简化复杂的SQL操作。编写完查询后，可方便重用而不必关心查询细节 使用表的组成部分而不是整表 保护数据。可给用户授予表的部分数据访问权限而不是整个表 改变数据格式和表示。 6.3 优缺点 优点： 查询简单化 数据安全性 逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性 缺点： 性能。如果视图由一个复杂的多表查询定义，那么即使视图的一个简单查询，也需要花费一定的时间 修改限制。较复杂的视图，可能是不可修改的 7. 存储过程存储过程：一个预编译的SQL语句，允许模块化设计，即只要创建一次，后续可多次调用。 优点： 预编译的，执行效率高 存储过程代码直接放数据库，通过存储过程名称调用，减少网络通信 安全性高，执行存储过程需要一定的权限 可重复使用 缺点： 调试麻烦 移植困难 带引用关系的对象发生改变，受影响的存储过程、包将需要重新编译 维护困难。对于大型项目，多版本迭代的数据结构变化，存储过程维护会相当麻烦。 存储过程实例： 设置参数log_bin_trust_function_creators 123--创建函数，可能出错: This function has none of DETERMINISTIC...show variables like &#x27;log_bin_trust_function_creators&#x27;;set global log_bin_trust_function_creators=1; 创建函数，随机产生数据 123456789101112DELIMITER $$CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)BEGIN DECLARE chars VARCHAR(100) DEFAULT &#x27;abcdefghijk...LMNOPQRSTUVWXYZ&#x27;; DECLARE ret VARCHAR(255) DEFAULT &#x27;&#x27;; DECLARE i INT DEFAULT 0; WHILE i &lt; n DO SET ret = CONCAT(ret, SUBSTRING(chars, FLOOR(1+RAND()*52),1)); SET i = i + 1; END WHILE; RETURN ret;END$$ 创建存储过程 123456789101112DELIMITER $$CREATE PROCEDURE insert_emp(IN start INT(10), IN offset INT(10))BEGIN DECLARE i INT DEFAULT 0; SET autocommit=0; # REPEAT SET i = i + 1; INSERT INTO emp(name, ...) VALUES(rand_string(4), ...); UNTIL i = offset END REPEAT; COMMIT;END$$ 调用存储过程 1DELIMITER ;CALL insert_emp(100, 50); 8. 主从复制主从复制：将主库中的DDL和DML操作通过二进制日志(BINLOG) 传输到从库上，然后在从库上重现这些操作，使主从数据库一致 主从复制的用途： 主数据库宕机，切到从库继续工作 实现读写分离 数据库日常备份 主从复制流程： 主：binlog线程，记录下所有改变数据的日志到binlog中 从：io线程，从master上拉取binlog日志，并放入relay log中 从：sql执行线程，执行relay log中的语句 8.1 读写分离方案 mysql-proxy 优点：直接实现了读写分离和负载均衡，不用修改代码 缺点：性能低，不支持事务。不推荐使用 ORM实现 8.2 主从配置12345678910# master[mysqld]port=3306server-id=1log-bin=/data/mysql/mysql-binlog-err=/data/mysql/mysql-err# slave[mysqld]server-id=2 授权： 1234567891011121314# mastergrant replication save on *.* to &#x27;root@192.168.80.3&#x27; identified by &#x27;123456&#x27;;flush privileges;show master status\\G# slavechange master to master_host=&#x27;192.168.80.1&#x27;, master_user=&#x27;root&#x27;, master_password=&#x27;123456&#x27;, master_log_file=&#x27;mysql-bin.000002&#x27;, master_log_pos=1206;start slave;show slave status\\G...Salve_IO_Running: Yes # 成功Slave_SQL_Running: Yes... 9. SQL9.1 语句分类 DDL: CREATE, DROP, ALTER，TRUNCATE DQL: SELECT DML: INSERT, UPDATE, DELETE DCL: GRANT, REVOKE, COMMIT, ROLLBACK 9.2 关联查询 INNER JOIN LEFT JOIN：以左表为主，先查出左表，然后按照ON的关联条件匹配右表，没有匹配到用NULL填充。 RIGHT JOIN：以右表为主，先查出右表，然后按照ON的关联条件匹配左表，没有匹配到用NULL填充。 FULL OUTER JOIN ：MySQL不支持，但可实现 123SELECT * FROM A LEFT JOIN B A.id=B.aid UNION SELECT * FROM A RIGHT JOIN B A.id=B.aid; UNION：合并多个集合(联合查询的列必须一致)，相同的记录会合并 UNION ALL：不会合并重复行，效率比UNION低 9.3 子查询 条件：一条SQL语句的查询结果作为另一条查询语句的条件或查询结果 嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询 子查询的三种情况： 1）子查询是一个单行单例，使用“=” 1select * from users where age=(select max(age) from users); 2）子查询是一个多行单例，使用“in” 1select * from users where age in (select age from users where gender=&#x27;female&#x27;); 3）子查询是多行多列，结果集类似一张虚表，但不能使用where 123select * from dept d, (select * from users where age&gt;20) u where u.dept_id=d.id;select d.*, u.* from dept d inner join users u on d.id==u.dept_id where u.age&gt;20; 9.4 in &amp; existsin: 把外表和内表做hash连接 exists： 对外表做loop循环，每次loop循环再对内表进行查询 执行效率对比： 如果查询的两个表大小相当，in和exists差别不大 如果两个表中一个较小，一个较大，则子查询表大的用exists，子查询表小的on-going-in not exists 使用索引，但not in无法使用索引，所以not exists更高效 9.5 分页123SELECT * FROM table_name LIMIT 5; // 1~5SELECT * FROM table_name LIMIT 5,10; // 6~15SELECT * FROM table_name LIMIT 5,-1; // 6~end 9.6 查找字段相同的数据123select a.id from group_member a,(select group_id, user_id, status from group_member group by group_id, user_id, status having count(*) &gt; 1) bwhere a.group_id=b.group_id and a.user_id=b.user_id and a.status=b.status; 9.7 循环更新数据12UPDATE contact a INNER JOIN users b ON a.inviter=b.phone SET a.inviter_id=b.id;UPDATE contact a INNER JOIN users b ON a.invitee=b.phone SET a.invitee_id=b.id; 9.8 强制删除外键引用的表123SET FOREIGN_KEY_CHECKS = 0drop table users;SET FOREIGN_KEY_CHECKS = 1; 10. 日志10.1 undoLog事务回滚日志 insert undo log: 插入数据时产生，事务提交后丢弃 update undo log: 更新或删除数据时产生，快照读的时候需要所以不能直接删除，只有当系统没有比这个log更早的read-view的时候才能被删除 10.2 redoLog重做日志文件，记录数据修改之后的值，用于持久化到磁盘中 redo log buffer: 内存中的日志缓冲，易丢失 redo log file: 磁盘上的日志文件，持久化的。记录物理数据页修改的信息。当数据更新时，InnoDB会先将数据更新，然后记录redoLog在内存中，然后找个时间将redoLog持久化到磁盘。不管提交是否成功都要记录 10.3 binLog逻辑日志，记录sql的原始逻辑 数据修改时，binlog会追加写入指定大小的物理文件中，如果文件写满则创建一个新的文件写入；用于复制和恢复在主从复制中，从库利用主库的binlog进行重播。 binlog 的三种格式：statement, row 和 mixed statement：每一条修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候，需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。 row：不记录sql语句上下文信息，仅保存那条记录被修改。记录单元为每一行的改动，基本可以全部记录下来。但由于操作过多，导致大量行改动 (如：alter table)。此种模式的文件保存信息过多，日志量太大。（新版优化：当表结构发生变化时，记录操作语言，而不是行记录） mixed：折中方案。普通操作使用statement记录，当无法使用statement时使用row。 11. 查询分析11.1 问题分析 开启慢查询日志，设置阈值，比如超过5s即为慢SQL，将其记录下来 explain 分析慢SQL，可解决大部分问题 show profile，查询SQL的执行细节和生命周期 数据库参数调优 11.2 慢查询日志slow_query_log: 慢查询日志参数 long_query_time：慢查询SQL记录阈值，默认10s 123456789101112131415161718mysql&gt; show variables like &#x27;slow_query_log%&#x27;;+---------------------+------------------------------------+| Variable_name | Value |+---------------------+------------------------------------+| slow_query_log | OFF || slow_query_log_file | /var/lib/mysql/ubuntu20-a-slow.log |+---------------------+------------------------------------+mysql&gt; show variables like &#x27;long_query_time%&#x27;;+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+mysql&gt; set global slow_query_log=1;mysql&gt; set global long_query_time=5; 慢SQL分析工具：mysqldumpslow 11.3 explain11.3.1 explain 详解123456mysql&gt; explain select * from tbl_emp where id=1;+----+-------------+---------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+---------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| 1 | SIMPLE | tbl_emp | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL |+----+-------------+---------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 注意字段含义： id: 优先级 相同时，自上而下顺序执行 不同时，id值越大，越早执行 select_type: 查询类型 simple primary: 最外层查询，也是最后的查询 subquery derived：衍生虚表 union union result: 联合结果合并 table：表名称，也可以为&lt;derived N&gt;或&lt;UNION N&gt; type: 访问类型，从好到差的顺序如下，至少需要优化到range system: 表中只有一条数据，相当于系统表 const: 一次索引就能找到，即主键、唯一索引 eq_ref: 唯一性索引扫描，只有一条数据与之匹配，常见于主键、唯一索引 ref: 非唯一性索引扫描，可能匹配到多条数据 range: 检索特定范围的行。使用一个索引来选择行，即 between, &gt;, &lt;, in index: 全索引扫描 select id from tbl_user, 直接从索引中获取数据 ALL: 全表扫描 select * from tbl_user possible_keys: 可能使用到的索引，但不一定实际使用 key： primary: 主键索引 idx_X: 普通索引名 NULL：未使用索引 key_len: 索引字段最大可能长度，越小越好 ref: 索引条件使用到的值。where uid=tbl_user.id and name=&#39;R&amp;D&#39; const: 常量条件 tbl_user.ID NULL rows: 估算所查记录需要读取的行数，越小越好 Extra: Using filesort: 索引外排序，即无法使用索引进行排序，被称为文件排序。order by 未用到索引时出现。要想办法优化 Using temporary: 使用临时表保存中间结果，常见于order by 或group by。较严重问题，可将by后的字段建立联合索引来解决该问题 Using index: 使用索引。索引覆盖：查询的列，可直接从索引中得到，不必读取数据行，即查询的列被所建索引覆盖 Using where Using join buffer impossible where: where 条件 false, where name=&#39;jack&#39; and name=&#39;tom&#39; select tables optimized away distinct 11.3.2 索引优化 尽量减少join中的NestedLoop的循环总是：永远用小结果集驱动大结果集。 优先优化NestedLoop的内层循环 保证join中被驱动表上join条件字段被建立索引 优化原则：小表驱动大表，即小表数据作为过滤条件 A为大表，B为小表，此时 in 的效率大于 exists: 1234select * from A where b_id in (select id from B)--&gt;for select id from B for select * from A where A.b_id = B.id A为小表，B为大表，此时 exists 的效率大于 in: 1234select * from A exists (select 1 from B where B.id = A.b_id)--&gt;for select * from A for select 1 from B where B.id = A.b_id 注意：exists (sub-query) 只返回 True 或 False 11.3.3 索引失效 全值匹配最优 最佳左前缀法则 不在索引列上做任何操作（计算、函数、类型转换等），会导致全表扫描 不能使用索引中范围条件右边的列 where name=&#39;jack&#39; and age&gt;20 and score=90 三字段索引 尽量使用覆盖索引（即直接从索引中查询数据，无需扫描表）即少使用select * 使用不等于(!= 或 &lt;&gt;)时，无法使用索引，导致全表扫描 is null, is not null 无法使用索引 like %xxx... 无法使用索引，导致全表扫描。 解决方案：使用覆盖索引（即select 索引列），然后从索引中直接获取 字符串不加单引号索引失效 少用or，它会导致索引失效 11.3.4 索引总结 带头大哥不能死 中间兄弟不能断，永远要符合左前缀最佳匹配原则 索引列上不计算 like %加右边 范围之后全失效 字符串有引号 11.4 Show profile用来分析当前会话中语句执行的资源消耗情况，可用于SQL的调优测量。 12345678910show variables like &#x27;profiling&#x27;;set profiling=1;--执行一堆查询select * from ...show profiles;show profile cpu, block io for query 10;-- all, block io, cpu, memory, ... 严重问题： converting HEAP to MyISAM: 查询结果太大，内存不足，使用磁盘 creating tmp table: 拷贝数据到临时表，用完删除 copying to tmp table on disk: 临时表存储在磁盘上，更要命 locked： 11.5 全局查询日志注意：绝对不能在生产环境开启此功能 12345678910111213mysql&gt; show variables like &#x27;general_log%&#x27;;+------------------+-------------------------------+| Variable_name | Value |+------------------+-------------------------------+| general_log | OFF || general_log_file | /var/lib/mysql/ubuntu20-a.log |+------------------+-------------------------------+show variables like &#x27;general_log&#x27;set global general_log=1;set global log_output=&#x27;TABLE&#x27;;select * from mysql.general_log; 11.6 Order by尽量使用 index 方式排序，避免使用 FileSort 方式排序 Order by使用Index的条件： order by 后使用索引最左前列 Where 条件与 order by子句条件组合满足索引最左前列 提高 order by 效率： 不要用 select *, 只查询order by 后的字段： query的字段长度总和小于max_length_for_sort_data时，排序字段不为TEXT|BLOB时，使用单路排序，否则使用多路排序（即两次磁盘扫描） 两种算法的数据可能超出sort_buffer容量，超出之后，会创建tmp文件进行合并排序，导致多次IO sort_buffer_size：尝试提高该参数值，避免产生tmp文件 max_length_for_sort_data: 尝试提高该参数值会增加改进算法的效率。但如果太高，会导致磁盘IO过高，CPU使用率低的情况 排序的两种方式：filesort, index KEY a_b_c (a, b, c) order by 使用索引左前缀： ORDER BY a ORDER BY a, b ORDER BY a, b, c ORDER BY a DESC, b DESC, c DESC WHERE中的索引与order by中的索引构成最左前缀： WHERE a=const ORDER BY b, c WHERE a=const AND b=const ORDER BY c WHERE a=const AND b&gt;const ORDER BY b, c 不能使用索引进行排序 ORDER BY a ASC, B DESC, c DESC // 排序不一致 WHERE x=const ORDER BY b, c // 丢失a索引 WHERE a=const ORDER BY c // 丢失b索引 WHERE a=const ORDER BY a, d // d不是索引的一部分 WHERE a in (…) ORDER BY b, c // 范围不能使用索引 11.7 Group by Group by 本质上先排序后分组，遵照索引最佳左前缀原则 当无法使用索引时，增大max_length_for_sort_data和sort_buffer_size参数 where 高于 having，能写在where的限定条件不要去having限定 12. SQL 性能优化 为避免全表扫描，涉及 WHERE 和 ORDER BY 的字段建立索引 避免 WHERE 中使用 NULL 判断，建表时尽量使用NOT NULL 避免 WHERE 中使用 != 或 &lt;&gt;，这些操作可使用索引：&lt;, &lt;=, =, &gt;, &gt;=, BETWEEN, IN，LIKE (某些时候) 避免 WHERE 中使用 OR，它会导致引擎放弃使用索引而进行全表扫描，可以使用 UNION 代替 慎用 IN 和 NOT IN，连续的数值，推荐BETWEEN WHERE 中字段 不要使用函数、表达式 12SELECT * FROM record WHERE amount/30 &lt; 1000;SELECT * FROM record WHERE convert(char(10), date, 112) = &#x27;20201220&#x27;; 用EXISTS 代替 IN 12select num from a where num in (select num from b)select num from a where num exists (select 1 from b) 索引会提高SELECT的效率，但也降低了INSERT和UPDATE的效率(索引重建), 一个表的索引，最好不要超过6个 JOIN的表不要超过5个，考虑使用临时表。 少用子查询，视图嵌套不要超过2层 数量统计，用count(1)代替 count(*) 记录是否存在，用 EXISTS 代替 count(1) &gt;= 效率比 &gt; 高 GROUP BY 前，先进行数据过滤： 12select job, avg(sal) from emp GROUP BY job HAVING job=&#x27;engineer&#x27; or job=&#x27;saler&#x27;;select job, avg(sal) from emp where job=&#x27;engineer&#x27; or job=&#x27;saler&#x27; GROUP BY job; 尽量不使用触发器，trigger事件比较耗时 避免使用DISTINCT 13. 索引问题13.1 什么是索引索引是一种特殊的文件，InnoDB 数据库上的索引是表空间的一个组成部分，它包含了对数据表中所有记录的引用指针，所以它要占用物理空间。 索引是一种排序的数据结构，以协助夸斯查询、更新数据库中数据。索引的实现通常使用B树及B+树。 13.2 索引优缺点优点： 提高检索速度 缺点： 创建和维护索引要消耗时间，即对表中数据进行增、删、改，索引也需要维护 索引需要占用物理空间 13.3 索引类型按存储结构： BTree, B+Tree 索引 Hash 索引 full-index 全文索引 R-Tree 按应用层次： 普通索引 唯一索引 符合索引 13.4 索引底层实现 Hash索引：基于hash表，只有精确匹配索引的查询才有效。对每行的索引列计算一个哈希值，并将其存储到索引表中，同时索引表中保存指向每列数据的指针。 B+Tree: 数据都住叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比BTree，进行范围查找只需要查找两个节点，进行遍历接口，效率更高 13.5 选 B+Tree，而不是BTree， Hash, 二叉树， 红黑树BTree: B+树磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对BTree更小，如果把所有同一内部节点的关键字存放放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。 B+树的数据存储在叶子节点上，分支节点均为索引：方便扫库，只需要扫一遍叶子节点接口。而B树因为其分支节点同样存储着数据，要找到具体的数据，需要进行一次中序遍历按序来扫。 Hash: 可快速定位，单没有排序，IO复杂度高 适合等值查询，不支持范围查询 不支持部分索引匹配查询 二叉树：树的高度不均匀，不能自平衡，查找效率和数据有关(树的高度)，IO代价高 红黑树：树的高度随着数据量增加而增加，IO代价高 99. 问题集99.1 删除百万级别数据不要直接去操作，直接操作会存在索引更新问题；另外删除过程中断，会导致回滚 1）先删除索引 2）删除无用数据 3）重建索引 99.2 线上环境大表，添加索引数据量超过100W，直接增加索引，可能导致服务器奔溃 两种方法： 1）临时表 注意：此方法可能会损失少量数据 1234567891011121314--复制旧表结构create table new_table like old_table;--加字段、索引alter table new_table add index (column);--拷贝旧表数据insert into new_table(field1, field2, ...) select field1, field2, ... from old_table;--修改表名rename table old_table to old_table_bak;rename table new_table to old_table;ALTER TABLE admin_user RENAME TO a_user; 2）主从切换 从库中进行加字段、索引 主库切换到从库 99.3 大表数据查询优化1）优化schema、sql、索引 2）增加缓存 redis 等 3）主从复制，读写分离 4）垂直拆分（一表分多表）。根据模块耦合度，将一个大的系统拆分成多个小系统，即分布式系统 5）水平切分（存储数据分片）。大表，考虑选择合适的分片(sharding key). 分片问题： 事务：需要支持分布式事务 跨库join、count, order by, group by及聚合函数等：分别在各个节点上得到结果，然后在应用程序端进行合并。 数据迁移、容量规划、扩容 ID问题：Twitter的分布式自增ID算法Snowflake 跨分区排序：多节点查询，结果集汇总并再排序 99.4 慢查询优化 分析查询语句，检查是否load了额外的数据，对查询语句重写，去除多余的查询 分析语句的执行计划，获取其使用索引的情况，优化索引，使其尽可能命中 已无法优化的大表，考虑横向或纵向分表 99.5 使用主键主键的好处：确保数据在整张表中的唯一性。在CURD的时候能确保操作数据范围安全 推荐使用自增ID，而不是UUID。因为InnoDB中的主键索引是聚簇索引，即主键索引的B+上叶子节点上存储了主键索引及全部数据(按顺序)。使用自增ID，只需要不断想后排列即可；但如果是UUID，先确定顺序，导致数据移动等操作，使插入性能下降。 99.6 字段定义要求not null的好处null值会占用更多的字节，也会在程序中造成很多与预期不符的情况 99.7 存储密码散列密码散列、盐值、也会手机号等固定长度的字符串应该使用char而不是varchar，这样可以节约空间且提高检索效率。 99.8 数据库CPU飙升到500%怎么处理1）使用top观察是不是mysqld占用导致的，如果不是，找到占用高的进程，并进行处理 2）对于mysqld造成的问题，可以使用show processlist 查看 session 情况，是否有消耗 sql 的资源在运行。查看执行计划是否准确，index是否缺失等 99.9 重复值高的字段不能建索引未命中索引的原因： 查询的数据量可能已经是总数据量的20%以上了，这个时候就会选择表扫描。 索引坏块，需要重建索引。 原因： 1）非聚簇索引存储了对主键的引用，如果select字段不在非聚簇索引内，就需要跳到主键索引（图中从右边索引树跳到左边的索引树），再获取select字段值 2）如果非聚簇索引值重复率高，那么将查询时就会出现图中从右边跳到左边的情况，导致整个流程很慢","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://elihe2011.github.io/categories/MySQL/"}],"tags":[]},{"title":"Go 缓存淘汰策略","slug":"Go 缓存淘汰策略","date":"2020-01-12T07:17:57.000Z","updated":"2021-06-22T10:50:49.748Z","comments":true,"path":"2020/01/12/Go 缓存淘汰策略/","link":"","permalink":"https://elihe2011.github.io/2020/01/12/Go%20%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","excerpt":"1. LRULeast Recently Used, 最近最少使用缓存。目的：淘汰最长时间未被使用的元素 快速存取原始 固定的最大容量，不会无限制增长 达到最大容量后，新增元素时，会把最近最少使用的元素删除，再放入新元素","text":"1. LRULeast Recently Used, 最近最少使用缓存。目的：淘汰最长时间未被使用的元素 快速存取原始 固定的最大容量，不会无限制增长 达到最大容量后，新增元素时，会把最近最少使用的元素删除，再放入新元素 1.1 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103type Entry struct &#123; Key string Value interface&#123;&#125; pre *Entry next *Entry&#125;type Cache struct &#123; cache map[string]*Entry capacity int head *Entry tail *Entry&#125;func newCache(cap int) *Cache &#123; return &amp;Cache&#123;cache: make(map[string]*Entry), capacity: cap&#125;&#125;var lock sync.RWMutexfunc (cache *Cache) Put(key string, val interface&#123;&#125;) interface&#123;&#125; &#123; lock.Lock() defer lock.Unlock() if existVal, exist := cache.cache[key]; exist &#123; cache.moveToHead(existVal) return nil &#125; // 重设 head 元素 e := &amp;Entry&#123;Key: key, Value: val, next: cache.head&#125; if cache.head != nil &#123; cache.head.pre = e &#125; cache.head = e // 第一次新增元素时，tail 为 nil if cache.tail == nil &#123; cache.tail = e &#125; cache.cache[key] = e if len(cache.cache) &lt;= cache.capacity &#123; return nil &#125; // 处理超出容量范围的元素 removedEntry := cache.tail cache.tail = cache.tail.pre removedEntry.pre = nil cache.tail.next = nil delete(cache.cache, removedEntry.Key) return removedEntry.Value&#125;func (cache *Cache) Get(key string) interface&#123;&#125; &#123; lock.Lock() defer lock.Unlock() if existVal, exist := cache.cache[key]; exist &#123; cache.moveToHead(existVal) return existVal.Value &#125; return nil&#125;func (cache *Cache) moveToHead(e *Entry) &#123; if e == cache.head &#123; return &#125; // 从link中断开，并连接前后元素 e.pre.next = e.next if e == cache.tail &#123; cache.tail = e.pre &#125; else &#123; e.next.pre = e.pre &#125; e.pre = nil e.next = cache.head cache.head.pre = e cache.head = e&#125;func main() &#123; cache := newCache(2) cache.Put(&quot;1&quot;, &quot;Golang&quot;) fmt.Println(cache.Get(&quot;1&quot;)) cache.Put(&quot;2&quot;, &quot;Python&quot;) fmt.Println(cache.Get(&quot;1&quot;)) cache.Put(&quot;3&quot;, &quot;Java&quot;) fmt.Println(cache.Get(&quot;1&quot;)) fmt.Println(cache.Get(&quot;2&quot;)) // nil fmt.Println(cache.Get(&quot;3&quot;)) // Java&#125; 1.2 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263type LinkNode struct &#123; key, val int pre, next *LinkNode&#125;type LRUCache struct &#123; m map[int]*LinkNode cap int head, tail *LinkNode&#125;func Constructor(capacity int) LRUCache &#123; head := &amp;LinkNode&#123;0, 0, nil, nil&#125; tail := &amp;LinkNode&#123;0, 0, nil, nil&#125; head.next = tail tail.pre = head return LRUCache&#123;make(map[int]*LinkNode), capacity, head, tail&#125;&#125;func (this *LRUCache) Get(key int) int &#123; cache := this.m if v, exist := cache[key]; exist &#123; this.MoveToHead(v) return v.val &#125; else &#123; return -1 &#125;&#125;func (this *LRUCache) RemoveNode(node *LinkNode) &#123; node.pre.next = node.next node.next.pre = node.pre&#125;func (this *LRUCache) AddNode(node *LinkNode) &#123; head := this.head node.next = head.next head.next.pre = node node.pre = head head.next = node&#125;func (this *LRUCache) MoveToHead(node *LinkNode) &#123; this.RemoveNode(node) this.AddNode(node)&#125;func (this *LRUCache) Put(key int, value int) &#123; tail := this.tail cache := this.m if v, exist := cache[key]; exist &#123; v.val = value this.MoveToHead(v) &#125; else &#123; v := &amp;LinkNode&#123;key, value, nil, nil&#125; if len(cache) == this.cap &#123; delete(cache, tail.pre.key) this.RemoveNode(tail.pre) &#125; this.AddNode(v) cache[key] = v &#125;&#125; 2. LFULFU（Least Frequently Used）算法根据数据的历史访问频率来淘汰数据，其核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。LFU的每个数据块都有一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。LFU需要记录所有数据的访问记录，内存消耗较高；需要基于引用计数排序，性能消耗较高。在算法实现复杂度上，LFU要远大于LRU。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package maintype LFUCache struct &#123; cache map[int]*Node freq map[int]*DoubleList ncap, size, minFreq int&#125;func (this *LFUCache) IncrFreq(node *Node) &#123; _freq := node.freq this.freq[_freq].RemoveNode(node) if this.minFreq == _freq &amp;&amp; this.freq[_freq].IsEmpty() &#123; this.minFreq++ delete(this.freq, _freq) &#125; node.freq++ if this.freq[node.freq] == nil &#123; this.freq[node.freq] = createDL() &#125; this.freq[node.freq].AddFirst(node)&#125;func Constructor(capacity int) LFUCache &#123; return LFUCache&#123; cache: make(map[int]*Node), freq: make(map[int]*DoubleList), ncap: capacity, &#125;&#125;func (this *LFUCache) Get(key int) int &#123; if node, ok := this.cache[key]; ok &#123; this.IncrFreq(node) return node.val &#125; return -1&#125;func (this *LFUCache) Put(key int, value int) &#123; if this.ncap == 0 &#123; return &#125; //节点存在 if node, ok := this.cache[key]; ok &#123; node.val = value this.IncrFreq(node) &#125; else &#123; if this.size &gt;= this.ncap &#123; node := this.freq[this.minFreq].RemoveLast() delete(this.cache, node.key) this.size-- &#125; x := &amp;Node&#123;key: key, val: value, freq: 1&#125; this.cache[key] = x if this.freq[1] == nil &#123; this.freq[1] = createDL() &#125; this.freq[1].AddFirst(x) this.minFreq = 1 this.size++ &#125;&#125;//节点nodetype Node struct &#123; key, val, freq int prev, next *Node&#125;//双链表type DoubleList struct &#123; tail, head *Node&#125;//创建一个双链表func createDL() *DoubleList &#123; head, tail := &amp;Node&#123;&#125;, &amp;Node&#123;&#125; head.next, tail.prev = tail, head return &amp;DoubleList&#123; tail: tail, head: head, &#125;&#125;func (this *DoubleList) IsEmpty() bool &#123; return this.head.next == this.tail&#125;//将node添加为双链表的第一个元素func (this *DoubleList) AddFirst(node *Node) &#123; node.next = this.head.next node.prev = this.head this.head.next.prev = node this.head.next = node&#125;func (this *DoubleList) RemoveNode(node *Node) &#123; node.next.prev = node.prev node.prev.next = node.next node.next = nil node.prev = nil&#125;func (this *DoubleList) RemoveLast() *Node &#123; if this.IsEmpty() &#123; return nil &#125; lastNode := this.tail.prev this.RemoveNode(lastNode) return lastNode&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://elihe2011.github.io/tags/algorithm/"}]},{"title":"Go 遍历树","slug":"Go 遍历树","date":"2020-01-09T02:51:19.000Z","updated":"2021-06-22T10:50:49.747Z","comments":true,"path":"2020/01/09/Go 遍历树/","link":"","permalink":"https://elihe2011.github.io/2020/01/09/Go%20%E9%81%8D%E5%8E%86%E6%A0%91/","excerpt":"1. 二叉树遍历123456789101112 1 / \\ 2 3 / \\ / \\4 5 6 7 / \\ 8 9前序输出: 1 2 4 5 3 6 8 9 7中序输出: 4 2 5 1 8 6 9 3 7后序输出: 4 5 2 8 9 6 7 3 1层序输出: 1 2 3 4 5 6 7 8 9","text":"1. 二叉树遍历123456789101112 1 / \\ 2 3 / \\ / \\4 5 6 7 / \\ 8 9前序输出: 1 2 4 5 3 6 8 9 7中序输出: 4 2 5 1 8 6 9 3 7后序输出: 4 5 2 8 9 6 7 3 1层序输出: 1 2 3 4 5 6 7 8 9 2. 实现代码2.1 构建二叉树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051type Tree struct &#123; Val int Left *Tree Right *Tree IsRoot bool&#125;var root = &amp;Tree&#123; Val: 1, Left: node2, Right: node3, IsRoot: true,&#125;var node2 = &amp;Tree&#123; Val: 2, Left: node4, Right: node5,&#125;var node3 = &amp;Tree&#123; Val: 3, Left: node6, Right: node7,&#125;var node4 = &amp;Tree&#123; Val: 4,&#125;var node5 = &amp;Tree&#123; Val: 5,&#125;var node6 = &amp;Tree&#123; Val: 6, Left: node8, Right: node9,&#125;var node7 = &amp;Tree&#123; Val: 7,&#125;var node8 = &amp;Tree&#123; Val: 8,&#125;var node9 = &amp;Tree&#123; Val: 9,&#125; 2.2 前序遍历123456789func preorder(t *Tree) &#123; if t == nil &#123; return &#125; fmt.Printf(&quot;%d, &quot;, t.Val) preorder(t.Left) preorder(t.Right)&#125; 2.3 中序遍历123456789func inorder(t *Tree) &#123; if t == nil &#123; return &#125; inorder(t.Left) fmt.Printf(&quot;%d, &quot;, t.Val) inorder(t.Right)&#125; 2.4 后序遍历123456789func postorder(t *Tree) &#123; if t == nil &#123; return &#125; postorder(t.Left) postorder(t.Right) fmt.Printf(&quot;%d, &quot;, t.Val)&#125; 2.5 层序遍历先将二叉树改造为队列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type Queue struct &#123; Val []*Tree Length int&#125;func (q *Queue) Push(t *Tree) &#123; q.Val = append(q.Val, t)&#125;func (q *Queue) Pop() *Tree &#123; len := q.Len() if len == 0 &#123; panic(&quot;Queue is empty&quot;) &#125; node := q.Val[0] if len == 1 &#123; q.Val = []*Tree&#123;&#125; &#125; else &#123; q.Val = q.Val[1:] &#125; return node&#125;func (q *Queue) Len() int &#123; q.Length = len(q.Val) return q.Length&#125;func levelorder(t *Tree) &#123; queue := Queue&#123;&#125; queue.Push(root) for queue.Len() &gt; 0 &#123; node := queue.Pop() if node == nil &#123; panic(&quot;node is nil&quot;) &#125; if node.IsRoot &#123; fmt.Printf(&quot;%d, &quot;, node.Val) &#125; if node.Left != nil &#123; fmt.Printf(&quot;%d, &quot;, node.Left.Val) queue.Push(node.Left) &#125; if node.Right != nil &#123; fmt.Printf(&quot;%d, &quot;, node.Right.Val) queue.Push(node.Right) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://elihe2011.github.io/tags/algorithm/"}]},{"title":"Go Etcd","slug":"Go Etcd","date":"2020-01-03T06:26:16.000Z","updated":"2021-06-22T10:50:49.747Z","comments":true,"path":"2020/01/03/Go Etcd/","link":"","permalink":"https://elihe2011.github.io/2020/01/03/Go%20Etcd/","excerpt":"","text":"1. etcd 介绍概念：高可用的分布式key-value存储，可用于配置共享和服务发现 类似项目：zookeeper 和 consul 接口：提供restful的http接口，使用简单 实现算法：基于raft算法的强一致性、高可用的服务存储目录 应用场景: 服务注册与发现 配置中心 分布式锁 master选举 2. etcd 安装 (docker)1234567891011121314151617181920212223242526272829303132333435$ docker pull gcr.io/etcd-development/etcd:v3.4.13 $ rm -rf /tmp/etcd-data.tmp &amp;&amp; mkdir -p /tmp/etcd-data.tmp$ docker run \\ -p 2379:2379 \\ -p 2380:2380 \\ --mount type=bind,source=/tmp/etcd-data.tmp,destination=/etcd-data \\ --name etcd-gcr-v3.4.13 \\ --detach gcr.io/etcd-development/etcd:v3.4.13 \\ /usr/local/bin/etcd \\ --name s1 \\ --data-dir /etcd-data \\ --listen-client-urls http://0.0.0.0:2379 \\ --advertise-client-urls http://0.0.0.0:2379 \\ --listen-peer-urls http://0.0.0.0:2380 \\ --initial-advertise-peer-urls http://0.0.0.0:2380 \\ --initial-cluster s1=http://0.0.0.0:2380 \\ --initial-cluster-token tkn \\ --initial-cluster-state new \\ --log-level info \\ --logger zap \\ --log-outputs stderr $ docker exec -it etcd-gcr-v3.4.13 /bin/sh# etcdctl versionetcdctl version: 3.4.13API version: 3.4# etcdctl endpoint health127.0.0.1:2379 is healthy: successfully committed proposal: took = 29.242978ms# etcdctl put name jackOK# etcdctl get namenamejack 3. etcd 使用3.1 连接 etcd12345678// 客户端配置config := clientv3.Config &#123; Endpoints: []string&#123;&quot;localhost:2379&quot;&#125;, DialTimeout: 5 * time.Second,&#125;// 建立连接cli, err := clientv3.New(config) 3.2 新增或修改数据123456789101112131415func put(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) putResp, err := cli.Put(ctx, &quot;/logagent/conf/&quot;, &quot;sample_value&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(putResp.Header.Revision) if putResp.PrevKv != nil &#123; fmt.Println(&quot;prev Value:&quot;, putResp.PrevKv.Value) fmt.Println(&quot;CreateRevision:&quot;, putResp.PrevKv.CreateRevision) fmt.Println(&quot;ModRevision:&quot;, putResp.PrevKv.ModRevision) fmt.Println(&quot;Version:&quot;, putResp.PrevKv.Version) &#125;&#125; 3.3 获取数据123456789101112func get(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/conf/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125;&#125; 3.4 删除数据12345678910111213141516func del(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) delResp, err := cli.Delete(ctx, &quot;/logagent/conf/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; if len(delResp.PrevKvs) &gt; 0 &#123; for _, ev := range delResp.PrevKvs &#123; fmt.Printf(&quot;Delete %s: %s\\n&quot;, ev.Key, ev.Value) &#125; &#125; fmt.Println(delResp.Deleted)&#125; 3.5 设置租期12345678910111213141516171819202122232425262728293031323334353637func lease(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) leaseGrantResp, err := cli.Grant(ctx, 10) cancel() if err != nil &#123; log.Fatal(err) &#125; leaseId := leaseGrantResp.ID ctx, cancel = context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, &quot;/logagent/ttl/&quot;, &quot;10s&quot;, clientv3.WithLease(leaseId)) cancel() if err != nil &#123; log.Fatal(err) &#125; for &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/ttl/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; if getResp.Count == 0 &#123; fmt.Println(&quot;ttl expire&quot;) break &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125; time.Sleep(2 * time.Second) &#125;&#125; 3.6 延迟租期1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func extentLease(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) leaseGrantResp, err := cli.Grant(ctx, 10) cancel() if err != nil &#123; log.Fatal(err) &#125; leaseId := leaseGrantResp.ID ctx, cancel = context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, &quot;/logagent/ttl/&quot;, &quot;10s&quot;, clientv3.WithLease(leaseId)) cancel() if err != nil &#123; log.Fatal(err) &#125; time.Sleep(5 * time.Second) ctx, cancel = context.WithTimeout(context.Background(), time.Second) leaseKeepAliveResp, err := cli.KeepAlive(ctx, leaseId) if err != nil &#123; log.Fatal(err) &#125; go func() &#123; for &#123; select &#123; case keepResp := &lt;-leaseKeepAliveResp: if keepResp == nil &#123; fmt.Println(&quot;Lease expire&quot;) return &#125; else &#123; fmt.Println(&quot;Receive lease extent resp&quot;) &#125; &#125; &#125; &#125;() ctx, cancel = context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/ttl/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125;&#125; 3.7 watch 功能123456789101112131415161718192021222324252627282930313233343536373839404142434445func watch(cli *clientv3.Client) &#123; kv := clientv3.NewKV(cli) // 模拟KV变化 go func() &#123; for &#123; _, _ = kv.Put(context.TODO(), &quot;/language&quot;, &quot;go&quot;) _, _ = kv.Delete(context.TODO(), &quot;language&quot;) time.Sleep(time.Second) &#125; &#125;() getResp, err := kv.Get(context.TODO(), &quot;language&quot;) if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125; watchStartVersion := getResp.Header.Revision + 1 fmt.Printf(&quot;Start watching from version: %d\\n&quot;, watchStartVersion) watcher := clientv3.NewWatcher(cli) ctx, cancel := context.WithCancel(context.TODO()) time.AfterFunc(5*time.Second, func() &#123; cancel() &#125;) watchRespChan := watcher.Watch(ctx, &quot;language&quot;, clientv3.WithRev(watchStartVersion)) for watchResp := range watchRespChan &#123; for _, event := range watchResp.Events &#123; switch event.Type &#123; case mvccpb.PUT: fmt.Printf(&quot;Modify: %s, %v, %v\\n&quot;, event.Kv.Value, event.Kv.CreateRevision, event.Kv.ModRevision) case mvccpb.DELETE: fmt.Printf(&quot;Delete: %v\\n&quot;, event.Kv.ModRevision) &#125; &#125; &#125;&#125; 1234567891011121314151617181920func main() &#123; cli, err := clientv3.New(clientv3.Config&#123; Endpoints: []string&#123;&quot;localhost:2379&quot;&#125;, DialTimeout: 5 * time.Second, &#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() for &#123; rch := cli.Watch(context.Background(), &quot;/logagent/conf/&quot;) for wresp := range rch &#123; for _, ev := range wresp.Events &#123; fmt.Printf(&quot;%s %q : %q\\n&quot;, ev.Type, ev.Kv.Key, ev.Kv.Value) &#125; &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Linux文本处理","slug":"Linux文本处理","date":"2019-12-19T07:48:58.000Z","updated":"2021-07-13T03:15:37.196Z","comments":true,"path":"2019/12/19/Linux文本处理/","link":"","permalink":"https://elihe2011.github.io/2019/12/19/Linux%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/","excerpt":"","text":"1. find123find PATH -option [-print] [-exec|-ok cmd] &#123;&#125; \\;-print \\n-print0 \\0, NULL 1.1 time123456-atime N-ctime N-mtime N-newer FILE-amin M-mmin M.. 实例： 12345find . -amin -10 # 10分钟内访问的文件find . -mtime -2 # 2天内修改的文件find . -mmin +60 # 60分钟前被修改的文件find /etc -mmin -120 # 两小时内被修改的文件find / -mtime 0 # 将过去24 小时内有改变过内容的文件 1.2 user &amp; group123456-uid n-gid n-user name-group name-nouser-nogroup 实例： 12find /var -uid +1048 # uid大于等于1048find /home -user test 1.3 file12345678910111213141516171819202122232425-name FILENAME-type TYPE （f，b，c，d，l，s，p）-size SIZE-empty-inum n-links NUM-depth sub-diectory first-maxdepth level Decend at most [level] levels of directories below the command-mindepth level Don&#x27;t apply tests or actions at levels less than [level]-xdev 不跨越filesystem -mount unix不支持-fstype TYPE（ext3，proc）-follow dereference symbolic links-L-prune Ignore directory or file-perm MODE 许可位正好是MODE-perm -MODE 许可位完全符合MODE-perm +MODE 许可位部分符合MODE， 老式写法/MODE 实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657find . -maxdepth 1 find . -maxdepth 2 find . -mindepth 4 find . -mindepth 2 -maxdepth 3find . -path ./.svnfind . -path /var/log -prune -o -print find . \\(-path /var/log -o -path /var/spool \\) -prune -o -print find . -size 1000 # 1000 blocks, 1Block=512Bytesfind . -size +70Mfind . -size 20c # 20 bytesfind . -size +10M -a -size -20Mfind . -empty # 空文件或空目录find . -links +2 # 链接数超过2find /mnt -name a.txt -fstype vfatfind / ！-fstype proc &#x27;(&#x27; -name &#x27;.??*&#x27; -o -name &#x27;.[^.]&#x27; &#x27;)&#x27;find / -perm 664 # 权限精确等于664find / -perm -664 # 权限完全满足664，但可包含额外权限，665，777find / -perm +664 # 权限部分满足664，例如660和600find . -perm -007 # others用户具有rwx权限find . -perm -100 # 属主至少具有x权限特殊权限SGID，SUID，SBIT(---s--s--t)find . -perm +7000 # 至少具有一个特殊权限位find . -perm -7000 # 具有全部特殊权位# 删除7天内未被读取的core文件，只涉及/所在的文件系统(-xdev)find / -xdev -type f &#x27;(&#x27; -name core -o name &#x27;core.[0-9]*&#x27; &#x27;)&#x27; -atime +7 -exec rm -f &#123;&#125; &#x27;;&#x27; # 删除那些用#, .#或.nfs开头，或者以~及。CKP结尾且3天内都未被访问过的文件find / -xdev -atime +3 &#x27;(&#x27; -name &#x27;#*&#x27; -o -name &#x27;.#*&#x27; -o -name &#x27;*.CKP&#x27;, -o -name &#x27;*~&#x27;, -o -name &#x27;.nfs*&#x27; &#x27;)&#x27; -exec rm -f &#123; &#125; &#x27;;&#x27;# 删除/tmp下载72小时内未被修的所有子目录cd /tmp; find . ! -name . ! -name lost+found -type d -mtime +3 -exec /bin/rm -rf &#123;&#125; \\;# 嵌入时间BACKUPFILE=backup-$(date +%m-%d-%Y)# 备份一天前的文件, 缺陷：发现太多的文件或文件名包含空格，执行失败tar cvf - `find . -mtime -1 -type f -print` &gt; $archive.tar# 改进型，GNU版本的find, this one is more betterfind . -mtime -1 -type f -print0 | xargs -0 tar rvf &quot;$archive.tar&quot;# 改进型，Unix风格的find，较慢find . -mtime -1 -type f -exec tar rvf &quot;$archive.tar&quot; &#123;&#125; \\; # remove file or directory it contains special charactersls -ilfind . -inum inode_num -exec rm -rf &#123;&#125; \\; 2. xargs可读入stdin的数据，并且以空格或换行符做分割，将stdin分割成arguments 1.1 选项说明1234567891011121314151617181920212223242526272829303132333435363738391) terminated by a null character, every character is taken literally, (`, \\, whitespace)--null-0 2) terminated by the specified character--delimiter=delim -d delim 3) use at most max-lines nonblank input lines per command line--max-lines[=max-lines]-l[max-lines] 4) use at most max-args arguments per command line.--max-args=max-args-n max-args 5) replace occurrences of replace-str(&#123;&#125; by default) in the initial-arguments with names read from standard input-I replace-str--replace[=replace-str]-i[replace-str] .6) a placeholder for output text&#123;&#125; 7) run up to max-procs processes at a time; 1 by default; 0: run as many as possible--max-procs=max-procs-P max-procs8) set the end of file string to EOF--eof=[EOF]-e[EOF] 9) prompt--interactive-p10) print the command line on the standard error output before executing it.--verbose-t 2.2 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768find -print0 | xargs -0# 单行输出cat a.txt | xargs# 每行3个参数cat a.txt | xargs -n3 # list files in 8 columnls | xargs -n 8 echo# 前3个用户活动情况cut -d&quot;:&quot; -f1 /etc/passwd | head -n 3 | xargs -p fingercut -d&quot;:&quot; -f1 /etc/passwd | xargs -p -e&quot;lp&quot; finger# 文件名含空格等find /home -size +1M -print0 | xargs -0 ls -l# core文件列表find / -name &quot;core&quot; -print | xargs echo &quot;&quot; &gt; core.log# 清除other组的可执行权限find . -perm -7 -print | xargs chmod o-x# 多文件过滤find . -name \\* -type f | xargs grep &quot;abc&quot;# 定界符echo &quot;aXbXc&quot; | xargs -dX# 拷贝整个目录ls | xargs -i -t cp ./&#123;&#125; /tmp/eli# 杀掉所有mysql进程ps ax | grep mysql | awk &#x27;&#123;print $1&#125;&#x27; | xargs -i kill &#123;&#125;# 参数-I和-icat a.shecho $*cat args.txtaaabbbccccat args.txt | xargs -I &#123;&#125; ./a.sh -p &#123;&#125; -l-p aaa -l-p bbb -l-p ccc -lcat args.txt | xargs -i ./a.sh -p &#123;&#125; -lcat args.txt | xargs -I % ./a.sh -p % -l# 逐一拷贝图片ls *.jpg | xargs -n 1 -i cp &#123;&#125; /home/images# 压缩文件，每次一个ls | xargs -p -l gzip# to handle arguments containing whitespace or quotesfind / -type f -print0 | xargs -0 grep -liwZ GUI | xargs -0 rm -f# 开启两个处理进程，每次压缩一个文件ls *.txt | xargs -t -n1 -P2 gzip# grep输出的文件名以\\0结尾grep -lZ &#x27;abc&#x27; &quot;*.txt&quot; | xargs -0 3. sedsed, stream editor , 按顺序逐行方式工作 i. 从输入读取一行数据存入临时缓冲区，即模式空间(pattern space) ii. 按指定的sed编辑命令处理缓冲区中的内容 iii. 把模式空间的内容送往屏幕，并将此行内容从模式空间中删除 iv. 读取下一行，重复上述过程直至全部处理 模式空间(pattern space) 保留空间(hold space) 3.1 参数说明123456sed [OPTION] [-e] cmd1 [[-e cmd2] [-e cmd3] ... [-e cmdn]] [input-file]sed [OPTION] -f script-file [input-file]-n 不打印模式空间-r 使用E-REGEX-i 直接修改文件 3.2 Address1234567811,1001,+5 &lt;=&gt; 1,65,10!1~2 &lt;=&gt;1,3,5/pattern//pattern1/,/pattern2/ 3.3 Command123456789101112131415161718d 从pattern space删除所有行D 从pattern space删除第一行p 打印pattern space中所有行P 打印pattern space中的第一行sed &#x27;3,$d&#x27; sed &#x27;/line/&#x27;d sed -n &#x27;$p&#x27;# delete spaces in front of each rowsed &#x27;s/^[ ]*/g&#x27; sed &#x27;s/^ */g&#x27; sed &#x27;s/^[[:space:]]*//g # grep &#x27;pattern&#x27;sed -n &#x27;/pattern/p&#x27;sed &#x27;/pattern/!d&#x27; 123456789101112r file 读取文件，将文件内容追加到匹配行w file 将匹配行写入文件a\\string 行后面追加一行文本i\\string 行前面插入一行文本s/pattern/string/ 用string替换pattern sed &#x27;s/abc/123/g&#x27; sed &#x27;s#\\(abc\\)defg#\\1#&#x27; sed &#x27;s/2/*/8&#x27; # 第8个&quot;2&quot;替换为&quot;*&quot; 123456789101112131415161718192021222324252627282930313233h cat pattern-space &gt; hold-spaceH cat &quot;\\n&quot;pattern-space &gt;&gt; hold-spaceg cat hold-space &gt; pattern-spaceG cat &quot;\\n&quot;hold-space &gt;&gt; pattern-spacex exchange hold-space with pattern-space! no actions # tac sed &#x27;1!G;h;$!d&#x27; # 新增空行 sed G # 多个空行变一个 sed &#x27;/^$/d;G&#x27; # add a blank line before the matching one sed &#x27;/python/&#123;x;p;x&#125;&#x27; # add a blank line after the matching one sed &#x27;/python/G&#x27; # add a blank line before and after the matching one sed &#x27;/python/&#123;x;p;x;G&#125;&#x27; # 匹配行的前一行 sed -n &#x27;/python/&#123;g;1!p&#125;;h&#x27; # 先h, 将ps保存至hs; 当匹配时，g使用hs替换ps, 如果不是第一行，则打印 # 匹配行的后一行 sed -n &#x27;/python/&#123;n;p&#125;&#x27; 123456789n 读取下一行至pattern space，此时pattern space有2行，后续命令，只操作n读入的行N 读取下一行至pattern space，但将当前读入行和N命令读入的下一行看成“一行&quot; # 匹配行的后一行，做替换操作 sed &#x27;/python/&#123;n;s/job/task/&#125;&#x27; # 删除偶数行 sed &#x27;n;d&#x27; sed -n &#x27;1~2p&#x27; 12y 与tr类似，字符替换 sed &#x27;1y/abcdef/ABCDEF/&#x27; 123= 打印行号 sed -n &#x27;/python/=&#x27; sed -n &#x27;$=&#x27; 1234567891011q 退出 # head -2 sed 2q # tail -2 sed &#x27;$!N;$!D&#x27; # tail -1 sed -e :a -e &#x27;$q;N;2,$D;ba&#x27; sed &#x27;$!d&#x27; sed -n &#x27;$p&#x27; 3.4 实例 1234567891011121314151617181920212223242526272829303132333435# replace Unix to Unix/Linuxsed -e &#x27;s#Unix#&amp;/Linux#g&#x27;# squeeze continuous c to single csed &#x27;s/cc*/c/g&#x27;# delete space at head of linesed &#x27;s/^[ \\t]*//&#x27;# delete dot at end of linesed &#x27;s/\\.$//g&#x27; # delete first character each linesed &#x27;s/.//g&#x27; # delete space at end of linesed &#x27;s/ *$//g&#x27; # insert two space before head each linesed &#x27;s/^/ /g&#x27; # remove punctuation(. , ? !)sed &#x27;s/\\.//g&#x27; -e &#x27;s/\\,//g&#x27; -e &#x27;s/\\?//g&#x27; -e &#x27;s/\\!//g&#x27;# more effectivesed &#x27;s/foo/bar/g&#x27; sed &#x27;/foo/ s/foo/bar/g&#x27; sed &#x27;/foo/ s//bar/g&#x27; # only replacement once, use &#x27;q&#x27;sed &#x27;s/foo/ s/foo/bar/;q&#125;&#x27; # delete blank linessed &#x27;/^$/d&#x27; sed &#x27;/./!d&#x27; 4. awk1234567891011awk [options] &#x27;BEGIN&#123;action&#125;pattern&#123;action&#125;...END&#123;action&#125;&#x27; fileawk [options] -f program.awk fileoptions:-F fs use fs for the input field separator-v val=val assign the value to the variable var, before execution of the program begins.pattern:/regex/: extended regular expressionrelational expression: if..else.. pattern1, pattern2: pattern range 4.1 Built-in Variables:123456789101112131415161718192021222324252627282930313233343536373839401. NF, NRNF The number of fieldsNR The total number of input records seen so far2. FS, RS, OFS, ORSFS The input field separator, a space by defaultRS The input record separator, by default a newlineOFS The output field separator, a space by defaultORS The output record separator, by default a newline3. IGNORECASE Not case-sensitivity4. ENVIRON# awk &#x27;BEGIN&#123;for(i in ENVIRON) print i, ENVIRON[i]&#125;&#x27;# awk &#x27;BEGIN&#123;print ENVIRON[&quot;JAVA_HOME&quot;]&#125;&#x27;5. ARGC, ARGV, ARGINDARGC: the number of argumentsARGIND: the index in ARGV of the current file being processedARGV: Array of arguments# awk &#x27;BEGIN&#123;print &quot;ARGC=&quot;ARGC; for(i in ARGV) print i&quot;=&quot;ARGV[i]&#125;&#x27; /etc/passwdARGC=2, 0=awk, 1=/etc/passwd 6. FILENAME : the name of the current input file# awk &#x27;BEGIN&#123;print FILENAME&#125;&#123;print FILENAME; exit&#125;&#x27;7. OFMT : number output format &quot;.6g&quot;# awk &#x27;BEGIN&#123;printf(&quot;%.2f %.2f\\n&quot;, 1/6, 3.1415926)&#125;&#x27;# awk &#x27;BEGIN&#123;OFMT=&quot;%.2f&quot;; print 1/6, 3.1415926)&#125;&#x27;8. FIELDWIDTH : set fields by fixed width# date +&quot;%Y%m%d%H%M%S&quot; | awk &#x27;BEGIN&#123;FIELDWIDTH=&quot;4 2 2 2 2 2&quot;&#125;&#123;print $1&quot;-&quot;$2&quot;-&quot;$3, $4&quot;:&quot;$5&quot;:&quot;$6&#125;&#x27;9. RSTART, RLENGTHRSTART: the index of the first character matched by match(), 0RLENGTH: the length of the string matched by matched by match(), -1# awk &#x27;BEGIN&#123;start=match(&quot;this is match test&quot;, /m[a-z]+/); print start, RSTART, RLENGTH&#125;&#x27;9 9 5 4.2 Built-in Functions:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611. Numericint(x)sqrt(x)rand(): return a random number, [0-1)srand([expr]): use expr as a seed for random generator, if not provided, use system current time# awk &#x27;BEGIN&#123;print int(2.3), int(012), int(0xFF), int(3a), int(a3)&#125;&#x27; 2 10 255 3 0# awk &#x27;BEGIN&#123;print rand(), 10*rand()&#125;&#x27;# awk &#x27;BEGIN&#123;srand(); print rand(), 10*rand()&#125;&#x27;2. Stringsub(regex, replacement[, target]): use the replacement to replace the regex matched in string target(by default $0)gsub(regex, replacement[, target]): global subgensub(regex, replacement, how[, target]): gawkgensub(regex, replacement, &quot;g|G&quot; target) =&gt; gsubgensub(regex, replacement, 0, target) =&gt; gsub, but with warninggensub(regex, replacement, N, target) =&gt; N is a digit from 1 to 9, index of the matched sub-expression# awk &#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;; gsub(/[0-9]+/,info); print info&#125;&#x27;# gawk &#x27;BEGIN&#123;a=&quot;abc def&quot;; b=gensub(/(.+) (.+)/, &quot;\\\\2 \\\\1&quot;, &quot;g&quot;, a); print b&#125;&#x27; def abc# echo &quot;a b c a b c&quot; | gawk &#x27;&#123;print gensub(/a/,&quot;AA&quot;,2)&#125;&#x27; a b c AA b cindex(string, find): index of the find in the string, or 0 if not presentmatch(string, regex[, array]): position of the regex occurring in the stringlength([string])substr(string, position[, len])split(string, array[, regexp]): split the string into the array on the regex# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print index(s, &quot;a&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print index(s, &quot;a&quot;) ? &quot;ok&quot; : :no found&quot;&#125;&#x27;# awk &#x27;BEGIN&#123;s=&quot;this is a match test&quot;; pos=match(s, /m[a-z]+/, array); print pos; for(i in array) print i, array[i]&#125;&#x27;110start 110length 50 match# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print substr(s, 9, 1)&#125;&#x27;a# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print substr(s, 9)&#125;&#x27;a test# awk &#x27;BEGIN&#123;s=&quot;this is a split test&quot;; len=split(s,array); print len; for(i in array) print i, array[i]&#125;&#x27;54 split5 test1 this2 is3 a# awk &#x27;BEGIN&#123;FS=&quot;:&quot;&#125;/^root/&#123;split($0,array); for(i in array) print i, array[i]&#125;&#x27; /etc/passwd# awk &#x27;/^root/&#123;split($0,array,/:/); for(i in array) print i, array[i]&#125;&#x27; /etc/passwd4 05 root6 /root7 /bin/bash1 root2 x3 0Associative Arraysa. sorting by valueslen = asort(s) # s: changed, the indexes are replaced with sequential integerslen = asort(s, d) # s: unchanged; d: a sorted duplicate array of sb. sorting by indexeslen = asorti(s) # s: changed, restorted by indexeslen = asorti(s, d) # s: unchanged; d: a new array of sorted indexes# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i in a) print i, a[i]&#125;&#x27; abc.txt10 3512 3022 1324 20# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i=1;i&lt;=asort(a,b);i++) print i, b[i]&#125;&#x27; abc.txt1 132 203 304 40# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i=1;i&lt;=asorti(a,b);i++) print i, b[i]&#125;&#x27; abc.txt1 102 123 224 24sprintf(format, expr): return the printed expr according to the formattolower(string)toupper(string)# awk &#x27;BEGIN&#123;s=sprintf(&quot;%.2g %s %d&quot;, 3.1415926, 3.1415926, 3.1415926); print s&#125;&#x27;3.1 3.14159 33. Timemktime(&quot;YYYY MM DD HH MM SS[ DST]&quot;): return a time stampsystime(): return current time stmapstrftime([format[, ts])# awk &#x27;BEGIN&#123;print mktime(&quot;2014 12 20 14 25 32&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;print systime()&#125;&#x27;# awk &#x27;BEGIN&#123;print strftime()&#125;&#x27;# awk &#x27;BEGIN&#123;print strftime(&quot;%c&quot;, systime())&#125;&#x27; # date +%c4. IOclose(file[, how]): close file, pipe or co-process; how is either &quot;from&quot; or &quot;to&quot;getline set $0 from next input record, set NF, NR, FNRgetline &lt;file set $0 from next record of file, set NFgetline var set var from next input record, set NR, FNRgetline var &lt;file set vat from next record of filecommand | getline [var] run command piping the output either into $0 or varcommand | &amp; getline [var] run command as a co-process piping the output either into $0 or var. co-processes are a gawk extensionnext: stop processing the current input recordprint [expr-list [&gt;file] ]printf [format, expr-list [&gt;file] ]system(&quot;cmd&quot;) execute the command, and return the exit statusfflush([file]) flush any buffersprint ... | command write on a pipeprint ... |&amp; command write on a co-process# awk &#x27;BEGIN&#123;while(&quot;cat /etc/passwd&quot; | getline) print; close(&quot;/etc/passwd&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;while(getline &lt;&quot;/etc/passwd&quot;) print; close(&quot;/etc/passwd&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;&quot;date&quot; | getline d; print d&#125;&#x27;# awk &#x27;BEGIN&#123;&quot;date&quot; | getline d; split(d,mon); print mon[2]&#125;&#x27;# awk &#x27;BEGIN&#123;while(&quot;ls&quot; | getline) print&#125;&#x27;# awk &#x27;BEGIN&#123;printf(&quot;Enter your account: &quot;); getline name; print name&#125;&#x27;awk &#x27;BEGIN&#123;l=system(&quot;ls -l&quot;); print l&#125;&#x27;// prompting, wait for input# awk &#x27;BEGIN&#123;printf &quot;What is your name? &quot;; getline name &lt;&quot;/dev/tty&quot;&#125; $1~name &#123;print &quot;Found&quot; name &quot;on line &quot;, NR&quot;.&#125; END&#123;print &quot;See you,&quot; name &quot;.&quot;&#125;&#x27; /etc/passwd// count number of file# awk &#x27;BEGIN&#123;while(getline &lt;&quot;/etc/passwd&quot; &gt;0) lc++; print lc&#125;// sort# awk &#x27;&#123;print $1, $2 | &quot;sort&quot;&#125; END&#123;close(&quot;sort)&#125;&#x27; abc.txt 4.3 FILE SPACING:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# insert a blank lineawk &#x27;1; &#123;print &quot;&quot;&#125;&#x27;awk &#x27;BEGIN&#123;ORS=&quot;\\n\\n&quot;&#125;; 1&#x27;# insert two blank linesawk &#x27;1;&#123;print &quot;\\n&quot;&#125;NUMBERING AND CALCULATIONS:# using a TAB instead of space will perserve marginsawk &#x27;&#123;print FNR &quot;\\t&quot; $0&#125;&#x27;awk &#x27;&#123;print NR &quot;\\t&quot; $0&#125;&#x27;# number each line of a fileawk &#x27;&#123;printf(&quot;%5d : %s\\n, NR, $0)&#125;&#x27;# number each line of a file, but only print numbers if line is not blankawk &#x27;NF&#123;$0=++a &quot;:&quot; $0&#125;;&#123;print&#125;&#x27;awk &#x27;&#123;print (NF ? ++a &quot;:&quot; : &quot;&quot;) $0&#125;&#x27;# wc -lawk &#x27;END&#123;print NR&#125;&#x27;# wc -wawk &#x27;&#123;total=total+NF&#125;END&#123;print total&#125;&#x27;# print the sum of the fields of every lineawk &#x27;&#123;s=0; for(i=1;i&lt;=NF;i++) s=s+$i; print s&#125;&#x27;# add all fields in all lines and print the sumawk &#x27;&#123;for(i=1;i&lt;=NF;i++) s=s+$i&#125;END&#123;print s&#125;&#x27;# print absolute value of fieldsawk &#x27;&#123;for(i=1;i&lt;=NF;i++) if($i&lt;0) $i=-$i; print&#125;&#x27;awk &#x27;(for(i=1;i&lt;=NF;i++) $i = ($i&lt;0) ? -$i : $i; print&#125;&#x27;# print the total number of lines that contains &quot;Beth&quot;awk &#x27;/Beth/&#123;n++&#125;; END&#123;print n+0&#125;&#x27;# print the largest first fieldawk &#x27;$1&gt;max&#123;max=$1; maxline=$0&#125;; END&#123;print max, maxline&#125;&#x27;# print the last fieldawk &#x27;&#123;print $NF&#125;&#x27;# print the last field of the last lineawk &#x27;&#123;field=$NF&#125;; END&#123;print feild&#125;&#x27;TEXT CONVERSION AND SUBSTITUTION:# dos2unixawk &#x27;&#123;sub(/\\r$/,&quot;&quot;); print&#125;&#x27;# unix2dosawk &#x27;&#123;sub(/$/,&quot;\\r&quot;); print&#125;&#x27;# delete leading whitespaceawk &#x27;&#123;sub(/^[ \\t]+/,&quot;&quot;); print&#125;&#x27;# delete trailing whitespaceawk &#x27;&#123;sub(/[ \\t]+$/,&quot;&quot;); print&#125;&#x27;# delete both leading and trailing whitespaceawk &#x27;&#123;sub(/^[ \\t]+|[ \\t]+$/); print&#125;&#x27;# insert 5 whitespace at the beginning of lineawk &#x27;&#123;sub/^/, &quot; &quot;); print&#125;&#x27;# align all text flush right in a 70-column widthawk &#x27;&#123;printf &quot;%79s\\n&quot;, $0&#125;&#x27;# center all text on a 79-character widthawk &#x27;&#123;l=length(); s=int((79-l)/2); printf &quot;%&quot;(s+l&#125;&quot;s\\n&quot;,$0&#125;&#x27;# substituteawk &#x27;&#123;sub(/foo/,&quot;bar&quot;); print&#125;&#x27; # 1stawk &#x27;&#123;$0=gensub(/foo/,&quot;bar&quot;,4); print&#125;&#x27; # 4stawk &#x27;&#123;gsub(/foo/,&quot;bar&quot;); print&#125;&#x27; # all#awk &#x27;&#123;gsub(/scarlet|ruby|puce/, &quot;red&quot;); print&#125;# tacawk &#x27;&#123;a[i++]=$0&#125;END&#123;for(j=i-1;i&gt;=0;j--) print a[j]&#125;# append the next line, if line ends with a backslash.(fails to handle mutiple lines ending with backslash)awk &#x27;/\\\\$/&#123;sub(/\\\\$/,&quot;&quot;); getline t; print $0 t; next&#125;; 1&#x27;# sortawk -F&quot;:&quot; &#x27;&#123;print $1 | &quot;sort&quot;&#125;&#x27; /etc/passwd# delete the 2nd fieldawk &#x27;&#123;$2=&quot;&quot;; print&#125;&#x27;# print in reverse order the fieldsawk &#x27;&#123;for(i=NF;i&gt;0;i--) printf(&quot;%s &quot;,i); print &quot;&quot;&#125;&#x27;# remove duplicate, consecutive lines, uniqawk &#x27;a!~$0; &#123;a=$0&#125;&#x27;# remove duplicate, nonconsecutive linesawk &#x27;!a[$0]++&#x27;awk &#x27;!($0 in a)&#123;a[$0]; print&#125;&#x27; # most efficient# concatenate every 5 lines of input, using a comma separatorawk &#x27;ORS=%NR%5 ? &quot;,&quot; : &quot;\\n&quot;&#x27; 4.4 SLECTIVE PRINTING OF CERTAIN LINES:12345678910111213141516171819202122232425262728293031323334353637383940# headawk &#x27;NR&lt;11&#x27;# head -1awk &#x27;NR&gt;1&#123;exit&#125;;1&#x27;# tail -2awk &#x27;&#123;y=x &quot;\\n&quot; $0; x=$0&#125; END&#123;print y&#125;&#x27;# tail -1awk &#x27;END&#123;print&#125;&#x27;# grepawk &#x27;/regex/&#x27;# print the line immediately before a regexawk &#x27;/regex/&#123;print x&#125;;&#123;x=$0&#125;&#x27; # grep &#x27;regex&#x27; -B1# print the line immediately after a regexawk &#x27;/regex/&#123;getline; print&#125;&#x27; # grep &#x27;regex&#x27; -A1# grep -E &quot;AAA|BBB|CCC&quot;awk &#x27;/AAA/;/BBB/;/CCC/&#x27;# print only lines of 65 characters or longerawk &#x27;length&gt;64&#x27;# print section of file from regular expression to end of fileawk &#x27;/regex/,0&#x27;awk &#x27;/regex/,EOF&#x27;# print section of file based on line numbers(lines 8-12)awk&#x27;NR==8,NR==12&#x27;# print line 8 &amp; 12awk &#x27;NR==8;NR==12&#x27;# print line number 52awk &#x27;NR==52&#x27;awk &#x27;NR==52&#123;print; exit&#125;&#x27; # more efficient 4.5 SELECTIVE DELETION OF CERTAIN LINES:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# delete all blank linesawk NFawk &#x27;/./&#x27;# print x by 512 timesawk &#x27;BEGIN&#123;while(++a&lt;512) s=s &quot;x&quot;; print s&#125;&#x27;# merge fileawk &#x27;NR==FNR&#123;a[$0]=1; print&#125; NR&gt;FNR&#123;if(!a[$0]) print&#125;&#x27;awk &#x27;&#123;a[$0]&#125;END&#123;for(i in a) print i&#125;&#x27;# sortawk &#x27;&#123;a[j++]=$0&#125; END&#123;len=asort(a); for(i=1;i&lt;=len;i++) print a[i]&#125;&#x27;44. convert DEC to OTCecho 37 | awk &#x27;&#123;printf &quot;%o\\n&quot;, $0&#125;&#x27;45. print single quotaawk &#x27;BEGIN&#123;print &quot;\\0472004-12-12\\047&quot;&#125;&#x27;# obtain total memorycat /proc/meminfo | grep -i memtotal | awk -F&#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27;cat /proc/meminfo | grep -i memtotal | awk -F\\: &#x27;&#123;print $2&#125;&#x27;# display all NICs exclude localifconfig -a | grep &#x27;^\\w&#x27; | awk &#x27;!/lo/&#123;print $1&#125;&#x27;# obtain IP address of NIC eth0ifconfig eth0 | grep &#x27;inet &#x27;ifconfig eth0 | grep &#x27;inet &#x27; | awk -F&#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27; | awk &#x27;&#123;print $1&#125;&#x27;ifconfig eth0 | grep &#x27;inet &#x27; | tr &#x27;:&#x27; &#x27; &#x27; | awk &#x27;&#123;print $3&#125;&#x27;ifconfig eth0 | awk -F&#x27;:&#x27; &#x27;/inet / &#123;print $2&#125;&#x27; | awk &#x27;&#123;print $1&#125;&#x27;# $1 is a space, cause it begins with spacesifconfig eth0 | grep &#x27;inet &#x27; | awk -F&#x27;[ :]+&#x27; &#x27;&#123;print $4&#125;&#x27; # kill all process named fookill `ps -ax | grep &#x27;foo&#x27; | grep -v &#x27;grep&#x27; | awk &#x27;&#123;print $1&#125;&#x27;`# print the result that executed command &quot;date&quot;awk &#x27;BEGIN&#123;&quot;date&quot; | getline d;print d&#125;&#x27;# print monthawk &#x27;BEGIN&#123;&quot;date&quot; | getline d; split(d, mon); print mon[2]&#125;&#x27;# print the result that executed comand &quot;ls&quot;awk &#x27;BEGIN&#123;while(&quot;ls&quot; | getline) print&#125;&#x27;# prompting, wait for inputawk &#x27;BEGIN&#123;printf &quot;What is your name? &quot;; getline name &lt;&quot;/dev/tty&quot; &#125; $1~name &#123;print &quot;Found &quot; name &quot; on line &quot;, NR&quot;.&quot;&#125; END&#123;print &quot;See you,&quot; name &quot;.&quot;&#125;&#x27; /etc/passwd# count number of linux usersawk &#x27;BEGIN&#123;while(getline&lt;&quot;/etc/passwd&quot; &gt;0) lc++; print lc&#125;&#x27; # must be contain quotationsawk &#x27;&#123;print $1, $2 | &quot;sort&quot; &#125;END&#123;close(&quot;sort&quot;)&#125;&#x27; myfileawk &#x27;BEGIN&#123;system(&quot;clear&quot;)&#125;&#x27;awk &#x27;&#123;gsub(/test/, &quot;xxxx&quot;, $2); print&#125;&#x27; myfileawk &#x27;BEGIN&#123;print index(&quot;mytest&quot;, &quot;test&quot;)&#125;&#x27; # 3# 多维数组，array[index1,index2,……] ，SUBSEP是数组下标分割符，默认为 &quot;\\034&quot;awk &#x27;BEGIN&#123;SUBSEP=&quot;:&quot;; array[&quot;a&quot;,&quot;b&quot;]=1; for(i in array) print i&#125;&#x27;awk &#x27;BEGIN&#123;array[&quot;a&quot;&quot;:&quot;&quot;b&quot;]=1;for(i in array) print i&#125;&#x27;# cat file1g1.1 2g2.2 4g2.1 5g4.1 3# cat file2g1.1 2g1.2 3g4.1 4# cat file3g1.2 3g5.1 3# awk &#x27;&#123;a[ARGIND&quot; &quot;$1]=$2; b[$1]&#125; END &#123; for(i in b) &#123; printf i&quot; &quot;; for(j=1;j&lt;=ARGIND;j++) printf &quot;%s &quot;, a[j&quot; &quot;i] ? a[j&quot; &quot;i] : &quot;-&quot;; print &quot;&quot;; &#125; &#125;&#x27; file1 file2 file3g2.2 4 - -g5.1 - - 3g1.1 2 2 -g1.2 - 3 3g4.1 3 4 -g2.1 5 - - echo &quot;37&quot; |awk &#x27;&#123;printf &quot;%o\\n&quot;,$0&#125;&#x27;/home/lee#awk &#x27;BEGIN&#123;print &quot;\\0472004-12-12\\047&quot;&#125;&#x27;&#x27;2004-12-12&#x27; 5. chatrr123chattr +i /etc/passwdchatrr +a /etc/passwdlsattr /etc/passwd 6. grep1234567891011121314151617181920212223242526# 网卡信息dmesg | grep -n --color=auto eth# 显示关键字前3行和后2行dmesg | grep -n -A2 -B3 --color=always eth0# 扩展表达式egrep &#x27;^$|^#&#x27;myfile# 前面的字符出现1次以上egrep -n --color=auto &#x27;go+d&#x27; myfile# 前面的字符出现0~1次egrep -n --color=auto &#x27;go?d&#x27; myfile# or方式匹配egrep -n --color=auto &#x27;gd|good|dog&#x27; myfile# 组匹配egrep -n --color=auto &#x27;g(la|oo)d&#x27; myfile# 多重复组匹配echo &#x27;AxyzxyzxyzxyzC&#x27; | egrep &#x27;A(xyz)+C&#x27;man grep | col -c &gt; grep.txt 7. sort123456789101112131415161718192021222324252627282930313233343536373839404142434445# output sorted resultsort -o result.out video.txt # split the fields by &#x27;:&#x27;sort -t: -r video.txt # test whether it has been sortedsort -c video.txt # sort by 2nd fieldsort -t: +1 video.txt # sort 3rd field using ascii ordersort -t: +2 video.txt sort -t: -k3 video.txt# sort 3rd field using number order sort -t: +2n video.txtsort -t: -k3n video.txt # uniqsort -u video.txt# sort 4th field, then sort 1st fieldsort -t: -k4 -k1 video.txt# sort +field_number.characters_in# sort 2nd filed, begining with 3rd charactersort -t: +1.2 video.txt# list all unix userscat /etc/passwd | sort -t: +0 | awk -F&quot;:&quot; &#x27;&#123;print $1&#125;&#x27;# only not duplicate. here, sort is recommendablesort video.txt | uniq -u # only duplicatesort video.txt | uniq -d# count dulicate timessort video.txt | uniq -c# sorting ignore case sensitivesort -f 8. join12345678910111213141516171819202122232425262728293031323334353637# join, the files must have a common content; the fields must be splited by single tab or spacejoin [options] input-file1 input-file2-an n, the number of file. -a1, means joining files based on file 1-o n.m n, the number of file; m, the number of field. -o 1.3, means display field 3 of file 1-jn m n, the number of file; m, the number of field.-t delimiter# join crossjoin names.txt town.txt# mismatch connections, join alljoin -a1 -a2 names.txt town.txt# base on file1, join alljoin -a1 names.txt town.txt# selective joinjoin -o 1.1,2.2 names.txt town.txt# different field join# extract 3rd field of file 1, 2nd field of file 2, then join them togetherjoin -j1 3 -j2 2 file1 file2cat persP.Jones Office Runner ID897S.Round UNIX admin ID666L.Clip Personl Chief ID982cat pers2Dept2C ID897 6 yearsDept3S ID666 2 yearsDept5Z ID982 1 yearjoin -j1 4 -j2 2 pers pers2ID897 P.Jones Office Runner Dept2C 6 yearsID666 S.Round UNIX admin Dept3S 2 yearsID982 L.Clip Personl Chief Dept5Z 1 year 9. cut12345678910111213141516cut [options] file1 file2-c LIST, select only these characters-f LIST, select only these fields-d, delimitercut -d: -f4 perscut -d: -f1,3 perscut -d: -f1-3 perscut -d: -f1,6 /etc/passwd# file permisionls -l | cut -c1-10echo $PATH | tr &quot;:&quot; &quot;\\n&quot; | nlecho $PATH | cut -d&quot;:&quot; -f3,5 10. paste1234567891011paste -d -s - file1 file2-d, delimiter-s, paste one file at a time instead of in parallelpaste -d: pas1 pas2# list file name, 3 files each rowls | paste -d&quot; &quot; - - -# list file name, ls -l|awk &#x27;NF&gt;3&#123;print $8&#125;&#x27;ls | paste -d&quot;&quot; - 11. split123split -output_file_size input-filename output-filename-output_file_size, default 1000 linesoutput-filename, default x[aa]-&gt;x[zz] 12. dos2unix, ^M=ctrl+v ctrl ^ enter12345678910111213dos2uninx dosfilesed -e &#x27;s/^M//&#x27; dosfiletr -s &quot;\\r\\n&quot; &quot;\\n&quot; &lt; dosfiletr -d &quot;\\015&quot; &lt; dosfilecol -bx &lt; dosfile# delete ^M in vim:set ff=unix:%s/\\r//g:%s/^M//gc 13. lsof, list open file1234567891011121314151617181920212223242526272829lsof filename 显示打开指定文件的所有进程 lsof -a 表示两个参数都必须满足时才显示结果 lsof -c string 显示COMMAND列中包含指定字符的进程所有打开的文件 lsof -u username 显示所属user进程打开的文件 lsof -g gid 显示归属gid的进程情况 lsof +d /DIR/ 显示目录下被进程打开的文件 lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 lsof -d FD 显示指定文件描述符的进程 lsof -n 不将IP转换为hostname，缺省是不加上-n参数 lsof -i 用以显示符合条件的进程情况 lsof -i[46] [protocol][@hostname|hostaddr][:service|port] lsof -i tcp:22lsof -i :22lsof -i @10.40.53.22lsof /etc/passwdlsof /etc/cdromlsof `which httpd`lsof -c bashlsof -u apachelsof +D /tmplsof -i # port 80 14. echo12345678910echo -n 取消行末换行echo -E 关闭反斜线控制字符转换echo -e 启用反斜线控制字符转换\\c 取消行末换行符\\n newline =&gt; \\012\\r return\\t TAB =&gt; \\011\\num ASCII八进制编码\\xnum ASCII十六进制编码 15. 删除空格123456sed &quot;/^\\s*$/d&quot;sed &#x27;/^$/d&#x27;sed -i &#x27;/^$/d&#x27;awk &#x27;NF&gt;0&#x27;perl -i.backup -n -e &quot;print if /\\S/&quot;grep -v &#x27;^$&#x27;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Linux系统","slug":"Linux系统","date":"2019-12-18T08:25:32.000Z","updated":"2021-07-13T03:13:54.387Z","comments":true,"path":"2019/12/18/Linux系统/","link":"","permalink":"https://elihe2011.github.io/2019/12/18/Linux%E7%B3%BB%E7%BB%9F/","excerpt":"1. buffer和cachebuffer强调写，cache强调读，读写都带的时候，几乎无差别。buffer另外也有排队等待被处理的意思，cache基本没有。 2. bash配置文件2.1 全局配置123/etc/profile/etc/profile.d/*.sh /etc/bashrc 2.2 用户配置12~/.bash_profile, ~/.bash_login, ~/.profile(同时存在时，依次读取)~/.bashrc","text":"1. buffer和cachebuffer强调写，cache强调读，读写都带的时候，几乎无差别。buffer另外也有排队等待被处理的意思，cache基本没有。 2. bash配置文件2.1 全局配置123/etc/profile/etc/profile.d/*.sh /etc/bashrc 2.2 用户配置12~/.bash_profile, ~/.bash_login, ~/.profile(同时存在时，依次读取)~/.bashrc 2.3 profile和bashrc1) profile文件： 设定环境变量 运行命令和脚本 2) bashrc文件： 设定本地变量 定义别名 2.4 登录shell和非登录shell1) Login Shell: 通过终端登录 123su - USERNAMEsu -l USERNAME/etc/profile --&gt; /etc/profile.d/*.sh --&gt; ~/.bash_profile --&gt; ~/.bashrc --&gt; /etc/bashrc 2) Non-Login Shell: 1234su USERNAMEGUI终端下打开Console自动执行的shell脚本~/.bashrc --&gt; /etc/bashrc --&gt; /etc/profile.d/*.sh 3. 随机数12345678910# datedate | md5sumdate +%s | sha256sum | base64 | head -c 32; echo# opensslopenssl rand -base64 32# /dev/urandomcat /dev/urandom | tr -dc &#x27;a-zA-Z0-9&#x27; | fold -w 32 | head -1strings /dev/urandom | grep -o &#x27;[a-zA-Z0-9]&#x27; | head -32 | tr -d &#x27;\\n&#x27;; echo 4. 脚本中修改用户密码4.1 使用代码组123456&#123; echo &#x27;pass&#x27; sleep 1 echo &#x27;pass&#x27; sleep 1&#125; | passwd abc 4.2 --stdin1echo &#x27;pass&#x27; | passwd --stdin abc 4.3 查看是否已设置密码12# 已设置密码，PS或Ppasswd -S abc | awk &#x27;&#123;print $2&#125;&#x27; 5. 使用stdin来屏蔽敏感信息12345678910111213$ cat shield_sensitive_info.sh #!/bin/shname=$1read passecho &quot;username=$name&quot;echo &quot;password=$pass&quot;$ echo 123 | ./shield_sensitive_info.sh abc$ ./shield_sensitive_info.sh abc &lt;&lt;EOF123EOF 6. 释放内存查看系统内存使用情况 12free -mcat /proc/meminfo 释放内存 12345678# to free pagecacheecho 1 &gt; /proc/sys/vm/drop_caches# to free dentries and inodesecho 2 &gt; /proc/sys/vm/drop_caches# to free pagecache, dentries and inodes, use echo 3 &gt;/proc/sys/vm/drop_caches 7. 磁盘管理7.1 创建分区（fdisk, sfdisk, part）1) 分区操作 123456fdisk /dev/sdbn add a new partitionp print the partition tablew write table to disk and exitl list known partition typest 82: swap, 83: linux, 8e: lvm, fd: raid 2) 查看分区信息 1fdisk -l /dev/sdb 3) 查看内核识别的分区 123cat /proc/partionspartprobe [/dev/sda] partx -a /dev/sda # RHEL6 4) 大磁盘分区，2TB以上 1234parted /dev/sdbparted /dev/sdc printparted /dev/sdc mkpart logical ext3 19.2GB 19.7GBparted /dev/sdc rm 8 7.2 创建文件系统默认支持的文件系统：mkfs.xx VFS: Virtual Filesystem ext[2-4], xfs iso9660 nfs, cifs jfs, resiserfs, vfat gfs, sfs2, ocfs 1) mkfs 123mkfs -t ext3 /dev/sdb1mkfs.ext3 /dev/sdb2mkfs.ext3 -b 1024 /dev/sdb3 # 设置block大小 1024, 2048, 4096 2) mke2fs (/etc/mke2fs.conf) 1234567-b [1024|2048|4096]-i bytes-per-inode # 多少个字节预留一个inode，默认8192 (每8K一个inode)-N numbers-of-inode-L label-j # ext3-m ratio # 预留给超级用户的磁盘百分比，默认%5-r blocks # 预留的blocks数量 123456mke2fs -j -L &quot;ora_logical&quot; -b 2048 -i 8192 /dev/sdb1mke2fs -j /dev/sdb1 mke2fs -t ext4 -m 2 /dev/sdb1 # 预留2%磁盘块tune2fs -l /dev/sdb1 | grep &quot;Reserved&quot; 3) tune2fs 调整文件系统属性 123456-j # ext2-&gt;ext3-L label -m N # 调整预留百分比-c N # 指定挂载次数达到N次，进行自检，0或-1关闭自检-i N # 每挂载使用多少天自检，默认180，0或-1关闭自检-l # 显示超级块中的信息， dumpe2fs 12tune2fs -j /dev/sda5 # ext3tune2fs -l /dev/sda5 | grep &#x27;Block size&#x27; 4) e2label 查看或定义卷标 12e2label /dev/sda5e2label /dev/sda5 mydisk 5) blkid 查看设备的相关属性属性(UUID, FSTYPE, LABEL) 1blkid /dev/sda5 6) dumpe2fs 分区系统，BLOCK-GROUPs 1dumpe2fs -h /dev/sdb1 # super-block信息 7.3 检查文件系统1) fsck 123-t FSTYPE -a # 自动修复，不询问-f # 强制价差 12fsck -C -f -t ext3 /dev/sdb1fsck -f /dev/sdb1 2) e2fsck 专用修复ext2,ext3 12-f # 强制价差-p # 自动修复，不询问 12345# 检测修复文件系统(单用户模式执行)fsck -y /dev/sda1e2fsck -p /dev/sdb1mke2fs -c /dev/sdb1 7.4 挂载1) mount [options] DEVICE MOUNT_POINT DEVICE: DEV LABEL=”mysql-data” UUID=”uuid” options: 12345678910111213-t fstype-a 挂载/etc/fstab中全部auto的分区-r readonly-n, --no-mtab 不更新/etc/mtab-odefaults rw,suid,dev,exec,auto,nousers,async,realtimero readonlynoatime 访问不更新atimenoauto mount -a不挂载sync 同步写入nodev 不读文件系统上的字符或块设备remount 重新挂载loop 本地回环设备 1234mount -o remount,ro /dev/sdb1mount -o ro /dev/cdrom /mediamount -o loop,ro /root/RHEL6.iso /media 2) umount [DEVICE|MOUNT_POINT] 1234umount /mntumount: /mnt: device is busy.fuser -km /mnt","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"MongoDB","slug":"MongoDB","date":"2019-11-07T08:20:21.000Z","updated":"2021-06-22T10:50:49.745Z","comments":true,"path":"2019/11/07/MongoDB/","link":"","permalink":"https://elihe2011.github.io/2019/11/07/MongoDB/","excerpt":"1. 基本概念 面向集合(Collection-Oriented):数据存储在集合中，每个集合在数据库中都有唯一的标识名，可以包含无限数量的文档 模式自由(Schema-Free):集合类似RMDB中的Table，但无Schema 文档型(Document File):存储数据是键值对的集合”JSON”，键是字符串，值可以是任意类型。存储数据类型称为BSON(Binary Serialized Document Notation) 1.1 数据逻辑结构 文档(document): RMDB中的行 集合(collection): RMDB中的表，由多个文档构成 数据库(database): 与RMDB一致","text":"1. 基本概念 面向集合(Collection-Oriented):数据存储在集合中，每个集合在数据库中都有唯一的标识名，可以包含无限数量的文档 模式自由(Schema-Free):集合类似RMDB中的Table，但无Schema 文档型(Document File):存储数据是键值对的集合”JSON”，键是字符串，值可以是任意类型。存储数据类型称为BSON(Binary Serialized Document Notation) 1.1 数据逻辑结构 文档(document): RMDB中的行 集合(collection): RMDB中的表，由多个文档构成 数据库(database): 与RMDB一致 2. 相关命令2.1 查看帮助123helpdb.help()db.account.help() 2.2 数据库管理1234567891011121314151617181920show dbsuse mydbdb.copyDatabase(&#x27;mydb&#x27;, &#x27;temp&#x27;, &#x27;127.0.0.1&#x27;)db.cloneDatabase(&#x27;10.137.5.44&#x27;)use tempdb.dropDatabase() # 删当前数据库db.repairDatabase()db.getName() # 当前数据库名db.getMongo() # 服务器地址db.stats()db.version()use admindb.shutdownServer() 2.3 集合操作12345678910db.createCollection(&#x27;account&#x27;, &#123;size:20, capped:5, max:100&#125;)db.getCollection(&#x27;account&#x27;)db.getCollectionNames()db.account.help()db.account.count()db.account.dataSize()db.account.totalSize()db.account.getDB()db.account.renameCollection(&#x27;accounts&#x27;) 2.4 用户管理123456789show rolesdb.createUser(&#123;user: &#x27;eli&#x27;,pwd: &#x27;123&#x27;,roles: [&#123;role: &#x27;userAdmin&#x27;, db: &#x27;mydb&#x27;&#125;]&#125;)db.auth(&#x27;eli&#x27;, &#x27;123&#x27;) 2.5 增删改查12345db.account.save(&#123;name: &#x27;mongo&#x27;&#125;)db.account.insert(&#123;x:1&#125;)db.account.find(&#123;name: &#x27;mongo&#x27;&#125;)db.account.update(&#123;name: &#x27;mongo&#x27;&#125;, &#123;$set, &#123;name: &#x27;new_mongo&#x27;&#125;&#125;)db.account.remove(&#123;name: &#x27;new_mongo&#x27;&#125;) update语法： 123456db.collection.update( &lt;query&gt;, &lt;update&gt;, upsert:&lt;boolean&gt;, multi:&lt;boolean&gt; // 默认只修改一条数据) 更新操作： ———｜————–｜名称 ｜描述｜———｜————–｜$inc ｜根据要添加的值递增该字段的值。｜$mul ｜将该字段的值乘以指定的值｜$rename ｜重命名字段｜$setOnInsert ｜操作时,操作给相应的字段赋值｜$set ｜用来指定一个键的值，如果不存在则创建它｜$unset ｜用来指定一个键的值，如果不存在不创建创建它｜$min ｜只有当指定的值小于现有字段值时才更新该字段。｜$max ｜只有当指定的值大于现有字段值时才更新该字段。｜$currentDate ｜设置当前日期字段的值，或者作为一个日期或时间戳。｜ 3. 查询操作12345db.test.insert(&#123;name:&#x27;jack&#x27;, age:29, gender:&#x27;male&#x27;, email:&#x27;jack@outlook.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;lucy&#x27;, age:21, gender:&#x27;female&#x27;, email:&#x27;lucy@gmail.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;tom&#x27;, age:30, gender:&#x27;male&#x27;, email:&#x27;tom@abc.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;bonnie&#x27;, age:29, gender:&#x27;female&#x27;, email:&#x27;bonnie@abc.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;jack&#x27;, age:25, gender:&#x27;male&#x27;, email:&#x27;jack@hotmail.com&#x27;&#125;) 3.1 基本查询1234567db.test.find() # alldb.test.findOne(). # just onedb.test.find(&#123;name:&#x27;jack&#x27;&#125;)db.test.find(&#123;name:&#x27;jack&#x27;, age:29&#125;)db.test.find(&#123;&#125;, &#123;name:1, gender:1&#125;) # 只返回name, gender字段db.test.find(&#123;&#125;, &#123;email:0&#125;) # 不返回email字段 3.2 条件查询($gt, $lt, $gte, $lte, $ne, $or, $in, $nin)123456789db.test.find(&#123;age: &#123;$gt: 25, $lt: 30&#125;&#125;)db.test.find(&#123;gender: &#123;$ne: &#x27;male&#x27;&#125;&#125;)db.test.find(&#123;age: &#123;$in: [21, 30]&#125;&#125;)db.test.find(&#123;age: &#123;$nin: [21, 30]&#125;&#125;)db.test.find(&#123;name: &#123;$not: &#123;$in: [&#x27;jack&#x27;, &#x27;lily&#x27;]&#125;&#125;&#125;)db.test.find(&#123;age: &#123;$mod: [10,1]&#125;&#125;)db.test.find(&#123;name: &#123;$exists: true&#125;&#125;)db.test.find(&#123;$or: [&#123;name:&#x27;jack&#x27;&#125;, &#123;name:&#x27;tom&#x27;&#125;]) 3.3 null类型查询12345db.test.update(&#123;name:&#x27;jack&#x27;&#125;, &#123;$set: &#123;addr: null&#125;&#125;)db.test.update(&#123;name:&#x27;tom&#x27;&#125;, &#123;$set: &#123;addr: &#123;city:&#x27;NJ&#x27;, prov:&#x27;JS&#x27;&#125;&#125;&#125;)db.test.find(&#123;addr: null&#125;)db.test.find(&#123;addr: &#123;$in: [null], $exists: true&#125;&#125;) 3.4 正则表达式12db.test.find(&#123;name:/Jack?/i&#125;)db.test.find(&#123;name: &#123;$not: /^b.*/&#125;&#125;) # not like &#x27;b%&#x27; 3.5 js和$where查询123456db.test.find(&#123;age: &#123;$lt: 30&#125;&#125;)db.test.find(&#123;$where: &quot;this.age &gt; 30&quot;&#125;)db.test.find(&quot;this.age &gt; 30&quot;)f = function() &#123;return this.age&gt;30;&#125;db.test.find(f) 3.6 count, limit, skip, sort1234db.test.find().count()db.test.find().limit(5)db.test.find().skip(3).limit(5)db.test.find().sort(&#123;age:-1&#125;) 3.7 数组1234567891011121314151617181920212223db.fruits.insert(&#123;fruit: [&#x27;apple&#x27;, &#x27;orange&#x27;, &#x27;peach&#x27;]&#125;)db.fruits.insert(&#123;fruit: [&#x27;apple&#x27;, &#x27;kuaquat&#x27;, &#x27;blueberry&#x27;]&#125;)db.fruits.insert(&#123;fruit: [&#x27;pear&#x27;, &#x27;strawberry&#x27;, &#x27;banana&#x27;]&#125;)db.fruits.find(&#123;fruit: &#x27;apple&#x27;&#125;)db.fruits.find(&#123;fruit: &#123;$in: [&#x27;apple&#x27;]&#125;&#125;) # same as abovedb.fruits.find(&#123;fruit: &#123;$all: [&#x27;apple&#x27;, &#x27;orange&#x27;]&#125;&#125;)db.fruits.find(&#123;fruit: [&#x27;apple&#x27;, &#x27;orange&#x27;, &#x27;peach&#x27;]&#125;)db.fruits.find(&#123;&#x27;fruit.2&#x27;: &#x27;peach&#x27;&#125;)db.fruits.find(&#123;fruit: &#123;$size: 3&#125;&#125;)db.fruits.update(&#123;&#125;, &#123;$set: &#123;size:3&#125;&#125;, false, true)db.fruits.find()db.fruits.update(&#123;&#125;, &#123;$push: &#123;fruit:&#x27;grape&#x27;&#125;, $inc: &#123;size:1&#125;&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:2&#125;, size: 0&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:-2&#125;, size: 0&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:[2,1]&#125;, size: 0&#125;) 3.8 查询组合条件3.8.1 $in满足列表中任意一个值 1db.funds.find(&#123;&#x27;Fee&#x27;: &#123;&#x27;$in&#x27;: [15, 21]&#125;&#125;) 3.8.2 $all满足列表中全部值 1db.funds.find(&#123;&#x27;Fee&#x27;: &#123;&#x27;$all&#x27;: [15, 21]&#125;&#125;) 3.8.3 $or1db.funds.find(&#123;&#x27;$or&#x27;: [&#123;&#x27;Fee&#x27;: 15&#125;, &#123;&#x27;Fee&#x27;: 21&#125;]&#125;) 3.8.4 $and1db.funds.find(&#123;&#x27;$and&#x27;: [&#123;&#x27;Fee&#x27;: 15&#125;, &#123;&#x27;Fee&#x27;: 21&#125;]&#125;) 3.8.5 $exist节点存在，不关心值是否为null 1db.test.find(&#123;&quot;Fee&quot;: &#123;&#x27;$exists&#x27;: true&#125;&#125;) 节点不存在或者节点存在但值为null 1db.test.find(&#123;&quot;Fee&quot;: null&#125;) 3.8.6 $ne1db.test.find(&#123;&quot;Fee&quot;: &#123;&#x27;$ne&#x27;: 21&#125;&#125;) 1&#123;&#x27;$and&#x27;: [&quot;BasicInfo.offshoreFund&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;, &quot;BasicInfo.cayman&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;, &quot;BasicInfo.America&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;]&#125;, &quot;BasicInfo.BVI&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;]&#125; 123456db.funds.find(&#123; &#x27;$and&#x27;: [ &quot;BasicInfo.America&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;]&#125;, &quot;BasicInfo.BVI&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125; ] &#125;).count() 3.9 聚合查询12345678910&#123; &quot;_id&quot; : 1, &quot;domainName&quot; : &quot;test1.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 2, &quot;domainName&quot; : &quot;test2.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot;&#125;&#123; &quot;_id&quot; : 3, &quot;domainName&quot; : &quot;test3.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 4, &quot;domainName&quot; : &quot;test4.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 5, &quot;domainName&quot; : &quot;test5.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 6, &quot;domainName&quot; : &quot;test6.com&quot;, &quot;hosting&quot; : &quot;cloud.google.com&quot; &#125;&#123; &quot;_id&quot; : 7, &quot;domainName&quot; : &quot;test7.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 8, &quot;domainName&quot; : &quot;test8.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 9, &quot;domainName&quot; : &quot;test9.com&quot;, &quot;hosting&quot; : &quot;cloud.google.com&quot; &#125;&#123; &quot;_id&quot; : 10, &quot;domainName&quot; : &quot;test10.com&quot;, &quot;hosting&quot; : &quot;godaddy.com&quot; &#125; 导入数据： 1mongoimport -d testdb -c website --file website.json --upsert 3.9.1 group &amp; sort1234567891011121314151617// group bydb.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;]);// sortdb.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]);// matchdb.website.aggregate([ &#123; $match: &#123; hosting: &quot;aws.amazon.com&quot; &#125; &#125;, &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]); 3.9.2 export result12345678var group_data = db.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]); print(group_data.toArray()) db.websitegroup.insert(group_data.toArray()) 123mongoexport -d testdb -c websitegroup -o websitegroup.jsonmongoexport -d testdb -c websitegroup -f _id,total -o websitegroup.csv --type=csv 3.9.3 Large sort operation: (sort in memory 100M)123456db.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;], &#123; allowDiskUse: true &#125;); 3.10 查询Embeded数据12345678910111213141516171819202122&#123; &quot;_id&quot;: &quot;alpha&quot;, &quot;name&quot;: &quot;Storage Alpha&quot;, &quot;items&quot;: [ &#123; &quot;category&quot;: &quot;food&quot;, &quot;name&quot;: &quot;apple&quot; &#125;, &#123; &quot;category&quot;: &quot;food&quot;, &quot;name&quot;: &quot;banana&quot; &#125;, &#123; &quot;category&quot;: &quot;tool&quot;, &quot;name&quot;: &quot;hammer&quot; &#125;, &#123; &quot;category&quot;: &quot;furniture&quot;, &quot;name&quot;: &quot;couch&quot; &#125; ]&#125; 3.10.1 查询整个文档:1234567db.storage.find(&#123; &#x27;items.category&#x27;: &#123; $eq: &#x27;food&#x27; &#125;&#125;);// result 3.10.2 映射操作符（Projection Operator）1) $ 操作符会限制 array 类型数据的返回结果，使其仅返回第一个满足条件的元素。 123456789101112131415161718192021db.storage.find(&#123; &#x27;items.category&#x27;: &#123; $eq: &#x27;food&#x27; &#125;&#125;,&#123; &#x27;items.$&#x27;: 1&#125;);// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125; ]&#125; 2) $elemMatch 和 $ 的区别在于，$ 使用的是数据查询条件作为来映射（或者说过滤）array 中的数据，而 $elemMatch 需要指定单独的条件（可以指定多个条件） 1234567891011121314151617181920212223db.storage.find(&#123; &#x27;_id&#x27;: &#x27;alpha&#x27;&#125;,&#123; &#x27;items&#x27;: &#123; &#x27;$elemMatch&#x27;: &#123; &#x27;category&#x27;: &#x27;food&#x27; &#125; &#125;&#125;)// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125; ]&#125; 3.10.3 聚合1) $filter 123456789101112131415161718192021222324252627282930db.storage.aggregate([&#123; $project: &#123; &quot;items&quot;: &#123; $filter: &#123; input: &quot;$items&quot;, as: &quot;item&quot;, cond: &#123; $eq: [ &#x27;$$item.category&#x27;, &#x27;food&#x27; ] &#125; &#125; &#125; &#125;&#125;])// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125;, &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;banana&quot; &#125; ]&#125; 2) $unwind 如果文档中包含 array 类型字段、并且其中包含多个元素，使用 $unwind 操作符会根据元素数量输出多个文档，每个文档的 array 字段中仅包含 array 中的单个元素。 123456789101112131415161718192021222324252627282930313233343536db.storage.aggregate([&#123; $match: &#123; &#x27;items.category&#x27;: &#x27;food&#x27; &#125;&#125;,&#123; $unwind: &#x27;$items&#x27;&#125;,&#123; $match: &#123; &#x27;items.category&#x27;: &#x27;food&#x27; &#125;&#125;])// result/* 1 */&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;name&quot; : &quot;Storage Alpha&quot;, &quot;items&quot; : &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125;&#125;/* 2 */&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;name&quot; : &quot;Storage Alpha&quot;, &quot;items&quot; : &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;banana&quot; &#125;&#125; 4. 索引4.1 基础索引1234db.test.ensureIndex(&#123;age:1&#125;)db.test.ensureIndex(&#123;age:1&#125;, &#123;background:true&#125;)db.test.getIndexes() 4.2 文档索引1234db.test.update(&#123;addr:null&#125;, &#123;$set: &#123;addr: &#123;city:&#x27;BJ&#x27;, prov:&#x27;BJ&#x27;&#125;&#125;&#125;)db.test.ensureIndex(&#123;addr:1&#125;)db.test.find(&#123;addr: &#123;city:&#x27;BJ&#x27;, prov:&#x27;BJ&#x27;&#125;&#125;) # 使用索引db.test.find(&#123;addr: &#123;prov:&#x27;BJ&#x27;, city:&#x27;BJ&#x27;&#125;&#125;) # 不使用索引 4.3 组合索引1db.test.ensureIndex(&#123;name:1, age:1&#125;) 4.4 唯一索引1db.test.ensureIndex(&#123;name:1&#125;, &#123;unique:true&#125;) 4.5 强制使用索引 (hint)12db.test.ensureIndex(&#123;name:1, age:1&#125;)db.test.find(&#123;age: &#123;$gt:25&#125;&#125;).hint(&#123;name:1, age:1&#125;).explain() 4.6 删除索引12db.test.dropIndex(&#123;name:1&#125;)db.test.dropIndexes() 5. 存储过程5.1 定义函数1function addNumbers(x, y) &#123;return x+y;&#125; 5.2 放入js表中12db.system.js.save(&#123;_id:&#x27;addNumbers&#x27;, value:addNumbers&#125;)db.system.js.save(&#123;_id:&#x27;addNumbers&#x27;, value:function(x, y) &#123;return x+y;&#125;&#125;) 5.3 执行存储过程1db.eval(&#x27;addNumbers(1,2)&#x27;) 6. 工具和命令6.1 常用命令123456789bsondump bson格式文件转换为jsonmongo 客户端, js解释器mongod 服务器，每个实例启动一个进程mongodump/mongorestoremongoexport/mongoimportmongofile GridFS管理器，实现二进制文件存取mongos 分片路由，使用sharding功能时，应用程序连接mongos，而不是mongodmongosniff tcpdump，监控mongodb相关包请求，并已指定可读形式输出mongostat 实时监控工具 6.2 数据导出1234567mongoexport-d, --db-c, --collection-o, --out-f, --fields--host/--port-csv, --type=csv 12mongoexport -d mydb -c test -o test.jsonmongoexport -d mydb -c test -f name,addr --type=csv -o test.csv 6.3 数据导入12345678910mongoimport-d, --db-c, --collection-f, --fields--host/--port-csv, --type=csv--drop =&gt; drop collecion first if exists--stopOnError--file--headerline # 忽略第一行 1mongoimport -d mydb -c test --headerline --type=csv --drop --file test.csv 6.4 数据库备份恢复12345678910111213141) mongodump-d, --db-c, --collection-o, --out-q, --querymongodump -d mydb # 生成dump目录，该目录下保存数据文件2) mongorestore-d, --db-c, --collection--objcheck--filter--drop","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://elihe2011.github.io/categories/NoSQL/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://elihe2011.github.io/tags/mongodb/"}]},{"title":"RabbitMQ","slug":"RabbitMQ","date":"2019-10-14T06:04:07.000Z","updated":"2021-10-15T10:41:56.396Z","comments":true,"path":"2019/10/14/RabbitMQ/","link":"","permalink":"https://elihe2011.github.io/2019/10/14/RabbitMQ/","excerpt":"1. 简介面向消息的中间件，用于组件之间的解藕，主要体现在消息的发送者和消费者之间无强依赖关系 消息中间件：在消息传输过程中保存消息的容器。其中作用： 解藕 削峰 异步处理 缓存存储 消息通知 提供系统的拓展性 消息中间传递模型： 点对点 (PTP) 发布订阅 (Pub/Sub) AMQP: Advanced Message Queue Protocol","text":"1. 简介面向消息的中间件，用于组件之间的解藕，主要体现在消息的发送者和消费者之间无强依赖关系 消息中间件：在消息传输过程中保存消息的容器。其中作用： 解藕 削峰 异步处理 缓存存储 消息通知 提供系统的拓展性 消息中间传递模型： 点对点 (PTP) 发布订阅 (Pub/Sub) AMQP: Advanced Message Queue Protocol 2. 安装RabbitMQ 3.7.19: Upgrading to Erlang 21.x or Later Versions 2.1 Linux12345678910111213141516yum repolist yum clean allyum makecache yum list erlangcd /etc/yum.repos.d/# erlangcurl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh | sudo bashyum install erlang# rabbitmqcurl -s https://packagecloud.io/install/repositories/rabbitmq/rabbitmq-server/script.rpm.sh | sudo bashyum install rabbitmq-server-3.7.19-1.el7 2.2 配置文件1) /etc/rabbitmq/rabbitmq-env.conf 1234RABBITMQ_NODE_IP_ADDRESS: 127.0.0.1RABBITMQ_NODE_PORT: 5672RABBITMQ_NODE_CONFIG_FILE: *.configRABBITMQ_NODE_LOG_BASE: 2) /etc/rabbitmq/rabbitmq.config 123tcp_listeners 5672disk_free_limitvm_memory_high_watermark 0.4 2.3 启动123systemctl enable rabbitmq-serversystemctl start rabbitmq-server 2.4 Mac123456789101112131415brew install rabbitmq# 配置环境变量export RABBIT_HOME=/usr/local/Cellar/rabbitmq/3.8.0export PATH=$PATH:$RABBIT_HOME/sbin# 启动服务sudo rabbitmq-serversudo rabbitmq-server -detached # 后台运行# 停止服务rabbitmqctl stop# 配置文件位置cd /usr/local/etc/rabbitmq 2.5 Docker1234567mkdir -p /data/rabbitmqdocker run -d --hostname rabbit-server --name rabbit-sever -p 5672:5672 -p 15672:15672 -p 25672:25672 -v /data/rabbitmq:/var/lib/rabbitmq rabbitmq:management5672: API15672: GUI 25672: 集群通信 3. 控制命令3.1 插件命令12345# 插件列表rabbitmq-plugins list# 开启管理工具 （支持http://localhost:15672/）rabbitmq-plugins enable rabbitmq_management 3.2 操作命令1234567891011121314151617181920212223# 虚拟主机rabbitmqctl add_vhost ut_vhostrabbitmqctl list_vhosts# 新增账号rabbitmqctl add_user utime welovetimerabbitmqctl list_users# 修改密码rabbitmqctl change_password utime utime@celery123# 设置tagsudo rabbitmqctl set_user_tags utime administrator# 设置权限rabbitmqctl set_permissions -p ut_vhost utime &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;rabbitmqctl list_permissions# 队列状态rabbitmqctl list_queues rabbitmqctl list_queues name messages messages_ready messages_unacknowledged rabbitmqctl list_queues name consumersrabbitmqctl list_queues name memory 4. 相关术语 Server(broker): 接受客户端连接，实现AMQP消息队列和路由功能的进程 VirtualHost：虚拟消息服务器，每个 VirtualHost 相当于一个相对独立的 RabbitMQ 服务器，每个 VirtualHost 之间是相互隔离的。 Connections：被监听的链接 Exchange：消息交换机，决定消息按什么规则，路由到哪个队列 Queue：队列，用于存储生产者的消息；接收到交换机发来的消息，未被消费暂存队列中 Binding：绑定，把exchange和queue按照路由规则绑定起来 Routing Key：路由关键字，exchange根据这个关键字来投递消息 Channel：消息通道，客户端的每个连接建立多个channel Producer/Publisher: 消息生产者，用于投递消息的程序 Consumer：消息消费者，用于接收消息的程序 ConnectionFactory：连接管理器，应用程序与 Rabbit 之间建立连接的管理器，程序代码中使用； 4.1 Exchange Fanout: 类似广播，转发到所有绑定交换机的Queue上 Direct：类似单播，RoutingKey和BindingKey完全匹配 Topic：类似组播，转发到符合通配符的Queue上 Headers：请求头与消息头匹配，才能接收消息 Fanout工作模式： Direct工作模式： Topic工作模式： 核心概念： Exchange：交互机，用于接受、分配消息；生成者产生的消息，送入交互机中，根据交换机规则绑定 key， 通过交换机把消息发到对应得 key 上。 Direct Exchange：直接交互式路由键。需要将一个队列绑定到交换机上，要求该消息一一个特定的路由完全匹配。例如一个队列绑定到该交换机上要求路由键为”dog”，只有被标记为”dog”的消息能够被转发。 Fanout Exchange: 广播式路由键。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。 Topic Exchange：主题式交换器。通过消息的路由关键字和绑定的关键字的模糊匹配，将消息路由到被绑定的队列中。支持通配符：*匹配一个词组，#零个或多个词组。*.stock.#匹配路由关键字usd.stock和eur.stock.db，但不匹配stock.nasdaq 5. 工作模式5.1 Simple生产者 ——&gt; 队列 ——&gt; 消费者 最简单常用的模式 12345678910111213141516171819202122232425func NewRabbitMQ(queueName, exchange, key string) *RabbitMQ &#123; return &amp;RabbitMQ&#123; QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL, &#125;&#125;// 设置queueNamefunc NewRabbitMQPubSub(queueName string) *RabbitMQ &#123; rabbitmq := NewRabbitMQ(queueName, &quot;&quot;, &quot;&quot;) var err error // 创建连接 rabbitmq.conn, err = amqp.Dial(rabbitmq.Mqurl) rabbitmq.failOnErr(err, &quot;创建连接失败&quot;) // 创建channel rabbitmq.channel, err = rabbitmq.conn.Channel() rabbitmq.failOnErr(err, &quot;获取channel失败&quot;) return rabbitmq&#125; 5.2 Work生产者 ——&gt; 队列 ——&gt; 多个消费者，争抢 一个消息只能被一个消费者获取。与Simple模式的区别，只在于开启了多个消费者端，负载均衡。 5.3 Publish / Subscribe消息被路由投递给多个队列，一个消息被多个消费者获取 生产者 ——&gt; 交换机 ——&gt; 队列 ——&gt; 消费者 ​ | ​ — ——&gt; 队列 ——&gt; 消费者 邮件群发，群聊天，广播 (广告) 12345678910111213141516171819202122232425func NewRabbitMQ(queueName, exchange, key string) *RabbitMQ &#123; return &amp;RabbitMQ&#123; QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL, &#125;&#125;// 设置exchangeNamefunc NewRabbitMQPubSub(exchangeName string) *RabbitMQ &#123; rabbitmq := NewRabbitMQ(&quot;&quot;, exchangeName, &quot;&quot;) var err error // 创建连接 rabbitmq.conn, err = amqp.Dial(rabbitmq.Mqurl) rabbitmq.failOnErr(err, &quot;创建连接失败&quot;) // 创建channel rabbitmq.channel, err = rabbitmq.conn.Channel() rabbitmq.failOnErr(err, &quot;获取channel失败&quot;) return rabbitmq&#125; 5.4 Routing从生产端就可以指定队列消息的消费者是谁, 一个消息被多个消费者获取，并且消息的目标队列可被生产者指定 5.5 Topic交换机根据 key 的规则模糊匹配到对应的队列，由队列的监听消费者接收消息消费 6. Golang6.1 支撑包1go get github.com/streadway/amqp 6.2 基础队列6.2.1 连接 RabbitMQ123456789func GetRabbitMQConn() (*amqp.Connection, error) &#123; username := &quot;guest&quot; password := &quot;guest&quot; host := &quot;127.0.0.1&quot; port := 5672 url := fmt.Sprintf(&quot;amqp://%s:%s@%s:%d&quot;, username, password, host, port) return amqp.Dial(url)&#125; 6.2.2 生产者123456789101112131415161718192021222324252627282930313233343536373839type demo struct &#123; Name string `json:&quot;name&quot;` Addr string `json:&quot;addr&quot;`&#125;func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() data := demo&#123; Name: &quot;Jack&quot;, Addr: &quot;Montreal&quot;, &#125; bs, _ := json.Marshal(data) err = ch.Publish( &quot;&quot;, // exchange &quot;simple:queue&quot;, // key, RoutingKey, same as Queue.Name when the exchange mode is direct. false, // mandatory false, // immediate amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, Body: bs, &#125;) if err != nil &#123; log.Fatalf(&quot;Failed to publish a message: %v&quot;, err) &#125; log.Printf(&quot;[*] sent %s&quot;, bs)&#125; 6.2.3 消费者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() q, err := ch.QueueDeclare( &quot;simple:queue&quot;, // name false, // durable false, // autoDelete false, // exclusive false, // noWait nil, // args ) if err != nil &#123; log.Fatalf(&quot;Failed to declare a queue: %v&quot;, err) &#125; // 定义一个消费者 msgs, err := ch.Consume( q.Name, // queue (string) &quot;&quot;, // consumer true, // autoAck false, // exclusive false, // noLocal false, // noWait nil, // args ) if err != nil &#123; log.Fatalf(&quot;Failed to register a consume: %v&quot;, err) &#125; go func() &#123; for msg := range msgs &#123; log.Printf(&quot;Received a message: %s\\n&quot;, msg.Body) &#125; &#125;() log.Println(&quot;[*] Waiting for messages. To exit press CTRL+C&quot;) select &#123;&#125;&#125; 6.3 任务队列为了避免等待执行一些耗时的任务, 而是将需要执行的任务封装为消息发送给工作队列, 后台运行的工作进程将任务消息取出来并执行相关任务。多个后台工作进程同时间进行, 那么任务在他们之间共享. 6.3.1 发布任务 (task.py)12345678910111213141516171819202122232425262728293031323334353637383940414243func bodyForm(args []string) string &#123; var s string if (len(args) &lt; 2) || os.Args[1] == &quot;&quot; &#123; s = &quot;no task&quot; &#125; else &#123; s = strings.Join(args[1:], &quot; &quot;) &#125; return s&#125;func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() body := bodyForm(os.Args) err = ch.Publish( &quot;&quot;, &quot;task:queue&quot;, false, false, amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, DeliveryMode: amqp.Persistent, Body: []byte(body), &#125;, ) if err != nil &#123; log.Fatalf(&quot;Failed to publish a message&quot;) &#125; log.Printf(&quot;sent %s\\n&quot;, body)&#125; 6.3.2 执行任务 (worker.py)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() q, err := ch.QueueDeclare( &quot;task:queue&quot;, false, false, false, false, nil, ) if err != nil &#123; log.Fatalf(&quot;Failed to declare a queue: %v&quot;, err) &#125; // 计数器 err = ch.Qos( 1, // prefetch count 0, // prefetch size false, // global ) if err != nil &#123; log.Fatalf(&quot;Failed to set Qos: %v&quot;, err) &#125; msgs, err := ch.Consume( q.Name, &quot;&quot;, false, false, false, false, nil, ) if err != nil &#123; log.Fatalf(&quot;Failed to register a consumer: %v&quot;, err) &#125; done := make(chan bool) go func() &#123; for msg := range msgs &#123; log.Printf(&quot;Received a message: %s\\n&quot;, msg.Body) msg.Ack(false) &#125; &#125;() log.Printf(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;) &lt;-done&#125;","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://elihe2011.github.io/categories/RabbitMQ/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://elihe2011.github.io/tags/rabbitmq/"}]},{"title":"Hexo","slug":"Hexo","date":"2019-09-24T08:06:10.000Z","updated":"2021-06-22T10:50:49.742Z","comments":true,"path":"2019/09/24/Hexo/","link":"","permalink":"https://elihe2011.github.io/2019/09/24/Hexo/","excerpt":"1. 安装hexo12345678npm install hexo-cli -g hexo init blogcd blognpm installhexo serv","text":"1. 安装hexo12345678npm install hexo-cli -g hexo init blogcd blognpm installhexo serv 2. 安装主题123git clone https://github.com/xaoxuu/hexo-theme-material-x themes/material-xnpm i -S hexo-generator-search hexo-generator-json-content hexo-renderer-less","categories":[{"name":"Tools","slug":"Tools","permalink":"https://elihe2011.github.io/categories/Tools/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://elihe2011.github.io/tags/hexo/"}]},{"title":"Nginx安装配置","slug":"Nginx安装","date":"2019-09-19T02:32:10.000Z","updated":"2021-06-22T10:50:49.741Z","comments":true,"path":"2019/09/19/Nginx安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/19/Nginx%E5%AE%89%E8%A3%85/","excerpt":"1. 添加nginx用户123groupadd nginx useradd -g nginx -s /sbin/nologin -M nginx","text":"1. 添加nginx用户123groupadd nginx useradd -g nginx -s /sbin/nologin -M nginx 2. 安装123456789101112131415161718192021wget http://openresty.org/download/openresty-1.15.8.2.tar.gztar zxvf openresty-1.15.8.2.tar.gzcd openresty-1.15.8.2# 解决openssl支撑包问题, 删除.opensslvi bundle/nginx-1.15.8/auto/lib/openssl/confCORE_INCS=&quot;$CORE_INCS $OPENSSL/.openssl/include&quot;CORE_DEPS=&quot;$CORE_DEPS $OPENSSL/.openssl/include/openssl/ssl.h&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libssl.a&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libcrypto.a&quot;./configure -j2 --prefix=/usr/local/openresty --with-openssl=/usr/local/opensslmakemake installvi ~/.bash_profileexport PATH=/usr/local/openresty/nginx/sbin:/usr/local/openresty/bin:$PATH 3. 开机启动1234567891011121314151617vi /usr/lib/systemd/system/nginx.serviceDescription=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/openresty/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 4. 管理ngnix123systemctl enable nginx.servicesystemctl start nginx 5. 配置123456789101112131415161718192021222324252627282930313233343536373839404142mkdir -p /usr/local/openresty/nginx/conf.dvi /usr/local/openresty/nginx/conf/nginx.confhttp &#123; # 去除注释 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27; &#x27;$request_time $upstream_response_time&#x27;; ... # 节点末尾添加 include /usr/local/openresty/nginx/conf.d/*.conf;&#125;vi /usr/local/openresty/nginx/conf.d/test.confserver &#123; listen 80; server_name 192.168.1.21; access_log /var/log/nginx/embo.access.log main; error_log /var/log/nginx/embo.error.log; error_page 404 = /404; error_page 403 = /403; location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; #include proxy_params; proxy_pass http://127.0.0.1:20002/; proxy_redirect off; &#125; location = / &#123; root /data/www/lp-web/; index index.html; &#125; location ~* \\.(html|ico)$ &#123; root /data/www/lp-web/; &#125;&#125; 6. nginx相关命令1234567nginxnginx -tnginx -s stopnginx -s reload 7. 安装问题7.1 PCRE未安装1234567891011121314checking for SA_RESTART ... found + ngx_stream_lua_module was configuredchecking for PCRE library ... not foundchecking for PCRE library in /usr/local/ ... not foundchecking for PCRE library in /usr/include/pcre/ ... not foundchecking for PCRE library in /usr/pkg/ ... not foundchecking for PCRE library in /opt/local/ ... not found./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 1yum -y install pcre-devel 8. systemctl启动服务，日志异常12345Dec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Starting nginx.service...Dec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal nginx[26980]: nginx: the configuration file /usr/local/openresty/nginx/conf/nginx.conf syntax is okDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal nginx[26980]: nginx: configuration file /usr/local/openresty/nginx/conf/nginx.conf test is successfulDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Failed to read PID from file /usr/local/openresty/nginx/logs/nginx.pid: Invalid argumentDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Started nginx.service. 原因：启动成功瞬间，暂未找到nginx.pid文件 解决：增加睡眠时间 123456789101112131415161718vi /usr/lib/systemd/system/nginx.serviceDescription=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/openresty/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf ExecStartPost=/bin/sleep 0.1 # 新增项ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 12345systemctl daemon-reloadsystemctl restart nginx.servicesystemctl status nginx","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://elihe2011.github.io/tags/nginx/"}]},{"title":"Supervisor","slug":"Supervisor","date":"2019-09-16T03:11:14.000Z","updated":"2021-07-13T02:50:42.530Z","comments":true,"path":"2019/09/16/Supervisor/","link":"","permalink":"https://elihe2011.github.io/2019/09/16/Supervisor/","excerpt":"1. 安装12345678910su - rootpip3 install supervisor/usr/local/python37/bin/echo_supervisord_conf &gt; /etc/supervisord.conf#supervisord -c /etc/supervisord.confln -s /usr/local/python37/bin/supervisord /usr/bin/supervisordln -s /usr/local/python37/bin/supervisorctl /usr/bin/supervisorctl","text":"1. 安装12345678910su - rootpip3 install supervisor/usr/local/python37/bin/echo_supervisord_conf &gt; /etc/supervisord.conf#supervisord -c /etc/supervisord.confln -s /usr/local/python37/bin/supervisord /usr/bin/supervisordln -s /usr/local/python37/bin/supervisorctl /usr/bin/supervisorctl 2. 修改配置123456789101112131415161718192021mkdir -p /etc/supervisord.conf.dvi /etc/supervisord.conf[unix_http_server];file=/tmp/supervisor.sock ; the path to the socket filefile=/var/run/supervisor.sock ;[supervisord];logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.loglogfile=/var/log/supervisord.log ;;pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pidpidfile=/var/run/supervisord.pid ;[supervisorctl];serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socketserverurl=unix:///var/run/supervisor.sock ;[include]files = /etc/supervisord.conf.d/*.conf 3. 开机启动12345678910111213141516vi /usr/lib/systemd/system/supervisord.service[Unit] Description=Supervisor daemon[Service] Type=forking ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf ExecStop=/usr/bin/supervisorctl shutdown ExecReload=/usr/bin/supervisorctl reload KillMode=process Restart=on-failure RestartSec=42s[Install] WantedBy=multi-user.target 4. 系统管理12345systemctl enable supervisordsystemctl start supervisordps -ef | grep supervisor 5. 新增配置5.1 webhhok12345678910111213141516171819vi /etc/supervisord.conf.d/webhook.conf [program:webhook]user=utimedirectory=/tmp/command=webhookit -c /etc/webhook/config.py -p 18340autostart=trueautorestart=truestartretries=10exitcodes=0stopsignal=KILLstopwaitsecs=10redirect_stderr=truestdout_logfile=/var/log/webhook-out.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/webhook-error.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5 5.2 业务123456789101112131415vi /etc/supervisord.conf.d/lp-service.conf[program:lp-service]command=/home/utime/.venv/py3/bin/gunicorn -b 127.0.0.1:20002 --worker-class eventlet -w 4 manage:app --access-logfile /tmp/lp-service-gunicorn.logautostart=trueautorestart=truedirectory=/home/utime/lp-service/user=utimestdout_logfile=/var/log/lp-service-stdout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/lp-service-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot; 6. 启动123supervisorctl updatesupervisorctl status","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"supervisor","slug":"supervisor","permalink":"https://elihe2011.github.io/tags/supervisor/"}]},{"title":"Go gRPC Gateway","slug":"Go gRPC Gateway","date":"2019-07-20T07:18:06.000Z","updated":"2021-06-22T10:50:49.737Z","comments":true,"path":"2019/07/20/Go gRPC Gateway/","link":"","permalink":"https://elihe2011.github.io/2019/07/20/Go%20gRPC%20Gateway/","excerpt":"1. gRPC 回顾总结1.1 gRPC1go get -u google.golang.org/grpc 强大的 IDL，使用 Protocol Buffers 作为数据交换格式 跨语言、跨平台 支持HTTP2，双向传输、多路复用、认证等 grpc下常用包： metadata: 提供方法对 grpc 元数据结构MD 进行获取和处理 credentials: 封装了客户端对服务端进行身份验证所需的所有状态，并做出各种断言 codes: grpc 标准错误码","text":"1. gRPC 回顾总结1.1 gRPC1go get -u google.golang.org/grpc 强大的 IDL，使用 Protocol Buffers 作为数据交换格式 跨语言、跨平台 支持HTTP2，双向传输、多路复用、认证等 grpc下常用包： metadata: 提供方法对 grpc 元数据结构MD 进行获取和处理 credentials: 封装了客户端对服务端进行身份验证所需的所有状态，并做出各种断言 codes: grpc 标准错误码 1.2 Protoc Plugin编译插件 1go get -u github.com/golang/protobuf/protoc-gen-go 1.3 Protocol Buffers v3Google 推出的一种数据描述语言，支持多语言、跨平台，二进制格式。 1.4 protocProtocol Buffers 运用程序 123456wget https://github.com/google/protobuf/releases/download/v3.5.1/protobuf-all-3.5.1.zipunzip protobuf-all-3.5.1.zipcd protobuf-3.5.1/./configuremakemake install 生成 golang 源文件： 1protoc --go_out=plugins=grpc,import_path=mypkg:. *.proto 2. gRPC-Gatewaygrpc-gateway 是proto的一个插件，它读取gRPC服务定义，并生成一个反向代理服务器，将RESTful JSON API转换为gRPC. 2.1 安装1go get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gateway 2.2 proto文件2.2.1 google.apigoogle 官方提供的 api 描述文件，主要针对 grpc-gateway 的 http 转换支持，定义了 Protocol Buffer 所扩展的 HTTP Option 1) annotations.proto 1234567891011121314151617181920212223242526272829// Copyright (c) 2015, Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.syntax = &quot;proto3&quot;;package google.api;import &quot;google/api/http.proto&quot;;import &quot;google/protobuf/descriptor.proto&quot;;option java_multiple_files = true;option java_outer_classname = &quot;AnnotationsProto&quot;;option java_package = &quot;com.google.api&quot;;extend google.protobuf.MethodOptions &#123; // See `HttpRule`. HttpRule http = 72295728;&#125; 2) http.proto 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281// Copyright 2016 Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.syntax = &quot;proto3&quot;;package google.api;option cc_enable_arenas = true;option java_multiple_files = true;option java_outer_classname = &quot;HttpProto&quot;;option java_package = &quot;com.google.api&quot;;// Defines the HTTP configuration for a service. It contains a list of// [HttpRule][google.api.HttpRule], each specifying the mapping of an RPC method// to one or more HTTP REST API methods.message Http &#123; // A list of HTTP rules for configuring the HTTP REST API methods. repeated HttpRule rules = 1;&#125;// `HttpRule` defines the mapping of an RPC method to one or more HTTP// REST APIs. The mapping determines what portions of the request// message are populated from the path, query parameters, or body of// the HTTP request. The mapping is typically specified as an// `google.api.http` annotation, see &quot;google/api/annotations.proto&quot;// for details.//// The mapping consists of a field specifying the path template and// method kind. The path template can refer to fields in the request// message, as in the example below which describes a REST GET// operation on a resource collection of messages://// ```proto// service Messaging &#123;// rpc GetMessage(GetMessageRequest) returns (Message) &#123;// option (google.api.http).get = &quot;/v1/messages/&#123;message_id&#125;/&#123;sub.subfield&#125;&quot;;// &#125;// &#125;// message GetMessageRequest &#123;// message SubMessage &#123;// string subfield = 1;// &#125;// string message_id = 1; // mapped to the URL// SubMessage sub = 2; // `sub.subfield` is url-mapped// &#125;// message Message &#123;// string text = 1; // content of the resource// &#125;// ```//// This definition enables an automatic, bidrectional mapping of HTTP// JSON to RPC. Example://// HTTP | RPC// -----|-----// `GET /v1/messages/123456/foo` | `GetMessage(message_id: &quot;123456&quot; sub: SubMessage(subfield: &quot;foo&quot;))`//// In general, not only fields but also field paths can be referenced// from a path pattern. Fields mapped to the path pattern cannot be// repeated and must have a primitive (non-message) type.//// Any fields in the request message which are not bound by the path// pattern automatically become (optional) HTTP query// parameters. Assume the following definition of the request message://// ```proto// message GetMessageRequest &#123;// message SubMessage &#123;// string subfield = 1;// &#125;// string message_id = 1; // mapped to the URL// int64 revision = 2; // becomes a parameter// SubMessage sub = 3; // `sub.subfield` becomes a parameter// &#125;// ```//// This enables a HTTP JSON to RPC mapping as below://// HTTP | RPC// -----|-----// `GET /v1/messages/123456?revision=2&amp;sub.subfield=foo` | `GetMessage(message_id: &quot;123456&quot; revision: 2 sub: SubMessage(subfield: &quot;foo&quot;))`//// Note that fields which are mapped to HTTP parameters must have a// primitive type or a repeated primitive type. Message types are not// allowed. In the case of a repeated type, the parameter can be// repeated in the URL, as in `...?param=A&amp;param=B`.//// For HTTP method kinds which allow a request body, the `body` field// specifies the mapping. Consider a REST update method on the// message resource collection://// ```proto// service Messaging &#123;// rpc UpdateMessage(UpdateMessageRequest) returns (Message) &#123;// option (google.api.http) = &#123;// put: &quot;/v1/messages/&#123;message_id&#125;&quot;// body: &quot;message&quot;// &#125;;// &#125;// &#125;// message UpdateMessageRequest &#123;// string message_id = 1; // mapped to the URL// Message message = 2; // mapped to the body// &#125;// ```//// The following HTTP JSON to RPC mapping is enabled, where the// representation of the JSON in the request body is determined by// protos JSON encoding://// HTTP | RPC// -----|-----// `PUT /v1/messages/123456 &#123; &quot;text&quot;: &quot;Hi!&quot; &#125;` | `UpdateMessage(message_id: &quot;123456&quot; message &#123; text: &quot;Hi!&quot; &#125;)`//// The special name `*` can be used in the body mapping to define that// every field not bound by the path template should be mapped to the// request body. This enables the following alternative definition of// the update method://// ```proto// service Messaging &#123;// rpc UpdateMessage(Message) returns (Message) &#123;// option (google.api.http) = &#123;// put: &quot;/v1/messages/&#123;message_id&#125;&quot;// body: &quot;*&quot;// &#125;;// &#125;// &#125;// message Message &#123;// string message_id = 1;// string text = 2;// &#125;// ```//// The following HTTP JSON to RPC mapping is enabled://// HTTP | RPC// -----|-----// `PUT /v1/messages/123456 &#123; &quot;text&quot;: &quot;Hi!&quot; &#125;` | `UpdateMessage(message_id: &quot;123456&quot; text: &quot;Hi!&quot;)`//// Note that when using `*` in the body mapping, it is not possible to// have HTTP parameters, as all fields not bound by the path end in// the body. This makes this option more rarely used in practice of// defining REST APIs. The common usage of `*` is in custom methods// which don&#x27;t use the URL at all for transferring data.//// It is possible to define multiple HTTP methods for one RPC by using// the `additional_bindings` option. Example://// ```proto// service Messaging &#123;// rpc GetMessage(GetMessageRequest) returns (Message) &#123;// option (google.api.http) = &#123;// get: &quot;/v1/messages/&#123;message_id&#125;&quot;// additional_bindings &#123;// get: &quot;/v1/users/&#123;user_id&#125;/messages/&#123;message_id&#125;&quot;// &#125;// &#125;;// &#125;// &#125;// message GetMessageRequest &#123;// string message_id = 1;// string user_id = 2;// &#125;// ```//// This enables the following two alternative HTTP JSON to RPC// mappings://// HTTP | RPC// -----|-----// `GET /v1/messages/123456` | `GetMessage(message_id: &quot;123456&quot;)`// `GET /v1/users/me/messages/123456` | `GetMessage(user_id: &quot;me&quot; message_id: &quot;123456&quot;)`//// # Rules for HTTP mapping//// The rules for mapping HTTP path, query parameters, and body fields// to the request message are as follows://// 1. The `body` field specifies either `*` or a field path, or is// omitted. If omitted, it assumes there is no HTTP body.// 2. Leaf fields (recursive expansion of nested messages in the// request) can be classified into three types:// (a) Matched in the URL template.// (b) Covered by body (if body is `*`, everything except (a) fields;// else everything under the body field)// (c) All other fields.// 3. URL query parameters found in the HTTP request are mapped to (c) fields.// 4. Any body sent with an HTTP request can contain only (b) fields.//// The syntax of the path template is as follows://// Template = &quot;/&quot; Segments [ Verb ] ;// Segments = Segment &#123; &quot;/&quot; Segment &#125; ;// Segment = &quot;*&quot; | &quot;**&quot; | LITERAL | Variable ;// Variable = &quot;&#123;&quot; FieldPath [ &quot;=&quot; Segments ] &quot;&#125;&quot; ;// FieldPath = IDENT &#123; &quot;.&quot; IDENT &#125; ;// Verb = &quot;:&quot; LITERAL ;//// The syntax `*` matches a single path segment. It follows the semantics of// [RFC 6570](https://tools.ietf.org/html/rfc6570) Section 3.2.2 Simple String// Expansion.//// The syntax `**` matches zero or more path segments. It follows the semantics// of [RFC 6570](https://tools.ietf.org/html/rfc6570) Section 3.2.3 Reserved// Expansion.//// The syntax `LITERAL` matches literal text in the URL path.//// The syntax `Variable` matches the entire path as specified by its template;// this nested template must not contain further variables. If a variable// matches a single path segment, its template may be omitted, e.g. `&#123;var&#125;`// is equivalent to `&#123;var=*&#125;`.//// NOTE: the field paths in variables and in the `body` must not refer to// repeated fields or map fields.//// Use CustomHttpPattern to specify any HTTP method that is not included in the// `pattern` field, such as HEAD, or &quot;*&quot; to leave the HTTP method unspecified for// a given URL path rule. The wild-card rule is useful for services that provide// content to Web (HTML) clients.message HttpRule &#123; // Selects methods to which this rule applies. // // Refer to [selector][google.api.DocumentationRule.selector] for syntax details. string selector = 1; // Determines the URL pattern is matched by this rules. This pattern can be // used with any of the &#123;get|put|post|delete|patch&#125; methods. A custom method // can be defined using the &#x27;custom&#x27; field. oneof pattern &#123; // Used for listing and getting information about resources. string get = 2; // Used for updating a resource. string put = 3; // Used for creating a resource. string post = 4; // Used for deleting a resource. string delete = 5; // Used for updating a resource. string patch = 6; // Custom pattern is used for defining custom verbs. CustomHttpPattern custom = 8; &#125; // The name of the request field whose value is mapped to the HTTP body, or // `*` for mapping all fields not captured by the path pattern to the HTTP // body. NOTE: the referred field must not be a repeated field. string body = 7; // Additional HTTP bindings for the selector. Nested bindings must // not contain an `additional_bindings` field themselves (that is, // the nesting may only be one level deep). repeated HttpRule additional_bindings = 11;&#125;// A custom pattern is used for defining custom HTTP verb.message CustomHttpPattern &#123; // The name of this custom HTTP verb. string kind = 1; // The path matched by this custom verb. string path = 2;&#125; 2.2.2 hello.proto12345678910111213141516171819202122syntax = &quot;proto3&quot;;package proto;import &quot;google/api/annotations.proto&quot;;service HelloWorld &#123; rpc SayHelloWorld(HelloWorldRequest) returns (HelloWorldResponse) &#123; option (google.api.http) = &#123; post: &quot;/hello_world&quot; body: &quot;*&quot; &#125;; &#125;&#125;message HelloWorldRequest &#123; string referer = 1;&#125;message HelloWorldResponse &#123; string message = 1;&#125; 2.3 编译 proto12345678# 编译google.apiprotoc -I . --go_out=plugins=grpc,Mgoogle/protobuf/descriptor.proto=github.com/golang/protobuf/protoc-gen-go/descriptor:. google/api/*.proto# 编译hello_http.proto为hello_http.pb.protoprotoc -I . --go_out=plugins=grpc,Mgoogle/api/annotations.proto=go-grpc-example/proto/google/api:. ./hello.proto# 编译hello_http.proto为hello_http.pb.gw.protoprotoc --grpc-gateway_out=logtostderr=true:. ./hello.proto 3. 命令行模块3.1 安装Cobra命令行工具1go get -u github.com/spf13/cobra 1) root.go 12345678910var rootCmd = &amp;cobra.Command&#123; Use: &quot;grpc&quot;, Short: &quot;Run the gRPC hello-world server&quot;,&#125;func Execute() &#123; if err := rootCmd.Execute(); err != nil &#123; log.Fatalf(&quot;rootCmd.Execute err: %v&quot;, err) &#125;&#125; 2) server.go 12345678910111213141516171819202122var serverCmd = &amp;cobra.Command&#123; Use: &quot;server&quot;, Short: &quot;Run the gRPC hello-world server&quot;, Run: func(cmd *cobra.Command, args []string) &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Println(&quot;Recover error: %v&quot;, err) &#125; &#125;() server.Serve() &#125;,&#125;func init() &#123; serverCmd.Flags().StringVarP(&amp;server.ServerPort, &quot;port&quot;, &quot;p&quot;, &quot;9005&quot;, &quot;server port&quot;) serverCmd.Flags().StringVarP(&amp;server.CertPath, &quot;cert&quot;, &quot;c&quot;, &quot;../../certs/server.pem&quot;, &quot;cert path&quot;) serverCmd.Flags().StringVarP(&amp;server.KeyPath, &quot;key&quot;, &quot;k&quot;, &quot;../../certs/server.key&quot;, &quot;key path&quot;) serverCmd.Flags().StringVarP(&amp;server.CertName, &quot;name&quot;, &quot;n&quot;, &quot;go-grpc-example&quot;, &quot;server hostname&quot;) rootCmd.AddCommand(serverCmd)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go gRPC","slug":"Go gRPC","date":"2019-07-18T01:23:17.000Z","updated":"2021-06-22T10:50:49.737Z","comments":true,"path":"2019/07/18/Go gRPC/","link":"","permalink":"https://elihe2011.github.io/2019/07/18/Go%20gRPC/","excerpt":"1. RPC1.1 什么是RPCRPC: Remote Procedure Call，远程过程调用。调用过程包括传输协议和对象编码（序列化）。 1.2 RPC框架 负载均衡 服务注册和发现 服务治理 1.3 为什么使用RPC简单、通用、安全、效率","text":"1. RPC1.1 什么是RPCRPC: Remote Procedure Call，远程过程调用。调用过程包括传输协议和对象编码（序列化）。 1.2 RPC框架 负载均衡 服务注册和发现 服务治理 1.3 为什么使用RPC简单、通用、安全、效率 2. ProtobufProtocol Buffers 是一种与语言、平台无关，可扩展的序列化结构化数据的方法，常用于通信协议、数据存储等。相较于JSON、XML，它更小、更快、更简单。 123456789101112131415syntax = &quot;proto3&quot;;service SearchService &#123; rpc Search (SearchRequest) returns (SearchResponse);&#125;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125;message SearchResponse &#123; ...&#125; 3. gRPCgRPC 是一个高性能、开源和通用的RPC框架，面向移动和 HTTP/2 设计 特点： HTTP/2 Protobuf 客户端、服务端基于同一份IDL 移动网络支持良好 支持多语言 3.1 安装gRPC: 1go get -u google.golang.org/grpc Protocol Buffers v3: 12brew search protobufbrew install protobuf@3.6 Protoc Plugin: 12345# 会自动编译安装protoc-gen-go可执行插件文件go get -u github.com/golang/protobuf/protoc-gen-go# 编译安装 (不要做这个操作，应该使用上面一个protoc-gen-go)#go install google.golang.org/protobuf/cmd/protoc-gen-go 3.2 入门3.2.1 编写 IDL1234567891011121314151617syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;; // 重要package proto;service SearchService &#123; rpc Search(SearchRequest) returns (SearchResponse) &#123;&#125;&#125;message SearchRequest &#123; string request = 1;&#125;message SearchResponse &#123; string response = 1;&#125; 3.2.2 生成 pb.go文件1234protoc --go_out=. *.proto# 比前一个多了注册函数等protoc --go_out=plugins=grpc:. *.proto 3.2.3 服务端12345678910111213141516171819type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;const HOST = &quot;:9001&quot;func main() &#123; server := grpc.NewServer() pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, HOST) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 3.2.4 客户端1234567891011121314151617func main() &#123; conn, err := grpc.Dial(HOST, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 4. gRPC 流gRPC 的流式，有三种类型： Server-side Streaming Client-side Streaming Bidirectional Streaming 适合用 Streaming RPC 的场景： 大规模数据包 实时场景 4.1 IDL 和 基础模板1234567891011121314151617181920212223242526syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;;package proto;service StreamService &#123; rpc List(StreamRequest) returns (stream StreamResponse) &#123;&#125;; rpc Record(stream StreamRequest) returns (stream StreamResponse) &#123;&#125;; rpc Route(stream StreamRequest) returns (stream StreamResponse) &#123;&#125;;&#125;message StreamPoint &#123; string name = 1; int32 value = 2;&#125;message StreamRequest &#123; StreamPoint pt = 1;&#125;message StreamResponse &#123; StreamPoint pt = 1;&#125; 服务器： 1234567891011121314151617181920212223func main() &#123; server := grpc.NewServer() pb.RegisterStreamServiceServer(server, &amp;StreamService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9002&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error &#123; return nil&#125;func (s *StreamService) Record(stream pb.StreamService_RecordServer) error &#123; return nil&#125;func (s *StreamService) Route(stream pb.StreamService_RouteServer) error &#123; return nil&#125; 客户端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func main() &#123; conn, err := grpc.Dial(&quot;:9002&quot;, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;grpc.Dial err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewStreamServiceClient(conn) err = printList(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: List&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printList.err: %v&quot;, err) &#125; err = printRecord(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: Record&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printRecord.err: %v&quot;, err) &#125; err = printRoute(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: Route&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printRoute.err: %v&quot;, err) &#125;&#125;func printList(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125;func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125;func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125; 4.2 服务器端流式 RPC 单向流 Server 为 Stream，多次向客户端发送数据 Client 为普通 RPC 请求 4.2.1 服务端12345678910111213141516func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error &#123; for n := 0; n &lt;= 6; n++ &#123; err := stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: r.Pt.Name, Value: r.Pt.Value + int32(n), &#125;, &#125;) if err != nil &#123; return nil &#125; &#125; return nil&#125; stream.Send() 方法： 12345678type StreamService_ListServer interface &#123; Send(*StreamResponse) error grpc.ServerStream&#125;func (x *streamServiceListServer) Send(m *StreamResponse) error &#123; return x.ServerStream.SendMsg(m)&#125; SendMsg() 方法： 消息体（对象）序列化 压缩序列化后的消息体 对正在传输的消息体增加5个字节的header 判断消息体总长度是否大于预设的maxSendMessageSize (默认math.MaxInt32)，超过则报错 写入给流的数据集 4.2.2 客户端12345678910111213141516171819202122func printList(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.List(context.Background(), r) if err != nil &#123; return err &#125; for &#123; resp, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;resp: pt.name: %s, pt.value: %d\\n&quot;, resp.Pt.Name, resp.Pt.Value) &#125; return nil&#125; stream.Recv()方法： 12345678910111213type StreamService_ListClient interface &#123; Recv() (*StreamResponse, error) grpc.ClientStream&#125;func (x *streamServiceListClient) Recv() (*StreamResponse, error)&#123; m := new(StreamResponse) if err := x.ClientStream.RecvMsg(m); err != nil &#123; return nil, err &#125; return m, nil&#125; RecvMsg()方法： 阻塞等待 流结束 (Close)时，返回 io.EOF 可能的错误 io.EOF io.ErrUnexpectedEOF transport.ConnectionError google.golang.org/grpc/codes 4.3 客户端流式RPC 单向流 客户端多次RPC请求服务端 服务端发起一次响应给客户端 4.3.1 服务端12345678910111213141516171819func (s *StreamService) Record(stream pb.StreamService_RecordServer) error &#123; for &#123; r, err := stream.Recv() if err == io.EOF &#123; return stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Server: Record&quot;, Value: 1, &#125;, &#125;) &#125; if err != nil &#123; return err &#125; log.Printf(&quot;stream.Recv pt.name: %s, pt.value: %d&quot;, r.Pt.Name, r.Pt.Value) &#125; return nil&#125; 4.3.2 客户端12345678910111213141516171819202122232425262728func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.Record(context.Background()) if err != nil &#123; return err &#125; for n := 0; n &lt; 6; n++ &#123; err := stream.Send(r) if err != nil &#123; return err &#125; &#125; // 主动关闭send err = stream.CloseSend() if err != nil &#123; return err &#125; resp, err := stream.Recv() if err != nil &#123; return nil &#125; log.Printf(&quot;resp: pt.name: %s, pt.value: %d&quot;, resp.Pt.Name, resp.Pt.Value) return nil&#125; 4.4 双向流RPC4.4.1 服务端12345678910111213141516171819202122232425262728func (s *StreamService) Route(stream pb.StreamService_RouteServer) error &#123; n := 0 for &#123; err := stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gPRC Stream Client: Route&quot;, Value: int32(n), &#125;, &#125;) if err != nil &#123; return err &#125; r, err := stream.Recv() if err == io.EOF &#123; return nil &#125; if err != nil &#123; return err &#125; n++ log.Printf(&quot;stream.Recv pt.name: %s, pt.value: %d&quot;, r.Pt.Name, r.Pt.Value) &#125; return nil&#125; 4.4.2 客户端12345678910111213141516171819202122232425262728func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.Route(context.Background()) if err != nil &#123; return err &#125; for n := 0; n &lt; 6; n++ &#123; err = stream.Send(r) if err != nil &#123; return err &#125; resp, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;resp: pt.name: %s, pt.value %d&quot;, resp.Pt.Name, resp.Pt.Value) &#125; stream.CloseSend() return nil&#125; 5. TLS 证书认证5.1 生成证书5.1.1 私钥1openssl ecparam -genkey -name secp384r1 -out server.key 5.1.2 自签公钥1openssl req -new -x509 -sha256 -key server.key -out server.pem -days 3650 5.2 服务端123456789101112131415161718192021222324252627type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;const HOST = &quot;:9001&quot;func main() &#123; // 1. 支持TLS creds, err := credentials.NewServerTLSFromFile(&quot;../certs/server.pem&quot;, &quot;../certs/server.key&quot;) if err != nil &#123; log.Fatalf(&quot;credentials.NewServerTLSFromFile err: %v&quot;, err) &#125; // 2. 加入认证 server := grpc.NewServer(grpc.Creds(creds)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, HOST) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 5.3 客户端1234567891011121314151617181920212223242526const HOST = &quot;:9001&quot;func main() &#123; // 1. 支持TLS creds, err := credentials.NewClientTLSFromFile(&quot;../certs/server.pem&quot;, &quot;go-grpc-example&quot;) if err != nil &#123; log.Fatalf(&quot;credentials.NewClientTLSFromFile err: %v&quot;, err) &#125; // 2. 传输认证 conn, err := grpc.Dial(HOST, grpc.WithTransportCredentials(creds)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 6. 基于 CA 的 TLS 证书认证6.1 CA6.1.1 生成CA证书根证书(root certificate)是属于根证书颁发机构（CA）的公钥证书。可以通过验证CA的签名从而信任CA，任何人都可以得到CA的证书（含公钥），用以验证它所签发的证书。 12345# 生成Keyopenssl genrsa -out ca.key 2048# 生成密钥openssl req -new -x509 -days 7200 -key ca.key -out ca.pem 6.1.2 服务端证书CSR: Cerificate Signing Request，证书请求文件。主要作用是 CA 会利用 CSR 文件进行签名使得攻击者无法伪装或篡改原有证书。 12345# 生成CSRopenssl req -new -key server.key -out server.csr# 基于CA签发openssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in server.csr -out server.pem 6.1.3 客户端证书12345678# 生成Keyopenssl ecparam -genkey -name secp384r1 -out client.key# 生成CSRopenssl req -new -key client.key -out client.csr# 基于CA签发openssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in client.csr -out client.pem 6.2 TLS认证代码6.2.1 服务端认证123456789101112131415161718192021222324252627282930313233343536373839type Server struct &#123; CaFile string CertFile string KeyFile string&#125;func (t *Server) GetCredentialsByCA() (credentials.TransportCredentials, error) &#123; cert, err := tls.LoadX509KeyPair(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; ca, err := ioutil.ReadFile(t.CaFile) if err != nil &#123; return nil, err &#125; certPool := x509.NewCertPool() if ok := certPool.AppendCertsFromPEM(ca); !ok &#123; return nil, errors.New(&quot;certPool.AppendCertsFromPEM err&quot;) &#125; c := credentials.NewTLS(&amp;tls.Config&#123; Certificates: []tls.Certificate&#123;cert&#125;, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, &#125;) return c, nil&#125;func (t *Server) GetTLSCredentials() (credentials.TransportCredentials, error) &#123; c, err := credentials.NewServerTLSFromFile(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; return c, nil&#125; 6.2.2 客户端认证12345678910111213141516171819202122232425262728293031323334353637383940type Client struct &#123; ServerName string CaFile string CertFile string KeyFile string&#125;func (t *Client) GetCredentialsByCA() (credentials.TransportCredentials, error) &#123; cert, err := tls.LoadX509KeyPair(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; ca, err := ioutil.ReadFile(t.CaFile) if err != nil &#123; return nil, err &#125; certPool := x509.NewCertPool() if ok := certPool.AppendCertsFromPEM(ca); !ok &#123; return nil, errors.New(&quot;certPool.AppendCertsFromPEM err&quot;) &#125; c := credentials.NewTLS(&amp;tls.Config&#123; Certificates: []tls.Certificate&#123;cert&#125;, ServerName: t.ServerName, RootCAs: certPool, &#125;) return c, nil&#125;func (t *Client) GetTLSCredentials() (credentials.TransportCredentials, error) &#123; c, err := credentials.NewClientTLSFromFile(t.CertFile, t.ServerName) if err != nil &#123; return nil, err &#125; return c, nil&#125; 6.3 实现代码6.3.1 服务端1234567891011121314151617181920212223242526272829type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 6.3.2 客户端1234567891011121314151617181920212223242526272829func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/client.pem&quot;, KeyFile: &quot;../../certs/client.key&quot;, &#125; c, err := tlsClient.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetCredentialsByCA err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9001&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 大致流程： Client 通过请求得到 Server 端的证书 使用 CA 认证的根证书对 Server 端证书进行可靠性、有效性等校验 校验 ServerName 是否有效 同样，在设置了 tls.RequireAndVerifyClientCert 模式下，Server 也会使用 CA 认证的根证书对Client的证书进行可靠性、有效性校验。 6.4 补充知识点：ssl/tls 单向认证双向认证 单向认证：只有一个对象校验对端的证书合法性。通常client来校验服务器的合法性。那么client需要一个ca.crt,服务器需要server.crt,server.key。 双向认证：相互校验，服务器需要校验每个client,client也需要校验服务器。server 需要 server.key、server.crt、ca.crt，client 需要 client.key、client.crt、ca.crt。 7. 拦截器7.1 Unary and Stream interceptor 普通方法：一元拦截器 grpc.UnaryInterceptor 流方法：流拦截器 grpc.StreamInterceptor 7.1.1 grpc.UnaryInterceptor12345678910func UnaryInterceptor(i UnaryServerInterceptor) ServerOption &#123; return func(o *options) &#123; if o.unaryInt != nil &#123; panic(&quot;The unary server interceptor was already set and may not be reset.&quot;) &#125; o.unaryInt = i &#125;&#125;type UnaryServerInterceptor func(ctx context.Context, req interface&#123;&#125;, info *UnaryServerInfo, handler UnaryHandler) (resp interface&#123;&#125;, err error) 7.1.2 grpc.StreamInterceptor123func StreamInterceptor(i StreamServerInterceptor) ServerOptionstype StreamServerInterceptor func(srv interface&#123;&#125;, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error 7.2 实现多个拦截器gRPC本身只能设置一个拦截器，但可以采用go-grpc-middleware项目来解决问题 12345678910import &quot;github.com/grpc-ecosystem/go-grpc-middleware&quot;myServer := grpc.NewServer( grpc.StreamInterceptor(grpc_middleware.ChainStreamServer( ... )), grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer( ... )),) 7.3 实现 logging 和 recover 拦截器7.3.1 logging123456func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125; 7.3.2 recover12345678910func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 7.3.3 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; // 服务选项 opts := []grpc.ServerOption&#123; grpc.Creds(c), grpc_middleware.WithUnaryServerChain( RecoveryInterceptor, LoggingInterceptor, ), &#125; server := grpc.NewServer(opts...) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125;func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 8. 同时提供 HTTP 服务8.1 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; http.ListenAndServeTLS( &quot;:9003&quot;, &quot;../../certs/server.pem&quot;, &quot;../../certs/server.key&quot;, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if r.ProtoMajor == 2 &amp;&amp; strings.Contains(r.Header.Get(&quot;Content-Type&quot;), &quot;application/grpc&quot;) &#123; GetHTTPServeGrpc().ServeHTTP(w, r) &#125; else &#123; GetHTTPServeMux().ServeHTTP(w, r) &#125; &#125;), )&#125;func GetHTTPServeGrpc() *grpc.Server &#123; tlsServer := gtls.Server&#123; CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetTLSCredentials err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) return server&#125;func GetHTTPServeMux() *http.ServeMux &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte(&quot;result: go-grpc-example&quot;)) &#125;) return mux&#125; 8.2 gRPC 客户端123456789101112131415161718192021222324252627func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CertFile: &quot;../../certs/server.pem&quot;, &#125; c, err := tlsClient.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetTLSCredentials err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9003&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 8.3 http/1.1 直接访问123curl -k --cert client.pem --key client.key https://127.0.0.1:9003curl -k --cacert ca.pem https://127.0.0.1:9003 9. 自定义认证9.1 自定义认证接口1234567type PerRPCCredentials interface &#123; // 获取当前请求认证所需的元数据 (metadata) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) // 是否需要基于TLS认证安全传输 RequireTransportSecurity() bool&#125; 9.2 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273type SearchService struct &#123; auth *Auth&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; if err := s.auth.Check(ctx); err != nil &#123; return nil, err &#125; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetTLSCredentials err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9004&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;type Auth struct &#123; appKey string appSecret string&#125;func (a *Auth) Check(ctx context.Context) error &#123; md, ok := metadata.FromIncomingContext(ctx) if !ok &#123; return status.Errorf(codes.Unauthenticated, &quot;metadata.FromIncomingContext err&quot;) &#125; var ( appKey string appSecret string ) if value, ok := md[&quot;app_key&quot;]; ok &#123; appKey = value[0] &#125; if value, ok := md[&quot;app_secret&quot;]; ok &#123; appSecret = value[0] &#125; if appKey != a.GetAppKey() || appSecret != a.GetAppSecret() &#123; return status.Errorf(codes.Unauthenticated, &quot;invalid token&quot;) &#125; return nil&#125;func (a *Auth) GetAppKey() string &#123; return &quot;wx20200719163021&quot;&#125;func (a *Auth) GetAppSecret() string &#123; return &quot;7d13b90ae8e40c0160209c4a985b3bdf01321b15&quot;&#125; 9.3 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type Auth struct &#123; AppKey string AppSecret string&#125;func (a *Auth) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) &#123; return map[string]string&#123; &quot;app_key&quot;: a.AppKey, &quot;app_secret&quot;: a.AppSecret, &#125;, nil&#125;func (a *Auth) RequireTransportSecurity() bool &#123; return true&#125;func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CertFile: &quot;../../certs/server.pem&quot;, &#125; c, err := tlsClient.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetTLSCredentials err: %v&quot;, err) &#125; auth := Auth&#123; AppKey: &quot;wx20200719163021&quot;, AppSecret: &quot;7d13b90ae8e40c0160209c4a985b3bdf01321b15&quot;, &#125; conn, err := grpc.Dial(&quot;:9004&quot;, grpc.WithTransportCredentials(c), grpc.WithPerRPCCredentials(&amp;auth)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 10. gRPC Deadline10.1 为什么要设置Deadline? 未设置 Deadlines 时，将采用默认的 DEADLINE_EXCEEDED（该时间非常大） 产生阻塞等待时，会造成大量正在进行的请求被保留，直到这些请求都达到最大超时 会导致资源耗尽的风险，也会增加服务的延迟，最坏时可能导致整个进出崩溃 10.2 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; // Deadline if ctx.Err() == context.Canceled &#123; return nil, status.Errorf(codes.Canceled, &quot;SearchService.Search canceled&quot;) &#125; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; // 服务选项 opts := []grpc.ServerOption&#123; grpc.Creds(c), grpc_middleware.WithUnaryServerChain( RecoveryInterceptor, LoggingInterceptor, ), &#125; server := grpc.NewServer(opts...) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125;func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 10.3 客户端12345678910111213141516171819202122232425262728293031323334353637383940func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/client.pem&quot;, KeyFile: &quot;../../certs/client.key&quot;, &#125; c, err := tlsClient.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetCredentialsByCA err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9001&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() // Deadlines ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Duration(5*time.Second))) defer cancel() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(ctx, &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; statusErr, ok := status.FromError(err) if ok &#123; if statusErr.Code() == codes.DeadlineExceeded &#123; log.Fatalf(&quot;client.Search err: deadline&quot;) &#125; &#125; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go 加密签名","slug":"Go 加密签名","date":"2019-07-07T01:21:53.000Z","updated":"2021-06-22T10:50:49.736Z","comments":true,"path":"2019/07/07/Go 加密签名/","link":"","permalink":"https://elihe2011.github.io/2019/07/07/Go%20%E5%8A%A0%E5%AF%86%E7%AD%BE%E5%90%8D/","excerpt":"1. 加密字符串格式密钥、密文、签名的加密字符串格式 1.1 hex123hex.DecodeString(s string)hex.EncodeToString(src []byte) string","text":"1. 加密字符串格式密钥、密文、签名的加密字符串格式 1.1 hex123hex.DecodeString(s string)hex.EncodeToString(src []byte) string 1.2 base64123base64.StdEncoding.DecodeString(s string) ([]byte, error)base64.StdEncoding.EncodeToString(src []byte) string 2. 私钥格式2.1 PKCS11x509.ParsePKCS1PrivateKey(der []byte) (key interface&#123;&#125;, err error) 2.2 PKCS81x509.ParsePCKS8PrivateKey(der []byte) (key interface&#123;&#125;, err error) 3. SHA算法3.1 SHA1123hash := sha1.New()hash.Write([]byte(plainText))cipherText, err := rsa.SignPKCS1v15(rand.Reader, prvKey, crypto.SHA1, hash.Sum(nil)) 3.2 SHA256123hash := sha256.New()hash.Write([]byte(plainText))cipherText, err := rsa.SignPKCS1v15(rand.Reader, prvKey, crypto.SHA256, hash.Sum(nil)) 4. RSA4.1 加密1rsa.EncryptPKCS1v15(rand io.Reader, pub *PublicKey, plaintext []byte) ([]byte, error) 4.2 解密1rsa.DecryptPKCS1v15(rand io.Reader, priv *PrivateKey, ciphertext []byte) ([]byte, error) 4.3 签名1rsa.SignPKCS1v15(rand io.Reader, priv *PrivateKey, hash crypto.Hash, hashed []byte) ([]byte, error) 4.4 验签1rsa.VerifyPKCS1v15(pub *PublicKey, hash crypto.Hash, hashed []byte, sig []byte) error 5. 应用示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import ( &quot;crypto&quot; &quot;crypto/rand&quot; &quot;crypto/rsa&quot; &quot;crypto/sha1&quot; &quot;crypto/x509&quot; &quot;encoding/base64&quot; &quot;encoding/hex&quot;)func RsaEncryptWithSha1Base64(plaintext, publicKey string) (string, error) &#123; key, _ := base64.StdEncoding.DecodeString(publicKey) pubKey, _ := x509.ParsePKIXPublicKey(key) ciphertext, err := rsa.EncryptPKCS1v15(rand.Reader, pubKey.(*rsa.PublicKey), []byte(plaintext)) if err != nil &#123; return &quot;&quot;, err &#125; return base64.StdEncoding.EncodeToString(ciphertext), nil&#125;func RsaDecryptWithSha1Base64(ciphertext, privateKey string) (string, error) &#123; ciphertextBytes, err := base64.StdEncoding.DecodeString(ciphertext) if err != nil &#123; return &quot;&quot;, err &#125; key, _ := base64.StdEncoding.DecodeString(privateKey) prvKey, _ := x509.ParsePKCS1PrivateKey(key) plaintext, err := rsa.DecryptPKCS1v15(rand.Reader, prvKey, ciphertextBytes) return string(plaintext), err&#125;func RsaSignWithSha1Hex(data, privateKey string) (string, error) &#123; key, err := hex.DecodeString(privateKey) if err != nil &#123; return &quot;&quot;, err &#125; prvKey, err := x509.ParsePKCS8PrivateKey(key) if err != nil &#123; return &quot;&quot;, err &#125; hash := sha1.New() hash.Write([]byte(data)) signature, err := rsa.SignPKCS1v15(rand.Reader, prvKey.(*rsa.PrivateKey), crypto.SHA1, hash.Sum(nil)) if err != nil &#123; return &quot;&quot;, err &#125; return hex.EncodeToString(signature), nil&#125;func RsaVerifySignWithSha1Base64(data, signature, publicKey string) error &#123; sign, err := base64.StdEncoding.DecodeString(signature) if err != nil &#123; return err &#125; key, _ := base64.StdEncoding.DecodeString(publicKey) pubKey, err := x509.ParsePKIXPublicKey(key) if err != nil &#123; return err &#125; hash := sha1.New() hash.Write([]byte(data)) return rsa.VerifyPKCS1v15(pubKey.(*rsa.PublicKey), crypto.SHA1, hash.Sum(nil), sign)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 包管理","slug":"Go 包管理","date":"2019-07-01T08:41:28.000Z","updated":"2021-06-22T10:50:49.736Z","comments":true,"path":"2019/07/01/Go 包管理/","link":"","permalink":"https://elihe2011.github.io/2019/07/01/Go%20%E5%8C%85%E7%AE%A1%E7%90%86/","excerpt":"1. Go Modules1.1 简介Go Modules 是官方最新的包管理方式，它解决了如下问题： 所有的依赖包必须在 GOPATH 下，但同一个库只能保存一个版本 工作目录必须在 GOPATH/src 目录下 使用 Go Modules 之后，可在 GOPATH/src 之外创建目录和管理包 设置 go mod 和 go proxy: 12345go env -w GOBIN=/Users/eli/go/bingo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,directgo env GO111MODULE: on: 强制使用modules, 不再去GOPATH下查找 off: 不使用modules，去GOPATH和vendor下查找 auto: 默认值，如果当前目录下有go.mod文件，则使用modules","text":"1. Go Modules1.1 简介Go Modules 是官方最新的包管理方式，它解决了如下问题： 所有的依赖包必须在 GOPATH 下，但同一个库只能保存一个版本 工作目录必须在 GOPATH/src 目录下 使用 Go Modules 之后，可在 GOPATH/src 之外创建目录和管理包 设置 go mod 和 go proxy: 12345go env -w GOBIN=/Users/eli/go/bingo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,directgo env GO111MODULE: on: 强制使用modules, 不再去GOPATH下查找 off: 不使用modules，去GOPATH和vendor下查找 auto: 默认值，如果当前目录下有go.mod文件，则使用modules 1.2 基础命令123456789101112go help modgo mod &lt;command&gt; [arguments]download download modules to local cacheedit edit go.mod from tools or scriptsgraph print module requirement graphinit initialize new module in current directorytidy add missing and remove unused modulesvendor make vendored copy of dependenciesverify verify dependencies have expected contentwhy explain why packages or modules are needed 1.3 基本使用1.3.1 初始化123go mod init github.com/elihe2011/gomodgo get -u github.com/gin-gonic/gin 生成的文件： go.mod: 模块管理文件 module语句: 指定包的名字（路径） require语句: 指定的依赖项模块 replace语句: 可以替换依赖项模块 exclude语句: 可以忽略依赖项模块 go.sum: 记录依赖看的版本和哈希值 解决获取包时的代理错误： 12345678$ go get -u github.com/gin-gonic/gingo get github.com/gin-gonic/gin: module github.com/gin-gonic/gin: Get &quot;https://proxy.golang.org/github.com/gin-gonic/gin/@v/list&quot;: dial tcp 34.64.4.113:443: i/o timeout# go包管理,默认使用的是proxy.golang.org，在国内无法访问，换为go env -w GOPROXY=https://goproxy.cn,direct # 七牛云go env -w GOPROXY=https://mirrors.aliyun.com/goproxy/,direct 1.3.2 下载指定版本的依赖库1234567891011# 当前模块和支撑包go list -m all# 可用版本go list -m -versions github.com/gin-gonic/gin# 删除无效的modulesgo mod tidy# 获取指定版本go get github.com/gin-gonic/gin@ 1.4 编译打包1.4.1 使用GOPATH模式进行打包123export GO111MODULE=offexport CGO_ENABLED=0go build -a -v -o app main.go 1.4.2 使用vendor目录下包来进行打包123export GO111MODULE=onexport CGO_ENABLED=0go build -mod=vendor -a -v -o app main.go 1.5 go modules包管理特点 第三方包存储路径：$GOPATH/pkg/mod $GOPATH/pkg/mod 下可以保存相同包的不同版本 当项目放在 $GOPATH/src 时，GO111MODULE=auto 自动模式 依赖包中的地址失效了怎么办？比如 golang.org/x/… 下的包都无法下载怎么办？ 在go.mod文件里用 replace 替换包，例如replace golang.org/x/text =&gt; github.com/golang/text latest这样，go会用 github.com/golang/text 替代golang.org/x/text，原理就是下载github.com/golang/text 的最新版本到 $GOPATH/pkg/mod/golang.org/x/text下 2. govendorgovendor只是用来管理项目的依赖包，如果GOPATH中本身没有项目的依赖包，则需要通过go get先下载到GOPATH中，再通过govendor add +external拷贝到vendor目录中。Go 1.6以上版本默认开启GO15VENDOREXPERIMENT环境变量。 2.1 安装1go get -u -v github.com/kardianos/govendor 2.2 常用命令1234567891011121314151617181920212223# 初始化, 生成vender目录等govendor init# 添加包govendor add github.com/fvbock/endlessgovendor add +external# 移除包govendor remove github.com/fvbock/endlessgovendor remove +unused# 查看包govendor list# 列出所有缺失、过期和修改过的包govendor status# 本地存在 vendor.json 时候拉去依赖包，匹配所记录的版本govendor sync# 获取包govendor get github.com/gorilla/websocketgovendor fetch github.com/gorilla/websocket 2.3 包状态 状态 缩写状态 含义 +local l 本地包，即项目自身的包组织 +external e 外部包，即被 $GOPATH 管理，但不在 vendor 目录下 +vendor v 已被 govendor 管理，即在 vendor 目录下 +std s 标准库中的包 +unused u 未使用的包，即包在 vendor 目录下，但项目并没有用到 +missing m 代码引用了依赖包，但该包并没有找到 +program p 主程序包，意味着可以编译为执行文件 +outside o 外部包和缺失的包 +all a 所有的包","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Redis","slug":"Go Redis","date":"2019-05-20T02:49:39.000Z","updated":"2021-06-22T10:50:49.735Z","comments":true,"path":"2019/05/20/Go Redis/","link":"","permalink":"https://elihe2011.github.io/2019/05/20/Go%20Redis/","excerpt":"1. 入门1.1 安装1go get -u github.com/go-redis/redis 1.2 初始化连接1234567891011121314151617181920const ( REDIS_IP = &quot;127.0.0.1&quot; REDIS_PORT = &quot;6379&quot; REDIS_PWD = &quot;&quot; REDIS_DB = 0)var ( ctx = context.Background() rdb *redis.Client)func init() &#123; rdb = redis.NewClient(&amp;redis.Options&#123; Addr: REDIS_IP + &quot;:&quot; + REDIS_PORT, Password: REDIS_PWD, DB: REDIS_DB, PoolSize: 20, &#125;)&#125;","text":"1. 入门1.1 安装1go get -u github.com/go-redis/redis 1.2 初始化连接1234567891011121314151617181920const ( REDIS_IP = &quot;127.0.0.1&quot; REDIS_PORT = &quot;6379&quot; REDIS_PWD = &quot;&quot; REDIS_DB = 0)var ( ctx = context.Background() rdb *redis.Client)func init() &#123; rdb = redis.NewClient(&amp;redis.Options&#123; Addr: REDIS_IP + &quot;:&quot; + REDIS_PORT, Password: REDIS_PWD, DB: REDIS_DB, PoolSize: 20, &#125;)&#125; 2. 操作2.1 基本操作12345678910111213141516171819202122232425func Basic() &#123; keys := rdb.Keys(ctx, &quot;*&quot;).Val() fmt.Println(keys) size := rdb.DBSize(ctx).Val() fmt.Println(size) exist := rdb.Exists(ctx, &quot;name&quot;, &quot;age&quot;) fmt.Println(exist) del := rdb.Del(ctx, &quot;abc&quot;).Val() fmt.Println(del) ttl := rdb.TTL(ctx, &quot;age&quot;).Val() fmt.Println(ttl) expire := rdb.Expire(ctx, &quot;age&quot;, time.Second*60).Val() fmt.Println(expire) _type := rdb.Type(ctx, &quot;name&quot;).Val() fmt.Println(_type) key := rdb.RandomKey(ctx).Val() fmt.Println(key)&#125; 2.2 String1234567891011121314151617181920212223242526272829303132func String() &#123; var ret interface&#123;&#125; ret = rdb.Set(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour*24).Val() fmt.Println(ret) // set if not exist ret = rdb.SetNX(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour).Val() fmt.Println(ret) // set if exist ret = rdb.SetXX(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour*12).Val() fmt.Println(ret) ret = rdb.Get(ctx, &quot;name&quot;) fmt.Println(ret) ret = rdb.MGet(ctx, &quot;name&quot;, &quot;age&quot;) fmt.Println(ret) ret = rdb.Incr(ctx, &quot;age&quot;).Val() fmt.Println(ret) ret = rdb.Decr(ctx, &quot;age&quot;).Val() fmt.Println(ret) ret = rdb.Append(ctx, &quot;name&quot;, &quot;he&quot;) fmt.Println(ret) ret = rdb.StrLen(ctx, &quot;name&quot;) fmt.Println(ret)&#125; 2.3 Hashmap1234567891011121314151617181920212223242526272829303132func Hashmap() &#123; key := &quot;account&quot; field := &quot;name&quot; fields := map[string]interface&#123;&#125;&#123; &quot;city&quot;: &quot;beijing&quot;, &quot;age&quot;: 27, &quot;skills&quot;: &quot;golang&quot;, &#125; rdb.HSet(ctx, key, field, &quot;jack&quot;) rdb.HMSet(ctx, key, fields) name := rdb.HGet(ctx, key, &quot;name&quot;) fmt.Println(name) items := rdb.HKeys(ctx, key).Val() fmt.Println(items) vals := rdb.HVals(ctx, key).Val() fmt.Println(vals) exist := rdb.HExists(ctx, key, &quot;city&quot;) fmt.Println(exist) rdb.HIncrBy(ctx, key, &quot;age&quot;, 1) values := rdb.HMGet(ctx, key, &quot;name&quot;, &quot;age&quot;).Val() fmt.Println(values) valuesAll := rdb.HGetAll(ctx, key).Val() fmt.Println(valuesAll)&#125; 2.4 List1234567891011121314151617181920212223242526272829func List() &#123; key := &quot;list&quot; rdb.Del(ctx, key) for i := 0; i &lt; 5; i++ &#123; rdb.RPush(ctx, key, strconv.Itoa(i)) &#125; for i := 5; i &lt; 10; i++ &#123; rdb.LPush(ctx, key, strconv.Itoa(i)) &#125; length := rdb.LLen(ctx, key).Val() fmt.Println(length) value := rdb.LIndex(ctx, key, 1).Val() fmt.Println(value) rdb.LSet(ctx, key, 1, &quot;golang&quot;) value = rdb.LPop(ctx, key).Val() fmt.Println(value) n := rdb.LRem(ctx, key, 0, &quot;5&quot;).Val() fmt.Println(n) l := rdb.LRange(ctx, key, 0, -1).Val() fmt.Println(l)&#125; 2.5 Set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func Set() &#123; key1 := &quot;set1&quot; key2 := &quot;set2&quot; rdb.Del(ctx, key1, key2) rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 5; i++ &#123; rdb.SAdd(ctx, key1, rand.Intn(10)) rdb.SAdd(ctx, key2, rand.Intn(10)) &#125; n1 := rdb.SCard(ctx, key1).Val() fmt.Println(n1) e1 := rdb.SIsMember(ctx, key1, 3).Val() fmt.Println(e1) v1 := rdb.SRandMember(ctx, key1).Val() fmt.Println(v1) v2 := rdb.SRandMemberN(ctx, key1, 3).Val() fmt.Println(v2) v3 := rdb.SPop(ctx, key1).Val() fmt.Println(v3) n2 := rdb.SRem(ctx, key1, 2).Val() fmt.Println(n2) v4 := rdb.SMembers(ctx, key1) fmt.Println(v4) v5 := rdb.SMembers(ctx, key2) fmt.Println(v5) v6 := rdb.SInter(ctx, key1, key2).Val() fmt.Println(v6) v7 := rdb.SUnion(ctx, key1, key2).Val() fmt.Println(v7) v8 := rdb.SDiff(ctx, key1, key2).Val() fmt.Println(v8) rdb.SInterStore(ctx, &quot;set3&quot;, key1, key2) rdb.SUnionStore(ctx, &quot;set4&quot;, key1, key2) rdb.SDiffStore(ctx, &quot;set5&quot;, key1, key2)&#125; 2.6 SortedSet1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465func SortedSet() &#123; key1, key2 := &quot;zset1&quot;, &quot;zset2&quot; rdb.Del(ctx, key1, key2) rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 10; i++ &#123; score := float64(rand.Intn(100)) member := &quot;golang-&quot; + strconv.Itoa(i) data := &amp;redis.Z&#123; score, member, &#125; rdb.ZAdd(ctx, key1, data) &#125; for i := 0; i &lt; 10; i++ &#123; score := float64(rand.Intn(100)) member := &quot;golang-&quot; + strconv.Itoa(i) data := &amp;redis.Z&#123; score, member, &#125; rdb.ZAdd(ctx, key2, data) &#125; n1 := rdb.ZCard(ctx, key1) fmt.Println(n1) s1 := rdb.ZScore(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s1) v1 := rdb.ZIncrBy(ctx, key1, 50, &quot;golang-3&quot;).Val() fmt.Println(v1) s2 := rdb.ZRank(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s2) s3 := rdb.ZRevRank(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s3) s4 := rdb.ZRange(ctx, key1, 0, -1).Val() fmt.Println(s4) s5 := rdb.ZRevRange(ctx, key2, 0, -1).Val() fmt.Println(s5) v2 := rdb.ZRem(ctx, key2, &quot;golang-3&quot;).Val() fmt.Println(v2) key3, key4 := &quot;zset3&quot;, &quot;zset4&quot; kslice := []string&#123;key1, key2&#125; wslice := []float64&#123;1.00, 1.00&#125; z := &amp;redis.ZStore&#123; kslice, wslice, &quot;SUM&quot;, &#125; r1 := rdb.ZInterStore(ctx, key3, z).Val() fmt.Println(r1) r2 := rdb.ZUnionStore(ctx, key4, z).Val() fmt.Println(r2)&#125; 2.7 订阅和发布12345678910111213141516171819202122232425262728293031323334func Subscription() &#123; channels := []string&#123;&quot;news&quot;, &quot;it&quot;, &quot;sports&quot;, &quot;shopping&quot;&#125; sub := rdb.PSubscribe(ctx, channels...) _, err := sub.Receive(ctx) if err != nil &#123; fmt.Println(err) &#125; ch := sub.Channel() for msg := range ch &#123; fmt.Printf(&quot;%v: %v\\n&quot;, msg.Channel, msg.Payload) &#125;&#125;func Publish() &#123; var msg string channels := []string&#123;&quot;news&quot;, &quot;it&quot;, &quot;sports&quot;, &quot;shopping&quot;&#125; rand.Seed(time.Now().UnixNano()) for &#123; fmt.Printf(&quot;please input some message: &quot;) fmt.Scanln(&amp;msg) if msg == &quot;quit&quot; &#123; break &#125; channel := channels[rand.Intn(4)] result := rdb.Publish(ctx, channel, msg).Val() if result == 1 &#123; fmt.Printf(&quot;send info to [%v] success\\n&quot;, channel) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go GORM","slug":"Go GORM","date":"2019-05-18T08:09:03.000Z","updated":"2021-06-22T10:50:49.735Z","comments":true,"path":"2019/05/18/Go GORM/","link":"","permalink":"https://elihe2011.github.io/2019/05/18/Go%20GORM/","excerpt":"1. 入门1.1 安装1go get -u github.com/jinzhu/gorm 1.2 驱动1234import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot;import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot;import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot;","text":"1. 入门1.1 安装1go get -u github.com/jinzhu/gorm 1.2 驱动1234import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot;import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot;import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot; 2. 操作2.1 表结构定义123456789101112131415161718192021type Admin struct &#123; ID int64 Username string `gorm:&quot;size:50;not null&quot;` Password string `gorm:&quot;size:128&quot;`&#125;type Account struct &#123; gorm.Model // ID, CreatedAt, UpdatedAt, DeletedAt Appkey string `gorm:&quot;type:varchar(15);index:idx_appkey;not null&quot;` Company string `gorm:&quot;column:company_name;size:30&quot;` Status int8 `gorm:&quot;default:1&quot;`&#125;func (Admin) TableName() string &#123; return &quot;tbl_admin&quot;&#125;func (Account) TableName() string &#123; return &quot;tbl_account&quot;&#125; 2.2 连接数据库1234567891011121314151617181920212223242526272829303132const ( DBUSER = &quot;root&quot; DBPASS = &quot;&quot; HOST = &quot;127.0.0.1&quot; PORT = &quot;3306&quot; DBNAME = &quot;blog&quot;)func GetConn() *gorm.DB &#123; connStr := fmt.Sprintf(&quot;%s:%s@tcp(%s:%s)/%s?charset=utf8&amp;parseTime=True&amp;loc=Local&amp;timeout=10ms&quot;, DBUSER, DBPASS, HOST, PORT, DBNAME) fmt.Println(connStr) db, err := gorm.Open(&quot;mysql&quot;, connStr) if err != nil &#123; log.Fatalf(&quot;mysql connect error: %v&quot;, err) &#125; db.DB().SetMaxIdleConns(10) db.DB().SetMaxOpenConns(100) // 自动创建和更新表结构 if !db.HasTable(&quot;tbl_admin&quot;) &#123; db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Admin&#123;&#125;) &#125; if !db.HasTable(&quot;tbl_account&quot;) &#123; db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Account&#123;&#125;) &#125; return db&#125; 2.3 新增数据12345678910111213141516171819202122232425262728293031323334func Insert(db *gorm.DB) &#123; c := make(chan Admin) go generateData(c) for v := range c &#123; db.NewRecord(v) // 检查主键是否存在 db.Create(&amp;v) &#125;&#125;func generateRandomString(n int) string &#123; s := &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890_&quot; bs := make([]byte, n) for i := 0; i &lt; n; i++ &#123; bs[i] = s[rand.Intn(len(s))] &#125; return string(bs)&#125;func md5Encrypt(s string) string &#123; return fmt.Sprintf(&quot;%x&quot;, md5.Sum([]byte(s)))&#125;func generateData(c chan Admin) &#123; for i := 0; i &lt; 20; i++ &#123; name := generateRandomString(6) pass := md5Encrypt(name + &quot;_123456&quot;) c &lt;- Admin&#123;Username: name, Password: pass&#125; &#125; close(c)&#125; 2.4 查询数据12345678910111213func Select(db *gorm.DB) &#123; a := Admin&#123;&#125; db.Select([]string&#123;&quot;id&quot;, &quot;username&quot;, &quot;password&quot;&#125;).Where(&quot;id = ?&quot;, 1).First(&amp;a) fmt.Println(a)&#125;func SelectMany(db *gorm.DB) &#123; as := []Admin&#123;&#125; db.Where(&quot;username like &#x27;%4%&#x27;&quot;).Find(&amp;as) for _, a := range as &#123; fmt.Println(a) &#125;&#125; 2.5 更新数据1234567891011121314151617func Update(db *gorm.DB) &#123; a := Admin&#123;&#125; db.Where(&quot;id = ?&quot;, 1).First(&amp;a) a.Username = &quot;elihe123&quot; a.Password = md5Encrypt(&quot;123456&quot;) db.Save(a) // 数据必须有变化，否则无法保存 b := Admin&#123; ID: 30, Username: &quot;rania123&quot;, Password: md5Encrypt(&quot;654321&quot;), &#125; db.Save(b) // id不存在时，自动创建 c := Admin&#123;ID: 10&#125; db.Model(&amp;c).Update(&quot;username&quot;, &quot;eli&quot;)&#125; 2.6 删除数据1234func Delete(db *gorm.DB) &#123; a := Admin&#123;ID: 30&#125; db.Delete(&amp;a)&#125; 3. 钩子函数(callbacks) 创建: BeforeSave, BeforeCreate, AfterCreate, AfterSave 更新: BeforeSave, BeforeUpdate, AfterUpdate, AfterSave 删除: BeforeDelete, AfterDelete 查询: AfterFind 123456789func (Account) BeforeCreate(scope *gorm.Scope) error &#123; scope.SetColumn(&quot;CreatedAt&quot;, time.Now().Unix()) return nil&#125;func (Account) BeforeUpdate(scope *gorm.Scope) error &#123; scope.SetColumn(&quot;UpdatedAt&quot;, time.Now().Unix()) return nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Gin框架","slug":"Go Gin框架","date":"2019-05-17T02:22:58.000Z","updated":"2021-07-12T12:38:39.733Z","comments":true,"path":"2019/05/17/Go Gin框架/","link":"","permalink":"https://elihe2011.github.io/2019/05/17/Go%20Gin%E6%A1%86%E6%9E%B6/","excerpt":"1. Gin简介1.1 核心术语 Engine: 实现 ServeHTTP 接口的 Handler MethodTree： 根据http请求方法分别维护的路由树 RouterGroup：路由表分组，方便中间件统一处理 Context：上下文，在 Handler 之间传递参数 1.2 HttpRoutergin 使用路由框架 httprouter，它使用动态压缩前缀树 (compact prefix trie) 或称基数树 (radix tree) ，具有共同前缀的节点拥有相同的父节点，内存开销极小，没有反射。 12345678910111213141516171819202122// router.gotype Router struct &#123; trees map[string]*node // 每种请求方法，单独管理一棵树 RedirectTrailingSlash bool // 自动处理URL尾部的 “/” RedirectFixedPath bool // 路径矫正，如../和// HandleMethodNotAllowed bool HandleOPTIONS bool // 开启OPTIONS自动匹配, 手动匹配优先级更高 NotFound http.Handler MethodNotAllowed http.Handler PanicHandler func(http.ResponseWriter, *http.Request, interface&#123;&#125;)&#125;// tree.gotype node struct &#123; path string indices string // 分支的首字母：indices = eu，下面的 s [earch, upport] wildChild bool // 是否为参数节点，参数节点用:name表示 nType nodeType // static：没有handler，root: 第一个插入的节点，catchAll: 有*匹配的节点，param: 参数节点如:post priority uint32 // 子节点越多，或说绑定handle方法越多的节点，priority优先级越高 children []*node handle Handle&#125;","text":"1. Gin简介1.1 核心术语 Engine: 实现 ServeHTTP 接口的 Handler MethodTree： 根据http请求方法分别维护的路由树 RouterGroup：路由表分组，方便中间件统一处理 Context：上下文，在 Handler 之间传递参数 1.2 HttpRoutergin 使用路由框架 httprouter，它使用动态压缩前缀树 (compact prefix trie) 或称基数树 (radix tree) ，具有共同前缀的节点拥有相同的父节点，内存开销极小，没有反射。 12345678910111213141516171819202122// router.gotype Router struct &#123; trees map[string]*node // 每种请求方法，单独管理一棵树 RedirectTrailingSlash bool // 自动处理URL尾部的 “/” RedirectFixedPath bool // 路径矫正，如../和// HandleMethodNotAllowed bool HandleOPTIONS bool // 开启OPTIONS自动匹配, 手动匹配优先级更高 NotFound http.Handler MethodNotAllowed http.Handler PanicHandler func(http.ResponseWriter, *http.Request, interface&#123;&#125;)&#125;// tree.gotype node struct &#123; path string indices string // 分支的首字母：indices = eu，下面的 s [earch, upport] wildChild bool // 是否为参数节点，参数节点用:name表示 nType nodeType // static：没有handler，root: 第一个插入的节点，catchAll: 有*匹配的节点，param: 参数节点如:post priority uint32 // 子节点越多，或说绑定handle方法越多的节点，priority优先级越高 children []*node handle Handle&#125; 路由的保存： 123456789101112131415161718Priority Path Handle9 \\ *&lt;1&gt;3 ├s nil2 |├earch\\ *&lt;2&gt;1 |└upport\\ *&lt;3&gt;2 ├blog\\ *&lt;4&gt;1 | └:post nil1 | └\\ *&lt;5&gt;2 ├about-us\\ *&lt;6&gt;1 | └team\\ *&lt;7&gt;1 └contact\\ *&lt;8&gt;GET(&quot;/search/&quot;, h1)GET(&quot;/support/&quot;, h2)GET(&quot;/blog/:post/&quot;, h3)GET(&quot;/about-us/&quot;, h4)GET(&quot;/about-us/team/&quot;, h5)GET(&quot;/contact/&quot;, h6) r.Handle：r.Get, r.Post等方法的具体实现 123456789101112131415161718func (r *Router) Handle(method, path string, handle Handle) &#123; if path[0] != &#x27;/&#x27; &#123; panic(&quot;path must begin with &#x27;/&#x27; in path &#x27;&quot; + path + &quot;&#x27;&quot;) &#125; if r.trees == nil &#123; r.trees = make(map[string]*node) &#125; // 按方法创建路由树 root := r.trees[method] if root == nil &#123; root = new(node) r.trees[method] = root &#125; root.addRoute(path, handle)&#125; 2. 使用2.1 安装1go get -u github.com/gin-gonic/gin 2.2 入门12func (c *Context) JSON(code int, obj interface&#123;&#125;)type H map[string]interface&#123;&#125; 12345678910111213func main() &#123; // 路由 r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(200, gin.H &#123; &quot;id&quot;: 1, &quot;content&quot;: &quot;hello world!&quot;, &#125;) &#125;) r.Run(&quot;:8080&quot;)&#125; 2.3 请求参数2.3.1 路由参数1func (c *Context) Param(key string) string 1234567891011121314151617181920func main() &#123; r := gin.Default() r.GET(&quot;/user/:name&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) c.String(http.StatusOK, &quot;hello %s&quot;, name) &#125;) // 将匹配 /user/john/ 和 /user/john/send // 如果没有其他路由匹配 /user/john，它将重定向到 /user/john/ r.GET(&quot;/user/:name/*action&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) action := c.Param(&quot;action&quot;) msg := name + &quot; is doing &quot; + action c.String(http.StatusOK, msg) &#125;) r.Run()&#125; 2.3.2 Query参数123func (c *Context) Query(key string) string func (c *Context) GetQuery(key string) (string, bool) func (c *Context) DefaultQuery(key, defaultValue string) string 12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/user&quot;, func(c *gin.Context) &#123; filters := c.Query(&quot;filters&quot;) pageIndex := c.DefaultQuery(&quot;page_index&quot;, &quot;1&quot;) pageSize := c.DefaultQuery(&quot;page_size&quot;, &quot;10&quot;) c.JSON(http.StatusOK, gin.H&#123;&quot;filters&quot;: filters, &quot;page_index&quot;: pageIndex, &quot;page_size&quot;: pageSize&#125;) &#125;) r.Run()&#125; 2.3.3 Form参数12func (c *Context) PostForm(key string) stringfunc (c *Context) DefaultPostForm(key, defaultValue string) string 123456789101112131415161718func main() &#123; r := gin.Default() r.POST(&quot;/login&quot;, func(c *gin.Context) &#123; username := c.PostForm(&quot;username&quot;) password := c.DefaultPostForm(&quot;password&quot;, &quot;123456&quot;) c.JSON(http.StatusOK, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;) &#125;) r.Run()&#125;// curl -d &#x27;username=tom&amp;password=abc123&#x27; -X POST http://127.0.0.1:8080/login 2.3.4 参数相关方法 查询参数 Form表单 说明 Query PostForm 获取key对应的值，不存在为空字符串 GetQuery GetPostForm 多返回一个key是否存在的结果 QueryArray PostFormArray 获取key对应的数组，不存在返回一个空数组 GetQueryArray GetPostFormArray 多返回一个key是否存在的结果 QueryMap PostFormMap 获取key对应的map，不存在返回空map GetQueryMap GetPostFormMap 多返回一个key是否存在的结果 DefaultQuery DefaultPostForm key不存在的话，可以指定返回的默认值 2.4 文件操作调整文件上传表单大小： 12// 给表单限制上传大小，默认 32MiBr.MaxMultipartMemory = 128 &lt;&lt; 20 // 128MB 2.4.1 单文件上传1234567891011121314151617181920212223242526272829303132333435363738394041func upload(c *gin.Context) &#123; // 限制文件大小 err := c.Request.ParseMultipartForm(4 &lt;&lt; 20) // 4Mb if err != nil &#123; c.String(http.StatusBadRequest, &quot;file is too large&quot;) return &#125; // header, err := c.FormFile(&quot;file&quot;) file, header, err := c.Request.FormFile(&quot;file&quot;) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; defer file.Close() fmt.Printf(&quot;filename: %s, size: %d&quot;, header.Filename, header.Size) err = saveFile(header.Filename, file) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; c.String(http.StatusOK, &quot;uploaded!&quot;)&#125;func saveFile(name string, input multipart.File) (err error) &#123; var output *os.File output, err = os.OpenFile(name, os.O_CREATE|os.O_RDWR, 0644) if err != nil &#123; return &#125; defer output.Close() _, err = io.Copy(output, input) return&#125;curl -X POST http://192.168.80.1:8080/upload \\ -F &quot;file=@/home/ubuntu/ryu-socket_20210527.tar&quot; \\ -H &quot;Content-Type: multipart/form-data&quot; 2.4.2 多文件上传12345678910111213141516171819202122232425262728293031323334func uploadFiles(c *gin.Context) &#123; form, err := c.MultipartForm() if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; files := form.File[&quot;upload[]&quot;] fmt.Printf(&quot;file numbers: %d\\n&quot;, len(files)) for i, _ := range files &#123; file, err := files[i].Open() if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; fmt.Printf(&quot;filename: %s, size: %d\\n&quot;, files[i].Filename, files[i].Size) err = saveFile(files[i].Filename, file) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; &#125; c.String(http.StatusOK, &quot;uploaded&quot;)&#125;curl -X POST http://192.168.80.1:8080/uploadFiles \\ -F &quot;upload[]=@/home/ubuntu/clean_ryu_imgs.sh&quot; \\ -F &quot;upload[]=@/home/ubuntu/.profile&quot; \\ -F &quot;upload[]=@/home/ubuntu/vegeta_12.8.4_linux_amd64.tar.gz&quot; \\ -H &quot;Content-Type: multipart/form-data&quot; 2.4.3 文件下载123456789101112func download(c *gin.Context) &#123; txt := c.Query(&quot;content&quot;) content := &quot;hello, 我是文件, &quot; + txt c.Writer.WriteHeader(http.StatusOK) c.Header(&quot;Content-Disposition&quot;, &quot;attachment; filename=hello.txt&quot;) c.Header(&quot;Content-Type&quot;, &quot;application/text/plain&quot;) c.Header(&quot;Accept-Length&quot;, fmt.Sprintf(&quot;%d&quot;, len(content))) c.Writer.Write([]byte(content))&#125;curl http://192.168.80.1:8080/download?content=abc 4. 高级功能4.1 路由分组12345678910111213func main() &#123; r := gin.Default() v1 := r.Group(&quot;/v1&quot;) &#123; v1.POST(&quot;/login&quot;, LoginHandler) &#125; v2 := r.Group(&quot;/v2&quot;) &#123; v2.POST(&quot;/login&quot;, LoginV2Handler) &#125;&#125; 4.2 中间件1func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes 1234567891011121314151617181920func main() &#123; // 不使用默认中间件： Logger 和 Recovery r := gin.New() // 全局中间件 r.Use(gin.Logger()) r.Use(gin.Recovery()) // 路由中间件 r.GET(&quot;/location&quot;, LocationLogger(), LocationHandler) // 分组中间件 auth := r.Group(&quot;/auth&quot;) auth.Use(AuthRequired()) &#123; auth.POST(&quot;/user&quot;, UserHandler) &#125; r.Run()&#125; 4.2.1 自定义中间件12345678910111213141516171819202122232425262728293031323334func main() &#123; r := gin.New() r.Use(Logger()) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; time.Sleep(time.Second * 5) c.JSON(http.StatusOK, gin.H&#123; &quot;msg&quot;: c.MustGet(&quot;foo&quot;), &#125;) &#125;) r.Run()&#125;func Logger() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; // before request t := time.Now() // set a variable c.Set(&quot;foo&quot;, &quot;bar&quot;) // DO request c.Next() // after request latency := time.Since(t) log.Println(latency) // access the result status status := c.Writer.Status() log.Println(status) &#125;&#125; 4.2.2 BasicAuth中间件12345678910111213141516171819202122232425262728293031// simulate private datavar secrets = gin.H&#123; &quot;foo&quot;: gin.H&#123;&quot;email&quot;: &quot;foo@abc.com&quot;, &quot;phone&quot;: &quot;13302254321&quot;&#125;, &quot;jack&quot;: gin.H&#123;&quot;email&quot;: &quot;jack@abc.com&quot;, &quot;phone&quot;: &quot;18952098765&quot;&#125;,&#125;func main() &#123; r := gin.Default() authorized := r.Group(&quot;/admin&quot;, gin.BasicAuth(gin.Accounts&#123; &quot;foo&quot;: &quot;bar&quot;, &quot;jack&quot;: &quot;1234&quot;, &#125;)) authorized.GET(&quot;/secrets&quot;, func(c *gin.Context) &#123; user := c.MustGet(gin.AuthUserKey).(string) if secret, ok := secrets[user]; ok &#123; c.JSON(http.StatusOK, gin.H&#123; &quot;user&quot;: user, &quot;secret&quot;: secret, &#125;) &#125; else &#123; c.JSON(http.StatusUnauthorized, gin.H&#123; &quot;user&quot;: user, &quot;secret&quot;: &quot;NO SECRET&quot;, &#125;) &#125; &#125;) r.Run()&#125; 4.3 记录日志4.3.1 日志文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107var ( LogSavePath = &quot;logs/&quot; LogSaveName = &quot;gin&quot; LogSaveFileExt = &quot;log&quot; TimeFormat = &quot;20060102&quot;)type Level intvar ( F *os.File DefaultPrefix = &quot;&quot; DefaultCallerDepth = 2 logger *log.Logger logPrefix = &quot;&quot; levelFlags = []string&#123;&quot;DEBUG&quot;, &quot;INFO&quot;, &quot;WRAN&quot;, &quot;ERROR&quot;, &quot;FATAL&quot;&#125;)const ( DEBUG Level = iota INFO WARNING ERROR FATAL)func init() &#123; filePath := getLogFileFullPath() F = openLogFile(filePath) // 新建日志处理 logger = log.New(F, DefaultPrefix, log.LstdFlags)&#125;func getLogFilePath() string &#123; return fmt.Sprintf(&quot;%s&quot;, LogSavePath)&#125;func getLogFileFullPath() string &#123; prefixPath := getLogFilePath() suffixPath := fmt.Sprintf(&quot;%s%s.%s&quot;, LogSaveName, time.Now().Format(TimeFormat), LogSaveFileExt) return fmt.Sprintf(&quot;%s%s&quot;, prefixPath, suffixPath)&#125;func openLogFile(filePath string) *os.File &#123; _, err := os.Stat(filePath) switch &#123; case os.IsNotExist(err): makeDir() case os.IsPermission(err): log.Fatalf(&quot;Permission: %v&quot;, err) &#125; handle, err := os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil &#123; log.Fatalf(&quot;Failed to OpenFile: %v&quot;, err) &#125; return handle&#125;func makeDir() &#123; pwd, _ := os.Getwd() err := os.MkdirAll(pwd+&quot;/&quot;+getLogFilePath(), os.ModePerm) if err != nil &#123; panic(err) &#125;&#125;func Debug(v ...interface&#123;&#125;) &#123; setPrefix(DEBUG) logger.Println(v)&#125;func Info(v ...interface&#123;&#125;) &#123; setPrefix(INFO) logger.Println(v)&#125;func Warn(v ...interface&#123;&#125;) &#123; setPrefix(WARNING) logger.Println(v)&#125;func Error(v ...interface&#123;&#125;) &#123; setPrefix(ERROR) logger.Println(v)&#125;func Fatal(v ...interface&#123;&#125;) &#123; setPrefix(FATAL) logger.Println(v)&#125;func setPrefix(level Level) &#123; _, file, line, ok := runtime.Caller(DefaultCallerDepth) if ok &#123; logPrefix = fmt.Sprintf(&quot;[%s][%s:%d]&quot;, levelFlags[level], filepath.Base(file), line) &#125; else &#123; logPrefix = fmt.Sprintf(&quot;[%s]&quot;, levelFlags[level]) &#125; logger.SetPrefix(logPrefix)&#125; 4.3.2 日志格式12345678910111213141516171819202122232425262728func main() &#123; router := gin.New() // LoggerWithFormatter 中间件会将日志写入 gin.DefaultWriter // By default gin.DefaultWriter = os.Stdout router.Use(gin.LoggerWithFormatter(func(param gin.LogFormatterParams) string &#123; // 你的自定义格式 return fmt.Sprintf(&quot;%s - [%s] \\&quot;%s %s %s %d %s \\&quot;%s\\&quot; %s\\&quot;\\n&quot;, param.ClientIP, param.TimeStamp.Format(time.RFC1123), param.Method, param.Path, param.Request.Proto, param.StatusCode, param.Latency, param.Request.UserAgent(), param.ErrorMessage, ) &#125;)) router.Use(gin.Recovery()) router.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(200, &quot;pong&quot;) &#125;) router.Run(&quot;:8080&quot;)&#125; 4.4 模型绑定和验证Gin使用 go-playground/validator.v10 验证参数。 将请求主体绑定到结构体中，目前支持JSON、XML、YAML和标准表单值(foo=bar&amp;boo=baz)的绑定。 绑定方法： Must bind: Methods: Bind, BindJSON, BindXML, BindQuery, BindYAML Behavior: 底层使用MustBindWith，如果存在绑定错误，请求将被以下指令中止 c.AbortWithError(400, err).SetType(ErrorTypeBind) Should bind: Methods: ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML Behavior: 底层使用ShouldBindWith，如果存在绑定错误，则返回错误，开发人员可正确处理请求和错误 4.4.1 请求参数绑定1234567891011121314151617181920212223242526272829303132333435type User struct &#123; Username string `form:&quot;username&quot; json:&quot;username&quot; xml:&quot;username&quot; binding:&quot;required&quot;` Password string `form:&quot;password&quot; json:&quot;password&quot; xml:&quot;password&quot; binding:&quot;required&quot;`&#125;func main() &#123; r := gin.Default() r.POST(&quot;/login&quot;, func(c *gin.Context) &#123; var user User //if err := c.ShouldBind(&amp;user); err != nil &#123; if err := c.ShouldBindJSON(&amp;user); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; if user.Username != &quot;admin&quot; || user.Password != &quot;123&quot; &#123; c.JSON(http.StatusUnauthorized, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: &quot;unauthorized&quot;, &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.2 自定义校验器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport ( &quot;net/http&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;gopkg.in/go-playground/validator.v10&quot; &quot;github.com/gin-gonic/gin&quot;)type Booking struct &#123; // v8 // CheckIn time.Time `form:&quot;check_in&quot; binding:&quot;required,bookabledate&quot; time_format:&quot;2006-01-02&quot;` CheckIn time.Time `form:&quot;check_in&quot; binding:&quot;required&quot; validate:&quot;bookabledate&quot; time_format:&quot;2006-01-02&quot;` CheckOut time.Time `form:&quot;check_out&quot; binding:&quot;required,gtfield=CheckIn&quot; time_format:&quot;2006-01-02&quot;`&#125;func bookableDate(fl validator.FieldLevel) bool &#123; if date, ok := fl.Field().Interface().(time.Time); ok &#123; today := time.Now() if today.Before(date) &#123; return true &#125; &#125; return false&#125;func main() &#123; r := gin.Default() // v10 validate := validator.New() validate.RegisterValidation(&quot;bookabledate&quot;, bookableDate) r.GET(&quot;/book&quot;, func(c *gin.Context) &#123; var book Booking if err := c.ShouldBindWith(&amp;book, binding.Query); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; // v10: 绑定和校验分离 err := validate.Struct(book) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.3 绑定uri1234567891011121314151617181920212223242526type Person struct &#123; ID string `uri:&quot;id&quot; binding:&quot;required,uuid&quot;` Name string `uri:&quot;name&quot; binding:&quot;required&quot;`&#125;func main() &#123; r := gin.Default() r.GET(&quot;/:name/:id&quot;, func(c *gin.Context) &#123; var person Person if err := c.ShouldBindUri(&amp;person); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.4 错误翻译器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 1. 定义翻译器 translator.gopackage translatorimport ( &quot;strings&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;github.com/go-playground/locales/zh&quot; ut &quot;github.com/go-playground/universal-translator&quot; &quot;github.com/go-playground/validator/v10&quot; zhTrans &quot;github.com/go-playground/validator/v10/translations/zh&quot;)var ( uni *ut.UniversalTranslator validate *validator.Validate trans ut.Translator)func InitTrans() &#123; // 翻译器 zh := zh.New() uni = ut.New(zh, zh) trans, _ = uni.GetTranslator(&quot;zh&quot;) // 获取gin的校验器 validate = binding.Validator.Engine().(*validator.Validate) // 注册翻译器 zhTrans.RegisterDefaultTranslations(validate, trans)&#125;func Translate(err error) string &#123; var result []string errors := err.(validator.ValidationErrors) for _, err := range errors &#123; result = append(result, err.Translate(trans)) &#125; return strings.Join(result, &quot;; &quot;)&#125;// 2. 初始化translator.InitTrans()// 3. 使用实例type addUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,min=3,max=20&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6,max=8&quot;` Email string `json:&quot;email&quot; binding:&quot;omitempty,email&quot;`&#125;func AddUserHandler(c *gin.Context) (interface&#123;&#125;, error) &#123; var req addUserRequest err := c.ShouldBindJSON(&amp;req) fmt.Println(err) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; // 新增用户 srv := &amp;service.AddUserService&#123;&#125; err = srv.AddUser(req.Username, req.Password, req.Email) return srv, err&#125; 4.5 响应渲染4.5.1 常见格式123c.JSON(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;)c.XML(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;)c.YAML(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;) 4.5.2 ProtoBuf1234567891011121314151617func main() &#123; r := gin.Default() r.GET(&quot;/protobuf&quot;, func(c *gin.Context) &#123; reps := []int64&#123;int64(1), int64(2)&#125; label := &quot;test&quot; data := &amp;protoexample.Test&#123; Label: &amp;label, Reps: reps, &#125; c.ProtoBuf(http.StatusOK, data) &#125;) r.Run()&#125; 4.5.3 SecureJSONSecureJSON可以防止json劫持，如果返回的数据是数组，则会默认在返回值前加上”while(1)” JSON劫持，其实就是恶意网站，通过&lt;script&gt;标签获取你的JSON数据，因为JSON数组默认为是可执行的JS，所以通过这种方式，可以获得你的敏感数据。 1234567891011121314func main() &#123; r := gin.Default() // facebook r.SecureJsonPrefix(&quot;for(;;);&quot;) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; nums := []int&#123;1, 2, 3, 4, 5&#125; c.SecureJSON(http.StatusOK, nums) // while(1);[1,2,3,4,5] 默认Google &#125;) r.Run()&#125; 4.5.4 JSONPJSONP可以跨域传输，如果参数中存在回调参数，那么返回的参数将是回调函数的形式 123456789101112131415func main() &#123; r := gin.Default() data := make(map[string]interface&#123;&#125;) data[&quot;bar&quot;] = &quot;foo&quot; r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.JSONP(http.StatusOK, data) &#125;) // http://localhost:8080/test?callback=sayHello // sayHello(&#123;&quot;bar&quot;:&quot;foo&quot;&#125;); r.Run()&#125; 1234567&lt;script&gt; function sayHello(data) &#123; alert(JSON.stringify(data)) &#125;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:8080/jsonp?callback=sayHello&quot; &gt;&lt;/script&gt; 4.5.5 AsciiJSON编码中文、标签等特殊字符 12345678910111213141516func main() &#123; r := gin.Default() data := map[string]interface&#123;&#125;&#123; &quot;lang&quot;: &quot;中文&quot;, &quot;tag&quot;: &quot;&lt;xml&gt;&quot;, &#125; r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.AsciiJSON(http.StatusOK, data) &#125;) // &#123;&quot;lang&quot;:&quot;\\u4e2d\\u6587&quot;,&quot;tag&quot;:&quot;\\u003cxml\\u003e&quot;&#125; r.Run()&#125; 4.5.6 PureJSONJSON会将特殊的HTML字符替换为对应的unicode字符, 但PureJSON保留原有格式 12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.PureJSON(http.StatusOK, gin.H&#123; &quot;html&quot;: &quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot;, &#125;) &#125;) // &#123;&quot;html&quot;:&quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot;&#125; r.Run()&#125; 4.5.7 jsoniter高性能json工具 12345import jsoniter &quot;github.com/json-iterator/go&quot;var json = jsoniter.ConfigCompatibleWithStandardLibraryjson.Marshal(&amp;data)json.Unmarshal(input, &amp;data) Gin 默认使用 encoding/json，可以在编译中使用标签将其修改为 jsoniter 1go build -tags=jsoniter . 4.6 静态文件12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world&quot;) &#125;) r.Static(&quot;/assets&quot;, &quot;./assets&quot;) r.StaticFS(&quot;/disk&quot;, http.Dir(`E:\\Download`)) r.StaticFile(&quot;favicon.ico&quot;, &quot;./assets/favicon.ico&quot;) r.Run(&quot;:8080&quot;)&#125; 4.7 代理下载文件1234567891011121314151617181920func downloadFromUrl(c *gin.Context) &#123; url := c.Query(&quot;url&quot;) resp, err := http.Get(url) if err != nil || resp.StatusCode != http.StatusOK &#123; c.Status(http.StatusServiceUnavailable) return &#125; arr := strings.Split(url, &quot;/&quot;) filename := arr[len(arr)-1] reader := resp.Body contentLength := resp.ContentLength contentType := resp.Header.Get(&quot;Content-Type&quot;) extraHeaders := map[string]string&#123; &quot;Content-Disposition&quot;: fmt.Sprintf(&quot;attachment; filename=%s&quot;, filename), &#125; c.DataFromReader(http.StatusOK, contentLength, contentType, reader, extraHeaders) 4.8 HTML渲染1234567891011121314func main() &#123; r := gin.Default() //r.LoadHTMLFiles(&quot;templates/index.tmpl&quot;, &quot;templates/login.tmpl&quot;) r.LoadHTMLGlob(&quot;templates/*&quot;) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.HTML(http.StatusOK, &quot;index.tmpl&quot;, gin.H&#123; &quot;title&quot;: &quot;Home Page&quot;, &#125;) &#125;) r.Run()&#125; 12345&lt;html&gt; &lt;h1&gt; &#123;&#123; .title &#125;&#125; &lt;/h1&gt;&lt;/html&gt; 4.9 重定向1234567891011121314151617181920func main() &#123; r := gin.Default() // 外部重定向 r.GET(&quot;/test1&quot;, func(c *gin.Context) &#123; c.Redirect(http.StatusMovedPermanently, &quot;https://google.com&quot;) &#125;) // 路由重定向 HandleContext r.GET(&quot;/test2&quot;, func(c *gin.Context) &#123; c.Request.URL.Path = &quot;/test3&quot; r.HandleContext(c) &#125;) r.GET(&quot;/test3&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world!&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125; 12345678910111213141516func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.Request.URL.Path = &quot;/test2&quot; r.HandleContext(c) &#125;) r.GET(&quot;/test2&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123; &quot;msg&quot;: &quot;hello world!&quot;, &#125;) &#125;) r.Run()&#125; 4.10 支持https123456789101112131415161718192021222324import ( &quot;log&quot; &quot;net/http&quot; &quot;golang.org/x/crypto/acme/autocert&quot; &quot;github.com/gin-gonic/autotls&quot; &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;pong&quot;) &#125;) m := autocert.Manager&#123; Prompt: autocert.AcceptTOS, HostPolicy: autocert.HostWhitelist(&quot;localhost:8080&quot;, &quot;example1.com&quot;, &quot;example2.com&quot;), Cache: autocert.DirCache(&quot;/var/www/.cache&quot;), &#125; log.Fatal(autotls.RunWithManager(r, &amp;m))&#125; 4.11 使用cookie123456789101112131415func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; cookie, err := c.Cookie(&quot;gin_cookie&quot;) if err != nil &#123; cookie = &quot;NO_SET&quot; c.SetCookie(&quot;gin_cookie&quot;, &quot;test&quot;, 3600, &quot;/&quot;, &quot;localhost&quot;, false, true) &#125; c.String(http.StatusOK, &quot;cookie=%s&quot;, cookie) &#125;) r.Run()&#125; 4.13 服务配置123456789101112type Server struct &#123; Addr string Handler http.Handler TLSConfig *tls.Config ReadTimeout time.Duration ReadHeaderTime time.Duration WriteTimeout time.Duration IdleTimeout time.Duration MaxHeaderBytes int ConnState func(net.Conn, http.ConnState) ErrorLog *log.Logger&#125; 123456789101112func main() &#123; router := gin.Default() s := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; s.ListenAndServe()&#125; 4.14 使用 goroutine在中间件或处理程序中启动 Goroutine 时，需要使用只读副本 c.Copy() 123456789101112131415161718192021222324func main() &#123; r := gin.Default() r.GET(&quot;/sync&quot;, func(c *gin.Context) &#123; start := time.Now() time.Sleep(5 * time.Second) log.Println(c.Request.URL) latency := time.Now().Sub(start) c.String(http.StatusOK, latency.String()) &#125;) r.GET(&quot;/async&quot;, func(c *gin.Context) &#123; start := time.Now() // 协程中使用，必须先复制 cc := c.Copy() go func() &#123; time.Sleep(5 * time.Second) log.Println(cc.Request.URL) &#125;() latency := time.Now().Sub(start) c.String(http.StatusOK, latency.String()) &#125;)&#125; 5. 运行多个服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import ( &quot;log&quot; &quot;net/http&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin&quot; &quot;golang.org/x/sync/errgroup&quot;)var ( g errgroup.Group)func router01() http.Handler &#123; r := gin.New() r.Use(gin.Recovery()) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;welcome to server 01&quot;&#125;) &#125;) return r&#125;func router02() http.Handler &#123; r := gin.New() r.Use(gin.Recovery()) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;welcome to server 02&quot;&#125;) &#125;) return r&#125;func main() &#123; server01 := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router01(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, &#125; server02 := &amp;http.Server&#123; Addr: &quot;:8081&quot;, Handler: router02(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, &#125; g.Go(func() error &#123; return server01.ListenAndServe() &#125;) g.Go(func() error &#123; return server02.ListenAndServe() &#125;) if err := g.Wait(); err != nil &#123; log.Fatal(err) &#125;&#125; 6. 集成JWT1go get github.com/dgrijalva/jwt-go 涉及方法： NewWithClaims(method SigningMethod, claims Claims), method对应着SigningMethodHMAC struct&#123;&#125;，其包含SigningMethodHS256, SigningMethodHS384, SigningMethodHS512三种crypt.Hash func (t *Token) SignedString(key interface&#123;&#125;) 内部生成签名字符串，再用于获取完整、已签名的token func (p *Parser) ParseWithClaims解析鉴权声明，方法内部主要是具体的解码和校验过程，最终返回*Token func (m MapClaims) Valid() 验证基于时间的声明exp, iat, nbf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import ( &quot;gin-blog/pkg/setting&quot; &quot;time&quot; jwt &quot;github.com/dgrijalva/jwt-go&quot;)var jwtSecret = []byte(setting.JwtSecret)type Claims struct &#123; Username string `json:&quot;username&quot;` Password string `json:&quot;password&quot;` jwt.StandardClaims&#125;func GenerateToken(username, password string) (string, error) &#123; nowTime := time.Now() expireTime := nowTime.Add(3 * time.Hour) claims := Claims&#123; username, password, jwt.StandardClaims&#123; ExpiresAt: expireTime.Unix(), Issuer: &quot;gin-blog&quot;, &#125;, &#125; tokenClaims := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) token, err := tokenClaims.SignedString(jwtSecret) return token, err&#125;func ParseToken(token string) (*Claims, error) &#123; tokenClaims, err := jwt.ParseWithClaims(token, &amp;Claims&#123;&#125;, func(token *jwt.Token) (interface&#123;&#125;, error) &#123; return jwtSecret, nil &#125;) if tokenClaims != nil &#123; if claims, ok := tokenClaims.Claims.(*Claims); ok &amp;&amp; tokenClaims.Valid &#123; return claims, nil &#125; &#125; return nil, err&#125; 7. 重启服务器要求： 不关闭现有连接 （正在运行中的程序） 新的进程启动并替代旧进程 新的进程结构新的连接 连接要随时响应用户的请求，当用户仍在请求旧进程时，要保持连接，新用户应请求新进程，不可出现拒绝请求的情况 7.1 endlessendless: Zero downtime restarts for golfing HTTP and HTTPS servers 每次更新发布、修改配置文件等，只要给该进行发送SIGTERM信号(kill )，而不需要强制结束应用 监听信号： syscall.SIGHUP: 触发fork子进程和重新启动 syscall.SIGUSR1/syscall.SIGTSTP: 被监听，但不触发任何动作 syscall.SIGUSR2: 触发hammerTime syscall.SIGINT/syscall.SIGTERM: 触发服务器关闭（会完成正在运行的请求） 123456789101112131415161718192021222324252627282930313233343536import ( &quot;fmt&quot; &quot;gin-blog/pkg/setting&quot; &quot;gin-blog/routers&quot; &quot;log&quot; &quot;syscall&quot; &quot;github.com/fvbock/endless&quot;)func main() &#123; //router := routers.InitRouter() // //server := &amp;http.Server&#123; // Addr: fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort), // Handler: router, // ReadTimeout: setting.ReadTimeout, // WriteTimeout: setting.WriteTimeout, // MaxHeaderBytes: 1 &lt;&lt; 20, //&#125; endless.DefaultReadTimeOut = setting.ReadTimeout endless.DefaultWriteTimeOut = setting.WriteTimeout endless.DefaultMaxHeaderBytes = 1 &lt;&lt; 20 endPoint := fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort) server := endless.NewServer(endPoint, routers.InitRouter()) server.BeforeBegin = func(add string) &#123; log.Printf(&quot;Actual pid is %d&quot;, syscall.Getpid()) &#125; err := server.ListenAndServe() if err != nil &#123; log.Printf(&quot;Server error: %v&quot;, err) &#125;&#125; 7.2 Shutdown使用 http.Server 内置的 Shutdown()方法优雅地关闭服务，它不会中断任何活动的连接，直到所有连接处理完毕 1234567891011121314151617181920212223242526272829303132func main() &#123; router := initRouter() server := &amp;http.Server&#123; Addr: fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort), Handler: router, ReadTimeout: setting.ReadTimeout, WriteTimeout: setting.WriteTimeout, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; go func() &#123; if err := server.ListenAndServe(); err != nil &#123; log.Printf(&quot;Listen: %v\\n&quot;, err) &#125; &#125;() quit := make(chan os.Signal) signal.Notify(quit, os.Interrupt) &lt;-quit log.Printf(&quot;Shutdown Server ...&quot;) ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() if err := server.Shutdown(ctx); err != nil &#123; log.Fatal(&quot;Server Shutdown:&quot;, err) &#125; log.Println(&quot;Server exiting&quot;)&#125; 8. Swagger API123go get -u github.com/swaggo/swag/cmd/swaggo get -u github.com/swaggo/gin-swaggergo get -u github.com/swaggo/gin-swagger/swaggerFiles 8.1 API 接口注释1234567891011121314151617181920212223242526// LoginHandler godoc// @Summary 登录系统// @Tags 用户相关接口// @Accept json// @Produce json// @Param object body loginRequest true &quot;请求参数&quot;// @Success 200 &#123;object&#125; router.Response// @Failure 400 &#123;object&#125; e.ApiError// @Router /api/v1/login [post]func LoginHandler(c *gin.Context) (interface&#123;&#125;, error) &#123; var req loginRequest err := c.ShouldBindJSON(&amp;req) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; // 登录 srv := &amp;service.LoginService&#123;&#125; err = srv.Login(req.Username, req.Password) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; return srv, nil&#125; 8.2 生成配置1swag init 8.3 引入配置12345678910// main.gofunc init() &#123; // swagger 相关信息 docs.SwaggerInfo.Title = &quot;XXX 项目接口文档&quot; docs.SwaggerInfo.Description = &quot;just a test&quot; docs.SwaggerInfo.Version = &quot;1.0&quot; docs.SwaggerInfo.Host = addr docs.SwaggerInfo.BasePath = &quot;/&quot; docs.SwaggerInfo.Schemes = []string&#123;&quot;http&quot;, &quot;https&quot;&#125;&#125; 8.4 禁用Swaggergin-swagger还提供了DisablingWrapHandler函数，方便我们通过设置某些环境变量来。例如： 1r.GET(&quot;/swagger/*any&quot;, gs.DisablingWrapHandler(swaggerFiles.Handler, &quot;NAME_OF_ENV_VARIABLE&quot;)) 此时如果将环境变量NAME_OF_ENV_VARIABLE设置为任意值，则/swagger/*any将返回404响应，就像未指定路由时一样。 9. 接口测试12345678910111213141516171819202122232425262728import ( &quot;net/http&quot; &quot;net/http/httptest&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/assert&quot; &quot;github.com/gin-gonic/gin&quot;)func setRouter() *gin.Engine &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;pong&quot;) &#125;) return r&#125;func TestPingRoute(t *testing.T) &#123; router := setRouter() w := httptest.NewRecorder() req, _ := http.NewRequest(&quot;GET&quot;, &quot;/ping&quot;, nil) router.ServeHTTP(w, req) assert.Equal(t, http.StatusOK, w.Code) assert.Equal(t, &quot;pong&quot;, w.Body.String())&#125; 10. 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229// 获取一个gin框架实例gin.Default()// 具体的Default方法func Default() *Engine &#123; // 调试模式日志输出 debugPrintWARNINGDefault() // 创建一个gin框架实例 engine := New() // 注册中间件的方式一致 engine.Use(Logger(), Recovery()) return engine&#125;// 创建一个gin框架实例 具体方法func New() *Engine &#123; // 调试模式日志输出 debugPrintWARNINGNew() // 初始化一个Engine实例 engine := &amp;Engine&#123; // 给框架实例绑定上一个路由组 RouterGroup: RouterGroup&#123; Handlers: nil, // engine.Use 注册的中间方法到这里 basePath: &quot;/&quot;, root: true, // 是否是路由根节点 &#125;, FuncMap: template.FuncMap&#123;&#125;, RedirectTrailingSlash: true, RedirectFixedPath: false, HandleMethodNotAllowed: false, ForwardedByClientIP: true, AppEngine: defaultAppEngine, UseRawPath: false, UnescapePathValues: true, MaxMultipartMemory: defaultMultipartMemory, trees: make(methodTrees, 0, 9), // 路由树 delims: render.Delims&#123;Left: &quot;&#123;&#123;&quot;, Right: &quot;&#125;&#125;&quot;&#125;, secureJsonPrefix: &quot;while(1);&quot;, &#125; // RouterGroup绑定engine自身的实例 engine.RouterGroup.engine = engine // 绑定从实例池获取上下文的闭包方法 engine.pool.New = func() interface&#123;&#125; &#123; // 获取一个Context实例 return engine.allocateContext() &#125; // 返回框架实例 return engine&#125;// 注册日志&amp;goroutin panic捕获中间件engine.Use(Logger(), Recovery())// 具体的注册中间件的方法func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes &#123; engine.RouterGroup.Use(middleware...) engine.rebuild404Handlers() engine.rebuild405Handlers() return engine&#125;///////////////////////////////////////////// 注册GET请求路由func (group *RouterGroup) GET(relativePath string, handlers ...HandlerFunc) IRoutes &#123; // 往路由组内 注册GET请求路由 return group.handle(&quot;GET&quot;, relativePath, handlers)&#125;func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes &#123; absolutePath := group.calculateAbsolutePath(relativePath) // 把中间件的handle和该路由的handle合并 handlers = group.combineHandlers(handlers) // 注册一个GET集合的路由 group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj()&#125;func (engine *Engine) addRoute(method, path string, handlers HandlersChain) &#123; assert1(path[0] == &#x27;/&#x27;, &quot;path must begin with &#x27;/&#x27;&quot;) assert1(method != &quot;&quot;, &quot;HTTP method can not be empty&quot;) assert1(len(handlers) &gt; 0, &quot;there must be at least one handler&quot;) debugPrintRoute(method, path, handlers) // 检查有没有对应method集合的路由 root := engine.trees.get(method) if root == nil &#123; // 没有 创建一个新的路由节点 root = new(node) // 添加该method的路由tree到当前的路由到路由树里 engine.trees = append(engine.trees, methodTree&#123;method: method, root: root&#125;) &#125; // 添加路由 root.addRoute(path, handlers)&#125;// 路由树节点type node struct &#123; path string indices string children []*node handlers HandlersChain // 所有的handle 构成一个链 priority uint32 nType nodeType maxParams uint8 wildChild bool&#125;// 启动http serverfunc (engine *Engine) Run(addr ...string) (err error) &#123; defer func() &#123; debugPrintError(err) &#125;() address := resolveAddress(addr) debugPrint(&quot;Listening and serving HTTP on %s\\n&quot;, address) // 执行http包的ListenAndServe方法 启动路由 err = http.ListenAndServe(address, engine) return&#125;// engine自身就实现了Handler接口type Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125;// 监听IP+端口ln, err := net.Listen(&quot;tcp&quot;, addr)// 接着就是Servesrv.Serve(tcpKeepAliveListener&#123;ln.(*net.TCPListener)&#125;)// Accept请求rw, e := l.Accept()// 使用goroutine去处理一个请求，最终就执行的是engine的ServeHTTP方法go c.serve(ctx)// engine实现http.Handler接口ServeHTTP的具体方法func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; // 获取一个上下文实例，从实例池获取 性能高 c := engine.pool.Get().(*Context) // 重置获取到的上下文实例的http.ResponseWriter c.writermem.reset(w) // 重置获取到的上下文实例*http.Request c.Request = req // 重置获取到的上下文实例的其他属性 c.reset() // 实际处理请求的地方，传递当前的上下文 engine.handleHTTPRequest(c) //归还上下文实例 engine.pool.Put(c)&#125;// 具体执行路由的方法engine.handleHTTPRequest(c)t := engine.treesfor i, tl := 0, len(t); i &lt; tl; i++ &#123; // 遍历路由树，查找当前请求method if t[i].method != httpMethod &#123; continue &#125; // 找到节点 root := t[i].root // 寻找当前请求的路由 handlers, params, tsr := root.getValue(path, c.Params, unescape) if handlers != nil &#123; // 把找到的handles赋值给上下文 c.handlers = handlers // 把找到的入参赋值给上下文 c.Params = params // 执行handle c.Next() // 处理响应内容 c.writermem.WriteHeaderNow() return &#125; ...&#125;// 方法树结构体type methodTree struct &#123; // HTTP Method method string // 当前HTTP Method的路由节点 root *node&#125;// 方法树集合type methodTrees []methodTree// 执行handlefunc (c *Context) Next() &#123; // 上下文处理之后c.index被执为-1 c.index++ for s := int8(len(c.handlers)); c.index &lt; s; c.index++ &#123; // 遍历执行所有handle(其实就是中间件+路由handle) c.handlers[c.index](c) &#125;&#125;// Context的重置方法func (c *Context) reset() &#123; c.Writer = &amp;c.writermem c.Params = c.Params[0:0] c.handlers = nil // 很关键 注意这里是-1哦 c.index = -1 c.Keys = nil c.Errors = c.Errors[0:0] c.Accepted = nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go OS性能数据","slug":"Go OS性能数据","date":"2019-05-16T07:22:58.000Z","updated":"2021-07-07T06:23:22.756Z","comments":true,"path":"2019/05/16/Go OS性能数据/","link":"","permalink":"https://elihe2011.github.io/2019/05/16/Go%20OS%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE/","excerpt":"1. 系统性能psutil是一个跨平台进程和系统监控的Python库，gopsutil是其Go语言版本的实现。适合做一些诸如采集系统信息和监控的服务 1go get github.com/shirou/gopsutil/cpu 123456789101112131415161718192021222324252627282930313233343536373839404142434445func getCpuInfo() &#123; cpuInfos, _ := cpu.Info() for _, ci := range cpuInfos &#123; fmt.Println(ci) &#125; // CPU 使用率 for &#123; percent, _ := cpu.Percent(time.Second, false) fmt.Printf(&quot;cpu percent: %v\\n&quot;, percent) &#125;&#125;func getMemInfo() &#123; memInfo, _ := mem.VirtualMemory() fmt.Printf(&quot;mem info: %v\\n&quot;, memInfo)&#125;func getHostInfo() &#123; hostInfo, _ := host.Info() fmt.Printf(&quot;host info: %v\\n&quot;, hostInfo)&#125;func getDiskInfo() &#123; parts, _ := disk.Partitions(true) for _, part := range parts &#123; fmt.Printf(&quot;part: %v\\n&quot;, part.String()) diskInfo, _ := disk.Usage(part.Mountpoint) fmt.Printf(&quot;disk info: used=%v, free=%v\\n&quot;, diskInfo.Used, diskInfo.Free) &#125; ioStat, _ := disk.IOCounters() for k, v := range ioStat &#123; fmt.Printf(&quot;%v: %v\\n&quot;, k, v) &#125;&#125;func getNetInfo() &#123; infos, _ := net.IOCounters(true) for i, v := range infos &#123; fmt.Printf(&quot;%v: %v, send: %v, recv: %v\\n&quot;, i, v, v.BytesSent, v.BytesRecv) &#125;&#125;","text":"1. 系统性能psutil是一个跨平台进程和系统监控的Python库，gopsutil是其Go语言版本的实现。适合做一些诸如采集系统信息和监控的服务 1go get github.com/shirou/gopsutil/cpu 123456789101112131415161718192021222324252627282930313233343536373839404142434445func getCpuInfo() &#123; cpuInfos, _ := cpu.Info() for _, ci := range cpuInfos &#123; fmt.Println(ci) &#125; // CPU 使用率 for &#123; percent, _ := cpu.Percent(time.Second, false) fmt.Printf(&quot;cpu percent: %v\\n&quot;, percent) &#125;&#125;func getMemInfo() &#123; memInfo, _ := mem.VirtualMemory() fmt.Printf(&quot;mem info: %v\\n&quot;, memInfo)&#125;func getHostInfo() &#123; hostInfo, _ := host.Info() fmt.Printf(&quot;host info: %v\\n&quot;, hostInfo)&#125;func getDiskInfo() &#123; parts, _ := disk.Partitions(true) for _, part := range parts &#123; fmt.Printf(&quot;part: %v\\n&quot;, part.String()) diskInfo, _ := disk.Usage(part.Mountpoint) fmt.Printf(&quot;disk info: used=%v, free=%v\\n&quot;, diskInfo.Used, diskInfo.Free) &#125; ioStat, _ := disk.IOCounters() for k, v := range ioStat &#123; fmt.Printf(&quot;%v: %v\\n&quot;, k, v) &#125;&#125;func getNetInfo() &#123; infos, _ := net.IOCounters(true) for i, v := range infos &#123; fmt.Printf(&quot;%v: %v, send: %v, recv: %v\\n&quot;, i, v, v.BytesSent, v.BytesRecv) &#125;&#125; 2. 获取IP地址12345678910111213141516171819202122232425262728293031func getLocalIP() &#123; addrs, _ := net.InterfaceAddrs() for _, addr := range addrs &#123; ipAddr, ok := addr.(*net.IPNet) if !ok &#123; continue &#125; if ipAddr.IP.IsLoopback() &#123; continue &#125; if !ipAddr.IP.IsGlobalUnicast() &#123; continue &#125; fmt.Println(ipAddr.IP.String()) &#125;&#125;func getOutboundIP() &#123; conn, err := net.Dial(&quot;udp&quot;, &quot;114.114.114.114:80&quot;) if err != nil &#123; panic(err) &#125; defer conn.Close() localAddr := conn.LocalAddr().(*net.UDPAddr) fmt.Println(localAddr.IP.String())&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 数据库 sqlx","slug":"Go 数据库 sqlx","date":"2019-05-01T08:30:58.000Z","updated":"2021-06-30T08:30:43.360Z","comments":true,"path":"2019/05/01/Go 数据库 sqlx/","link":"","permalink":"https://elihe2011.github.io/2019/05/01/Go%20%E6%95%B0%E6%8D%AE%E5%BA%93%20sqlx/","excerpt":"1. Getting Started12go get github.com/jmoiron/sqlxgithub.com/go-sql-driver/mysql 2. Handle Types4 handle types: sqlx database/sql sqlx.DB sql.DB sqlx.Tx sql.Tx sqlx.Stmt sql.Stmt sqlx.NamedStmt 2 cursor types: sqlx database/sql from sqlx.Rows sql.Rows Queryx sqlx.Row sql.Row QueryRowx","text":"1. Getting Started12go get github.com/jmoiron/sqlxgithub.com/go-sql-driver/mysql 2. Handle Types4 handle types: sqlx database/sql sqlx.DB sql.DB sqlx.Tx sql.Tx sqlx.Stmt sql.Stmt sqlx.NamedStmt 2 cursor types: sqlx database/sql from sqlx.Rows sql.Rows Queryx sqlx.Row sql.Row QueryRowx 3. Connecting to Database12345678910111213var dsn = &quot;root:123456@tcp(127.0.0.1:3306)/mydb?parseTime=true&amp;&amp;charset=utf8mb4&quot;var db *sqlx.DB// 1. same as sql.Open()db, err = sqlx.Open(&quot;mysql&quot;, dsn)err = db.Ping() // force a connection and test that is worked // 2. open and connect at the same timedb, err = sqlx.Connect(&quot;mysql&quot;, dsn)// 3. same as 2, but panic on errordb = sqlx.MustConnect(&quot;mysql&quot;, dsn) 4. Querying12345678910111213141516171819202122232425262728// 1. unchanged from database/sqlExec(query string, args ...interface&#123;&#125;) (sql.Result, error)Query(query string, args ...interface&#123;&#125;) (*sql.Rows, error)QueryRow(query string, args ...interface&#123;&#125;) *sql.Row// 2. extensionsMustExec(query string, args ...interface&#123;&#125;) sql.ResultQueryx(query string, args ...interface&#123;&#125;) (*sqlx.Rows, error)QueryRowx(query string, args ...interface&#123;&#125;) *sqlx.Row// 3. new semantics: 结构体struct与数据库schema绑定Select(dest interface&#123;&#125;, query string, args ...interface&#123;&#125;) errorGet(dest interface&#123;&#125;, query string, args ...interface&#123;&#125;) error // An error is returned if the result set is empty// 4. sqlx.Rowtype Rows struct &#123; *sql.Rows unsafe bool Mapper *reflectx.Mapper // these fields cache memory use for a rows during iteration w/ structScan started bool fields [][]int values []interface&#123;&#125;&#125;// 5. sql.ResultLastInsertId() (int64, error)RowsAffected() (int64, error) 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func querying(db *sqlx.DB) &#123; // 1. Exec &amp; MustExec schema := `CREATE TABLE IF NOT EXISTS person (id INT(10) AUTO_INCREMENT PRIMARY KEY,name VARCHAR(20) NOT NULL,age TINYINT,address VARCHAR(100))` db.MustExec(schema) sqlStr := &quot;insert into person(name, age) values(?, ?)&quot; db.MustExec(sqlStr, &quot;jack&quot;, 21) db.MustExec(sqlStr, &quot;maxin&quot;, 30) sqlStr = &quot;insert into person(name, age, address) values(?, ?, ?)&quot; result, err := db.Exec(sqlStr, &quot;lucy&quot;, 39, &quot;London, UK&quot;) if err != nil &#123; panic(err) &#125; id, _ := result.LastInsertId() fmt.Printf(&quot;last insert id is %d\\n&quot;, id) // 2. Query &amp; Queryx sqlStr = &quot;select * from person&quot; rows1, err := db.Query(sqlStr) if err != nil &#123; panic(err) &#125; for rows1.Next() &#123; var id int var name string var age uint8 var address sql.NullString err = rows1.Scan(&amp;id, &amp;name, &amp;age, &amp;address) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;id: %d, name: %s, age: %d, address: %v\\n&quot;, id, name, age, address) &#125; type person struct &#123; Id int Name string Age uint8 Address sql.NullString &#125; rows2, err := db.Queryx(sqlStr) if err != nil &#123; panic(err) &#125; for rows2.Next() &#123; var p person rows2.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p) &#125; // 3. Get &amp; Select var p person var pp []person err = db.Get(&amp;p, &quot;select * from person limit 1&quot;) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v\\n&quot;, p) err = db.Select(&amp;pp, &quot;select * from person where id &gt; 2&quot;) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v\\n&quot;, pp) var count int db.Get(&amp;count, &quot;select count(*) from person&quot;) fmt.Println(count) var names []string db.Select(&amp;names, &quot;select name from person&quot;) fmt.Println(names)&#125; 5. Transactions123456// 1. sql.TxBegin() (*sql.Tx, error)// 2. sqlx.TxBeginx() (*sqlx.Tx, error)MustBegin() (*sql.Tx) 示例： 123456789101112131415161718func transaction(db *sqlx.DB) &#123; tx := db.MustBegin() defer func() &#123; if err := recover(); err != nil &#123; tx.Rollback() &#125; &#125;() tx.MustExec(&quot;delete from person where id=4&quot;) tx.MustExec(&quot;insert into person values(2, &#x27;abc&#x27;, 22, &#x27;LA&#x27;)&quot;) tx.MustExec(&quot;insert into person values(100, &#x27;abc&#x27;, 22, &#x27;LA&#x27;)&quot;) err := tx.Commit() if err != nil &#123; panic(err) &#125;&#125; 6. Prepared Statements123456789101112131415161718func prepared(db *sqlx.DB) &#123; stmt, _ := db.Prepare(&quot;select * from person where id=?&quot;) row := stmt.QueryRow(5) var id int var name string var age uint8 var address sql.NullString row.Scan(&amp;id, &amp;name, &amp;age, &amp;address) fmt.Printf(&quot;id: %d, name: %s, age: %d, address: %v\\n&quot;, id, name, age, address) stmtx, _ := db.Preparex(&quot;select * from person where id=?&quot;) rowx := stmtx.QueryRowx(5) var p person rowx.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p)&#125; 7. Query Helpers7.1 “In” Queries123456789101112131415161718192021222324252627282930313233func inQuery(db *sqlx.DB) &#123; ids := []int&#123;1, 2, 3, 4, 5&#125; /* // converting argument $1 type: unsupported type []int, a slice of int rows, err := db.Query(&quot;select name from person where id in (?)&quot;, ids) if err != nil &#123; panic(err) &#125; for rows.Next() &#123; var name string rows.Scan(&amp;name) fmt.Println(name) &#125;*/ // convert to (?, ?, ...) query, args, err := sqlx.In(&quot;select name from person where id in (?)&quot;, ids) if err != nil &#123; panic(err) &#125; query = db.Rebind(query) fmt.Println(query) rows, err := db.Query(query, args...) if err != nil &#123; panic(err) &#125; for rows.Next() &#123; var name string rows.Scan(&amp;name) fmt.Println(name) &#125;&#125; 7.2 Named Queries123NamedQuery(query string, arg interface&#123;&#125;) (*sqlx.Rows, error)NamedExec(query string, arg interface&#123;&#125;) (sql.Result, error)PrepareNamed(query string) (*NamedStmt, error) 示例： 1234567891011121314151617func namedQuery(db *sqlx.DB) &#123; // named query with a struct p := person&#123;Name: &quot;jack&quot;&#125; rows, _ := db.NamedQuery(&quot;select count(*) from person where name=:name&quot;, p) for rows.Next() &#123; var count int rows.Scan(&amp;count) fmt.Println(count) &#125; // named query with a map m := map[string]interface&#123;&#125;&#123;&quot;address&quot;: &quot;LA&quot;&#125; stmt, _ := db.PrepareNamed(&quot;select * from person where address=:address limit 1&quot;) row := stmt.QueryRowx(m) row.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p)&#125; 8. Alternate Scan Types1234567891011121314func alternateScan(db *sqlx.DB) &#123; rows, _ := db.Queryx(&quot;select * from person&quot;) for rows.Next() &#123; cols, _ := rows.SliceScan() fmt.Println(cols) &#125; rows, _ = db.Queryx(&quot;select * from person&quot;) for rows.Next() &#123; cols := make(map[string]interface&#123;&#125;) rows.MapScan(cols) fmt.Println(cols) &#125;&#125; 9. Connection Pool12DB.SetMaxIdleConns(n int)DB.SetMaxOpenConns(n int)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Linux 使用总结","slug":"Linux 使用总结","date":"2019-04-30T06:12:26.000Z","updated":"2021-07-13T03:05:04.798Z","comments":true,"path":"2019/04/30/Linux 使用总结/","link":"","permalink":"https://elihe2011.github.io/2019/04/30/Linux%20%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/","excerpt":"1. Ubuntu1.1 修改IPUbuntu 16, 18: 12345678910sudo vi /etc/network/interfacesauto ens33iface ens33 inet staticaddress 192.168.80.20netmask 255.255.255.0gateway 192.168.80.2dns-nameservers 8.8.8.8sudo ip addr flush ens33sudo systemctl restart networking","text":"1. Ubuntu1.1 修改IPUbuntu 16, 18: 12345678910sudo vi /etc/network/interfacesauto ens33iface ens33 inet staticaddress 192.168.80.20netmask 255.255.255.0gateway 192.168.80.2dns-nameservers 8.8.8.8sudo ip addr flush ens33sudo systemctl restart networking Ubuntu 20: 123456789101112131415sudo vi /etc/netplan/00-installer-config.yamlnetwork: ethernets: ens33: addresses: - 192.168.80.121/24 gateway4: 192.168.80.2 nameservers: addresses: - 8.8.8.8 search: - 8.8.8.8 version: 2sudo netplan apply 1.2 防火墙1234567sudo ufw statussuod ufw enable/disablesudo ufw allow/deny 22/tcpsudo ufw allow from 192.168.80.1sudo ufw delete allow from 192.168.80.1 1.3 sshd12345sudo apt-get updatesudo apt-get install openssh-serversudo ps -ef | grep ssh 1.4 Docker123456789101112131415161718192021222324# 可能缺少的公共命令sudo apt-get install software-properties-common -y# 证书sudo curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 仓库信息sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;# 更新 cachesudo apt-get update# 可用版本查询sudo apt-cache policy docker-cesudo apt-cache madison docker# 安装 docker 19.03.15~3-0~ubuntu-xenialsudo apt-get install docker-ce=5:19.03.15~3-0~ubuntu-xenial -ysudo docker version# 不需要 sudo， 重新登录sudo usermod -aG docker $USERsudo systemctl restart docker 1.5 Python 多版本1234567891011121314151617181920212223242526# 增加 deadsnakes PPA 源sudo add-apt-repository ppa:deadsnakes/ppa# 安装 python 3.9sudo apt-get updatesudo apt-get install python3.9# python 默认版本切换成 3.9sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2sudo update-alternatives --config python3There are 2 choices for the alternative python3 (providing /usr/bin/python3). Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/python3.8 2 auto mode 1 /usr/bin/python3.8 2 manual mode 2 /usr/bin/python3.9 1 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 2sudo apt install python3-pip python3.9-venvpython3 -m venv /home/ubuntu/python/venv 1.6 防火墙123sudo ufw allow sshsudo ufw allow 6379/tcp 1.7 阿里源ubuntu16: 12345678910111213141516171819202122232425262728sudo -iecho &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.confmv /etc/apt/sources.list /etc/apt/sources.list.bakcat &gt; /etc/apt/sources.list &lt;&lt;EOF# deb cdrom:[Ubuntu 16.04 LTS _Xenial Xerus_ - Release amd64 (20160420.1)]/ xenial main restricteddeb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-propertiesdeb http://archive.canonical.com/ubuntu xenial partnerdeb-src http://archive.canonical.com/ubuntu xenial partnerdeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverseEOFapt-get update ubuntu20: 1234567891011121314151617181920mv /etc/apt/sources.list /etc/apt/sources.list.bakcat &gt; /etc/apt/sources.list &lt;&lt;EOFdeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverseEOFapt update 1.8 时区1234567891011121314151617ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# alternativetimedatectl set-timezone &quot;Asia/Shanghai&quot;timedatectl status# alternative 2vi /etc/profileTZ=&#x27;Asia/Shanghai&#x27;export TZ# 时间更新date -s &quot;2019-06-04 11:06:30&quot; # 修改为一个正确的时间hwclock -wcrontab -e* */1 * * * ntpdate 0.asia.pool.ntp.org 1.9 k8s1234567891011apt-get update &amp;&amp; apt-get install -y apt-transport-httpscurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - # ubuntu16cat &gt;/etc/apt/sources.list.d/kubernetes.list &lt;&lt;EOFdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOFapt-get updateapt-get install -y kubelet kubeadm kubectl 2. CentOS2.1 寻找命令所在包1yum whatprovides */lspci 2.2 获取磁盘的 uuid1234blkid/dev/sr0: UUID=&quot;2020-04-22-00-51-40-00&quot; LABEL=&quot;CentOS 7 x86_64&quot; TYPE=&quot;iso9660&quot; PTTYPE=&quot;dos&quot; /dev/sda1: UUID=&quot;8447e521-4bb8-4fb7-853e-cd6661dd98b4&quot; TYPE=&quot;xfs&quot; 2.3. 换yum源123456mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -Oyum makecache 2.4 防火墙12345iptables -A INPUT -p tcp -s 0/0 --dport 80 -j ACCEPT iptables -A OUTPUT -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT service iptables save 3. 公共部分3.1 进程 &amp; 线程1234567891011121314# 线程top -H # 需要ncurses， 更友好htop# 进程的关联子进程ps -T -p 959 PID SPID TTY TIME CMD 959 959 ? 00:00:27 redis-server 959 960 ? 00:00:00 redis-server 959 961 ? 00:00:00 redis-server 959 962 ? 00:00:00 redis-server 3.2 路由1234567891011# 删除默认设置route delete 0.0.0.0# 外网路由，全走无线route add 0.0.0.0 mask 0.0.0.0 192.168.33.1 –p# 公司内网全部在10.40.*.*网段route add 10.40.0.0 mask 255.255.0.0 10.40.254.1 -p# 路由追踪tracert -d google.com 3.3 tcpdump12345678tcpdump -i ens33 port 8080 -w http.captcpdump src port 1025tcpdump portrange 21-23tcpdump -vvAls0 | grep &#x27;User-Agent:&#x27;tcpdump -vvAls0 | grep &#x27;Set-Cookie|Host:|Cookie:&#x27; 3.4 支持密码登录1234vi /etc/ssh/sshd_configPasswordAuthentication no =&gt; yessystemctl restart sshd 3.5 远程端口检查3.5.1 telnet1telnet baidu.com 80 3.5.2 nc (NetCat)1nc -v baidu.com 80 3.5.3 nmap1nmap baidu.com -p 80 3.6 sudo3.6.1 语法条目1who host=(runas) TAG:command 3.6.2. 配置123456789visudooracle ALL=(root) NOPASSWD:/sbin/useradd, PASSWD:/sbin/userdel%admin ALL=(root) NOPASSWD:/sbin/shutdownweb ALL=(operator) /etc/webhook/mytest.shtest ALL=(ALL) /bin/cat /var/log/secure*, !/bin/cat /var/log/secure* * 3.6.3. 执行sudo12345su - oraclesudo /sbin/useradd test123su - websudo -u operator /etc/webhook/mytest.sh 4. 软件4.1 Redis1234wget http://download.redis.io/releases/redis-5.0.12.tar.gz tar zxvf redis-5.0.12.tar.gz cd redis-5.0.12make 4.2 k8s12345678910111213cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFsetenforce 0yum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Nginx配置","slug":"Nginx","date":"2019-04-25T01:15:17.000Z","updated":"2021-06-22T10:50:49.734Z","comments":true,"path":"2019/04/25/Nginx/","link":"","permalink":"https://elihe2011.github.io/2019/04/25/Nginx/","excerpt":"1. 重定向1.1 proxy_pass302跳转，不能传递原来请求的header 12345678910111213server &#123; listen 80; server_name a.example.com; listen 443 ssl; location = /xx &#123; proxy_pass http://b.example.com/xx; proxy_set_header Host b.example.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; break; &#125;&#125;","text":"1. 重定向1.1 proxy_pass302跳转，不能传递原来请求的header 12345678910111213server &#123; listen 80; server_name a.example.com; listen 443 ssl; location = /xx &#123; proxy_pass http://b.example.com/xx; proxy_set_header Host b.example.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; break; &#125;&#125; 1.2 rewrite12345server &#123; listen 80; server_name test1.com; rewrite ^(.*) https://www.test1.com$1 permanent;&#125; 2. 负载均衡 upstream123456789101112131415upstream balanceServer &#123; ip_hash; server 192.168.1.10:8080 weight 2; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125;server &#123; server_name test.com; listen 80; location /api &#123; proxy_pass http://balanceServer; &#125;&#125; weight：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。与ip_hash不兼容 负载均衡策略： 轮询（默认） 缺点：如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。 12345upstream balanceServer &#123; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 最小连接数策略 将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求 123456upstream balanceServer &#123; least_conn; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 最快响应时间策略 依赖于 NGINX Plus，优先分配给响应时间最短的服务器。 123456upstream balanceServer &#123; fair; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; session共享 每个访问安访问ip的hash结果分配，可确保每个访客孤独访问一个后端服务器，可解决session保持问题。 123456upstream balanceServer &#123; ip_hash; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 3. Nginx内置全局变量 变量名 功能 $host 请求信息中的Host，没有则设置成服务器名 $request_method GET, POST $args $content_length $http_user_agent $http_cookie $remote_addr $remote_port $server_protocol HTTP/1.0 HTTP/1.1 $server_addr $server_port $server_name 4. 请求过滤4.1 按状态码过滤123456789101112server &#123; listen 80; server_name test.com; access_log /var/log/nginx/nginx-access.log main; error_log /var/log/nginx/nginx-error.log; error_page 404 = /404; error_page 403 = /403; error_page 500 501 502 503 504 506 /50x.html; location /50x.html &#123; root /data/www/static/html; &#125; 4.2 按URL过滤12345server &#123; #... rewrite ^.*$ /index.html;&#125; 4.3 按请求类型过滤12345server &#123; if ( $request_method !~ ^(GET|POST|HEAD)$ ) &#123; return 403; &#125;&#125; 5. 配置gzip1234567http &#123; gzip on; gzip_http_version 1.1; gzip_comp_level 5; gzip_min_length 1000; gzip_types text/csv text/xml text/css text/plain text/javascript application/javascript application/x-javascript application/json application/xml;&#125; 6. Nginx配置文件结构123456789101112131415161718192021222324252627events &#123; &#125;http &#123; upstream node &#123; &#125; server &#123; location path &#123; ... &#125; location path &#123; ... &#125; &#125; server &#123; ... &#125;&#125; 7. 静态资源配置123456location ~* \\.(png|gif|jpg|jpeg)$ &#123; root /root/static/; autoindex on; access_log off; expires 24h; # 过期时间为24小时 &#125; 8. 静态资源缓存1234567891011121314151617location /hhhh/ &#123; root /data/www/lp-web/; index index.html; try_files $uri index.html; if ($request_filename ~* .*\\.(?:htm|html)$) &#123; add_header Cache-Control &quot;private, no-store, no-cache, must-revalidate, proxy-revalidate&quot;; &#125; if ($request_filename ~* .*\\.(?:js|css)$) &#123; expires 7d; &#125; if ($request_filename ~* .*\\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm)$) &#123; expires 7d; &#125;&#125; 9. nginx日志request_time 和upstream_response_time区别 request_time: request processing time in seconds with a milliseconds resolution; time elapsed between the first bytes were read from the client and the log write after the last bytes were sent to the client. 指的就是从接受用户请求的第一个字节到发送完响应数据的时间，即包括接收请求数据时间、程序响应时间、输出响应数据时间。 upstream_response_time: keeps times of responses obtained from upstream servers; times are kept in seconds with a milliseconds resolution. Several response times are separated by commas and colons like addresses in the $upstream_addr variable. 指从Nginx向后端建立连接开始到接受完数据然后关闭连接为止的时间。 从上面的描述可以看出，$request_time肯定比$upstream_response_time值大，特别是使用POST方式传递参数时，因为Nginx会把request body缓存住，接受完毕后才会把数据一起发给后端。所以如果用户网络较差，或者传递数据较大时，$request_time会比$upstream_response_time大很多。 $request_time 包含了用户数据接收时间，而真正程序的响应时间应该用$upstream_response_time。 配置说明： 1234log_format timed_combined &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27; &#x27;$request_time $upstream_response_time&#x27;;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://elihe2011.github.io/categories/Nginx/"}],"tags":[]},{"title":"select、poll和epoll","slug":"IO多路复用和异步","date":"2019-04-12T03:22:17.000Z","updated":"2021-06-22T10:50:49.733Z","comments":true,"path":"2019/04/12/IO多路复用和异步/","link":"","permalink":"https://elihe2011.github.io/2019/04/12/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%BC%82%E6%AD%A5/","excerpt":"1. selectselect最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 1234567while true &#123; select(streams[]) for i in streams[] &#123; if i has data read until unavailable &#125;&#125;","text":"1. selectselect最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 1234567while true &#123; select(streams[]) for i in streams[] &#123; if i has data read until unavailable &#125;&#125; select的优点是支持目前几乎所有的平台，缺点主要有如下2个： 1）单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024(32位，64位默认2048，proc/sys/fs/file-max)，不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制。 2）select 所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长。同时，由于网络响应时间的延迟使得大量TCP连接处于非活跃状态，但调用select()会对所有socket进行一次线性扫描，所以这也浪费了一定的开销。 2. pollpoll则在1986年诞生于System V Release 3，它和select在本质上没有多大差别，但是poll没有最大文件描述符数量的限制。 3. epoll epoll是Linux 2.6 开始出现的为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 123456while true &#123; active_stream[] = epoll_wait(epollfd) for i in active_stream[] &#123; read or write till &#125;&#125; 1.3 epollepoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 epoll的优点： 1、没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数； 即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 3、 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 1.4 select、poll、epoll 区别总结1、支持一个进程所能打开的最大连接数 类型 特点 select 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 poll poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 epoll 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 2、FD剧增后带来的IO效率问题 类型 特点 select 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 poll 同上 epoll 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 3、 消息传递方式| 类型 | 特点 || —— | ———————————————————— || select | 内核需要将消息传递到用户空间，都需要内核拷贝动作 || poll | 同上 || epoll | epoll通过内核和用户空间共享一块内存来实现的。 | 总结： 综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。 1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 2. 异步与非阻塞的区别非阻塞是对于socket而言；异步是相对于应用程序而言，是一种编程模型 Epoll是非阻塞的，但不是异步。实现阻塞和简单，socket.setblocking(False)即可；实现异步很复杂。 Linux没有实现异步IO(效率并不高)，Epoll是一种I/O多路复用技术，用户程序需要主动去询问内核是否有事件发生，而不是事件发生时内核主动去调用回调函数，所以不是异步的。 Tornado框架之所以是异步的，它在epoll的基础上进行了一层封装，由框架去取事件，然后由框架去调用用户的回调函数，所以对于基于该框架的用户程序来说，是异步的。 Tornado使用Epoll实现了异步编程模型，使用异步的前提是socket是非阻塞的。 3. Python selectPython的select()方法直接调用操作系统的IO接口，它监控sockets,open files, and pipes(所有带fileno()方法的文件句柄)何时变成readable 和writeable, 或者通信错误，select()使得同时监控多个连接变的简单，并且这比写一个长循环来等待和监控多客户端连接要高效，因为select直接通过操作系统提供的C的网络接口进行操作，而不是通过Python的解释器。 select()方法接收并监控3个通信列表， 第一个是所有的输入的data,就是指外部发过来的数据，第2个是监控和接收所有要发出去的data(outgoing data),第3个监控错误信息，接下来我们需要创建2个列表来包含输入和输出信息来传给select(). select_echo_server.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import selectimport socketimport sysfrom queue import Queue, Emptyserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server.setblocking(False)server_address = (&#x27;localhost&#x27;, 5000)print(&#x27;starting up on %s port %s&#x27; % server_address, file=sys.stderr)server.bind(server_address)server.listen(5)# reading socketsinputs = [server, ]# writing socketsoutputs = []message_queues = &#123;&#125;while inputs: print(&#x27;\\nwaiting for the next event.&#x27;) readable, writable, exceptional = select.select(inputs, outputs, inputs) for s in readable: if s is server: # A readable server socket is ready to accept a connection connection, client_address = s.accept() print(&#x27;new connection from&#x27;, client_address) connection.setblocking(False) inputs.append(connection) # Give the connection a queue for data we want to send message_queues[connection] = Queue() else: data = s.recv(1024) if data: # A readable client socket has data print(&#x27;received &quot;%s&quot; from %s&#x27; % (data, s.getpeername())) message_queues[s].put(data) # Add output channel for response if s not in outputs: outputs.append(s) else: # Interpret empty result as closed connection print(&#x27;closing&#x27;, client_address, &#x27;after reading not data.&#x27;) # Stop listening for input on the connection if s in outputs: outputs.remove(s) inputs.remove(s) s.close() # Remove message queue del message_queues[s] for s in writable: try: next_msg = message_queues[s].get_nowait() except Empty: # No message waiting so stop checking for writability print(&#x27;output queue for&#x27;, s.getpeername(), &#x27;is empty&#x27;) outputs.remove(s) else: print(&#x27;sending &quot;%s&quot; to %s&#x27; % (next_msg, s.getpeername())) reply = &#x27;replied: &#x27; + next_msg.decode(&#x27;utf-8&#x27;) s.send(reply.encode(&#x27;utf-8&#x27;)) for s in exceptional: print(&#x27;handling exceptional condition for&#x27;, s.getpeername()) inputs.remove(s) if s in outputs: outputs.remove(s) s.close() del message_queues[s] select_echo_multiclient.py 12345678910111213141516171819202122232425import socketimport sysserver_address = (&#x27;localhost&#x27;, 5000)messages = [&#x27;message %s&#x27; % i for i in range(10)]socks = [socket.socket(socket.AF_INET, socket.SOCK_STREAM) for _ in range(3)]print(&#x27;connecting to %s port %s&#x27; % server_address, file=sys.stderr)for s in socks: s.connect(server_address)for message in messages: # send messages on both sockets for s in socks: print(&#x27;%s: sending &quot;%s&quot;&#x27; % (s.getsockname(), message), file=sys.stderr) s.send(message.encode(&#x27;utf-8&#x27;)) # read response on both sockets for s in socks: data = s.recv(1024) print(&#x27;%s: received &quot;%s&quot;&#x27; % (s.getsockname(), data), file=sys.stderr) if not data: print(&#x27;closing socket&#x27;, s.getsockname(), file=sys.stderr) s.close()","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Redis","slug":"Redis","date":"2019-01-29T03:12:17.000Z","updated":"2021-10-15T08:00:32.311Z","comments":true,"path":"2019/01/29/Redis/","link":"","permalink":"https://elihe2011.github.io/2019/01/29/Redis/","excerpt":"1. 概述Redis：Remote Dictionary Server，高性能非关系型(NoSQL)键值对数据库 Redis特性： key-value 存储 支持数据可靠性存储及落地 单进程但线程高性能服务器 crash safe &amp; recovery slow 单机qps可达10W 适合小数据量高速读写访问","text":"1. 概述Redis：Remote Dictionary Server，高性能非关系型(NoSQL)键值对数据库 Redis特性： key-value 存储 支持数据可靠性存储及落地 单进程但线程高性能服务器 crash safe &amp; recovery slow 单机qps可达10W 适合小数据量高速读写访问 1.1 应用场景 高速缓存 高频次，热门数据，降低数据库IO 分布式，做session共享 多样化数据结构 最新N个数据：通过List实现按时间排序的数据 排行榜，top N：zset有序集合 时效性数据，验证码：Expire过期 计算器，秒杀：原子性，INCR， DECR 大数据量去重：set集合 队列：list 发布订阅：pub/sub 1.2 安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# 1. 编译工具apt install -y build-essential pkg-config libssl-dev# 2. 下载wget https://download.redis.io/releases/redis-6.2.5.tar.gztar zxvf redis-6.2.5.tar.gz# 3. 编译cd redis-6.2.5make MALLOC=libc BUILD_TLS=yes# 4. 创建redis系统用户adduser --system --group --no-create-home redis# 5. 拷贝编译后的命令cd srccp redis-server redis-cli redis-benchmark redis-check-aof redis-check-rdb /usr/local/bin/# 6. 创建数据目录mkdir /var/lib/redischown -R redis:redis /var/lib/redischmod 770 /var/lib/redis# 7. 创建日志目录mkdir /var/log/redischown -R redis:redis /var/log/redis# 8. 运行PID目录mkdir /var/run/redischown -R redis:redis /var/run/redis# 9. 配置文件mkdir -p /etc/rediscp ../redis.conf /etc/redisvi /etc/redis/redis.confbind 0.0.0.0 ::daemonize yessupervised systemdpidfile /var/run/redis_6379.pidlogfile &quot;/var/log/redis/redis.log&quot;dir /var/lib/redis/# 10. 开机启动cat &gt; /etc/systemd/system/redis.service &lt;&lt;EOF[Unit]Description=Redis data structure serverDocumentation=https://redis.io/documentation[Service]Type=forkingExecStart=/usr/local/bin/redis-server /etc/redis/redis.confExecStop=/usr/local/bin/redis-cli shutdownExecReload=/bin/kill -s HUP \\$MAINPIDPrivateTmp=trueRestartSec=10User=redisGroup=redisLimitCORE=infinityLimitNOFILE=10032LimitNPROC=10032Restart=always[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl start redissystemctl status redissystemctl enable redis 1.3 相关知识Redis: 单线程 + 多路 IO 复用 多路复用：使用一个线程来检查多个文件描述符 (socket) 的就绪状态，比如调用select 和pol函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后，进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如线程池） 1.4 管理命令12345678910111213keys *exists KEYtype KEYdel KEYunlink KEY # 非阻塞删除expire KEY 10 # 10s后过期ttl KEY # 过期剩余时间 -1：永不过期 -2: 已过期 dbsize # key总数量flushdb # 清空当前库flushall # 清空所有库 Redis-benchmark: 服务器性能测试 12# 100个并发，100000次redis-benchmark -h localhost -p 6379 -c 100 -n 100000 1.5 优缺点优点： 读写性能高 支持持久化，RDB &amp; AOF 数据类型丰富，五种：string, list, set, sorted-set, hash 支持简单事务 支持TTL 支持主从复制，可以进行读写分离 缺点： 数据库容量受限物理内存（低于物理内存的60%），不能支持海量数据的高性能读写。 不具备自动容错和恢复功能 主节点宕机，可能会有部分数据未及时同步到从节点，导致数据不一致 很难在线扩容，一般在系统上线前必须保有足够的空间 buffer io造成系统OOM 2. 数据类型2.1 基础类型 string: 字符串操作、原子计数器等 hash: 以hashmap方式存储，可用来存储json对象。 list: 消息队列，timeline等 set：Unique去重操作。统计独立IP，好友推荐去重等 sorted-set: 排行榜，TOP N操作，带权重 跳表：一种随机化的数据结构，实质就是一种可以进行二分查找的有序链表。Redis中的set类型低层使用跳表实现。 2.1.1 String数据结构：简单动态字符串 (Simple Dynamic String, SDS)，是可以修改的，内部结构类似Golang的Slice，采用预先分配冗余空间方式来减少内存的频繁分配。扩容机制，长度小于1M，按两倍扩容；超过1M，扩容一次只新增1M。最大512M 123456789101112131415161718get KEYset KEY VALUEsetex KEY 10 VALUEappend KEY VALUEstrlen KEYsetnx KEY VALUE # 不存在才设置# 原子性操作incr KEYdecr KEYincrby KEY 5decrby KEY 3mset k1 v1 k2 v2 ...mget k1 k2 ... 2.1.2 List数据结构：快速链表 quickList. 在元素较少的情况下，使用一块连续的内存存储，结构为ziplist，即压缩列表。 数据量较大时。会改成quickList，即链表存储，结构上有二外的指针prev 和 next Redis 将链表和ziplist 集合起来组成quicklist，即满了快速插入删除性能，又不会出现太大的冗余空间。 1234567891011121314151617181920lpush KEY e1 e2 ...rpush KEY e1 e2 ...lpop KEYrpop KEYrpoplpush KEY1 KEY2 # KEY1列表右吐出一个附加到KEY左边lrange KEY 0 -1lindex KEY 2llen KEYlinsert KEY before pivot elementlinsert KEY after pivot elementlrem KEY count element # 从左边删除count个elment元素lset KEY index element # 替换 2.1.3 Set数据结构：string类型的无序集合，底层其实是一个value为null的hash表，所以添加、删除和查找的时间复杂度都是o(1) 12345678910111213141516sadd KEY member...smembers KEYsismember KEY memberscard KEY # srem KEY member...spop KEY # 随机取出一个值srandmember KEY count # 随机取出多个值，注意：不删除smove source destination member # 将source中的member移动到destinationsinter k1 k2 # 交集sunion k1 k2 # 并集sdiff k1 k2 # 差集 2.1.4 Hash数据结构：ziplist(压缩列表)，hashtable(哈希表)。当field-value长度短且个数少时，使用ziplist，否则使用hashtable 123456789101112hset k f1 v1 f2 v2 # hmset 效果一样hget k f1hmget k f1 f2 f3hexists k f1hkeys kkvals khincrby k age 5hsetnx k addr LA # 不存在时才添加 2.1.5 ZSet数据结构：hashtable + skiplist hash：关联member和score，保证member的唯一性，可直接通过member找到相应的score值 跳跃表：根据score值，为member排序 1234567891011121314zadd k 100 java 200 cpp 300 golang 400 python 500 phpzrange k 0 -1 # 按score从小到大排序zrangebyscore k 200 400zrevrangebyscore k 200 400zincrby k 200 golangzrem k php cppzcount k 100 300zrank k golang # 排名 2.1.6 数据结构 2.1.6.1 hashTable哈希表：由数组 + 链表构成的二维数据结构，数组是第一维，链表是第二维。数组中的每个元素称为槽或者桶，存储着链表的第一个元素的指针。 整体结构图： 一维数组： 二维链表： 扩容和缩容： 扩容：元素个数等于一维数组长度时，会对数组进行两倍扩容 缩容：元素个数小于一维数组的10% 扩缩容时，需要重新申请一维数组，并对所有元素重新hash并挂载到元素链表。Redis采用rehash策略：所有的字典结构内部首层时一个数组，数组的两个元素分别指向一个hashtable，正常情况下只有一个hashtable，而在迁移过程中，保留新旧两个hashtable，元素可能会在两个表中任意一个中，因此同时尝试从两个hashtable中查找数据。当数据搬迁完毕，旧的hashtable会被自动删除。 哈希函数：将key值打散的越均匀越好，高随机性的元素分布能够提升整体的查找效率。Redis的hash函数为siphash。hash函数打散效率如果很差或有迹可循，就会存在hash攻击，攻击者利用模式偏向性产生大量数据，并将这些数据挂载在同一个链表上，这种不均匀会导致查找性能急剧下降，同时浪费大量内存空间，导致Redis性能低下 2.1.6.2 跳跃表 根据score值插入紫色kv节点，首先从 kv-head 的最高层启动，判断指针的下一个元素的score值是否小于新元素的score，小于则继续向前遍历，否则从kv-head降一层，重新比较 寻找51： 从第2层开始，1节点比51小，向后比较、 21节点比51小，继续向后，但后面是NULL，则从21节点下降到第1层 41节点比51小，继续向后，61节点比51大，则从41节点下降到第0层 51节点即为所要查找的节点，共查找了四次 2.2 发布订阅123456# 1. 订阅subscribe mychannel# 2. 发布消息publish mychannel hellopublish mychannel world 2.3 新类型2.3.1 BitmapsBitmaps本身不是数据类型，实际它就是字符串，但可可以对字符串的位进行操作 注意：初始化bitmaps时，如果offset过大，整个初始化过程会较慢，可能会造成redis的阻塞 12345678910111213141516171819202122232425262728293031setbit permission 2 1setbit permission 5 1getbit permission 5bitcount permissionbitcount permission 0 -2setbit k1 2 1setbit k1 3 1setbit k1 4 1setbit k1 5 1setbit k2 0 1setbit k2 1 1setbit k2 2 1setbit k2 3 1bitop and k3 k1 k2bitcount k3 # 2bitop xor k4 k1 k2bitcount k4 # 4bitop or k5 k1 k2bitcount k5 # 6bitop not k6 k1getbit k6 1 # 1getbit k6 2 # 0 2.3.2 HyperLogLog (基数统计)网站统计PV(PageView): 可使用 incr, incrby实现 但独立访客UV(UniqueVistor)、独立IP、搜索记录数等需要去重和计数的问题。 HyperLogLog 用来做基数统计，其优点是，在输入元素的数量或者体积非常大时，计算基数需要的空间是固定的，并且很小。 每个 HyperLogLog 键只需要花费 12KB内存，就可以计算接近 2^64个不同元素的基数。 HyperLogLog 只会根据输入的元素来计算基数，但不会存储输入元素，所以它不能像集合一样，返回输入的各个元素。 12345678910111213141516pfadd lang1 javapfadd lang1 phppfadd lang1 golangpfadd lang1 pythonpfadd lang1 golangpfadd lang1 phppfadd lang1 c++pfcount lang1 # 5pfadd lang2 swiftpfadd lang2 jspfadd lang2 dartpfmerge lang lang1 lang2pfcount lang # 8 2.3.3 GeospatialGeospatial 是一个2维坐标，即经纬度。 123456789geoadd cities 121.47 31.23 Shanghaigeoadd cities 106.50 29.53 Chongqinggeoadd cities 114.05 22.52 Shenzhengeopos cities Shanghaigeodist cities Shanghai Chongqing kmgeoradius cities 110 30 1000 km 3. 事务和锁3.1 事务Redis事务：是一个单独的隔离操作。事务中所有命令都会序列化，按顺序执行；在执行过程中，不会被其他客户端发送的命令请求打断。 作用：串行执行多个命令，防止其他命令插队 Redis事务特性： 单独的隔离操作，一次性、顺序性、排他性的执行一个队列中的一系列命令 没有隔离级别 不保证原子性 相关命令： Multi: 组队阶段 Exec：执行阶段 Discard: 放弃执行 Queued失败，无法执行： 12345&gt; MULTI&gt; set k1 v1&gt; set k2 v2&gt; getset k3 v3 # 语法性错&gt; EXEC # 上述命令不会被执行 Queued成功，正常执行，跳过失败命令： 123456&gt; MULTI&gt; set k1 v1&gt; set k2 v2&gt; incr k3 # 运行时异常&gt; set k4 v4&gt; EXEC # 上述命令被执行，执行incr时抛出错误，但不影响其他命令 3.2 锁 悲观锁：每次操作，都上锁，别人不能操作，等我释放锁后，才能操作。MySQL中的行锁、表锁；读锁、写锁即为该类锁。 乐观锁：使用版本机制，在操作前，所有人均能获得当前的版本，在提交操作时，比对用户用户操作的版本是否和当前系统中的版本一致，只有在一致的情况下，操作才能成功，并生成新的版本号。乐观锁适用于多读的的应用类型，这样可提高吞吐量。 Redis使用乐观锁，CAS: check-and-set 机制实现事务。 1234567891011&gt; set balance 10000# session 1&gt; WATCH balance&gt; MULTI&gt; decrby balance 2000&gt; EXEC # 事务失败&gt; UNWATCH# session 2&gt; decrby blanace 5000 # 在 session 1的 WATCH后，EXEC前操作 3.3 LuaRedis 的乐观锁，在多写的情况下，复杂的事务操作提交失败，导致与预想不一致的情况发生 Lua脚本，很容易被 C/C++调用，也可反过来调用C/C++函数。解释器不超过200k，适合做嵌入式脚本语言。 在Redis中，可将复杂、多步调用操作，写为一个Lua脚本，一次提交给Redis执行，减少连接Redis的次数，提升性能。 123456789101112131415161718local uid=KEYS[1];local pid=KEYS[2];local stock=&quot;sk:&quot;..pid..&quot;:stock&quot;;local users=&quot;sk:&quot;..pid..&quot;:users&quot;;local grabbed=redis.call(&quot;ismember&quot;, users, uid);if tonumber(grabbed) == then return 2;endlocal num=redis.call(&quot;get&quot;, stock)if tonumber(num) &lt;= 0 then return 0;else redis.call(&quot;decr&quot;, stock); redis.call(&quot;sadd&quot;, users, uid); return 1;end 相关命令： EVAL EVALSHA SCRIPT LOAD - SCRIPT EXISTS SCRIPT FLUSH SCRIPT KILL 1234EVAL script numkeys key [key …] arg [arg …]EVAL &quot;return KEYS[1]&quot; 1 key1 # key：从eval的第三个参数开始算起EVAL &quot;return ARGV[1]&quot; 0 value1 # 附加参数 4. 持久化4.1 RDB (Redis Database) 将数据以快照(snapshot)形式保存在磁盘上 (dump.db) 触发数据快照的三种机制： save: 手动持久化，将阻塞服务器，save期间，不能处理其他命令，直到持久化完毕 bgsave: 后台异步进行快照操作。它会fork一个子进程负责处理 自动触发： 123456789save 3600 1 # 1h内，至少有一个key变化，触发持久化save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.dbdir /data/redis/db 快照保存过程： redis调用fork，产生一个子进程 父进程继续处理client请求，子进程负责将fork时刻整个内存数据库快照写入临时文件。 子进程完成写入临时文件后，用临时文件替换原来的快照文件，然后子进程退出。 ​ 问题：每次快照持久化都是将内存数据完整写入到磁盘，如果数据量较大，读写操作较多，必然会引起磁盘IO问题。 优势: RDB文件紧凑，全量备份，适合用于进行备份和灾难恢复 生成RDB时，Redis主进程fork一个子进程来处理保存工作，主进程不需要进行任何磁盘IO操作 RDB恢复比AOF快 劣势：RDB数据保存子进程可能来不及保存数据，导致数据丢失 4.2 AOF (append only file) 以日志形式记录每个写操作(增量保存)，追加写，不修改原有记录 aof的问题：aof文件会越来越大。可通过bgrewriteaof命令，将内存中的数据以命令方式保存到临时文件，同时fork一个子进程来重写aof文件，最后替换原来的文件。 AOF和RDB同时开启，系统默认取AOF的数据 1234567891011appendonly yesappendfilename &quot;appendonly.aof&quot;# 三选一appendsync alwaysappendsync everysecappendsync no # 完全依赖操作系统，性能最好，但持久化可能丢数据# 自动bgrewriteaofauto-aof-rewrite-percentage 100 # 大于64M到100%，即超过128M时开始重写auto-aof-rewrite-size 64mb 优势： 数据不容易丢失 日志文件过大时，会出现后台重写，不会影响客户端读写 日志文件以命令可读方式记录，容易查找命令记录来恢复数据 劣势： AOF日志文件比RDB文件大 AOF开启后，写的QPS会降低 重写压缩： AOF文件持续增长过大时，会fork一个新的进程来重新日志文件。Redis4.0后的重写，就是把rdb快照，以二进制附加在新的aof头部，替换已有的历史数据。 4.3 方案选择Snapchat性能更高，但可能会引起一定程度的数据丢失 建议： 更新频繁，一致性要求较高，AOF策略为主 更新不频繁，可以容忍少量数据丢失或错误，Snapshot为主 5. 分布式锁1234setnx lock 1del lockSET lock 1 NX 30 EX # 上锁 + 设置过期时间 锁释放问题：别人可以去释放你加的锁，你也亦然。 解决方案： UUID：锁的值设置为uuid，只在获取到的锁的值等于你设置的uid时，才允许释放锁 Lua脚本： 12345if redis.call(&quot;get&quot;, KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;, KEYS[1]);else return 0;end 6. 过期策略6.1 过期键删除策略 定时过期：过期立即删除。对内存友好，但会占用大量CPU资源去处理过期的键，影响缓存的响应时间和吞吐量 惰性过期：只有当访问一个key时，才会判断它是否过期，过期则清除。对内存不友好，无用key占用了大量内存。 定期过期：每隔一定时间，扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。 Redis 同时使用 惰性过期 和 定期过期 两种策略。 6.2 设置和取消过期EXPIRE PERSIST 6.3 过期机制12345678910redis-cli&gt; flushdb&gt; keys *&gt; exists name&gt; set name tom&gt; ttl name # -1, 永不过期&gt; expire name 5 # 5s后过期&gt; set age 20&gt; expireat age 1555506769 过期机制：redis采用 Lazy Expriation 方式，即在访问key时判断是否过期，如果过期，则进行过期处理。其次，每秒对volation keys进行抽样测试，如果有过期键，那对所有过期key处理。 7. 内存淘汰策略MySQL中2000w数据，redis中只存20w数据，如何保证redis中的数据都是热数据？ 全局键空间选择性移除： noeviction：内存不足，写入新数据，报错 allkeys-lru：内存不足，写入新数据，将移除最近最少使用的key （最常用） allkeys-random: 内存不足，写入新数据，将随机删除一个key 带TTL的键空间选择性移除： volatile-lru：内存不足，写入新数据，在设置了过期时间的键空间中，移除最近最少使用的key volatile-random：内存不足，写入新数据，在设置了过期时间的键空间中，随机移除一个key volatile-ttl：内存不足，写入新数据，在设置了过期时间的键空间中，移除更早过期的key 8. 集群方案8.1 主从模式主从同步特点: 一个master可拥有多个slave master可读写，并将变化的数据sync给slave slave只读，接收master的sync数据 缺点：master只有一个，如果挂掉，无法对外提供写服务 配置 salve: 12replicaof 192.168.1.200 6379masterauth &lt;master-password&gt; 1234redis-cli&gt; info&gt; monitor&gt; info replication # 查看集群状态 8.2 Sentinel 模式 哨兵模式建立在主从模式之上 当master挂掉，sentinel会在salve中选择一个作为master，并修改它们的配置文件，其他slave节点的配置文件也会同步修改 当master恢复后，它将不再是master，而是做为slave接收新master同步数据 多sentinel配置时，形成一个sentinel小集群，sentinel之间也会自动监控 配置： 123sentinel monitor mymaster 192.168.1.200 6379sentinel auth-pass mymaster 123456sentinel down-after-milliseconds mymaster 30000 # 默认30s 启动： 1/usr/local/bin/redis-sentinel /usr/local/reids/sentinel.conf 8.3 Cluster模式 多个主从模式节点网络互联，数据共享 客户端可连接任意一个master节点进行读写 不支持同时处理多个key (MSET/MGET), 因为redis需要把key均匀分布在各个节点上，高并发下同时创建key-value会降低性能并导致不可预测行为 支持在线增加、删除节点 Redis 集群没有使用一致性hash，而是引入额哈希槽的概念。Redis集群有16384（2^14）个哈希槽，每个key通过CRC16校验后对16384取模来决定放置在哪个槽，集群的每个节点负责一部分hash槽。 数据库无法选择，都在0上 配置： 123cluster-enabled yescluster-config-file node_6379.confcluster-node-timeout 15000 集群命令： 123456789101112# 增加节点&gt; CLUSTER MEET 192.168.1.201 6380&gt; CLUSTER NODES# 更改节点身份, 节点改为slave&gt; CLUSTER REPLICATE a8fdc205a9f19cc1c7507a60c4f01b13d11d7fd0# 删除节点&gt; CLUSTER FORGET 40bd001563085fc35165329ea1ff5c5ecbdbbeef# 保存配置&gt; CLUSTER SAVECONFIG 9. 缓存异常9.1 雪崩 (大量key集中过期)场景：服务器重启或大量缓存同一时期失效时，大量的流量会冲击到数据库上，数据库会因承受不了而当机。即缓存层出现了错误，所有数据请求到达存储层，导则存储层无法响应 解决方案： 构建多级缓存架构：nginx缓存 + redis缓存 + 其他缓存 使用锁或队列：可保证问题不出现，但不适合高并发情况 设置过期标志更新缓存：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程去后台更新实际key的缓存 将缓存失效时间分散开：可通过随机数生成随机时间，这样保证key不在同一时间内过期。 9.2 穿透 (缓存空值)场景：用户查询某条数据，但redis中没有，即缓存未命中；继续向持久层数据库查询，还是没有，即本次查询失败。当大量查询失败时，导则持久层数据库压力过大，即为缓存穿透 解决方案： 缓存空值：即数据不存在，依旧设置一个默认值到缓存中，但该key的过期时间较短。简单应急方案 设置白名单：使用bitmaps定义一个可访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmaps中的id进行比较，如果id不存在，则不允许访问。每次访问都要查询，效率不高 布隆过滤器(Bloom Filter)：是一个二进制向量(位图)和一系列随机映射函数(哈希函数)。布隆过滤器科研检测一个元素是否在一个集合中，其优点是空间效率和查询时间远超过一般的算法，缺点是有一定的错误识别率和删除困难。实现：将所有可能存在的数据哈希到以恶搞足够大的bitmaps中，一个一定不存在的数据会被这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。 实时监控：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，设置黑名单限制访问。 9.3 击穿 (热门key过期)场景：某个key非常热点，高并发访问它时，该key突然失效，导则高并发请求直接访问持久数据库，就像在屏障上凿了一个洞 解决方案： 预先设置热门数据：在redis高峰访问前，把一些热门数据提前存入redis中，并加大这些热门数据key的过期时长 实时调整：现场监控哪些热门数据，实时调整可以的过期时长 使用互斥锁：缓存失效时，不立即查询数据库，先获取锁setnx mutex lock，成功后，查询数据库并设置缓存，删除mutex锁。缺点：访问效率会被降低 10. Redis优化10.1 内存管理1234567# HashMap成员数量，小于配置，按紧凑格式存储，内存开销少，任意一个超过，就使用真实的HashMap存储，内存占用大hash-max-zipmap-entries 64 # 成员数量少hash-max-zipmap-value 512 # 成员长度小# Listlist-max-ziplist-value 64list-max-ziplist-entries 512 10.2 持久化选择aof，每个实例不要超过2G 10.3 优化方向 进行master-slave主从同步配置，在出现服务故障时可切换 在master禁用数据持久化，在slave上配置数据持久化 Memory+swap不足。此时dump会挂死，最终会导致机器挡掉。64-128GB内存， SSD硬盘。 当使用的Memory超过60%，会使用swap，内存碎片大 当达到最大内存时，会清空带过期时间的key，即使该key未过期 redis和DB同步，先写DB，后写redis，内存写速度快 Redis使用建议： 1234567key: object-type:id:field length 10~20 value: string 不超过2K set, sortedset 元素个数不超过5000","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://elihe2011.github.io/categories/NoSQL/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://elihe2011.github.io/tags/redis/"}]},{"title":"Kubernetes Helm","slug":"Kubernetes Helm","date":"2018-07-09T12:34:25.000Z","updated":"2021-06-22T10:50:49.721Z","comments":true,"path":"2018/07/09/Kubernetes Helm/","link":"","permalink":"https://elihe2011.github.io/2018/07/09/Kubernetes%20Helm/","excerpt":"1. HelmHelm：让应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成的k8s资源清单文件 (deployment.yaml, service.yaml)，然后调用kubectl自动执行k8s资源部署。 Helm 包管理工具，是部署环境的流程封装 Helm 两个重要概念： chart: 创建一个应用的信息集合，包含各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元，即yum中的安装包 release: chart的运行实例。当chart被安装到kubernetes中，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个realease helm 包含两个组件：Helm 客户端 和 Tiller 服务器 Helm客户端: 负责chart和release的创建和管理、和Tiller的交互 Tiller服务器：运行在kubernetes集群节点中，处理Helm客户端请求，与API Server交互","text":"1. HelmHelm：让应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成的k8s资源清单文件 (deployment.yaml, service.yaml)，然后调用kubectl自动执行k8s资源部署。 Helm 包管理工具，是部署环境的流程封装 Helm 两个重要概念： chart: 创建一个应用的信息集合，包含各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元，即yum中的安装包 release: chart的运行实例。当chart被安装到kubernetes中，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个realease helm 包含两个组件：Helm 客户端 和 Tiller 服务器 Helm客户端: 负责chart和release的创建和管理、和Tiller的交互 Tiller服务器：运行在kubernetes集群节点中，处理Helm客户端请求，与API Server交互 1.1 Helm 部署安装包下载地址：https://github.com/helm/helm/releases 123wget https://get.helm.sh/helm-v2.16.10-linux-amd64.tar.gztar zxvf helm-v2.16.10-linux-amd64.tar.gzcp linux-amd64/helm /usr/local/bin 安装Tiller: k8s APIServer开启了RBAC访问控制，在创建Tiller需要使用service account: tiller，并分配合适的角色给它 1234567891011121314151617181920# tiller-rbac-config.yamlapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system ---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: tiller namespace: kube-system 1234567891011121314# 创建RBAC$ kubectl create -f tiller-rbac-config.yaml# 部署 tiller 服务器$ helm init --service-account tiller --skip-refresh# tiller 服务器，namespace 为 kube-system$ kubectl get pod -n kube-system | grep tillerNAME READY STATUS RESTARTS AGEtiller-deploy-6845b7d56c-2wk2x 1/1 Running 0 31s$ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.16.10&quot;, GitCommit:&quot;bceca24a91639f045f22ab0f41e47589a932cf5e&quot;, GitTreeState:&quot;clean&quot;&#125;Server: &amp;version.Version&#123;SemVer:&quot;v2.16.10&quot;, GitCommit:&quot;bceca24a91639f045f22ab0f41e47589a932cf5e&quot;, GitTreeState:&quot;clean&quot;&#125; 部署 helm v3.3: 1234567$ wget https://get.helm.sh/helm-v3.3.1-linux-amd64.tar.gz$ tar zxvf helm-v3.3.1-linux-amd64.tar.gz$ cp linux-amd64/helm /usr/local/bin/helm$ helm repo add stable https://kubernetes-charts.storage.googleapis.com/$ helm repo update 命令汇总： 命令 说明 helm search hub xxx 在Helm Hub上搜索Chart helm search repo repo_name 在本地配置的Repo中搜索Chart helm install release_name chart_reference chart一共有5种reference helm list 查看已部署的release helm status release_name 查看release信息 helm upgrade release_name chart_reference 修改chart信息后升级release helm history release_name 查看release的更新历史记录 helm rollback release_name revision 回滚操作 helm uninstall release_name 卸载release 1.2 Helm 自定义模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263$ mkdir helm-demo &amp;&amp; cd helm-demo# 创建自描述文件$ cat &gt; Chart.yaml &lt;&lt;EOFname: helloversion: 1.0.0EOF# 创建目标文件，用于生成 kubernetes 资源清单 manifests$ mkdir templates$ cat &gt; ./templates/deployment.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 3 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: hub.elihe.io/library/nginx:v1 ports: - containerPort: 80 protocol: TCPEOF# 创建 svc$ cat &gt; ./templates/service.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: hello-worldspec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP selector: app: hello-worldEOF# 安装#$ helm install . --name hello$ helm install hello . NAME: helloLAST DEPLOYED: Thu Oct 15 10:35:57 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None# 查询$ helm listNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONhello default 1 2020-10-15 10:35:57.015330177 +0800 CST deployed hello-1.0.1 通过动态配置项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 动态配置$ cat &gt; values.yaml &lt;&lt;EOFimage: repository: hub.elihe.io/test/nginx tag: v2EOF# 动态模板$ cat &gt; ./templates/deployment.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 1 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: &#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125; ports: - containerPort: 80 protocol: TCPEOF# 升级版本$ helm upgrade hello -f values.yaml .# 指定版本升级$ helm upgrade --set image.tag=&#x27;v3&#x27; hello . # 历史$ helm history helloREVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Thu Oct 15 10:35:57 2020 superseded hello-1.0.1 Install complete2 Thu Oct 15 10:40:11 2020 superseded hello-1.0.1 Upgrade complete3 Thu Oct 15 10:40:33 2020 deployed hello-1.0.1 Upgrade complete# 回滚$ helm rollback hello 2Rollback was a success.# 卸载$ helm uninstall --keep-history hello# 还原$ helm rollback hello 1# 彻底删除$ helm uninstall hello debug： 12# 配置检查和预生成配置清单$ helm install . --dry-run --debug --set image.tag=v2 2. 部署 Dashboard12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061$ mkdir dashboard &amp;&amp; cd dashboard$ helm repo update$ helm repo listNAME URL stable https://kubernetes-charts.storage.googleapis.comlocal http://127.0.0.1:8879/charts $ helm fetch stable/kubernetes-dashboard$ tar zxvf kubernetes-dashboard-1.11.1.tgz $ cd kubernetes-dashboard# 参数设置$ cat &gt; kubernetes-dashboard.yaml &lt;&lt;EOFimage: repository: k8s.gcr.io/kubernetes-dashboard-amd64 tag: v1.8.3ingress: enable: true hosts: - k8s.frognew.com annotations: nginx.ingress.kubernetes.io/ssl-redirect: true nginx.ingress.kubernetes.io/backend-protocol: HTTPS tls: - secretName: frognew-com-tls-secret hosts: - k8s.frognew.comrbac: clusterAdminRole: trueEOF# 安装$ helm install kubernetes-dashboard . \\--namespace kube-system \\-f kubernetes-dashboard.yaml # 容器已运行$ kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkubernetes-dashboard-7cfd66fc8b-8t79v 1/1 Running 0 37s# 查看访问$ kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard ClusterIP 10.98.142.181 &lt;none&gt; 443/TCP 66s# 改为NodePort访问$ kubectl edit svc kubernetes-dashboard -n kube-systemtype: NodePort$ kubectl get svc -n kube-systemkubernetes-dashboard NodePort 10.101.30.189 &lt;none&gt; 443:31667/TCP 3m11s# 获取令牌访问 token$ kubectl get secret -n kube-system | grep kubernetes-dashboard-tokenkubernetes-dashboard-token-bbt69 kubernetes.io/service-account-token 3 3m12s$ kubectl describe secret kubernetes-dashboard-token-bbt69 -n kube-systemtoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IlduNEdhTUJxOWtXbFhwdlhRSzhEMGFRemdJR0duQl9FNm9Rc2d0ekREQkEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi1iYnQ2OSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBlMTZlZjcyLWM5YjgtNDViMC05OTEzLThhNzY2NmY2ZDQzNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.4FxXZN-Gc6mpd50sl7Wrm_ZjO5T53LrMa30MYMAHubIxOSgIh5HBvpdq5SxgQg2-XGTWZy8yZvxdmC53XOl5zqq-7RMKKjTv-Qa3O_KcHRPpnAOjj9aXvRbGdSlc5Y4D2nkysRKjWca8NjSrTXOzNHMFK0CHEIqVP-GFrKUMWmZRGYiwIoaBBKgTaS-KM3vF2Be94U2f1-ybFloOsAgEijqhUWrxpBgvXYfAmWjH4tdjCgo_1YEFPYUuUS9hq_VifdvWma9ZQthKbWplik9nuG2g-9o_xS0en5rnbxJQFfoAl5iypEi6zJiKgFoGwJsl5ScLFhpDaYN3QNhOnHhJrA 部署Dashboard2.0: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# 卸载V1.8.3$ helm uninstall kubernetes-dashboard --namespace kube-system# 使用kubectl安装$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml# 安装$ kubectl apply -f recommended.yaml$ kubectl get pod -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-6b4884c9d5-8j778 1/1 Running 0 38skubernetes-dashboard-7d8574ffd9-wff2g 1/1 Running 0 38s$ kubectl get svc -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.99.116.101 &lt;none&gt; 8000/TCP 115skubernetes-dashboard ClusterIP 10.111.190.197 &lt;none&gt; 443/TCP 116s# 改为NodePort$ kubectl edit svc kubernetes-dashboard -n kubernetes-dashboardtype: NodePort$ kubectl get svc -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.99.116.101 &lt;none&gt; 8000/TCP 2m40skubernetes-dashboard NodePort 10.111.190.197 &lt;none&gt; 443:32202/TCP 2m41s# 开放账号权限cat &gt; dashboard-admin.yaml &lt;&lt;EOF# Creating a Service AccountapiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard ---# Creating a ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboardEOF# 开放管理员权限$ kubectl apply -f dashboard-admin.yaml# 访问token$ kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)Name: admin-user-token-zjkxsNamespace: kubernetes-dashboardLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: af11f2f3-613e-4bc5-959b-4591e3ada6dfType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 20 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IlduNEdhTUJxOWtXbFhwdlhRSzhEMGFRemdJR0duQl9FNm9Rc2d0ekREQkEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXpqa3hzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJhZjExZjJmMy02MTNlLTRiYzUtOTU5Yi00NTkxZTNhZGE2ZGYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.NRMwYGUtsf0v8rL3aZQDmi1lTAFMp1m2xEvAO6zavtFFo6HJzbpF_ReSssgWeK5LLk6sbOXVUx19O0wnASSPKg7JXiXBBGyb_qHkMdD5p2yc5ggGJu_MjE_0kXS-0OvSMS20Dtv1BiZiWB-eNEy3xxTorivG2Zah8-ART5J1HtqHauxxyQr21pHfQ9XlmOlby3MQVelIbQ1e7-EZemOSggcQI0rlpWlU_OPiakksoJGEcwr0xK7kypLnxG4AjM9x9fgjIBft30c4tfwMDXzYiB5ZwwDP2cHRiYN6fnE9XdJmrGBVAL4SgTabXFz2DOfOFpsbWkcDNdOBBWsZHzvUww# 卸载$ kubectl delete -f dashboard-admin.yaml $ kubectl delete -f recommended.yaml 3. Prometheus3.1 组件说明 MetricServer: k8s 集群资源使用情况的集合器，收集数据给 k8s 集群内使用，如kubectl, hpa, scheduler等 （支持kubectl top node等操作） PrometheusOperator: 系统监控和警报工具箱，用来存储监控数据 NodeExporter: 各个node的关键度量指标状态数据 KubeStateMetrics: 收集k8s集群内资源对象数据，制定告警规则 Prometheus: 采用pull方式收集apiserver, scheduler, controller-manager, kubelet组件数据，通过http协议传输 Grafana: 可视化数据统计和监控平台 3.2 构建记录1234567$ mkdir prometheus &amp;&amp; cd promethues$ git clone https://github.com/coreos/kube-prometheus.git$ cd kube-prometheus/manifests# 当前k8s版本为 v1.18.6, 切换分支 release-0.6$ git checkout release-0.6 修改 grafana-service.yaml, 开启NodePort方式: 12345678910111213141516apiVersion: v1kind: Servicemetadata: labels: app: grafana name: grafana namespace: monitoringspec: type: NodePort # add ports: - name: http port: 3000 targetPort: http nodePort: 30100 # add selector: app: grafana 修改 prometheus-service.yaml, 开启NodePort方式: 123456789101112131415161718apiVersion: v1kind: Servicemetadata: labels: prometheus: k8s name: prometheus-k8s namespace: monitoringspec: type: NodePort # add ports: - name: web port: 9090 targetPort: web nodePort: 30200 # add selector: app: prometheus prometheus: k8s sessionAffinity: ClientIP 修改 alertmanager-service.yaml, 开启NodePort方式: 123456789101112131415161718apiVersion: v1kind: Servicemetadata: labels: alertmanager: main name: alertmanager-main namespace: monitoringspec: type: NodePort # add ports: - name: web port: 9093 targetPort: web nodePort: 30300 # add selector: alertmanager: main app: alertmanager sessionAffinity: ClientIP 获取需要的镜像: 1234567891011121314151617$ find . -type f | xargs grep &#x27;image:&#x27; | awk &#x27;&#123;print $3&#125;&#x27; | sed &#x27;/^[ ]*$/d&#x27; | sort | uniqdirectxman12/k8s-prometheus-adapter:v0.7.0grafana/grafana:7.1.0quay.io/coreos/kube-rbac-proxy:v0.4.1quay.io/coreos/kube-state-metrics:v1.9.5quay.io/coreos/prometheus-operator:v0.40.0quay.io/prometheus/alertmanager:v0.21.0quay.io/prometheus/node-exporter:v0.18.1quay.io/prometheus/prometheus:v2.20.0# 先手动拉取镜像docker pull quay.io/coreos/kube-rbac-proxy:v0.4.1docker pull quay.io/coreos/kube-state-metrics:v1.9.5docker pull quay.io/coreos/prometheus-operator:v0.40.0docker pull quay.io/prometheus/alertmanager:v0.21.0docker pull quay.io/prometheus/node-exporter:v0.18.1docker pull quay.io/prometheus/prometheus:v2.20.0 执行安装： 1234567# Create the namespace and CRDs, and then wait for them to be availble before creating the remaining resources$ kubectl create -f manifests/setup$ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo &quot;&quot;; done$ kubectl create -f manifests/# teardown the stack$ kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup 安装后检查： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647$ kubectl get pod -n monitoringNAME READY STATUS RESTARTS AGEalertmanager-main-0 2/2 Running 0 6m17salertmanager-main-1 2/2 Running 0 6m16salertmanager-main-2 2/2 Running 0 6m16sgrafana-67dfc5f687-vqfbh 1/1 Running 0 6m7skube-state-metrics-69d4c7c69d-2lmfl 3/3 Running 0 6m6snode-exporter-j9nzx 2/2 Running 0 6m4snode-exporter-lwmkw 2/2 Running 0 6m3snode-exporter-p5sl8 2/2 Running 0 6m3sprometheus-adapter-66b855f564-qvs8x 1/1 Running 0 5m53sprometheus-k8s-0 3/3 Running 1 5m46sprometheus-k8s-1 3/3 Running 1 5m46sprometheus-operator-75c98bcfd7-smmwd 2/2 Running 0 8m22s$ kubectl top nodeNAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master 321m 16% 1329Mi 70% k8s-node01 190m 9% 1062Mi 56% k8s-node02 961m 48% 1011Mi 53% $ kubectl top pod -n monitoringNAME CPU(cores) MEMORY(bytes) alertmanager-main-0 7m 22Mi alertmanager-main-1 11m 23Mi alertmanager-main-2 9m 24Mi grafana-67dfc5f687-vqfbh 25m 25Mi kube-state-metrics-69d4c7c69d-2lmfl 2m 33Mi node-exporter-j9nzx 58m 19Mi node-exporter-lwmkw 5m 18Mi node-exporter-p5sl8 5m 13Mi prometheus-adapter-66b855f564-qvs8x 4m 18Mi prometheus-k8s-0 31m 235Mi prometheus-k8s-1 26m 195Mi prometheus-operator-75c98bcfd7-smmwd 1m 34Mi $ kubectl get svc -n monitoringNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEalertmanager-main NodePort 10.105.101.126 &lt;none&gt; 9093:30300/TCP 9m37salertmanager-operated ClusterIP None &lt;none&gt; 9093/TCP,9094/TCP,9094/UDP 9m37sgrafana NodePort 10.100.132.19 &lt;none&gt; 3000:30100/TCP 9m26skube-state-metrics ClusterIP None &lt;none&gt; 8443/TCP,9443/TCP 9m25snode-exporter ClusterIP None &lt;none&gt; 9100/TCP 9m25sprometheus-adapter ClusterIP 10.101.16.41 &lt;none&gt; 443/TCP 9m12sprometheus-k8s NodePort 10.101.33.228 &lt;none&gt; 9090:30200/TCP 9m10sprometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 9m4sprometheus-operator ClusterIP None &lt;none&gt; 8443/TCP 11m 访问 promethues：http://192.168.31.40:30200 1sum by (pod_name)(rate(container_cpu_usage_seconds_total&#123;image!=&quot;&quot;&#125;[1m] )) 访问 Grafana: http://192.168.31.40:30100 1admin/admin 3. Horizontal Pod AutoscalingHPA 可以根据CPU利用率自动伸缩一个 Replication Controller、Deployment或者 ReplicaSet中的Pod数量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104cat &gt; hpa.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: php-apachespec: replicas: 1 selector: matchLabels: app: apache template: # Pod metadata: labels: app: apache spec: containers: - name: php-apache image: gcr.io/google_containers/hpa-example ports: - containerPort: 80 resources: requests: cpu: 0.1 memory: 32Mi---apiVersion: v1kind: Servicemetadata: name: php-apachespec: type: ClusterIP selector: app: apache ports: - name: http port: 80 targetPort: 80EOF# 启动$ kubectl apply -f hpa.yaml$ kubectl top podNAME CPU(cores) MEMORY(bytes) php-apache-86d4bcdcd9-wlvs5 1/1 Running 0 29m # 创建HPA控制器$ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10# 查看数据释放统计到了$ kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 0%/50% 1 10 1 5m# 增加负载，查看负载数量 （新开一个窗口）$ kubectl run -i --tty load-generator --image=busybox /bin/sh$ while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done# 监控 kubectl get hpa -wNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache &lt;unknown&gt;/50% 1 10 0 7sphp-apache Deployment/php-apache &lt;unknown&gt;/50% 1 10 1 15sphp-apache Deployment/php-apache 0%/50% 1 10 1 4m3sphp-apache Deployment/php-apache 0%/50% 1 10 1 5m19sphp-apache Deployment/php-apache 1%/50% 1 10 1 19mphp-apache Deployment/php-apache 0%/50% 1 10 1 20mphp-apache Deployment/php-apache 0%/50% 1 10 1 25mphp-apache Deployment/php-apache 378%/50% 1 10 1 28mphp-apache Deployment/php-apache 378%/50% 1 10 4 28mphp-apache Deployment/php-apache 467%/50% 1 10 8 28m# 尝试新作 Pod$ kubectl get pod -wNAME READY STATUS RESTARTS AGEload-generator 1/1 Running 0 45mphp-apache-86d4bcdcd9-wlvs5 1/1 Running 0 29mphp-apache-86d4bcdcd9-7cjmm 0/1 Pending 0 0sphp-apache-86d4bcdcd9-7cjmm 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 Pending 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 Pending 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-7cjmm 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-hzf8h 0/1 Pending 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 Pending 0 0sphp-apache-86d4bcdcd9-hzf8h 0/1 Pending 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 Pending 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 Pending 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 Pending 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 Pending 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 Pending 0 0sphp-apache-86d4bcdcd9-hzf8h 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 Pending 0 0sphp-apache-86d4bcdcd9-z6qkt 0/1 Pending 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 Pending 0 0sphp-apache-86d4bcdcd9-z6qkt 0/1 Pending 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-z6qkt 0/1 ContainerCreating 0 3s 4. 资源限制4.1 Pod12345678910111213spec: containers: - name: php-apache image: gcr.io/google_containers/hpa-example ports: - containerPort: 80 resources: requests: cpu: 0.1 memory: 32Mi limits: cpu: 200m memory: 100Mi 4.2 名称空间 计算姿态配额 123456789101112apiVersion: v1kind: ResourceQuotametadata: name: compute-resource namespace: spark-clusterspec: hard: pods: 20 requests.cpu: 20 requests.memory: 100Gi limits.cpu: 40 limits.memory: 200Gi 配置对象数量配额限制 12345678910111213apiVersion: v1kind: ResourceQuotametadata: name: object-counts namespace: spark-clusterspec: hard: configmaps: 10 persistentvolumeclaims: 4 replicationcontrollers: 20 secrets: 10 services: 10 services.loadbalancer: 2 配置CPU 和 内存的 LimitRange 12345678910111213apiVersion: v1kind: LimitRangemetadata: name: mem-limit-rangespec: limits: - default: memory: 50Gi cpu: 5 defaulyRequest: memory: 1Gi cpu: 1 type: Container 5. EFK 日志EFK: Elasticsearch + Fluentd + Kibana ELFK: Elasticsearch + Logstash + Filebeat + Kibana 安装参考：https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes 5.1 创建 Namespace12345678910111213$ mkdir efk &amp;&amp; cd efk$ cat &gt; kube-logging.yaml &lt;&lt;EOFkind: NamespaceapiVersion: v1metadata: name: kube-loggingEOF$ kubectl create -f kube-logging.yaml$ kubectl get ns | grep kube-loggingkube-logging Active 6s 5.2 ElasticSearch5.2.1 创建无头服务123456789101112131415161718192021222324$ cat &gt; elasticsearch_svc.yaml &lt;&lt;EOFkind: ServiceapiVersion: v1metadata: name: elasticsearch namespace: kube-logging labels: app: elasticsearchspec: selector: app: elasticsearch clusterIP: None ports: - port: 9200 name: rest - port: 9300 name: inter-nodeEOF$ kubectl create -f elasticsearch_svc.yaml$ kubectl get services --namespace=kube-loggingNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 13s 5.2.2 创建PV1234567891011121314151617181920212223$ cat &gt; elasticsearch_pv.ymal &lt;&lt;EOFapiVersion: v1kind: PersistentVolumemetadata: name: nfspv1 namespace: kube-loggingspec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs server: 192.168.31.200EOF$ kubectl create -f elasticsearch_pv.ymal$ kubectl get pv -n kube-loggingNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Available nfs 18s 5.2.3 安装ES123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101$ cat &gt; elasticsearch_statefulset.yaml &lt;&lt;EOFapiVersion: apps/v1kind: StatefulSetmetadata: name: es-cluster namespace: kube-loggingspec: serviceName: elasticsearch #replicas: 3 replicas: 1 selector: matchLabels: app: elasticsearch template: metadata: labels: app: elasticsearch spec: containers: - name: elasticsearch image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0 resources: limits: #cpu: 1000m cpu: 400m requests: cpu: 100m ports: - containerPort: 9200 name: rest protocol: TCP - containerPort: 9300 name: inter-node protocol: TCP volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data env: - name: cluster.name value: k8s-logs - name: node.name valueFrom: fieldRef: fieldPath: metadata.name - name: discovery.type # test-bed value: single-node #- name: discovery.seed_hosts #value: &quot;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&quot; #- name: cluster.initial_master_nodes #value: &quot;es-cluster-0,es-cluster-1,es-cluster-2&quot; - name: ES_JAVA_OPTS #value: &quot;-Xms512m -Xmx512m&quot; value: &quot;-Xms256m -Xmx256m&quot; initContainers: - name: fix-permissions image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;] securityContext: privileged: true volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data - name: increase-vm-max-map image: busybox command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;] securityContext: privileged: true - name: increase-fd-ulimit image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;] securityContext: privileged: true volumeClaimTemplates: - metadata: name: data labels: app: elasticsearch spec: accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: nfs resources: requests: storage: 1GiEOF$ kubectl create -f elasticsearch_statefulset.yaml# 监控创建进度$ kubectl rollout status sts/es-cluster --namespace=kube-logging$ kubectl get pod -n kube-loggingNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 59s# 监控日志$ kubectl logs -f es-cluster-0 -n kube-logging # 开启本地端口，测试服务$ kubectl port-forward es-cluster-0 9200:9200 --namespace=kube-logging$ curl http://localhost:9200/_cluster/state?pretty 5.3 Kibana1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162$ cat &gt; kibana.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: kibana namespace: kube-logging labels: app: kibanaspec: type: NodePort ports: - port: 5601 selector: app: kibana---apiVersion: apps/v1kind: Deploymentmetadata: name: kibana namespace: kube-logging labels: app: kibanaspec: replicas: 1 selector: matchLabels: app: kibana template: metadata: labels: app: kibana spec: containers: - name: kibana image: docker.elastic.co/kibana/kibana:7.2.0 resources: limits: cpu: 1000m requests: cpu: 100m env: - name: ELASTICSEARCH_URL value: http://elasticsearch:9200 ports: - containerPort: 5601EOF$ kubectl create -f kibana.yaml$ kubectl rollout status deployment/kibana --namespace=kube-logging$ kubectl get pod -n kube-loggingNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 13mkibana-5749b5778b-zvtwn 1/1 Running 0 4m33s$ kubectl get svc -n kube-loggingNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 89mkibana NodePort 10.106.103.244 &lt;none&gt; 5601:30750/TCP 8s$ curl http://192.168.1.40:30750 5.4 Fluentd123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100$ cat &gt; fluentd.yaml &lt;&lt;EOFapiVersion: v1kind: ServiceAccountmetadata: name: fluentd namespace: kube-logging labels: app: fluentd---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: fluentd labels: app: fluentdrules:- apiGroups: - &quot;&quot; resources: - pods - namespaces verbs: - get - list - watch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: fluentdroleRef: kind: ClusterRole name: fluentd apiGroup: rbac.authorization.k8s.iosubjects:- kind: ServiceAccount name: fluentd namespace: kube-logging---apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd namespace: kube-logging labels: app: fluentdspec: selector: matchLabels: app: fluentd template: metadata: labels: app: fluentd spec: serviceAccount: fluentd serviceAccountName: fluentd tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd image: fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1 env: - name: FLUENT_ELASTICSEARCH_HOST value: &quot;elasticsearch.kube-logging.svc.cluster.local&quot; - name: FLUENT_ELASTICSEARCH_PORT value: &quot;9200&quot; - name: FLUENT_ELASTICSEARCH_SCHEME value: &quot;http&quot; - name: FLUENTD_SYSTEMD_CONF value: disable resources: limits: #memory: 512Mi memory: 256Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containersEOF$ kubectl create -f fluentd.yaml$ kubectl get ds -n kube-loggingNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEfluentd 2 2 2 2 2 &lt;none&gt; 27s 5.5 Kibana 页面 5.6 测试创建一个 Pod： 1234567891011121314$ cat &gt; counter.yaml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: [/bin/sh, -c, &#x27;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&#x27;]EOF$ kubectl create -f counter.yaml 6. 补充：Port说明：Pod Template中的ports: containerPort: 容器对外开发的端口 Service 中的 ports: port: 监听请求，接收端口，绑定在ClusterIP上 targetPort: 指定Pod的接收端口，与containerPort绑定 nodePort: 类型为NodeType时，绑定在NodeIP上，未指定则随机给一个","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 安全机制","slug":"Kubernetes 安全机制","date":"2018-07-08T07:44:26.000Z","updated":"2021-06-22T10:50:49.721Z","comments":true,"path":"2018/07/08/Kubernetes 安全机制/","link":"","permalink":"https://elihe2011.github.io/2018/07/08/Kubernetes%20%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/","excerpt":"1. 机制说明API Server 是集群内部各个组件通讯的中介，也是外部控制的入口。k8s 使用认证(Authentication)、鉴权(Authorization)、准入控制(Admission Control) 三步来确保API Server的安全。 2. 认证 (Authentication) HTTP Token：HTTP Request Header 的 Token字段 HTTP Base: 客户端通过base64 USERNAME:PASSWORD, 填充 HTTP Request Header 的 Authorization字段，服务端收到后解码获取用户名和密码 HTTPS: 基于CA根证书签名的客户端身份认证方式。（推荐）","text":"1. 机制说明API Server 是集群内部各个组件通讯的中介，也是外部控制的入口。k8s 使用认证(Authentication)、鉴权(Authorization)、准入控制(Admission Control) 三步来确保API Server的安全。 2. 认证 (Authentication) HTTP Token：HTTP Request Header 的 Token字段 HTTP Base: 客户端通过base64 USERNAME:PASSWORD, 填充 HTTP Request Header 的 Authorization字段，服务端收到后解码获取用户名和密码 HTTPS: 基于CA根证书签名的客户端身份认证方式。（推荐） 2.1 HTTPS 证书认证 2.2 需要认证的节点 两种类型： Kubernetes组件对API Server的访问：kubectl、Controller Manager、Scheduler、kubelet、kube-proxy Kubernetes管理的Pod对容器的访问：Pod（dashborad也是以Pod形式运行） 安全性说明： Controller Manager、Scheduler与API Server在同一台机器，所以直接使用API Server的非安全端口访问--insecure-bind-address=127.0.0.1 kubectl、kubelet、kube-proxy访问API Server都需要证书进行HTTPS双向认证 证书颁发： 手动签发：通过k8s集群的根 ca 进行签发 HTTPS 证书 自动签发：kubelet 首次访问 API Server 时，使用 token 认证，通过后，Controller Manager 会为kubelet生成一个证书，以后的访问均使用该证书 2.3 kubeconfigkubeconfig 文件包含集群参数（CA证书、API Server地址），客户端参数，集群context信息（集群名称、用户名）。k8s 组件通过启动时指定不同的 kubeconfig 文件可以切换到不同的集群 cat ~/.kube/config 2.4 ServiceAccountPod 中的容器访问API Server。因为Pod的创建和销毁是动态的，所以要为它手动生成证书是不可行的，k8s 使用 Service Account解决Pod访问API Server的认证问题 2.5 Secret 与 SA 的关系Secret 分两类： 用于ServiceAccount的 service-account-token 用于保存用户自定义的保密信息的 Opaque SA 中包含三个部分： token：使用API Server私钥签名的 JWT ca.crt: 根证书，用于Client端验证API Server发送的证书 namespace: 标识该service-account-token的作用域名空间 1234567891011121314151617181920212223242526272829303132$ kubectl get secret --all-namespacesNAMESPACE NAME TYPE DATA AGEdefault default-token-rhw7k kubernetes.io/service-account-token 3 5d16hingress-nginx default-token-ftjf6 kubernetes.io/service-account-token 3 2d3hkube-system kube-proxy-token-kcgcp kubernetes.io/service-account-token 3 5d16h$ kubectl describe secret default-token-rhw7kName: default-token-rhw7kNamespace: defaultLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: default kubernetes.io/service-account.uid: 3fdb2906-e8c4-4bb1-9dc0-ac8aa15167b6Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 7 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6Ikx5ZjJCcWJPandjZzl5czlkRHpZZWp0d2NtT2dSU0w3c2M5dXY2ZUQ0QkUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tcmh3N2siLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjNmZGIyOTA2LWU4YzQtNGJiMS05ZGMwLWFjOGFhMTUxNjdiNiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.FkcID8mWCOXDQbZAZPJLWSSWngvt9R-69AEDVV_QQvyvP_BW1MwiANOM2cXkS-qDo4-hcDcRKGOZ-q7BxQC96YUsj41iiLBbsXyVI1_ovEgp58dwROJe-MTxkSlk8sic40QmW2y1CwREf-5EIxwLy1iGekbbMZb4W0m4oXa-BN7qzNzMwu4Bb6ScJbxljHpO33K80oKtWYN-fpow31FjMjZMEebUvf-pGw6O2FPLvzwC7A7_U-WRNrFWd2wZIRQf8GfQgUf5-phAnmyawcJ4gpQooRvHoyGyW366dEY-qAk4D-1xSj598X0Q_pq7PdT1WQkO3nozHL-w4mbSlb3Ytw$ kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkube-proxy-c5t62 1/1 Running 13 5d16hkube-proxy-q7m2t 1/1 Running 13 5d16hkube-proxy-t2tgb 1/1 Running 13 5d16h$ kubectl exec kube-proxy-c5t62 -n kube-system -it -- ls -l /run/secrets/kubernetes.io/serviceaccounttotal 0lrwxrwxrwx 1 root root 13 Sep 13 06:40 ca.crt -&gt; ..data/ca.crtlrwxrwxrwx 1 root root 16 Sep 13 06:40 namespace -&gt; ..data/namespacelrwxrwxrwx 1 root root 12 Sep 13 06:40 token -&gt; ..data/token 2.6 总结 3. 鉴权 (Authorization)认证 和鉴权： 认证(authencation): 通过只代表通讯双方是可信的 鉴权(authorization): 确定请求方有哪些资源权限 API Server的授权策略，启动参数--authorization-mode AlwaysDeny: 拒绝所有请求，一般用于测试 AlwaysAllow: 接收所有请求。如果集群不需要授权流程，采用该策略 ABAC (Attribute-Based Access Control): 基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webbook: 通过调用外部REST服务对用户进行授权 RBAC (Role-Based Access Control): 基于角色的访问控制，默认规则 RBAC优势： 对集群中的资源和非资源均拥有完整的覆盖 整个RBAC完全由几个API对象完成，同其他API对象一样，可以用kubectl或API进行操作 可在运行时调整，无需重启API Server 3.1 RBAC 的 API资源对象 Role ClusterRole RoleBinding ClusterRoleBinding k8s 不会提供用户管理，User, Group, ServiceAccount指定的用户，需要通过证书请求文件指定： 1234567891011121314151617&#123; &quot;CN&quot;: &quot;admin&quot;, // User &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;HangZhou&quot;, &quot;L&quot;: &quot;XS&quot;, &quot;O&quot;: &quot;system:master&quot;, // Group &quot;OU&quot;: &quot;Sytem&quot; &#125; ]&#125; 3.2 Role &amp; ClusterRole3.2.1 RoleRole 表示一组规则权限，权限只会增加（累加权限），不存在一开始就开通很多权限而通过RBAC对其减少的操作。Role 必须定义在一个namespace中，跨namespace可以使用ClusterRole 123456789apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: pod-reader namespace: defaultrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ pods ] verbs: [get, watch, list] 3.2.2 ClusterRoleClusterRole 是集群级别的，可用于： 集群级别资源控制，例如node访问权限 非资源型 endpoints，例如/healthz 访问 所有命名空间资源控制，例如pod 12345678apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: secret-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ secrets ] verbs: [get, watch, list] 3.3 RoleBinding &amp; ClusterRoleBinding3.3.1 RoleBindingRoleBinding 可以将角色中定义的权限赋予用户或组，它包含了一种权限列表(subjects)，权限列表包含不同形式的待授予权限资源类型（users，groups，service accounts），同时它也包含被Bind的Role引用 12345678910111213apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: read-pods namespace: defaultsubjects:- kind: User name: jane apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io RoleBinding引用ClusterRole： 1234567891011121314# This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespaceapiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: read-secrets namespace: developmentsubjects:- kind: User name: dave apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 3.3.2 ClusterRoleBindingClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权 12345678910111213# This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in any namespace.apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: read-secrets-globalsubjects:- kind: Group name: manager apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 3.4 Resources访问子资源: 1GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log 12345678apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: pod-and-pod-logs-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ pods, &quot;pods/log&quot; ] verbs: [get, list] 3.5 to SubjectsRoleBinding &amp; ClusterRoleBinding 可以将Role绑定到Subjects, Subjects 可以是groups, users, 或SA 3.6 示例3.6.1 创建Linux账号123456useradd devuserpasswd devusersu - devuser$ kubectl get pod # 无权限The connection to the server localhost:8080 was refused - did you specify the right host or port? 3.6.2 安装证书工具12345678# 下载证书生成工具$ wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64$ wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 $ wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 $ chmod +x cfssl*$ mv cfssl_linux-amd64 /usr/local/bin/cfssl $ mv cfssljson_linux-amd64 /usr/local/bin/cfssljson$ mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo 3.6.3 生成证书1234567891011121314151617181920212223242526$ mkdir -p ~/cert/devuser# 证书请求文件$ cat &gt; ~/cert/devuser/user-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;devuser&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;JS&quot;, &quot;L&quot;: &quot;NJ&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;Sytem&quot; &#125; ]&#125;EOF# 生成证书$ cd /etc/kubernetes/pki$ cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes ~/cert/devuser/user-csr.json | cfssljson -bare devuser 3.6.4 设置集群参数1234567891011121314151617181920212223# 设置集群参数cd ~/cert/devuserexport KUBE_APISERVER=&quot;https://192.168.31.40:6443&quot;kubectl config set-cluster kubernetes \\--certificate-authority=/etc/kubernetes/pki/ca.crt \\--embed-certs=true \\--server=$&#123;KUBE_APISERVER&#125; \\--kubeconfig=devuser.kubeconfig# 设置客户端认证参数kubectl config set-credentials devuser \\--client-certificate=/etc/kubernetes/pki/devuser.pem \\--client-key=/etc/kubernetes/pki/devuser-key.pem \\--embed-certs=true \\--kubeconfig=devuser.kubeconfig# 设置上下文kubectl config set-context kubernetes \\--cluster=kubernetes \\--user=devuser \\--namespace=dev \\--kubeconfig=devuser.kubeconfig 3.6.5 角色绑定123# rolebindingkubectl create ns devkubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev 3.6.6 用户管理配置123mkdir -p /home/devuser/.kubecp devuser.kubeconfig /home/devuser/.kube/configchown -R devuser:devuser /home/devuser/.kube 3.6.7 设置默认上下 和 验证123456789101112131415161718# 设置默认上下文su - devuser$ kubectl config use-context kubernetes --kubeconfig=.kube/configSwitched to context &quot;kubernetes&quot;.# devuser 用户下创建 pod$ kubectl get podNo resources found in dev namespace.$ kubectl run nginx --image=hub.elihe.io/test/nginx:v1pod/nginx created$ kubectl get podNAME READY STATUS RESTARTS AGEnginx 1/1 Running 0 4s$ kubectl get pod -n defaultError from server (Forbidden): pods is forbidden: User &quot;devuser&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot; 4. 准入控制准入控制是 API Server 的插件集合，通过添加不同的插件，实现额外的准入控制规则 常见准入控制插件： NamespaceLifecycle: 防止在不存在的namespace上创建对象；防止删除系统预置的namespace；删除namespace时，连带删除它下面的所有资源 LimitRanger: 确保请求的资源不会超过资源所在Namespace的LimitRange的限制 ServiceAccount: 实现自动化添加SA ResourceQuota: 确保请求的资源不会超过资源的ResourceQuota限制","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 集群调度","slug":"Kubernetes 集群调度","date":"2018-07-07T03:52:25.000Z","updated":"2021-06-22T10:50:49.720Z","comments":true,"path":"2018/07/07/Kubernetes 集群调度/","link":"","permalink":"https://elihe2011.github.io/2018/07/07/Kubernetes%20%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6/","excerpt":"1. 调度说明1.1 简介Scheduler 是 K8S 的调度器，主要任务是把定义的 pod 分配到集群节点上。它主要考虑如下问题： 公平： 如何确保每个节点都被分配资源 资源高利用率：集群所有资源最大化被使用 效率：调度性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Scheduler 作为独立的进程允许，启动后会一直监听API Server，获取 PodSpec.NodeName 为空的pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上","text":"1. 调度说明1.1 简介Scheduler 是 K8S 的调度器，主要任务是把定义的 pod 分配到集群节点上。它主要考虑如下问题： 公平： 如何确保每个节点都被分配资源 资源高利用率：集群所有资源最大化被使用 效率：调度性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Scheduler 作为独立的进程允许，启动后会一直监听API Server，获取 PodSpec.NodeName 为空的pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上 1.2 调度过程 首先，过滤掉不满足条件的节点，这个过程称为 predicate 其次，对通过的节点按优先级排序，这个是 priority 最后，从中选择优先级最高的节点。 总结：预选 + 优选 Predicate 算法： PodFitsResources: 节点上剩余资源是否大于 pod 请求资源 PodFitsHost: 如果 pod 指定了NodeName，检查当前节点名称是否与之匹配 PodFitsHostPorts: pod 申请的port 是否已被占用 PodSelectorMatches: 过滤掉和 pod 指定的 label 不匹配的节点 NoDiskConflict: 已经 mount 的 volume和pod指定的 volume 不冲突，除非它们都是只读的 如果在 predicate 过程中没有合适的节点，pod 会一直在 pending 状态，不断重试调度，直到有节点满足条件。多个节点同时满足条件，继续按 priorities 过程，按优先级大小排序 优先级选项： LeastRequestedPriority: 计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高 BalancedResourceAllocation: CPU 和 Memory 的使用率接近，权重越高。通常和上一个一起使用 ImageLocalityPriority: 本地已下载镜像，镜像总大小越大，权重越高 1.3 自定义调度器spec.schedulername 指定调度器名称 1234567891011apiVersion: v1kind: Podmetadata: name: annotation-second-scheduler labels: name: multischeduler-examplespec: schedulername: my-scheduler conatiners: - name: pod-with-second-annotation-container image: gcr.io/google_containers/pause:2.0 2. 调度亲和性2.1 节点亲和性pod.spec.nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: 软策略 requiredDuringSchedulingIgnoredDuringExecution: 硬策略 12345678910111213141516171819202122232425262728apiVersion: v1kind: Podmetadata: name: node-affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn values: - k8s-node02 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: source operator: In values: - k8s-node01 2.2 Pod 亲和性pod.spec.affinity.podAffinity/PodAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: 软策略 requiredDuringSchedulingIgnoredDuringExecution: 硬策略 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: Podmetadata: name: pod-affinity labels: app: pod-3spec: containers: - name: pod-3 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - pod-1 topologyKey: kubernetes.io/hostname podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - pod-2 topologyKey: kubernetes.io/hostname 12345678910111213$ kubectl get podNAME READY STATUS RESTARTS AGEnode-affinity 1/1 Running 0 9m22spod-affinity 0/1 Pending 0 10s# 注意node-affinity必须是running的，否则即使修改了的label满足条件，pod-3也不会创建$ kubectl label pod node-affinity app=pod-1 --overwrite=truepod/node-affinity labeled$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSnode-affinity 1/1 Running 1 10m app=pod-1pod-affinity 1/1 Running 0 95s app=pod-3 2.3 亲和性/反亲和性策略对比 调度策略 匹配标签 操作符 拓扑域支持 调度目标 nodeAffinity Node In, NotIn, Exists, DoesNotExist, Gt, Lt No 指定主机 podAffinity Pod In, NotIn, Exists, DoesNotExist Yes 指定Pod在同一个拓扑域 podAntiAffinity Pod In, NotIn, Exists, DoesNotExist Yes 指定Pod不在同一个拓扑域 3. 污点 和 容忍 亲和性：Pod的一种偏好或硬性要求，它使 Pod 能被吸引到一类特定的节点 污点：与亲和性相反，它使节点能够排斥一类特定的Pod Taint：用来避免pod节点被分配到不合适的节点上 Toleration：表示pod可以(容忍)被分配到Taint节点上 3.1 Taint3.1.1 污点的组成1key=value:effect 其中value可以为空，effect描述污点的作用，当前支持如下三个选项： NoSchedule: 不会将Pod调度到具有该污点的Node上 PreferNoSchedule: 尽量避免将Pod调度到具有该污点的Node上 NoExecute: 不会将Pod调度到具有该污点的Node上，同时会将已存在的Pod驱逐出该Node 3.1.2 污点的设置，查看和去除123456789# 设置污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule# 查看污点$ kubectl describe node k8s-node01 | grep -i taintTaints: kickoff=test:NoSchedule# 去除污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule- 3.2 Tolerationpod.spec.tolerations 12345678910111213tolerations:- key: key1 operator: Equal value: value1 effect: NoSchedule tolerationSeconds: 3600 # 驱离前保留时间- key: key2 operator: Equal value: value2 effect: NoExecute- key: key3 operator: Exists effect: NoSchedule key, value, effect 要与 Node 上设置的taint一致 operator等于 Exists 时，忽略 value值 tolerationSeconds Pod被驱离前的保留时间 当不指定key时，容忍所有的污点key 12tolerations:- operator: Exists 当不指定effect时，容忍所有的污点作用 123tolerations:- key: key operator: Exists 多个master节点，可去除默认污点 12345# 主节点默认设置污点$ kubectl describe node k8s-master | grep -i taintTaints: node-role.kubernetes.io/master:NoSchedule$ kubectl taint nodes k8s-master node-role.kubernetes.io/master=:PreferNoSchedule 3.2.1 示例1234567891011121314151617181920212223242526# taint-toleration.yamlapiVersion: v1kind: Podmetadata: name: pod-1spec: containers: - name: pod-1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;]---apiVersion: v1kind: Podmetadata: name: pod-2spec: containers: - name: pod-2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] tolerations: - key: kickoff operator: Equal value: test effect: NoSchedule 12345678910111213141516171819# 节点都打上污点标识$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule$ kubectl taint nodes k8s-node02 kickoff=test:NoSchedule$ kubectl create -f taint-toleration.yaml$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod-1 0/1 Pending 0 58s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;pod-2 1/1 Running 0 58s 10.244.2.55 k8s-node02 &lt;none&gt; &lt;none&gt;# 去除污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule-# 不再Pending$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod-1 1/1 Running 0 2m 10.244.1.40 k8s-node01 &lt;none&gt; &lt;none&gt;pod-2 1/1 Running 0 2m 10.244.2.55 k8s-node02 &lt;none&gt; &lt;none&gt; 4. 固定节点4.1 指定节点名称pod.spec.nodeName 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: test-1spec: replicas: 3 selector: matchLabels: app: tools template: metadata: labels: app: tools spec: nodeName: k8s-node01 # 指定节点名称 containers: - name: pod-1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] 12345$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-1-5c889d444f-pp9td 1/1 Running 0 48s 10.244.1.41 k8s-node01 &lt;none&gt; &lt;none&gt;test-1-5c889d444f-rtk25 1/1 Running 0 48s 10.244.1.43 k8s-node01 &lt;none&gt; &lt;none&gt;test-1-5c889d444f-rv2fc 1/1 Running 0 48s 10.244.1.42 k8s-node01 &lt;none&gt; &lt;none&gt; 4.2 指定节点选择器pod.spec.nodeSelector, 通过label-selector机制选择节点，由调度器调度策略匹配label，然后调度到目标节点 1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: test-2spec: replicas: 2 selector: matchLabels: app: web template: metadata: labels: app: web spec: nodeSelector: # 指定标签 type: backendNode1 containers: - name: web image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] 12345678910111213$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGEtest-2-564fd7c7df-4jftd 0/1 Pending 0 3s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;test-2-564fd7c7df-tdwj7 0/1 Pending 0 3s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;# 给node打标签$ kubectl label node k8s-node02 type=backendNode1node/k8s-node02 labeled$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-2-564fd7c7df-4jftd 1/1 Running 0 3m24s 10.244.2.56 k8s-node02 &lt;none&gt; &lt;none&gt;test-2-564fd7c7df-tdwj7 1/1 Running 0 3m24s 10.244.2.57 k8s-node02 &lt;none&gt; &lt;none&gt;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 存储","slug":"Kubernetes 存储","date":"2018-07-05T23:12:05.000Z","updated":"2021-06-22T10:50:49.720Z","comments":true,"path":"2018/07/06/Kubernetes 存储/","link":"","permalink":"https://elihe2011.github.io/2018/07/06/Kubernetes%20%E5%AD%98%E5%82%A8/","excerpt":"1. ConfigMap提供向容器注入配置信息的机制，可以用来保存单个属性，也可以用来保存整个配置文化或 JSON 二进制大对象 1.1 创建 ConfigMap1.1.1 文件--from-file：指定文件或目录 12345678910111213141516$ cat &gt; ./ui.properties &lt;&lt;EOFcolor=redbackground=cyanEOF$ kubectl create configmap ui-config --from-file=./ui.properties $ kubectl get cm ui-config -o yamlapiVersion: v1data: ui.properties: | # key 为文件名称 color=red background=cyankind: ConfigMapmetadata: ...","text":"1. ConfigMap提供向容器注入配置信息的机制，可以用来保存单个属性，也可以用来保存整个配置文化或 JSON 二进制大对象 1.1 创建 ConfigMap1.1.1 文件--from-file：指定文件或目录 12345678910111213141516$ cat &gt; ./ui.properties &lt;&lt;EOFcolor=redbackground=cyanEOF$ kubectl create configmap ui-config --from-file=./ui.properties $ kubectl get cm ui-config -o yamlapiVersion: v1data: ui.properties: | # key 为文件名称 color=red background=cyankind: ConfigMapmetadata: ... 1.1.2 字面值--from-literal 123456789101112$ kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm$ kubectl describe cm special-config$ kubectl get cm special-config -o yamlapiVersion: v1data: special.how: very special.type: charmkind: ConfigMapmetadata: ... 1.2 使用 ConfigMap1.2.1 使用 ConfigMap 代替环境变量spec.containers[].env[] spec.containers[].envFrom[] 123456789101112131415161718192021222324252627282930313233343536373839404142434445# configmap-injection.yamlapiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: very special.type: charm---apiVersion: v1kind: ConfigMapmetadata: name: env-config namespace: defaultdata: log_level: INFO---apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot;] env: # 按key导入 - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: # 全部导入 - configMapRef: name: env-config restartPolicy: Never 1234567891011121314$ kubectl create -f configmap-injection.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEconfigmap-pod 0/1 Completed 0 2m35s$ kubectl logs configmap-pod ...SPECIAL_TYPE_KEY=charm # targetSPECIAL_LEVEL_KEY=very # targetlog_level=INFO # targetKUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_SERVICE_HOST=10.96.0.1 1.2.2 用 ConfigMap 设置命令行参数12345678910111213141516171819202122apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $&#123;SPECIAL_LEVEL_KEY&#125; $&#123;SPECIAL_TYPE_KEY&#125; &quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never 1.2.3 通过数据插件使用 ConfigMap123456789101112131415161718apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 300&quot;] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never 12$ kubectl exec configmap-pod -it -- cat /etc/config/special.howvery 1.2.4 ConfigMap 热更新12345678910111213141516171819202122232425262728293031323334353637# configmap-hot-update.yamlapiVersion: v1kind: ConfigMapmetadata: name: log-config namespace: defaultdata: log_level: INFO---apiVersion: apps/v1kind: Deploymentmetadata: name: nginxspec: replicas: 1 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: log-config 12345678910111213141516171819202122$ kubectl apply -f configmap-hot-update.yaml$ kubectl get podNAME READY STATUS RESTARTS AGEnginx-df47dc9cd-9mjnx 1/1 Running 0 82s$ kubectl exec nginx-df47dc9cd-9mjnx -it -- cat /etc/config/log_levelINFO# 修改 ConfigMap$ kubectl edit configmap log-configapiVersion: v1data: log_level: DEBUGkind: ConfigMap# 30s 后再次查询$ kubectl exec nginx-df47dc9cd-9mjnx -it -- cat /etc/config/log_levelDEBUG# 触发热更新, 会重新启动, 配置生效$ kubectl patch deployment nginx --patch &#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;version.config&quot;: &quot;20201014&quot;&#125;&#125;&#125;&#125;&#125;&#x27; 2. SecretSecret 解决密码、token、密钥等敏感数据的配置问题，可以以Volume 或环境变量方式导入 Pod 中使用 Secret 类型有三种： Service Account: 用来访问 k8s api。由 k8s 自动创建，自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录下 Opaque: base64 编码格式的 Secret，用来存储密码、密钥等 kubernetes.io/dockerconfigjson: 用来存储私有 docker registry 的认证信息 2.1 Service Account (SA)12$ kubectl exec nginx-596675fccc-v8gfw -it -- ls /run/secrets/kubernetes.io/serviceaccountca.crt namespace token 2.2 Opaque2.2.1 创建12345$ echo -n &quot;admin&quot; | base64YWRtaW4=$ echo -n &quot;pass123&quot; | base64cGFzczEyMw== 123456789# secret.yamlapiVersion: v1kind: Secretmetadata: name: my-secrettype: Opaquedata: username: YWRtaW4= password: cGFzczEyMw== 2.2.2 使用 Secret 将 Secret 挂载到 Volume 1234567891011121314151617181920# secret-volume.yamlapiVersion: v1kind: Podmetadata: labels: name: secret-volume name: secret-volumespec: volumes: - name: secrets secret: secretName: my-secret containers: - name: db image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent volumeMounts: - name: secrets mountPath: &quot;/etc/secrets&quot; readOnly: true 123456789101112$ kubectl create -f secret-volume.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEsecret-volume 1/1 Running 0 8s$ kubectl exec secret-volume -it -- ls /etc/secretspassword username# 容器内自动解密$ kubectl exec secret-volume -it -- cat /etc/secrets/passwordpass123 将 Secret 导入环境变量 1234567891011121314151617181920212223242526272829303132# secret-env.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: secret-envspec: replicas: 2 selector: matchLabels: app: secret-pod template: metadata: labels: app: secret-pod spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 env: - name: TEST_USER valueFrom: secretKeyRef: name: my-secret key: username - name: TEST_PASSWORD valueFrom: secretKeyRef: name: my-secret key: password 12345678910$ kubectl apply -f secret-env.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEsecret-env-6f5785997f-2w7dj 1/1 Running 0 8ssecret-env-6f5785997f-khzjz 1/1 Running 0 8s$ kubectl exec secret-env-6f5785997f-2w7dj -it -- env | grep TESTTEST_USER=adminTEST_PASSWORD=pass123 2.3 kubernetes.io/dockerconfigjson创建 docker register 认证 1$ kubectl create secret docker-register myregisterkey --docker-server=hub.elihe.io --docker-username=admin --docker-password=Harbor12345 --docker-email=eli.he@live.cn 创建 Pod 时，用 imagePullSecrets 来引用刚创建的 myregisterkey 12345678910apiVersion: v1kind: Podmetadata: name: nginxspec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullSecrets: - name: myregisterkey 3. Volumevolume 解决问题： 容器磁盘上的新增文件，容器重启后将消失，无法持久化 Pod中运行的多个容器需求共享文件 当 Pod 中的容器重启时，volume 数据还在。但是当 Pod 不存在时，volume 也将不复存在。 Volume 支持的类型： awsElasticBlockStore, azureDisk, azureFile, cephfs, csi, downwardAPI, emptyDir fc, flocker, gcePersistentDisk, gitRepo, glusterfs, hostPath, iscsi, local, nfs persistentVolumeClaim, projected, portworxVolume, quobyte, rbd, scaleIO, secret storageos vsphereVolume 3.1 emptyDir创建 Pod 时，会自动创建 emptyDir 卷，它最初是空的，Pod 中的容器可以读取和写入 emptyDir 卷中的文件。当删除 Pod 时，emptyDir 中的数据将被永久删。容器崩溃不会导致 Pod 被删除，因此 emptyDir 卷中的数据在容器崩溃时是安全的。 emptyDir 用法： 暂存空间，例如用于基于磁盘的合并排序 用于长时间计算崩溃恢复时的检查点 Web服务器容器提供数据时，保存内容管理容器提取的文件 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: vol-emptydirspec: containers: - name: c1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /cache name: cache-volume - name: c2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; 1234$ kubectl exec vol-emptydir -c c1 -it -- touch /cache/now.txt$ kubectl exec vol-emptydir -c c2 -it -- ls -l /cache/now.txt-rw-r--r-- 1 root root 0 Oct 14 01:34 /cache/now.txt 3.2 hostPath将主机节点的文件系统中的文件和目录挂载到集群中 hostPath 用途： 运行需要访问 Docker 内部的容器，使用 /var/lib/docker 的 hostPath 在容器中运行 cAdvisor(猫头鹰，Google提供的一个服务)，使用 /dev/cgroups 的 hostPath hostPath 卷指定 type检查： 值 行为 空字符串(默认)，向后兼容，在挂载hostPath 卷之前不会执行任何检查 DirectoryOrCreate 目录不存在自动创建，权限0755，与kubectl具有相同组和所有权 Directory 目录必须存在 FileOrCreate 文件不存在自动创建，权限0644，与kubectl具有相同组和所有权 File 文件必须存在 Socket Unix 套接字必须存在 CharDevice 字符设备必须存在 BlockDevice 块设备必须存在 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: vol-hostpathspec: containers: - name: c1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /data name: data-volume - name: c2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /data name: data-volume volumes: - name: data-volume hostPath: path: /data type: Directory 1234567891011$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESvol-hostpath 0/2 ContainerCreating 0 44s &lt;none&gt; k8s-node02 &lt;none&gt; &lt;none&gt;# k8s-node02 上创建目录 /data$ mkdir /data$ date &gt; /data/abc.txt# 查看文件内容$ kubectl exec vol-hostpath -c c1 -it -- cat /data/abc.txtSat Sep 12 11:10:53 CST 2020 4. PV &amp; PVCPV 作用：屏蔽后端不同存储类型之间，挂载方式不一致等特性差异 PVC: 寻找一个合适的PV进行绑定 4.1 概念 PV: Persistent Volume。由管理员设置的存储，它是集群的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期之外。 静态 PV：集群管理员创建一些 PV。它们带有可供集群用户使用的实际存储的细节。它们存储在 k8s api 中，可用于消费 动态 PV：当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim时，集群可能会尝试动态地为 PVC创建卷。此配置基于StorageClasses: PVC必须请求（存储类），并且管理员必须创建并配置该类才能够尽兴动态创建。声明该类为 “” 可有效地禁用其动态配置 PVC: PersistentVolumeClaim。是用户存储的请求。它与Pod 类似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源(CPU &amp; Memory)。PVC 可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载) 4.1.1 绑定mater 中的控制环路监视新的 PVC，寻找匹配的PV（如果可能），并将它们绑定在一起。如果为新的PVC动态调配PV，则该环路将始终将该PV绑定到PVC。否则，用户总会得到他们所请求的存储，但容器可能会超出要求的数量。一旦PV和PVC绑定后，PVC绑定是排他性的，不管它们是如何绑定的，PVC和PV绑定是一一映射的 4.1.2 持久化卷声明的保护PVC 保护的目的是确保 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话，可能导致数据丢失。 当 Pod 状态为 Pending 或 Running 时，PVC 处于活动状态 当启用 PVC 保护 alpha 功能时，如果用户删除一个 pod 正在使用的 PVC，该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 Pod 使用 4.1.3 持久化卷类型 GCEPersistentDisk, AWSElasticBlockStore, AsureFile, AzureDisk, FC(Fibre Channel) FlexVolume, Flocker, NFS, iSCSI, RBD(Ceph Block Device), CephFS Cinder (OpenStack block storage), Glusterfs, VsphereVolume, QuoByte Volumes HostPath, VMware Photon, Portworx Volumes, ScaleIO Volumes, StorageOS 4.1.4 PV 访问模式PV 可以以资源提供者支持的任何方式挂载在主机上。 ReadWriteOnce: 单节点读写模式，RWO ReadOnlyMany: 多节点只读模式，ROX ReadWriteMany: 多节点读写模式， RWX 4.1.5 回收策略 Retain: 保留，需手动回收 Recycle: 基本擦除 （rm -rf /thevolume/*），新版k8s已不支持 Delete: 关联的存储资产将被删除 只有 NFS和HostPath 支持 Recycle 策略 AWS EBS、GCE PD、Azure Disk 和 Cinder 卷 支持 Delete 策略 4.1.6 状态 Available: 空闲资源，还未被绑定 Bound: 已绑定 Released: 解除绑定，但未被集群重新声明 Failed: 自动回收失败 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv-1spec: capacity: storage: 2Gi volumeMode: Filesystem accessModes: - ReadWriteOnce # 同时只允许一个用户读写操作 persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsserevr=4.1 nfs: path: /tmp server: 192.168.31.200 4.2 持久化演示 NFS4.2.1 安装 NFS 服务器123456789101112131415yum install -y nfs-common nfs-utils rpcbindmkdir /nfschmod 666 /nfschown nfsnobody /nfsecho &#x27;/nfs *(rw, no_root_squash,no_all_squash,sync)&#x27; &gt; /etc/exportssystemctl start rpcbindsystemctl start nfsexportfs -rv# 客户端安装yum install -y nfs-utils rpcbindshowmount -e 192.168.31.200mkdir /testmount -t nfs 192.168.31.200:/nfs /test 4.2.2 部署 PV1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: nfspv1spec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs server: 192.168.31.200---apiVersion: v1kind: PersistentVolumemetadata: name: nfspv2spec: capacity: storage: 2Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs2 server: 192.168.31.200---apiVersion: v1kind: PersistentVolumemetadata: name: nfspv3spec: capacity: storage: 3Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs3 server: 192.168.31.200 4.2.3 创建服务并使用 PVCStatefulSet 控制器，必须先要有一个无头服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# app.yamlapiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx ---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx serviceName: nginx # service 必须为无头服务 replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: # 选择条件 accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: nfs resources: requests: storage: 1Gi 1234567891011121314151617181920212223242526272829$ kubectl apply -f pv.yaml$ kubectl apply -f app.yaml$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Bound default/www-web-0 nfs 5m23snfspv2 2Gi RWO Retain Bound default/www-web-1 nfs 5m23snfspv3 3Gi RWO Retain Bound default/www-web-2 nfs 5m23s$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound nfspv1 1Gi RWO nfs 2m53swww-web-1 Bound nfspv2 2Gi RWO nfs 2m50swww-web-2 Bound nfspv3 3Gi RWO nfs 2m45s$ kubectl get sts # statefulsetNAME READY AGEweb 3/3 3m11s$ kubectl get podNAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 3m29sweb-1 1/1 Running 0 3m26sweb-2 1/1 Running 0 3m21s$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d17hnginx ClusterIP None &lt;none&gt; 80/TCP 49m StatefulSet 相关总结： Pod Name(网络标识)：$(statefulset name)-(order)。例如：web-0 DNS 域名：$(podname).(headless server name) Pod 重建，IP改变，但域名不变。例如：web-0.nginx 域名FQDN：$(service name).$(namespace).svc.cluster.local, 其中”cluster.local”为集群的域名。例如：nginx.default.svc.cluster.local 123456789$ kubectl get pod -n kube-system -o wide | grep corednscoredns-66bff467f8-8lb4m 1/1 Running 4 21d 10.244.0.10 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 4 21d 10.244.0.11 k8s-master &lt;none&gt; &lt;none&gt;$ dig -t A nginx.default.svc.cluster.local. @10.244.0.10;; ANSWER SECTION:nginx.default.svc.cluster.local. 30 IN A 10.244.2.53nginx.default.svc.cluster.local. 30 IN A 10.244.1.36nginx.default.svc.cluster.local. 30 IN A 10.244.2.54 FQDN：(Fully Qualified Domain Name)全限定域名：同时带有主机名和域名的名称。（通过符号“.”）例如：主机名是bigserver,域名是mycompany.com,那么FQDN就是bigserver.mycompany.com StatefulSet 启停顺序： 有序部署：如果有多个Pod副本，它们会按顺序创建 0～N-1，并且只有当Pod处于Running和Ready状态，才会创建下一个Pod 有序删除：Pod被删除时，删除顺序从N-1～ 0 有序扩展：扩展时，也必须按顺序进行 StatefulSet 使用场景： 稳定的持久存储 稳定的网络标识，即Pod重新调度后，PodName 和 Hostname 不变 有序部署，有序扩展，具有 init containers 来实现 有序收缩 pv资源释放： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647$ kubectl delete svc nginx$ kubectl delete sts --all$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound nfspv1 1Gi RWO nfs 39mwww-web-1 Bound nfspv2 2Gi RWO nfs 39mwww-web-2 Bound nfspv3 3Gi RWO nfs 39m$ kubectl delete pvc --allpersistentvolumeclaim &quot;www-web-0&quot; deletedpersistentvolumeclaim &quot;www-web-1&quot; deletedpersistentvolumeclaim &quot;www-web-2&quot; deleted$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Released default/www-web-0 nfs 41mnfspv2 2Gi RWO Retain Released default/www-web-1 nfs 41mnfspv3 3Gi RWO Retain Released default/www-web-2 nfs 41m$ kubectl edit pv nfspv1...spec: accessModes: - ReadWriteOnce capacity: storage: 1Gi claimRef: # 删除 apiVersion: v1 kind: PersistentVolumeClaim name: www-web-0 namespace: default resourceVersion: &quot;104634&quot; uid: 57597e18-963d-4ce1-b1d9-880ac0ef3da0 nfs: path: /nfs server: 192.168.31.200 persistentVolumeReclaimPolicy: Retain storageClassName: nfs ...$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Available nfs 46mnfspv2 2Gi RWO Retain Released default/www-web-1 nfs 46mnfspv3 3Gi RWO Retain Released default/www-web-2 nfs 46m","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes Service","slug":"Kubernetes Service","date":"2018-07-05T08:07:23.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/05/Kubernetes Service/","link":"","permalink":"https://elihe2011.github.io/2018/07/05/Kubernetes%20Service/","excerpt":"1. Service 的概念SVC：服务发现 Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 – 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector Service 能够提供负载均衡能力，但只提供了 4 层，而没有 7 层。当需要更多的匹配规则来转发请求时，不支持。","text":"1. Service 的概念SVC：服务发现 Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 – 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector Service 能够提供负载均衡能力，但只提供了 4 层，而没有 7 层。当需要更多的匹配规则来转发请求时，不支持。 2. Service 代理模式分类2.1 VIP 和 Service 代理kube-proxy 进程：负责为 Service 实现一种 VIP（虚拟IP）的形式，代理模式有如下三种： userspace：k8s v1.0 iptables: v1.1 加入，v1.2 默认 ipvs: v1.8 加入，v1.14 默认 Ingress API: v1.1 新增，支持 7 层服务 为什么不使用 round-robin DNS? dns 存在缓存，当有Pod节点故障时，无法自动处理 2.1.1 userspace 2.1.2 iptables 2.1.3 ipvs kube-proxy 监控 Service 和 Endpoints，调用 netlink 接口以相应地创建 ipvs 规则，并定期与 Service 和 Endpoints 对象同步 ipvs 规则，以确保 ipvs 状态与期望一致。访问服务时，流量将被重定向到其中一个后端 Pod 与 iptables 类似，ipvs 于 netfilter 的 hook 功能，但使用hash表作为底层数据结构并在内核空间中工作。这意味着 ipvs 可以快速地重定向流量，并且在同步代理规则时具有更好的性能。 ipvs 为负载均衡算法提供了更多选项： rr: 轮训调度 lc: 最小连接数 dh: 目标hash sh: 源hash sed: 最短期望延迟 nq: 不排队调度 3. Service 的类型 ClusterIp: 默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟IP NodePort: 在ClusterIp 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 &lt;NodeIp&gt;:&lt;NodePort&gt; 来访问服务 LoadBalancer: 在 NodePort 基础上，借助 Cloud Provider 创建一个外部负载均衡器，并将请求转发到 &lt;NodeIp&gt;:&lt;NodePort&gt; ExternalName: 把集群外部的服务引入集群内部，在集群内部直接使用。 3.1 ClusterIpClusterIP 主要在每个 node 节点使用 iptables，将发向 ClusterIp 的流量转发至 kube-proxy，然后 kube-proxy 自己内部实现负载均衡算法，查询到该 Service 下对应 Pod 的地址和端口，进而将数据转发给对应的 Pod 工作原理： apiserver: 用户通过 kubectl 向 apiserver 下发创建 service 的命令，apiserver 接收到请求后，将数据存储到 etcd 中 kube-proxy: 该进程负载监控 Service 和 Pod 的变化 (etcd)，并将变化信息更新到本地 iptables中 iptables: 使用NAT 等技术，将 VIP 的流量转发至 Endpoint 中 12345678910111213141516171819202122232425# myapp-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deployspec: replicas: 3 selector: matchLabels: app: myapp release: stable template: metadata: labels: app: myapp release: stable env: test spec: containers: - name: myapp image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 1234567891011121314# myapp-service-clusterip.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: ClusterIP selector: # 绑定Pod app: myapp release: stable ports: - name: http port: 80 targetPort: 80 操作： 123456789101112131415161718192021222324252627$ kubectl apply -f myapp-deploy.yaml$ kubectl apply -f myapp-service-clusterip.yaml$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyapp-deploy-7779c7f4bb-dv7zh 1/1 Running 0 24s 10.244.2.31 k8s-node02 &lt;none&gt; &lt;none&gt;myapp-deploy-7779c7f4bb-jc8dp 1/1 Running 0 24s 10.244.2.32 k8s-node02 &lt;none&gt; &lt;none&gt;myapp-deploy-7779c7f4bb-lx4kl 1/1 Running 0 24s 10.244.1.25 k8s-node01 &lt;none&gt; &lt;none&gt;$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20dmyapp ClusterIP 10.96.155.51 &lt;none&gt; 80/TCP 42s# 通过 ClusterIp 访问$ curl 10.96.155.51Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;# ipvs转发$ ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 10.96.155.51:80 rr -&gt; 10.244.1.25:80 Masq 1 0 0 -&gt; 10.244.2.31:80 Masq 1 0 0 -&gt; 10.244.2.32:80 Masq 1 0 0 Headless Service: 当不需要负载均衡和独立Service Ip时，可以指定 spec.clusterIP 为 None来创建 Headless Service。这类 Service 并不会分配 Cluster IP，kube-proxy 也不会处理它们，而且平台也不会其对进行负载均衡和路由 123456789101112131415# myapp-service-clusterip-headless.yamlapiVersion: v1kind: Servicemetadata: name: myapp-headlessspec: type: ClusterIP selector: app: myapp release: stable clusterIP: None ports: - name: http port: 80 targetPort: 80 操作： 12345678910111213141516171819202122$ kubectl apply -f myapp-service-clusterip-headless.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp-headless ClusterIP None &lt;none&gt; 80/TCP 31s# 获取 DNS 地址信息$ kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66bff467f8-8lb4m 1/1 Running 2 20d 10.244.0.6 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 2 20d 10.244.0.7 k8s-master &lt;none&gt; &lt;none&gt;# 安装 dig 命令$ yum install -y bind-utils# 解析域名 i 记录$ dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.6;; ANSWER SECTION:myapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.32myapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.31myapp-headless.default.svc.cluster.local. 30 IN A 10.244.1.25 虽然没有svc，但依旧可以通过访问域名，路由到不同Pod上 3.2 NodePort原理：在当前Node的物理机上暴露一个端口，外部可以通过IP:PORT 方式访问集群服务 1234567891011121314# myapp-service-nodeport.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: NodePort selector: app: myapp release: stable ports: - name: http port: 80 targetPort: 80 操作： 1234567891011121314$ kubectl apply -f myapp-service-nodeport.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp NodePort 10.106.31.155 &lt;none&gt; 80:31205/TCP 6s$ curl 192.168.31.40:31205# 访问流程$ ipvsadm -LnTCP 192.168.31.40:31205 rr -&gt; 10.244.1.26:80 Masq 1 0 0 -&gt; 10.244.2.33:80 Masq 1 0 0 -&gt; 10.244.2.34:80 Masq 1 0 3.3 ExternalName该类型的 Service 通过返回 CNAME 和 它的值，可将服务映射到 externalName 字段的内容。ExternalName没有 selector，也未指定任何端口和 Endpoint。相反，它为集群提供访问外部服务方式 12345678# myapp-service-external-name.yamlapiVersion: v1kind: Servicemetadata: name: my-servicespec: type: ExternalName externalName: hub.elihe.io 123456789101112131415$ kubectl apply -f myapp-service-external-name.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmy-service ExternalName &lt;none&gt; hub.elihe.io &lt;none&gt; 21s$ kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66bff467f8-8lb4m 1/1 Running 3 20d 10.244.0.8 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 3 20d 10.244.0.9 k8s-master &lt;none&gt; &lt;none&gt;$ dig -t A my-service.default.svc.cluster.local. @10.244.0.8;; ANSWER SECTION:my-service.default.svc.cluster.local. 30 IN CNAME hub.elihe.io. 4. Service Ingressingress: 进入、入境 4.1 Ingress-Nginx 部署 部署： 12345678910111213141516171819202122232425262728293031323334353637$ wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml$ wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml# 手动下载包$ grep image mandatory.yaml image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0$ docker pull quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0# 导出$ docker save -o nginx-ingress.tar quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0$ gzip nginx-ingress.tar# 上次到每个节点，然后导入镜像$ gunzip nginx-ingress.tar.gz $ docker load -i nginx-ingress.tar # 部署$ kubectl apply -f mandatory.yaml$ kubectl apply -f service-nodeport.yaml$ kubectl get deploy -n ingress-nginxNAME READY UP-TO-DATE AVAILABLE AGEnginx-ingress-controller 1/1 1 1 5m26s$ kubectl get rs -n ingress-nginxNAME DESIRED CURRENT READY AGEnginx-ingress-controller-5bb8fb4bb6 1 1 1 6m10s$ kubectl get pod -n ingress-nginxNAME READY STATUS RESTARTS AGEnginx-ingress-controller-5bb8fb4bb6-6lnb4 1/1 Running 0 6m13s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 5m36s 4.2 Ingress HTTP 代理访问123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ingress-http-1.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-1spec: replicas: 2 selector: matchLabels: app: nginx-1 template: metadata: labels: app: nginx-1 name: nginx-1 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-1spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-1---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-1spec: rules: - host: www1.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-1 servicePort: 80 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ingress-http-2.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-2spec: replicas: 2 selector: matchLabels: app: nginx-2 template: metadata: labels: app: nginx-2 name: nginx-2 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v2 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-2spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-2---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-2spec: rules: - host: www2.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-2 servicePort: 80 操作： 123456789101112131415161718192021222324252627282930313233343536$ kubectl apply -f ingress-http-1.yaml$ kubectl apply -f ingress-http-2.yaml $ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx-svc-1 ClusterIP 10.109.205.227 &lt;none&gt; 80/TCP 32snginx-svc-2 ClusterIP 10.108.96.68 &lt;none&gt; 80/TCP 29s$ curl 10.109.205.227Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ curl 10.108.96.68Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-1 &lt;none&gt; www1.elihe.io 10.107.51.68 80 5m46snginx-2 &lt;none&gt; www2.elihe.io 10.107.51.68 80 116s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 37m$ kubectl get pod -n ingress-nginxNAME READY STATUS RESTARTS AGEnginx-ingress-controller-5bb8fb4bb6-6lnb4 1/1 Running 0 42m# 进入 nginx-ingress-controller 容器, 查询 nginx 配置$ kubectl exec nginx-ingress-controller-5bb8fb4bb6-6lnb4 -n ingress-nginx -it -- /bin/sh/etc/nginx $ cat nginx.conf$ curl http://www1.elihe.io:31319Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ curl http://www2.elihe.io:31319Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt; 4.3 Ingress HTTPS 代理访问创建证书，以及cert存储方式 123$ openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=nginxsvc/O=nginxsvc&quot;$ kubectl create secret tls tls-secret --key tls.key --cert tls.crt 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# ingress-https.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-3spec: replicas: 2 selector: matchLabels: app: nginx-3 template: metadata: labels: app: nginx-3 name: nginx-3 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v3 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-3spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-3---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-httpsspec: tls: - hosts: - www3.elihe.io secretName: tls-secret rules: - host: www3.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-3 servicePort: 80 1234567891011$ kubectl apply -f ingress-https.yaml$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-https &lt;none&gt; www3.elihe.io 10.107.51.68 80, 443 51s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 56mhttps://www.elihe.io:32750/ 4.4 Nginx 进行 BasicAuth1234# 安装apacheyum install -y httpdhtpasswd -c auth elikubectl create secret generic basic-auth --from-file=auth 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# ingress-http-basicauth.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-basicauthspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx name: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-basicauth annotations: nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: basic-auth nginx.ingress.kubernetes.io/auth-realm: &#x27;Authentication Required - eli&#x27;spec: rules: - host: auth.elihe.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 1234567891011$ kubectl apply -f ingress-http-basicauth.yaml $ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-basicauth &lt;none&gt; auth.elihe.io 80 15s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 71mhttp://auth.elihe.io:31319 # 弹出验证窗口 4.5 Nginx 重写 名称 类型 描述 nginx.ingress.kubernetes.io/rewrite-target String 重定向的目标URI nginx.ingress.kubernetes.io/ssl-redirect Boolean 仅支持https nginx.ingress.kubernetes.io/force-ssl-redirect Boolean 强制重定向至https nginx.ingress.kubernetes.io/app-root String 上下文 “/” nginx.ingress.kubernetes.io/use-regex Boolean 使用正则表达式 12345678910111213141516# ingress-http-rewrite.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-rewrite annotations: nginx.ingress.kubernetes.io/rewrite-target: http://baidu.comspec: rules: - host: www1.elihe.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 1234567891011$ kubectl apply -f ingress-http-rewrite.yaml$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-rewrite &lt;none&gt; www1.elihe.io 10.107.51.68 80 14s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 75mhttp://www1.elihe.io:31319 # 重定向到百度","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 资源控制器","slug":"Kubernetes 资源控制器","date":"2018-07-04T06:30:31.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/04/Kubernetes 资源控制器/","link":"","permalink":"https://elihe2011.github.io/2018/07/04/Kubernetes%20%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/","excerpt":"1. Pod分类 自主式Pod：Pod退出，不会被再次创建，因为无管理者（资源控制器）。 控制器管理的Pod： 在控制器的生命周期里，始终要维持 Pod 的副本数目 2. 什么是控制器K8S 中内建了很多 controller (控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为","text":"1. Pod分类 自主式Pod：Pod退出，不会被再次创建，因为无管理者（资源控制器）。 控制器管理的Pod： 在控制器的生命周期里，始终要维持 Pod 的副本数目 2. 什么是控制器K8S 中内建了很多 controller (控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为 3. 控制器类型 ReplicationController 和 ReplicaSet Deployment DaemonSet StatefulSet Job/CronJob Horizontal Pod Autoscalling 3.1 ReplicationController 和 ReplicaSet作用：维持Pod的副本数 RC: 用来确保容器应用的副本数量始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收 RS: RC的的替代者，支持集合式的selector ReplicaSet 123456789101112131415161718192021222324# nginx-rs.yaml#apiVersion: extension/v1beta1 # 统一迁移到apps/v1apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: # Pod metadata: labels: tier: frontend spec: containers: - name: my-nginx image: hub.elihe.io/test/nginx:v1 env: - name: GET_HOST_FROM value: dns ports: - containerPort: 80 123456789101112131415161718192021$ kubectl create -f nginx-rs.yaml$ kubectl get rsNAME DESIRED CURRENT READY AGEfrontend 3 3 2 21s$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSfrontend-cdxws 1/1 Running 0 51s tier=frontendfrontend-fqx6q 1/1 Running 0 51s tier=frontendfrontend-s255j 1/1 Running 0 51s tier=frontend$ kubectl label pod frontend-s255j tier=frontend1 --overwrite=truepod/frontend-s255j labeled$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSfrontend-cdxws 1/1 Running 0 3m25s tier=frontendfrontend-fqx6q 1/1 Running 0 3m25s tier=frontendfrontend-pb5c4 1/1 Running 0 5s tier=frontendfrontend-s255j 1/1 Running 0 3m25s tier=frontend1 # 不再受rs管理 3.2 DeploymentDeployment 为 Pod 和 ReplicaSet 提供一个声明式 (declarative) 方法，用来替代以前的 RC 来方便的管理应用，典型的应用场景包括： 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 (创建一个新的RS，新RS中Pod增1，旧RS的Pod减1) 扩容和缩容 暂停和继续 Deployment 补充：命令式编程和声明式编程 命令式编程：它侧重于如何实现程序，需要把程序的实现结果按照逻辑一步一步写下来 声明式编程：它侧重于定义想要什么，然后告诉计算机 / 引擎，让它帮你去实现。（SQL） 声明式（Deployment）：apply优先 命令式（RS）：create优先 RS 与 Deployment的关联： 部署一个简单的 Nginx 应用 123456789101112131415161718192021# nginx-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployspec: replicas: 3 selector: matchLabels: tier: frontend template: # Pod metadata: labels: app: nginx tier: frontend spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 ports: - containerPort: 80 123456789101112131415$ kubectl apply -f nginx-deploy.yaml --record # record 更新时，记录每一步的状态$ kubectl get deployNAME READY UP-TO-DATE AVAILABLE AGEnginx-deploy 3/3 3 3 22s$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deploy-7775dd49df 3 3 3 72s$ kubectl get podNAME READY STATUS RESTARTS AGEnginx-deploy-7775dd49df-8jlh9 1/1 Running 0 76snginx-deploy-7775dd49df-gjkbj 1/1 Running 0 77snginx-deploy-7775dd49df-ksj9t 1/1 Running 0 76s 1234567891011121314151617181920# 扩容$ kubectl scale deployment nginx-deploy --replicas=5# 更新镜像, 会自动创建rs$ kubectl set image deployment/nginx-deploy nginx=hub.elihe.io/test/nginx:v2# 回滚$ kubectl rollout undo deployment/nginx-deploy# 查询回滚状态$ kubectl rollout status deployment/nginx-deploy# 查看历史版本 (创建时，加--record，会显示描述)$ kubectl rollout history deployment/nginx-deploy# 回滚到某个历史版本$ kubectl rollout undo deployment/nginx-deploy --to-revision=2# 暂停更新$ kubectl rollout pause deployment/nginx-deploy 版本更新策略：默认25%替换 清理历史版本：可以通过设置 .spec.revisionHistoryLimit 来指定 Deployment 最多保留多少个 revision 历史记录。默认保留所有的revision，如果该项设置为0，Deployment将不能被回退 3.3 DaemonSetDaemonSet 确保全部（或一些）Node上运行一个Pod副本。当有Node加入集群时，也会为它们新增一个Pod。当Node从集群移除时，这些Pod也会被回收。删除DaemonSet 将会删除它创建的所有 Pod。 使用DaemonSet 的一些典型场景： 运行集群存储 daemon，例如在每个Node上运行 glusterd, ceph 在每个Node上运行日志收集 daemon，例如 fluentd, logstash 在每个Node上运行监控 daemon, 例如 Promethesus Node Exporter, collectd, Datalog代理，New Replic代理，Ganglia, gmond 123456789101112131415161718apiVersion: apps/v1kind: DaemonSetmetadata: name: daemonset labels: app: daemonsetspec: selector: matchLabels: tier: daemonset-example template: metadata: labels: tier: daemonset-example spec: containers: - name: daemonset-example image: hub.elihe.io/test/nginx:v1 12345678910$ kubectl create -f nginx-daemonset.yaml$ kubectl get dsNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEdaemonset 2 2 2 2 2 &lt;none&gt; 23s$ kubectl get podNAME READY STATUS RESTARTS AGEdaemonset-msnrn 1/1 Running 0 86sdaemonset-nw5t9 1/1 Running 0 86s 3.4 JobJob 仅执行一次的任务，它确保批处理任务的一个或多个 Pod 成功结束。 特殊说明： spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个Pod时，默认Pod成功运行后 Job 结束 .spec.completions 标志 Job 结束需要运行的Pod个数，默认为1 .spec.parallelism 标志并行运行的 Pod 个数，默认为1 .spec.activeDeadlineSeconds 标志失败 Pod的重试最大时间，超过这个时间将不会再重试 1234567891011121314apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [&quot;perl&quot;, &quot;-Mbignum-bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] restartPolicy: Never 123456789101112$ kubectl create -f job.yaml job.batch/pi created$ kubectl get jobNAME COMPLETIONS DURATION AGEpi 0/1 10s 10s$ kubectl get podNAME READY STATUS RESTARTS AGEpi-779v9 0/1 ContainerCreating 0 14s$ kubectl describe pod pi-779v9 3.5 CronJobCornJob 管理基于时间的 Job，即： 在给定时间点只执行一次 周期性地在给定时间点运行 特殊说明： .spec.schedule: 调度，必选字段，格式同Cron spec.jobTemplate: 格式同 Pod .spec.startingDeadlineSeconds: 启动Job的期限，可选字段。如果因为任何原因而错过了被调度的时间，那么错过了执行时间的Job被认为是失败的 .spec.concurrencyPolicy: 并发策略，可选字段 Allow: 默认，允许并发运行 Job Forbid: 禁止并发Job，只能顺序执行 Replace: 用新的Job替换当前正在运行的 Job .spec.suspend: 挂起，可选字段，如果设置为true，后续所有执行都会被挂起。默认为fasle .spec.successfulJobsHistoryLimit 和 .spec.failedJobsHistoryLimit: 历史限制，可选字段。它们指定了可以保留多少完成和失败的Job。默认值为3和1。如果设置为0，相关类型的Job完成后，将不会保留 123456789101112131415161718apiVersion: batch/v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure 1234567891011121314$ kubectl create -f cronjob.yaml cronjob.batch/hello created$ kubectl get cjNAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGEhello */1 * * * * False 0 52s 2m24s$ kubectl get jobNAME COMPLETIONS DURATION AGEhello-1602576000 1/1 17s 49s$ kubectl get podNAME READY STATUS RESTARTS AGEhello-1602576000-r6mgh 0/1 Completed 0 52 3.6 StatefulSet （有状态服务）StatefulSet 作为 Controller 为 Pod 提供的唯一标识，它可以确保部署和 scale 的顺序 StatefulSet 解决了有状态服务的问题，其应用场景包括： 稳定的持久化存储，即 Pod 重新调度后，还能够访问到相同的持久化数据，基于PVC来实现 稳定的网络标识，即 Pod 重新调度后其 PodName 和 HostName 不变，基于 Headless Service （即没有Cluster IP的Service）来实现 有序部署、有序扩展，即Pod是有序的，在部署和扩展时，要按照定义的顺序依次进行 (即从 0 到N - 1, 在下一个Pod 运行前，所有 Pod 必须是 Running 和 Ready 状态)，基于 Init Containers 来实现 有序收缩、有序删除（即从 N-1 到 0） 3.7 Horizontal Pod AutoScalling应用的资源使用率通常有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，HPA 提供了 Pod 的水平自动缩放功能 通过控制RS，Deployment 来实现自动缩放","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 资源清单","slug":"Kubernetes 资源清单","date":"2018-07-03T12:37:13.000Z","updated":"2021-10-27T11:14:09.614Z","comments":true,"path":"2018/07/03/Kubernetes 资源清单/","link":"","permalink":"https://elihe2011.github.io/2018/07/03/Kubernetes%20%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95/","excerpt":"1. K8S 资源k8s中，所有的内容都被抽象为资源，资源实例化后，称为对象 集群资源分类： 名称空间级别: 只在本名称空间下可见 集群级别: role, 不管在什么名称空间小，均可见 元数据级别: HPA(可以CPU利用率平滑扩展)","text":"1. K8S 资源k8s中，所有的内容都被抽象为资源，资源实例化后，称为对象 集群资源分类： 名称空间级别: 只在本名称空间下可见 集群级别: role, 不管在什么名称空间小，均可见 元数据级别: HPA(可以CPU利用率平滑扩展) 1.1 工作负载 (workload) Pod: 最小资源，共享网络栈、存储卷等 ReplicaSet：调度器，管理Pod的创建，通过标签的选择去控制Pod的副本数 Deployment: 控制器，通过控制RS的创建，去创建Pod StatefulSet：有状态服务管理器 DaemonSet：可在每个节点都运行一个Pod组件 Job: 批量工作 CronJob: 定时或轮训工作 1.2 服务发现及负载均衡 Service Ingress 1.3 配置与存储 Volume: 存储卷 CSI: 容器存储接口，可扩展第三方存储设备 ConfigMap: 配置中心 Secret: 敏感数据保存 DownwardAPI: 外部环境中的信息输出给容器 1.4 集群不指定名称空间，所有节点均能访问：role Namespace Node Role ClusterRole RoleBinding ClusterRoleBinding 1.5 元数据 HPA PodTemplate LimitRange 1.6 用法查询123kubectl explain podkubectl explain pod.spec 2. Pod 生命周期 1）kubectl –&gt; apiserver –&gt; CRI –&gt; kubelet 环境初始化 2）启动Pause容器: 初始化网络和数据卷 3）init C初始化。多个initC时，必须串行执行，且每个必须执行成功才向下走 4）Main C，开始运行时，启动Start命令/脚本；结束时，执行Stop命令(做哪些清理操作等) 5）Readiness 就绪检测：若干秒后，进行是否就绪的探测。只有当Readiness成功后，Pod才会显示Ready状态 6）Liveness 生存检测：探测Main C中的进程是否正常，不正常则执行重启、删除等命令 2.1 InitC 容器即 Infra 容器，其镜像是一个用汇编写成，永远处于“pause”状态的容器，解压后大小100~200KB，运行时占用极小的资源 作用： initC 容器可作为 Pod 中其他容器的初始化工具 出于安全考虑，将应用容器中的某些实用工具（python, awk等）单独拆开放入initC容器 应用容器的启动是并行的，而 initC 容器可阻塞应用容器的启动，直到满足一些先决条件 实例： 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: v1kind: Podmetadata: name: test-initc labels: app: myappspec: initContainers: - name: init-myservice image: busybox:1.28.4 command: [&#x27;sh&#x27;,&#x27;-c&#x27;,&#x27;until nslookup myservice;do echo waiting for myservice;sleep 2; done;&#x27;] - name: init-mydb image: busybox:1.28.4 command: [&#x27;sh&#x27;,&#x27;-c&#x27;,&#x27;until nslookup mydb;do echo waiting for mydb;sleep 2;done;&#x27;] containers: - name: mypod image: busybox:1.28.4 command: [&#x27;sh&#x27;,&#x27;-c&#x27;,&#x27;echo The app is running!&amp;&amp; sleep 3600&#x27;] ---apiVersion: v1kind: Servicemetadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9001---apiVersion: v1kind: Servicemetadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9002 2.2 容器探针健康状态探针： ReadinessProbe: 判断容器服务是否可用，成功显示ready， 失败不触发重启 LivenessProbe: 判断容器是否存活，如果探测到不健康，将触发重启策略。如果未配置该探针，则永远返回成功. 探针的三种实现方式： ExecAction: 容器内执行命令，返回码等于0则认为成功 TCPSocketAction: 在指定端口上的容器IP地址进行TCP检查，如果端口打开，则认为成功 HTTPGetAction: 在指定端口和路径的容器IP地址执行HTTP GET请求，状态码在 [200, 399] 表示成功 探测结果： success failed：失败，按策略处理 unknown：诊断失败，但不会采取任何行动 2.2.1 就绪检测检测失败，状态非Ready，但不会重启容器 spec.containers[].readinessProbe.httpGet 12345678910111213141516# readiness-probe-httpget.yaml apiVersion: v1kind: Podmetadata: name: readiness-httpget-podspec: containers: - name: readiness-httpget-container image: nginx imagePullPolicy: IfNotPresent readinessProbe: httpGet: port: 80 path: /index1.html initialDelaySeconds: 1 periodSeconds: 3 123456789101112131415161718192021222324$ kubectl create -f readiness-probe-httpget.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 0/1 Running 0 9s$ kubectl describe pod readiness-httpget-podWarning Unhealthy 1s (x3 over 7s) kubelet, k8s-node01 Readiness probe failed: HTTP probe failed with statuscode: 404# 进入容器$ kubectl exec readiness-httpget-pod -it -- /bin/sh# cd /usr/share/nginx/html# ls -altotal 8drwxr-xr-x 2 root root 40 Aug 14 00:36 .drwxr-xr-x 3 root root 18 Aug 14 00:36 ..-rw-r--r-- 1 root root 494 Aug 11 14:50 50x.html-rw-r--r-- 1 root root 612 Aug 11 14:50 index.html# echo &quot;hello, i&#x27;am index1.html&quot; &gt; index1.html# logout$ kubectl get podNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 1/1 Running 0 2m57s 2.2.2 存活检测检测失败，直接重启Pod spec.containers[].livenessProbe.exec 12345678910111213141516# liveness-prob-exec.yaml apiVersion: v1kind: Podmetadata: name: liveness-exec-podspec: containers: - name: liveness-exec-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;touch /tmp/abc.txt; sleep 60; rm -f /tmp/abc.txt; sleep 3600&quot;] livenessProbe: exec: command: [&quot;test&quot;, &quot;-e&quot;, &quot;/tmp/abc.txt&quot;] initialDelaySeconds: 1 periodSeconds: 3 123456789$ kubectl create -f liveness-prob-exec.yaml # 失败，重启自动重启$ kubectl get pod -wNAME READY STATUS RESTARTS AGEliveness-exec-pod 1/1 Running 0 26sliveness-exec-pod 1/1 Running 1 2m58sliveness-exec-pod 1/1 Running 2 3m35sliveness-exec-pod 1/1 Running 3 5m15s spec.containers[].livenessProbe.httpGet 12345678910111213141516apiVersion: v1kind: Podmetadata: name: liveness-httpget-podspec: containers: - name: liveness-httpget image: nginx imagePullPolicy: IfNotPresent livenessProbe: httpGet: port: 80 path: /index.html initialDelaySeconds: 1 periodSeconds: 3 timeoutSeconds: 10 # 超时处理 spec.containers[].livenessProbe.tcpSocket 1234567891011121314apiVersion: v1kind: Podmetadata: name: tcpsocket-podspec: containers: - name: redis image: redis livenessProbe: tcpSocket: port: 6379 initialDelaySeconds: 5 periodSeconds: 3 timeoutSeconds: 1 2.3 启动 &amp; 退出spec.containers[].lifecycle.postStart|preStop 123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello postStart &gt; /tmp/hello.txt&quot;] preStop: exec: command: [&quot;/usr/sbin/nginx&quot;, &quot;-s&quot;, &quot;quit&quot;] 2.4 Pod 状态值 Pending：Pod已被k8s系统接受，但有一个或多个镜像容器尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间。 Running: Pod已经绑定到一个节点上了，Pod中的所有容器已被创建 Succeeded: Pod中的所有容器都被成功终止，且不会再重启 Failed: Pod中的所有容器都已终止，但至少有一个容器以非0返回值退出 Unknown: 未知原因无法获取Pod状态，通常是因为与Pod所在主机的通信失败 3. 注入卷Projected Volume: 不是为了存放容器里的数据，也不是用于容器和宿主机之间的数据交换，而是为了给容器提供预先定义好的数据 常见的 Projected Volume: Secret ConfigMap Downward API ServiceAccountToken 3.1 Secret作用：把 Pod 想要访问的加密数据放入 etcd 中 类型： 内置类型 用法 Opaque 用户定义的任意数据 kubernetes.io/service-account-token 服务账号令牌 kubernetes.io/dockercfg ~/.dockercfg 文件的序列化形式 kubernetes.io/dockerconfigjson ~/.docker/config.json 文件的序列化形式 kubernetes.io/basic-auth 用于基本身份认证的凭据 kubernetes.io/ssh-auth 用于 SSH 身份认证的凭据 kubernetes.io/tls 用于 TLS 客户端或者服务器端的数据 bootstrap.kubernetes.io/token 启动引导令牌数据 3.1.1 Opaque创建 secret： 1234567891011121314# 方法1：$ kubectl apply -f - &lt;&lt;EOFapiVersion: v1kind: Secretmetadata: name: mysecrettype: OpaquestringData: user: root pass: &quot;123456&quot;EOF# 方法2：$ kubectl create secret generic my-secret --from-literal=user=root --from-literal=pass=123456 使用 secret： 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: pod-secret-volumespec: containers: - name: secret-volume image: busybox args: - sleep - &quot;86400&quot; volumeMounts: - name: mysql-cred mountPath: &quot;/projected-volume&quot; readOnly: true volumes: - name: mysql-cred secret: secretName: mysecret items: - key: user path: cred/user - key: pass path: cred/pass 检查数据挂载： 12$ kubectl exec -it pod-secret-volume -- cat /projected-volume/cred/pass123456 3.1.2 TLS12345678910apiVersion: v1kind: Secretmetadata: name: secret-tlstype: kubernetes.io/tlsdata: tls.crt: | MIIC2DCCAcCgAwIBAgIBATANBgkqh ... tls.key: | MIIEpgIBAAKCAQEA7yn3bRHQ5FHMQ ... 3.2 ConfigMap作用：保存无需加密的，应用所需的配置信息 1234567891011121314151617181920212223242526272829303132333435apiVersion: v1kind: ConfigMapmetadata: name: special-configdata: special.how: very---apiVersion: v1kind: ConfigMapmetadata: name: env-configdata: log_level: INFO---apiVersion: v1kind: Podmetadata: name: pod-configmapspec: containers: - name: cm-container image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: LOG_LEVEL valueFrom: configMapKeyRef: name: env-config key: log_level restartPolicy: Never 3.3 DownwardAPI作用：让 Pod 中的容器，能够直接获取该 Pod API 对象本身的信息 12345678910111213141516171819202122232425262728293031323334353637apiVersion: v1kind: Podmetadata: name: downward-api-volume labels: zone: china-standard-time cluster: taos-1 rack: rack-22 annotations: version: &quot;1.2&quot; builder: gopherspec: containers: - name: busybox image: busybox command: [&quot;sh&quot;, &quot;-c&quot;] args: - while true; do if [[ -e /etc/podinfo/labels ]]; then echo -en &#x27;\\n\\n&#x27;; cat /etc/podinfo/labels; fi; if [[ -e /etc/podinfo/annotations ]]; then echo -en &#x27;\\n\\n&#x27;; cat /etc/podinfo/annotations; fi; sleep 5; done; volumeMounts: - name: podinfo mountPath: /etc/podinfo volumes: - name: podinfo downwardAPI: items: - path: &quot;labels&quot; fieldRef: fieldPath: metadata.labels - path: &quot;annotations&quot; fieldRef: fieldPath: metadata.annotations 环境变量方式： 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: downward-api-envspec: containers: - name: busybox image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_IP valueFrom: fieldRef: fieldPath: status.podIP 3.4 ServiceAccountTokenService Account 是 k8s 的一种内置”服务账户“，它绑定了一个特殊的 Secret，即 ServiceAccountToken, 保存了授权信息等内容。任何在 k8s 集群上运行的应用，都必须使用 ServiceAccountToken 中的授权信息，才能合法访问 API Server. 12345678910111213141516$ kubectl describe pod nginxContainers: nginx: ... Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-stqtv (ro)Volumes: kube-api-access-stqtv: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: &lt;nil&gt; DownwardAPI: true$ kubectl exec -it nginx -- ls /run/secrets/kubernetes.io/serviceaccountca.crt namespace token","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 集群安装","slug":"Kubernetes 集群安装","date":"2018-07-02T13:44:16.000Z","updated":"2021-06-22T10:50:49.718Z","comments":true,"path":"2018/07/02/Kubernetes 集群安装/","link":"","permalink":"https://elihe2011.github.io/2018/07/02/Kubernetes%20%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"1. 安装准备1.1 设置主机名123456# masterhostnamectl set-hostname k8s-master# nodehostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02","text":"1. 安装准备1.1 设置主机名123456# masterhostnamectl set-hostname k8s-master# nodehostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02 1.2 hostname相互解析1234vi /etc/hosts192.168.31.40 k8s-master192.168.31.41 k8s-node01192.168.31.42 k8s-node02 1.3 关闭虚拟内存 swap1swapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab 1.4 调整内核参数1234567891011121314151617181920cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_tw_recycle=0vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它vm.overcommit_memory=1 # 不检查物理内存是否够用fs.inotify.max_user_instances=8192 # 开启 OOMvm.panic_on_oom=0 fs.inotify.max_user_watches=1048576fs.file-max=52706963fs.nr_open=52706963net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max=2310720EOFsysctl -p /etc/sysctl.d/kubernetes.conf# 问题 sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directorymodprobe br_netfilter 1.5 升级内核123456789101112131415161718uname -r3.10.0-1127.el7.x86_64# 内核reporpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm# 安装新内核yum --enablerepo=elrepo-kernel install -y kernel-lt# 检查启动menu是否已加入新内核版本cat /boot/grub2/grub.cfg | grep elrepo | grep menuentrymenuentry &#x27;CentOS Linux (4.4.236-1.el7.elrepo.x86_64) 7 (Core)&#x27; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &#x27;gnulinux-3.10.0-1127.el7.x86_64-advanced-3ec6d414-2b79-482d-9643-b7baeb42cb3d&#x27; &#123;# 开机从新内核启动grub2-set-default &#x27;CentOS Linux (4.4.236-1.el7.elrepo.x86_64) 7 (Core)&#x27;# 重启系统reboot 1.6 开启 ipvs (kube-proxy需要)1234567891011121314modprobe br_netfiltercat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.moduleslsmod | grep -e ip_vs -e nf_conntrack_ipv4 2. Kubeadm 部署安装2.1 安装kubeadm12345678910111213141516cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 查询版本yum list kubelet --showduplicatesyum install -y kubeadm-1.18.6 kubelet-1.18.6 kubectl-1.18.6systemctl enable kubelet kubelet: 运行在集群的所有节点上，用于启动Pod和容器对象的工具 kubeadm: 初始化集群，启动集群的命令工具 kubectl: 和集群通信的命令行工具。可以部署和管理应用，查看各种资源，创建、删除和更新各种组建 2.2 下载k8s镜像默认镜像放google服务器上，国内使用aliyun服务器 123456789101112$ vi load_kube_images.sh#!/bin/bashurl=registry.aliyuncs.com/google_containersversion=v1.18.6images=(`kubeadm config images list --kubernetes-version=$version|awk -F &#x27;/&#x27; &#x27;&#123;print $2&#125;&#x27;`)for imagename in $&#123;images[@]&#125; ; do docker pull $url/$imagename docker tag $url/$imagename k8s.gcr.io/$imagename docker rmi -f $url/$imagenamedone$ chmod u+x load_kube_images.sh &amp;&amp; bash load_kube_images.sh 2.3 初始化主节点 (k8s-master)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 默认配置$ kubeadm config print init-defaults &gt; kubeadm-config.yaml$ vi kubeadm-config.yaml...localAPIEndpoint: advertiseAddress: 192.168.31.40 # 修改为本机IP bindPort: 6443...kubernetesVersion: v1.18.6 # 版本必须匹配networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 # 新增 serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;# 新增如下，修改kube-proxy协议为ipvs---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs# 执行初始化$ kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log...[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.31.40:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1c02156e6d3d6b85938e20f0473af2dffff7a22a6c67387aba97da38f0952386 # 如果发生错误，重置后重新init$ kubeadm reset# 执行初始化后的提示步骤$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config# 获取节点$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 3m31s v1.18.6 2.4 部署网络 (k8s-master)1234567891011121314151617181920212223# 解决DNS污染问题 (不推荐)$ echo &quot;199.232.68.133 raw.githubusercontent.com&quot; &gt;&gt; /etc/hosts # 尽量用nsloop查询，将dns配对$ yum install -y bind-utils$ nslookup raw.githubusercontent.com$ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml$ kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds created$ kubectl get pod -n kube-systemkube-flannel-ds-4dlvt 1/1 Running 0 54s$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master Ready master 22m v1.18.6 2.5 工作节点加入集群 (k8s-node1, k8s-node2)123# k8s-master节点下 kubeadm init 的运行日志最后行$ kubeadm join 192.168.31.40:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1c02156e6d3d6b85938e20f0473af2dffff7a22a6c67387aba97da38f0952386 如果未找到，主节点(k8s-master) 执行下列操作获取令牌 1234567891011$ kubeadm token listTOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS7114t2.imdu2ivf56cbjk38 1h 2020-09-22T22:31:42+08:00 &lt;none&gt; Proxy for managing TTL for the kubeadm-certs secret &lt;none&gt;abcdef.0123456789abcdef 23h 2020-09-23T20:31:43+08:00 authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-token# 令牌过期$ kubeadm token create# 生成密钥$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;0daca31a7b9820fc60eaa28cacc25ee3a16c7af5c6e8104d91bf709bf2e741bc 2.6 查看所有节点12345678910111213# kubectl 命令补齐yum install -y bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profilekubectl get nodekubectl get pod -n kube-system# 当前各个节点的详细情况kubectl get pod -n kube-system -o wide 2.7 问题：组件controller-manager 和scheduler状态 Unhealthy1234567$ kubectl get csNAME STATUS MESSAGE ERRORscheduler Unhealthy Get http://127.0.0.1:10251/healthz: dial tcp 127.0.0.1:10251: connect: connection refused controller-manager Unhealthy Get http://127.0.0.1:10252/healthz: dial tcp 127.0.0.1:10252: connect: connection refused etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; $ netstat -an | grep -e 10251 -e 10252 解决方法: 检查kube-scheduler和kube-controller-manager组件配置是否禁用了非安全端口 123456789101112131415161718192021222324252627282930$ vi /etc/kubernetes/manifests/kube-scheduler.yaml ...spec: containers: - command: - kube-scheduler - --kubeconfig=/etc/kubernetes/scheduler.conf - --leader-elect=true #- --port=0 # 注释掉 image: k8s.gcr.io/kube-scheduler:v1.18.6$ vi /etc/kubernetes/manifests/kube-controller-manager.yaml...spec: containers: - command: - kube-controller-manager - --node-cidr-mask-size=24 #- --port=0 # 注释掉 - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt# 重启kubelet$ systemctl restart kubelet# 再次查询状态$ kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 6. k8s主节点测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788vi nginx.yml# API 版本号apiVersion: apps/v1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Deploymentmetadata: # Kind 的名称 name: nginx-appspec: selector: matchLabels: # 容器标签的名字，发布 Service 时，selector 需要和这里对应 app: nginx # 部署的实例数量 replicas: 2 template: metadata: labels: app: nginx spec: # 配置容器，数组类型，说明可以配置多个容器 containers: # 容器名称 - name: nginx # 容器镜像 image: hub.elihe.io/library/nginx:v1 # 只有镜像不存在时，才会进行镜像拉取 imagePullPolicy: IfNotPresent ports: # Pod 端口 - containerPort: 80 kubectl apply -f nginx.ymlkubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-app-76b8bd9478-z74zq 1/1 Running 0 93s 10.244.1.2 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-z8zt6 1/1 Running 0 93s 10.244.2.5 k8s-node01 &lt;none&gt; &lt;none&gt;kubectl delete pod nginx-app-76b8bd9478-z74zqkubectl get pod -o wide# 变更数量kubectl scale --replicas=3 deployment/nginx-appkubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-app-76b8bd9478-6gkq6 1/1 Running 0 4m25s 10.244.1.3 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-d7p6r 1/1 Running 0 13s 10.244.1.4 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-z8zt6 1/1 Running 0 6m37s 10.244.2.5 k8s-node01 &lt;none&gt; &lt;none&gt;kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEnginx-app 3/3 3 3 12mkubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16h# 开放访问端口kubectl expose deployment nginx-app --port=3000 --target-port=80kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16hnginx-app ClusterIP 10.104.89.46 &lt;none&gt; 3000/TCP 9s# 测试端口转发curl -i 10.104.89.46:3000ipvsadm -LnTCP 10.104.89.46:3000 rr -&gt; 10.244.1.3:80 Masq 1 0 1 -&gt; 10.244.1.4:80 Masq 1 0 1 -&gt; 10.244.2.5:80 Masq 1 0 1 # 开放外部访问nginxkubectl edit svc nginx-apptype: NodePort #ClusterIPkubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16hnginx-app NodePort 10.104.89.46 &lt;none&gt; 3000:31057/TCP 8m44shttp://192.168.31.40:31057/http://192.168.31.41:31057/http://192.168.31.42:31057/","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 基础概念","slug":"Kubernetes 基础概念","date":"2018-07-01T08:27:43.000Z","updated":"2021-06-22T10:50:49.718Z","comments":true,"path":"2018/07/01/Kubernetes 基础概念/","link":"","permalink":"https://elihe2011.github.io/2018/07/01/Kubernetes%20%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","excerpt":"1. 架构Kubernetes特点： 轻量级：消耗资源小 开源 弹性伸缩 负载均衡：IPVS 1.1 核心组件 etcd: 保存整个集群的状态 apiserver: 资源操作的唯一入口，提供了认证、授权、访问控制、API注册和发现等机制 controller manager: 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler: 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet: 负责维护容器的生命周期、Volume(CVI) 和网络(CNI)的管理 container runtime: 负责镜像管理以及Pod和容器的真正运行 (CRI) kube-proxy: 负责为Service提供cluster内部的服务发现和负载均衡 （四层） iptables ipvs etcd: 可信赖的分布式键值对存储服务，为整个分布式集群存储关键数据，协助分布式集群的正常运转。","text":"1. 架构Kubernetes特点： 轻量级：消耗资源小 开源 弹性伸缩 负载均衡：IPVS 1.1 核心组件 etcd: 保存整个集群的状态 apiserver: 资源操作的唯一入口，提供了认证、授权、访问控制、API注册和发现等机制 controller manager: 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler: 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet: 负责维护容器的生命周期、Volume(CVI) 和网络(CNI)的管理 container runtime: 负责镜像管理以及Pod和容器的真正运行 (CRI) kube-proxy: 负责为Service提供cluster内部的服务发现和负载均衡 （四层） iptables ipvs etcd: 可信赖的分布式键值对存储服务，为整个分布式集群存储关键数据，协助分布式集群的正常运转。 1.2 Add-ons: kube-dns: 负责为整个集群提供DNS服务（CoreDNS, 可以为集群中的SVC创建一个域名IP对应关系解析，即A记录) Ingress Controller: 为服务提供外网入口 （七层代理） Dashboard: 提供GUI Federation: 提供跨可用区的集群 Prometheus：监控 ELK：集群日志统一分析接入平台 2. Pod 共享存储 共享网络 2.1 Pod 控制器类型 RelicationController &amp; ReplicaSet &amp; Deployment 2.1.1 ReplicationController &amp; ReplicaSet &amp; Deployment ReplicationController: 用来确保容器的应用副本数始终是用户定义的副本数。即如果有容器异常退出，会创建新的Pod来代替；如果多出来，自动回收。 ReplicaSet: 新版k8s中建议使用ReplicaSet取代RelocationController，它支持集合式selector Deployment: 用来自动管理ReplicaSet。ReplicaSet不支持rolling-update，但Deployment支持。 2.1.2 HPA （HorizontalPodAutoScale)HPA仅适用于Deployment和ReplicaSet，在v1版本中仅支持根据Pod的CPU利用率扩/缩容，在v1alpha中，支持根据内存和用户自定义的metric扩/缩容 2.1.3 StatefulSet解决有状态服务的问题（Deployment和ReplicaSet只支持无状态服务），应用场景： 稳定的持久化存储，即Pod重新调度后还是能够访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后，其PodName和HostName不变，基于Headless Service (即没有Cluster IP的Service)来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或扩展的时候，要依据定义的顺序依次进程（即从0到N-1，在下一个Pod运行之前，所有之前的Pod必须是Running和Ready状态)，基于init containers来实现 有序收缩，有序删除（即从N-1到0） 2.1.4 DaemonSet确保全部（或部分）Node上运行一个Pod副本。当有Node加入集群时，也会为它们新增一个Pod；当有Node从集群移除时，这些Pod会被回收。删除DaemonSet，将会删除它创建的所有Pod。 一些典型的DaemonSet用法： 运行集群存储daemon，例如每个Node上运行glusterd、ceph 在每个Node上进行日志收集daemon，例如fluentd、logstash 在每个Node上运行监控daemon，例如Prometheus Node Exporter 2.1.5 Job &amp; CronJob Job: 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束 CronJob：定时Job 在给定时间点运行一次 周期性地在给定时间点运行 2.2 服务发现Service 通过标签选择到Pod 3. 网络通讯模式k8s 的网络模型假定了所有Pod都在一个可以直接连通的扁平化网络空间中。在GCE(Google Compute Engine) 里面是现成的网络模型。但在私有云中搭建k8s集群，一般需要我们自己去实现这个扁平化网络模型。 扁平化网络：所有的Pod可以通过IP“直接到达” 3.1 通讯模式 同一个Pod内的多个容器之间：lo 各Pod之间的通信: Overlay Network Pod与Service之间的通讯：各节点的iptables规则 3.2 FlannelFlannel是CoreOS团队针对k8s设计的一种网络规划服务。它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址，而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network)，通过这个网络，将数据包原封不动地传递到模板容器内。 etcd为Flannel提供服务： 存储Flannel可分配的IP地址段资源 监控etcd中每个Pod的实际地址，并在内存中创建和维护Pod节点路由表 3.3 总结：不同情况下网络的通信方式 同一个Pod内部通信：共享同一个网络命名空间，共享同一个Linux协议栈。lo网卡 Pod1至Pod2: 同一台主机：由Docker0网桥转发，不需要经过Flannel 不同主机：将Pod的IP和Node的IP关联起来，通过这个关联让Pod可以相互访问。涉及网络封包和拆包，较消耗资源。 Pod至Service网络：基于性能考虑，全部为iptables/LVS维护和转发 Pod到外网：Pod向外网发送请求，查找路由表，转发数据包到宿主机的网卡，宿主机网卡完成路由选择后，iptables执行Masquerade，把源IP更改为宿主网卡的IP，然后向外网服务器发送请求 外网访问Pod：Service 3.4 组件通讯示意图 节点网络：物理的网络 Pod网络：虚拟网络 Service网络：虚拟网络","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Docker 私有仓库","slug":"Docker 私有仓库","date":"2018-06-17T08:41:09.000Z","updated":"2021-06-22T10:50:49.717Z","comments":true,"path":"2018/06/17/Docker 私有仓库/","link":"","permalink":"https://elihe2011.github.io/2018/06/17/Docker%20%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","excerpt":"1. 安装Docker详见 Docker 安装 2. 安装Docker Compose123curl -L &quot;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose","text":"1. 安装Docker详见 Docker 安装 2. 安装Docker Compose123curl -L &quot;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose 3. 安装Harbor下载地址：https://github.com/goharbor/harbor/releases 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152wget https://github.com/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgztar zxvf harbor-offline-installer-v2.0.2.tgzmv harbor /usr/local/cd /usr/local/harborcp harbor.yml.tmpl harbor.ymlvi harbor.ymlhostname: hub.elihe.iohttps: port: 443 # The path of cert and key files for nginx certificate: /data/cert/server.crt private_key: /data/cert/server.keymkdir -p /data/cert &amp;&amp; cd /data/cert# 私钥openssl genrsa -des3 -out server.key 2048# 证书请求openssl req -new -key server.key -out server.csr# 备份私钥cp server.key server.key.org# 转换成证书 （去除设置的密码）openssl rsa -in server.key.org -out server.key# 签名openssl x509 -req -days 3650 -in server.csr -signkey server.key -out server.crt# 证书赋予执行权限chmod a+x *# 安装harborcd /usr/local/harbor./install.sh# 启动 docker-composedocker-compose start# 开机启动 docker-compose# 启动不一定成功，废弃vi /etc/rc.d/rc.local/usr/local/bin/docker-compose -f /usr/local/harbor/docker-compose.yml up -d# 按这种方式crontab -e@reboot sleep 60 &amp;&amp; /usr/local/bin/docker-compose -f /usr/local/harbor/docker-compose.yml up -d 4. Harbor服务器和客户端配置1234567891011# 添加域名解析echo &quot;192.168.31.200 hub.elihe.io&quot; &gt;&gt; /etc/hosts# 配置daemon.jsonvi /etc/docker/daemon.json&#123; &quot;insecure-registries&quot;: [&quot;https://hub.elihe.io&quot;]&#125;# 重启dockersystemctl daemon-reload &amp;&amp; systemctl restart docker 5. 访问Harbor1234567891011121314151617181920https://hub.elihe.io admin/Harbor12345docker login https://hub.elihe.io docker pull nginxdocker tag nginx hub.elihe.io/library/nginx:v1 cat index.html echo &#x27;Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;&#x27; &gt; index.htmlcat &gt; hostname.html &lt;&lt;EOF&lt;script type=&quot;text/javascript&quot;&gt;document.write(location.hostname);&lt;/script&gt;EOFdocker commit 7e7553b2204f hub.elihe.io/library/nginx:v1docker push hub.elihe.io/library/nginx:v1","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 网络","slug":"Docker 网络","date":"2018-06-16T07:22:58.000Z","updated":"2021-06-22T10:50:49.717Z","comments":true,"path":"2018/06/16/Docker 网络/","link":"","permalink":"https://elihe2011.github.io/2018/06/16/Docker%20%E7%BD%91%E7%BB%9C/","excerpt":"","text":"1. 通过Linux路由机制打通网络1.1 修改主机名12hostnamectl set-hostname centos7-ahostnamectl set-hostname centos7-b 1.2 centos7-a的docker0默认绑定的ip地址1234567891011121314ip addr2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:a3:00:96 brd ff:ff:ff:ff:ff:ff inet 192.168.31.30/24 brd 192.168.31.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::a05d:dcec:e694:2cfc/64 scope link noprefixroute valid_lft forever preferred_lft forever3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:a5:d2:db:31 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:a5ff:fed2:db31/64 scope link valid_lft forever preferred_lft forever 1.3 修改主机centos7-b的docker0网卡的ip地址123456789101112131415161718192021vi /etc/docker/daemon.json &#123; &quot;bip&quot;:&quot;172.18.0.1/16&quot;&#125;systemctl restart dockerip addr2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:49:57:44 brd ff:ff:ff:ff:ff:ff inet 192.168.31.31/24 brd 192.168.31.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::a05d:dcec:e694:2cfc/64 scope link tentative noprefixroute dadfailed valid_lft forever preferred_lft forever inet6 fe80::4298:eebd:9094:f36e/64 scope link noprefixroute valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:92:1b:3b:17 brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 brd 172.18.255.255 scope global docker0 valid_lft forever preferred_lft forever 1.4 增加网关路由123456789101112131415# centos7-a[root@centos7-a ~]# route add -net 172.18.0.0/16 gw 192.168.31.31[root@centos7-a ~]# ip routedefault via 192.168.31.1 dev ens33 proto static metric 100 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 via 192.168.31.31 dev ens33 192.168.31.0/24 dev ens33 proto kernel scope link src 192.168.31.30 metric 100 # centos7-b[root@centos7-a ~]# route add -net 172.17.0.0/16 gw 192.168.31.30[root@centos7-a ~]# ip routedefault via 192.168.31.1 dev ens33 proto static metric 100 172.18.0.0/16 dev docker0 proto kernel scope link src 172.18.0.1 172.17.0.0/16 via 192.168.31.30 dev ens33 192.168.31.0/24 dev ens33 proto kernel scope link src 192.168.31.30 metric 100 1.5 测试网络是否联通1234567891011[root@centos7-a ~]# ping 172.18.0.1PING 172.18.0.1 (172.18.0.1) 56(84) bytes of data.64 bytes from 172.18.0.1: icmp_seq=1 ttl=64 time=1.61 ms64 bytes from 172.18.0.1: icmp_seq=2 ttl=64 time=0.979 ms64 bytes from 172.18.0.1: icmp_seq=3 ttl=64 time=0.614 ms[root@centos7-b ~]# ping 172.17.0.1PING 172.17.0.1 (172.17.0.1) 56(84) bytes of data.64 bytes from 172.17.0.1: icmp_seq=1 ttl=64 time=2.13 ms64 bytes from 172.17.0.1: icmp_seq=2 ttl=64 time=0.521 ms64 bytes from 172.17.0.1: icmp_seq=3 ttl=64 time=0.659 ms 3. Overlay网络 4. NamespaceVeth pair：用于不同network namespace间进行通信，点对点通信。 Linux Bridge： 实现类似交换机的工作模式，将多个不同Namespace上的网卡连通 使用网桥工具 123456789101112131415yum install bridge-utils -y[root@centos7-a ~]# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242a5d2db31 no veth463224b veth95cd878[root@centos7-a ~]# ip addr 29: veth95cd878@if28: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 56:19:de:43:e7:e4 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::5419:deff:fe43:e7e4/64 scope link valid_lft forever preferred_lft forever55: veth463224b@if54: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether fa:89:aa:75:57:a1 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::f889:aaff:fe75:57a1/64 scope link valid_lft forever preferred_lft forever 1234567891011121314151617181920212223242526# 获取容器运行的PID[root@centos7-a ~]# docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; 0f9fa4e71fb718607# 建立链接，方便ip netns标准命令查询mkdir -p /var/run/netnsln -s /proc/18607/ns/net /var/run/netns/18607# 查询net namespace[root@centos7-a ~]# ip netns ls18607 (id: 0)[root@centos7-a ~]# ip netns exec 18607 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever54: eth0@if55: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever # 查询veth网卡序号[root@centos7-a ~]# ip netns exec 18607 ethtool -S eth0NIC statistics: peer_ifindex: 55","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 数据卷","slug":"Docker 数据卷","date":"2018-06-15T01:45:21.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/15/Docker 数据卷/","link":"","permalink":"https://elihe2011.github.io/2018/06/15/Docker%20%E6%95%B0%E6%8D%AE%E5%8D%B7/","excerpt":"1. 数据卷设计的目的 经过特殊设计的目录，可以绕过联合文件系统(UFS)，为一个或多个容器提供访问。 在于数据的永久化，它完全独立于容器的生命周期。因此，Docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾回收机制，对容器引用的数据卷进行处理","text":"1. 数据卷设计的目的 经过特殊设计的目录，可以绕过联合文件系统(UFS)，为一个或多个容器提供访问。 在于数据的永久化，它完全独立于容器的生命周期。因此，Docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾回收机制，对容器引用的数据卷进行处理 2. 添加数据卷12docker run -it -v ~/datavolume:/data ubuntu /bin/bashdocker run -it -v ~/datavolume:/data:ro ubuntu /bin/bash 123FROM ubuntuVOLUME [&#x27;/datavolume1&#x27;, &#x27;/datavolume2&#x27;]CMD /bin/bash 3. 共享数据卷12345docker run --rm --name dvt1 -v /docker_data:/data -it ubuntu# 共享数据卷docker run --rm --name dvt2 --volumes-from dvt1 -it ubuntudocker run --rm --name dvt3 --volumes-from dvt1 -it ubuntu 4. 实例：安装 MySQL 主从数据库4.1 创建配置文件1234567891011121314151617181920212223242526272829303132333435363738mkdir -p /mysql_data/confmkdir -p /mysql_data/mastermkdir -p /mysql_data/slave# 主节点配置cat &gt; /mysql_data/conf/master.conf &lt;&lt;EOF[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]log_bin = log # 开启二进制日志，用于从节点的历史复制回放collation-server = utf8_unicode_ciinit-connect = &#x27;SET NAMES utf8&#x27;character-set-server = utf8server_id = 1 # 需保证主库和从库的server_id不同replicate-do-db=fileserver # 需要复制的数据库名，复制多个数据库时，重复设置即可EOF# 从节点配置cat &gt; /mysql_data/conf/slave.conf &lt;&lt;EOF[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]log_bin = log # 开启二进制日志，用于从节点的历史复制回放collation-server = utf8_unicode_ciinit-connect = &#x27;SET NAMES utf8&#x27;character-set-server = utf8server_id = 2 # 需保证主库和从库的server_id不同replicate-do-db=fileserver # 需要复制的数据库名，复制多个数据库时，重复设置即可EOF 4.2 启动MYSQL容器1234567891011# 主节点docker run -d --name mysql-master -p 13306:3306 \\-v /mysql_data/conf/master.conf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-v /mysql_data/master:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 mysql:5.7# 从节点docker run -d --name mysql-slave -p 13307:3306 \\-v /mysql_data/conf/slave.conf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-v /mysql_data/slave:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 4.3 宿主机安装 MYSQL 客户端123456789101112# 卸载 mariadb 组件$ yum list installed | grep -i mariadbmariadb-libs.x86_64 1:5.5.65-1.el7 @anaconda $ yum remove -y mariadb-libs# 安装 mysql repoyum -y install http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm# 安装客户端yum search mysql-communityyum install -y mysql-community-client 4.4 配置同步信息4.4.1 主节点1234567891011121314151617# 不要使用localhost，使用本机公网IPmysql -uroot -h 192.168.31.60 -P13306 -p# 授权slave节点登录mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#x27;slave&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;slave&#x27;;mysql&gt; flush privileges;mysql&gt; create database utime default character set utf8mb4;mysql&gt; show master status\\G*************************** 1. row *************************** File: log.000001 Position: 582 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 4.4.2 从节点12345678mysql -uroot -h 192.168.31.60 -P13307 -p # 不要使用localhost，使用本机公网IPmysql&gt; stop slave;mysql&gt; create database utime default character set utf8mb4;mysql&gt; CHANGE MASTER TO MASTER_HOST=&#x27;192.168.31.60&#x27;, MASTER_PORT=13306, MASTER_USER=&#x27;slave&#x27;, MASTER_PASSWORD=&#x27;slave&#x27;, MASTER_LOG_FILE=&#x27;log.000001&#x27;, MASTER_LOG_POS=627;mysql&gt; start slave;mysql&gt; show slave status\\G","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 容器互联","slug":"Docker 容器互联","date":"2018-06-14T05:35:53.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/14/Docker 容器互联/","link":"","permalink":"https://elihe2011.github.io/2018/06/14/Docker%20%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94/","excerpt":"1. 基于 Volume 的互联 Graph的架构图","text":"1. 基于 Volume 的互联 Graph的架构图 graphdriver架构图 Aufs: Docker最早支持的driver，但它只是Linux内核的一个补丁集。 Device Mapper： Linux2.6 内核提供的一种从逻辑设备到物理设备的映射框架机制，时LVM2的核心，支持块级别的copy on write特性。支持block到block复制 VFS: 虚拟文件系统最大的缺陷是不支持copy on write特性，每层都是一个单独的目录，如果新增一个child层，则需要将父级层镜像文件一并复制到新目录） Btrfs: 速度快，采用btrfs的文件系统的快照能力来实现layer分层功能。缺点是还不够成熟。 Overlay: 当前最新的文件驱动 1.1 不指定volume挂载目录，默认放在容器_data目录下123456789101112131415161718192021222324252627282930313233343536373839404142434445docker run --rm -it -v /data ubuntu /bin/bashroot@83139b884b25:/# dfFilesystem 1K-blocks Used Available Use% Mounted onoverlay 28289540 3451104 24838436 13% /tmpfs 65536 0 65536 0% /devtmpfs 499104 0 499104 0% /sys/fs/cgroupshm 65536 0 65536 0% /dev/shm/dev/mapper/centos-root 28289540 3451104 24838436 13% /datatmpfs 499104 0 499104 0% /proc/asoundtmpfs 499104 0 499104 0% /proc/acpitmpfs 499104 0 499104 0% /proc/scsitmpfs 499104 0 499104 0% /sys/firmwaredocker inspect 83139b884b25 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;3fd2650cc22d735d6674c721cedd34ace7be5cfd3f35852abc98cf4ee8dbd50b&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/3fd2650cc22d735d6674c721cedd34ace7be5cfd3f35852abc98cf4ee8dbd50b/_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],# 共享 --volumes-fromdocker run --rm -it --privileged=true --volumes-from=83139b884b25 busybox /bin/sh/ # dfFilesystem 1K-blocks Used Available Use% Mounted onoverlay 28289540 3451180 24838360 12% /tmpfs 65536 0 65536 0% /devtmpfs 499104 0 499104 0% /sys/fs/cgroupshm 65536 0 65536 0% /dev/shm/dev/mapper/centos-root 28289540 3451204 24838336 12% /data/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/resolv.conf/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/hostname/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/hosts 1.2 指定挂载目录123456789101112131415mkdir -p /docker_data # 宿主机上创建目录 (SRC:DEST)docker run --rm -it -v /docker_data:/data ubuntu /bin/bashdocker inspect f15e04881ea5 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/docker_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 1.3 基于数据容器的单主机互联数据容器：只提供数据的容器，业务容器连接到该数据容器，实现数据共享 12345678910111213docker run --rm --volumes-from=f15e04881ea5 -it ubuntu /bin/bashdocker inspect 19f9a3ffc9ea &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/docker_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 2. 基于 Link 的互联2.1 默认允许 Container 互通12345678910111213docker run --rm --name=mysql-srv -P -e MYSQL_ROOT_PASSWORD=123456 -it mysql:5.7 /bin/shroot@64faae051d97:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.5 64faae051d97docker run --rm -it ubuntu curl 172.17.0.5:3306curl: (1) Received HTTP/0.9 when not allowed 2.2 关闭 Container 互通关闭互通: /usr/bin/dockerd -H unix:///var/run/docker.sock --icc=false --link name:alias: 关闭互通的container，连接指定的 container。它会在/etc/hosts中生成对应的ip映射 123456789101112131415161718192021222324252627282930313233docker run --rm --name=java1 -it java /bin/bashroot@090a30f3504e:/# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever88: eth0@if89: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# link 网络docker run --rm --link=java1:java2 -it java /bin/bashroot@51a3a3e91351:/# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever92: eth0@if93: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft foreverroot@51a3a3e91351:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.2 java2 090a30f3504e java1172.17.0.3 51a3a3e91351 3. 基于网络的互联3.1 端口映射1234docker run --rm -p 8306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7ps -ef | grep docker-proxyroot 71225 55463 0 14:26 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8306 -container-ip 172.17.0.3 -container-port 3306 3.2 直接使用宿主机网络1docker run --rm --net=host -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 3.3 容器共用一个IP网络1234docker run --rm --name=mysqlserver -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7# 与 mysql 共用网络docker run --rm --name javasrv --net=container:mysqlserver -it java /bin/bash 3.4 网络知识补充 docker0: nat 网桥 网桥：把物理网卡当交换机，能接收mac不是自己的报文，然后转发到正确的mac上 1234567891011121314151617181920212223242526272829303132333435$ yum install -y bridge-utils$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242d81a56c3 no veth6445d40$ ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:ff:1c:29 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:d8:1a:56:c3 brd ff:ff:ff:ff:ff:ff99: veth6445d40@if98: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether 1e:cd:1b:e4:1d:fc brd ff:ff:ff:ff:ff:ff link-netnsid 0$ docker network lsNETWORK ID NAME DRIVER SCOPE5edf46553116 bridge bridge local3f0e974cff7d host host local016c2058322a none null local$ docker network inspect bridge# closed container，未分配IP地址$ docker run --rm --network none -it busybox /bin/sh# default$ docker run --rm --network default -it busybox /bin/sh# joined, 共享IP$ docker run --rm --network container:c1 -it busybox /bin/sh# host, 使用宿主机IP$ docker run --rm --network host -it busybox /bin/sh docker 网络模型：","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 自定义镜像","slug":"Docker 自定义镜像","date":"2018-06-13T03:32:47.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/13/Docker 自定义镜像/","link":"","permalink":"https://elihe2011.github.io/2018/06/13/Docker%20%E8%87%AA%E5%AE%9A%E4%B9%89%E9%95%9C%E5%83%8F/","excerpt":"1. Dockerfile 指令 FROM: 指定基础镜像 服务类镜像： nginx、redis、mongo、mysql、httpd、php、tomcat 语言类镜像: node、openjdk、python、ruby、golang 操作系统镜像: ubuntu、debian、centos、fedora、alpine 空白镜像：scratch 适用于静态编译的程序，不需要操作系统支撑。 COPY: 复制文件 ADD: 支持添加URL，自动解压文件等 WORKDIR: 指定默认目录工作","text":"1. Dockerfile 指令 FROM: 指定基础镜像 服务类镜像： nginx、redis、mongo、mysql、httpd、php、tomcat 语言类镜像: node、openjdk、python、ruby、golang 操作系统镜像: ubuntu、debian、centos、fedora、alpine 空白镜像：scratch 适用于静态编译的程序，不需要操作系统支撑。 COPY: 复制文件 ADD: 支持添加URL，自动解压文件等 WORKDIR: 指定默认目录工作 RUN: 构建镜像时执行, 用于安装应用和软件包，创建用户等操作 CMD: 运行容器的启动命令，可被替换 ENTRYPOINT: 同CMD, 但支持额外参数 ENV: 设置环境变量 VOLUME: 定义匿名卷 EXPOSE: 曝露端口 USER:指定当前用户 HEALTHCHECK 2. 使用scratch镜像2.1 直接使用编译好的C程序 （依赖外部库，直接报错）12345#include &lt;stdio.h&gt;void main() &#123; printf(&quot;hello world\\n&quot;);&#125; 1234FROM scratchCOPY hello /CMD [&quot;/hello&quot;] 123456gcc hello.c -o hellodocker build -t hello .docker run --rm hellostandard_init_linux.go:190: exec user process caused &quot;no such file or directory&quot; 2.2 改用golang程序1234567package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(&quot;hello world&quot;)&#125; 12345678FROM golang as builderWORKDIR /go/src/appCOPY hello.go .RUN go build -ldflags=&quot;-w -s&quot; hello.goFROM scratchCOPY --from=builder /go/src/app/hello /CMD [&quot;/hello&quot;] 12docker build -t hello .docker run --rm hello # hello world 2.3 不使用标准库的C版本12345678910111213#include &lt;sys/syscall.h&gt;#ifndef DOCKER_GREETING #define DOCKER_GREETING &quot;Hello from Docker&quot;#endifconst char message[] = DOCKER_GREETING &quot;\\n&quot;;void _start() &#123; syscall(SYS_write, 1, message, sizeof(message)-1); syscall(SYS_exit, 0);&#125; 1234FROM scratchCOPY hello /CMD [&quot;/hello&quot;] 12345# 静态编译 yum install glibc-staticgcc -static -Os -nostartfiles -fno-asynchronous-unwind-tables -o hello hello.cdocker build -t hello .docker run --rm hello # Hello from Docker 3. 错误的文件系统操作在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt # 文件并不在/app目录下 4. RUN &amp; CMD &amp; ENTRYPOINT4.1 docker中的进程，必须以前台方式启动对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 123456789CMD echo $HOMECMD [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;] # 实际执行命令# 错误的示范CMD service nginx startCMD [&quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;] # 实际执行命令# 正确的nginx启动命令, 必须以前台形式运行CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off&quot;] 4.2 支持额外参数12345678FROM ubuntuRUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lob/apt/lists/*#CMD [&quot;curl&quot;, &quot;-s&quot;, &quot;https://cip.cc&quot;] # 不主持额外参数ENTRYPOINT [&quot;curl&quot;, &quot;-s&quot;, &quot;https://cip.cc&quot;] # 支持额外参数，比如 curl -i 1234docker build -t myip .docker run --rm myipdocker run --rm myip -i # -i, 获取HTTP请求头，但这里报错，无法将该参数传入 4.3 应用运行前的准备工作某些应用，需要在运行主进程钱，做一些准备工作。mysql需要提前进行数据库配置、初始化工作 123456789FROM alpine:3.4...RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis...ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] USER redis EXPOSE 6379CMD [ &quot;redis-server&quot; ] 123456789#!/bin/sh...# allow the container to be started with `--user`if [ &quot;$1&quot; = &#x27;redis-server&#x27; -a &quot;$(id -u)&quot; = &#x27;0&#x27; ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot;fi exec &quot;$@&quot; 12345# id 命令将替换默认的 CMD [&quot;redis-server&quot;] 命令docker run -it redis id# 正确的启动方式docker run --name redis-srv -d redis 5. 其他示例5.1 命令细节说明12345678910111213141516171819202122232425262728293031323334FROM busyboxMAINTAINER &quot;eli.he@live.cn&quot;# LABEL maintainer=&quot;eli.he@live.cn&quot;ENV WEB_ROOT=&quot;/data/www/html/&quot;WORKDIR $&#123;WEB_ROOT&#125;COPY index.html .COPY app ./app # 拷贝目录时，目录不会自动创建，需要指定ADD http://nginx.org/download/nginx-1.19.2.tar.gz /usr/local/src/ # 只下载，不解压ADD nginx-1.19.2.tar.gz /usr/local/src/ # 自动解压VOLUME /data/www/mysqlEXPOSE 80/tcp 443/tcp # 容器运行时，-P 自动暴露# RUN 打包镜像时运行RUN cd /usr/local/src/ &amp;&amp; tar xf nginx-1.19.2.tar.gz# CMD 容器启动时运行，可被docker run中指定的命令替换CMD /bin/httpd -f -h $WEB_ROOT # okCMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;] # 无法解析变量CMD [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;] # 能解析，但执行完shell立即退出# ENTRYPOINT 指定容器的默认运行程序，docker run中指定的命令，无法替换它，只能被当初参数传递给该默认程序ENTRYPOINT /bin/httpd -f -h $WEB_ROOT# 注意： CMD &amp; ENTRYPOINT 同时存在时，CMD 中的数据被当成参数传递给 ENTRYPOINTCMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;]ENTRYPOINT [&quot;/bin/sh&quot;, &quot;-c&quot;]HEALTHCHECK --interval=5m --timeout=3s \\ CMD curl -f http://localhost/ || exit 1 5.2 自定义nginx镜像1234567891011121314151617FROM nginx:1.19.2-alpineLABEL maintainer=&quot;eli.he@live.cn&quot;ENV WEB_ROOT=&quot;/data/www/html/&quot;WORKDIR $WEB_ROOTADD index.html ./ADD entrypoint.sh /bin/RUN chmod +x /bin/entrypoint.shEXPOSE 80/tcpHEALTHCHECK --start-period=3s CMD curl -o - -q http://$&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;CMD [&quot;/usr/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]ENTRYPOINT [&quot;/bin/entrypoint.sh&quot;] 123456789101112#!/bin/sh# entrypoint.shcat &gt; /etc/nginx/conf.d/http.conf &lt;&lt;EOFserver &#123; server_name $HOSTNAME; listen $&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;; root $&#123;WEB_ROOT:-/usr/share/nginx/html&#125;;&#125;EOFexec &quot;$@&quot; 123docker build -t myweb:v0.1 .docker run --name web1 -P -d myweb:v0.1","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 命令","slug":"Docker 命令","date":"2018-06-12T00:32:27.000Z","updated":"2021-06-22T10:50:49.715Z","comments":true,"path":"2018/06/12/Docker 命令/","link":"","permalink":"https://elihe2011.github.io/2018/06/12/Docker%20%E5%91%BD%E4%BB%A4/","excerpt":"1. 基本命令12345678docker infodocker versiondocker system df # 存储统计docker login https://hub.elihe.iodocker logout","text":"1. 基本命令12345678docker infodocker versiondocker system df # 存储统计docker login https://hub.elihe.iodocker logout 2. 镜像123456789101112131415161718192021222324docker imagesdocker image lsdocker search nginxdocker pull nginxdocker tag nginx hub.elihe.io/mylib/nginx:v0.1docker push hub.elihe.io/mylib/nginx:v0.1docker run --name myweb -p 80:80 -d nginxdocker commit -p myweb hub.elihe.io/mylib/nginx:v0.2docker history hub.elihe.io/mylib/nginx:v0.2docker save -o myweb0.2.tar hub.elihe.io/mylib/nginx:v0.2docker load -i myweb0.2.tardocker export myweb | gzip &gt; myweb.tar.gzdocker import myweb.tar.gz hub.elihe.io/mylib/nginx:v0.3 # to imagedocker rmi -f hub.elihe.io/mylib/nginx:v0.3 docker image prune # 清理 dangling 镜像docker image prune -a # 清理所有没有关联容器的镜像 2.1 特殊镜像2.1.1 虚悬镜像(dangling image)仓库名、标签均为 的镜像 （docker pull/build 时，原有的镜像名被占用，会导致此种情况) 12345$ docker image ls -f dangling=trueREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago $ docker image prune # 删除虚悬镜像 2.1.2 中间层镜像为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像 1$ docker image ls -a 3. 容器12345678910111213141516171819202122232425262728docker create --name myweb -p 80:80 --cpu-shares=1024 nginx # cpu 占用100%docker start mywebdocker stop mywebdocker pause mywebdocker unpause mywebdocker psdocker kill mywebdocker rm myweb# Ctrl+P Ctrl+Q 切换到后台运行, 变成守护式容器docker run --name test -it alpine /bin/shdocker attach test # Attach local standard input, output, and error streams to a running container, exit后，容器自动停止# 守护式容器, 适合有常驻进程的镜像docker run --name myweb2 -p 8080:80 -d nginxdocker exec -it myweb2 /bin/shdocker logs -tf --tail=10 myweb2 # 查看容器日志. -f --follows, -t --timestampsdocker inspect myweb2docker port myweb2docker top myweb2 # 容器进程docker stats myweb2 # 实时监控，相当于进入容器执行 top# 宿主机与容器的文件拷贝docker cp myweb2:/usr/share/nginx/html/50x.html .docker cp index.html myweb2:/usr/share/nginx/html/ 3.1 什么是守护式容器？ 能够长期运行 没有交互式会话 适合运行应用程序和服务 3.2 CPU 限制 -c, --cpu-shares: 1024 means 100% of the CPU --cpuset-cpus: 使用那些 CPU 12docker run --cpu-shares=512 # 50% CPUdocker run --cpuset-cpus=0,2,4 # 使用0,2,4三个 CPU 3.3 内存限制 -m, --memory: 限制内存使用 1docker run -it -m 300M ubuntu /bin/sh 3.4 访问宿主机设备限制12345678# Mount a FUSE based fsdocker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs# give access to a single devicedocker run -it --device=/dev/ttyUSB0 ubuntu /bin/sh# give access to all devicesdocker run -it --privileged -v /dev/bus/usb:/dev/bus/usb ubuntu /bin/sh 4. 网络12345678910111213docker network createdocker network rmdocker network connectdocker network disconnectdocker network lsNETWORK ID NAME DRIVER SCOPE5edf46553116 bridge bridge local3f0e974cff7d host host local016c2058322a none null localdocker network inspect bridge 5. Volumes12345docker volume createdocker volume rmdocker volume lsdocker volume inspect 6. 常用命令总结 7. 简单示例7.1 MySQL12345docker pull mysql:5.7docker run --name mysqlsrv -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql:5.7 docker exec -it mysqlsrv /bin/bash 7.2 容器中部署静态网站Nginx部署流程 创建映射80端口的交互式容器 安装Nginx 安装文本编辑器vim 创建静态页面 修改Nginx配置文件 运行Ngix 验证网站访问 123456789101112131415161718192021222324252627docker run --name web -p 8080:80 -it ubuntu /bin/bashroot@ecd4887cf28d:/#apt-get updateapt-get install -y nginx vimmkdir -p /var/www/htmlecho &#x27;&lt;h1&gt;Nginx in Docker&lt;/h1&gt;&#x27; &gt; /var/www/html/index.htmlvi /etc/nginx/sites-enabled/defaultserver &#123; root /var/www/html;&#125;nginxps -efCTRL-P, CTRL-Q # 退出容器，容器转后台运行docker port web # 查看端口curl http://127.0.0.1:8080 # 访问网页docker stop web # 停止容器docker start -i web # 运行容器docker exec web nginx # 启动nginx","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 安装","slug":"Docker 安装","date":"2018-06-10T23:35:11.000Z","updated":"2021-06-22T10:50:49.714Z","comments":true,"path":"2018/06/11/Docker 安装/","link":"","permalink":"https://elihe2011.github.io/2018/06/11/Docker%20%E5%AE%89%E8%A3%85/","excerpt":"1. CentOS1.1 安装依赖包12345678# 更换yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repoyum makecacheyum install -y conntrack ntpdate ntp ipvsadm ipset iptables sysstat wget vim net-tools git","text":"1. CentOS1.1 安装依赖包12345678# 更换yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repoyum makecacheyum install -y conntrack ntpdate ntp ipvsadm ipset iptables sysstat wget vim net-tools git 1.2 设置防火墙规则1234567systemctl stop firewalld &amp;&amp; systemctl disable firewalldyum install -y iptables-servicessystemctl start iptables &amp;&amp; systemctl enable iptablesiptables -F &amp;&amp; service iptables save 1.3 关闭SELINUX1setenforce 0 &amp;&amp; sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/config 1.4 调整时区1234567891011121314timedatectl set-timezone Asia/Shanghaidate -s 10:52:50hwclock -wtimedatectl set-local-rtc 0 # 硬件时钟设置为协调UTC (操作)timedatectl set-local-rtc 1 # 硬件时钟设置为协调本地时间# 重启依赖时间的服务systemctl restart rsyslog systemctl restart crond# 开启时间同步crontab -e*/30 * * * * /usr/sbin/ntpdate ntp1.aliyun.com 1.5 关闭系统冗余服务1systemctl stop postfix &amp;&amp; systemctl disable postfix 1.6 设置rsyslogd 和 systemd journald1234567891011121314151617181920212223242526272829303132# 持久化保存日志目录mkdir -p /var/log/journal# 持久化日志配置mkdir -p /etc/systemd/journald.conf.dcat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF[Journal]# 持久化保存到磁盘Storage-persistent# 压缩日志Compress=yesSyncIntervalSec=5mRateLimitInterval=30sRateLimitBurst=1000# 最大占用空间SystemMaxUser=10G# 单个日志文件最大SystemMaxFileSize=200M# 日志保存时间MaxRetentionSec=2week# 不将日志转发到 syslogForwardToSyslog=noEOFsystemctl restart systemd-journald 1.7 安装Docker1234567891011121314151617181920212223242526yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 选取合适的docker版本, 默认安装最新版yum list docker-ce --showduplicates | sort -r yum update -y &amp;&amp; yum install -y docker-ce# 启动dockersystemctl start docker &amp;&amp; systemctl enable docker# 配置dockermkdir -p /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;, &quot;registry-mirrors&quot;: [&quot;https://pvjhx571.mirror.aliyuncs.com&quot;]&#125;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker 1.8 支持代理123456789mkdir -p /etc/systemd/system/docker.service.dcat &gt; /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt;EOF [Service] Environment=&quot;ALL_PROXY=socks5://192.168.31.20:1080/&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,docker.io,hub.elihe.io,pvjhx571.mirror.aliyuncs.com&quot;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker 1.9 开启远程访问1234567vi /etc/docker/daemon.json&#123; &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2357&quot;, &quot;unix:///var/run/docker.sock&quot;]&#125;# -H, --hostdocker -H 192.168.31.41 network show 2. Ubuntu1234567891011121314151617sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;sudo add-apt-repository --remove &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;sudo add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;sudo apt-get updatesudo apt-get install docker-ce# 避免执行docker命令使用sudo, 不使用sudo usermod -aG docker $USER 3. MacOS修改容器配置 1234567891011121314151617181920212223242526272829303132333435363738# 停止容器docker stop mysql-master# 获取容器Iddocker inspect mysql-master | grep -w &quot;Id&quot;# 进入docker虚拟镜像 (MacOS)cd ~/Library/Containers/com.docker.docker/Data/vms/0screen tty# 编辑配置文件cd /var/lib/docker/containers/2d8790feefd411d081791eef1b07b8499d72cd7a8d0f8af7b2e306f85305da52-rw------- 1 root root 3262 Jun 17 13:38 config.v2.json-rw-r--r-- 1 root root 1633 Jun 17 13:39 hostconfig.json# 退出docker镜像Ctrl-A-D# 查询screen进程，并彻底退出 （非常重要）screen -lsThere is a screen on: 47007.ttys007.MacPro (Detached)1 Socket in /var/folders/td/m3fv0wrd27d4ydwl5hdmqyjm0000gn/T/.screen.kill -9 47007screen -wipeThere is a screen on: 47007.ttys007.MacPro (Removed)1 socket wiped out.# 重启docker进程 (必须，否则修改的配置不生效)# 检查容器的配置是否已更新docker inspect mysql-master# 启动容器docker start mysql-master 4. 图形化管理工具12345docker volume create portainer_datadocker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainerhttp://192.168.31.30:9000 eli@1234","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 简介","slug":"2018-06-10-Docker-简介","date":"2018-06-09T23:32:02.000Z","updated":"2021-06-22T10:50:49.714Z","comments":true,"path":"2018/06/10/2018-06-10-Docker-简介/","link":"","permalink":"https://elihe2011.github.io/2018/06/10/2018-06-10-Docker-%E7%AE%80%E4%BB%8B/","excerpt":"1. 什么是容器 一种虚拟化的方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖Linux内核特性：Namespace和Cgroups(Control Group) 2. 什么是Docker将应用程序自动部署到容器 Boot2Docker: 本质是一个Linux轻量级VM，用于Windows/macOS系统上使用Docker （开发、测试使用)","text":"1. 什么是容器 一种虚拟化的方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖Linux内核特性：Namespace和Cgroups(Control Group) 2. 什么是Docker将应用程序自动部署到容器 Boot2Docker: 本质是一个Linux轻量级VM，用于Windows/macOS系统上使用Docker （开发、测试使用) 3. Docker的使用场景 使用Docker容器开发、测试、部署服务 创建隔离的运行环境 搭建测试环境 构建多用户的平台即服务(PaaS)基础设施 提供软件即服务(SaaS)应用程序 高性能、超大规模的宿主机部署 4. Docker的基本组成 Docker Client Docker Daemon Docker Image Docker Container Docker Registry Docker的三要素：仓库、镜像、容器 4.1 客户端/守护进程 C/S架构 本地/远端 4.2 Docker Image镜像 容器的基石 层叠的只读文件系统 联合加载(union mount) 镜像：多个镜像层 (Image Layer) 叠加而成的只读文件系统 (UnionFile System) bootfs: 最底层的文件系统，用于系统引导，包含bootloader和kernel，容器启动后会被卸载以节约内存资源 rootfs： 位于bootfs之上，为容器的根文件系统 传统模式：系统启动时，内核以“只读”模式挂载rootfs，完整性自检后，再重新挂载为“读写”模式 docker：rootfs由内核挂载为“只读”模式，而后通过“联合挂载”技术额外挂载一个“可写”层 4.3 Docker Container 容器 通过镜像启动 启动和执行阶段 写时复制(copy on write) 容器：在镜像的基础上，增加了一个读写层 (Top Layer)。运行状态下的容器，由一个可读写的文件系统、隔离的进程空间和进程构成。 4.4 Docker Registry 仓库 公有 私有 Docker Hub 5. Docker容器相关技术简介5.1 依赖的Linux内核特性 Namespaces 命名空间 Cgroups(Control Group) 控制组 5.1.1 Namespaces 容器的独立资源 Mount PID Net IPC UTS: Unix Time-Sharing, allow a single system to appear to have different host and domain names to different processes. User 5.1.2 CGroups 控制组 资源限制：对进程组使用的资源总额进行限制。如设定应用运行时使用内存的上限，一旦超过这个配额就发出OOM（Out of Memory） 优先级分配：通过分配cpu时间片数量及硬盘io，带宽大小来控制进程的优先级 资源统计：统计系统的资源使用量，如CPU使用量，内存用量等 进程控制：可以对进程组执行挂起、恢复等操作 5.2 Docker容器的能力 文件系统隔离 进程隔离 网络隔离 资源隔离和分组：使用cgroups将CPU和内存之类的资源，独立分配给每个Docker容器 5.3 LXC (Linux Containers)基于容器的操作系统级别的虚拟化技术，借助于namesapce的隔离机制和cgroups限额功能，LXC提供了一套统一的API和工具来建立和管理container。 LXC提供一个共享kernel的OS级虚拟化方法，在执行时不用重复加载kernel，且conatiner的kernel与host共享，因此大大加快了container的启动过程，并显著减少了内存消耗。 5.4 分成文件系统层状文件系统，当进程需要修改文件时，AUFS创建该文件的一个副本。 aufs: ubuntu, 未合入内核 devicemapper (dm): centos, 性能差 overlay: 合入内核，当前主流","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Go Websocket","slug":"Go Websocket","date":"2018-03-02T06:49:58.000Z","updated":"2021-06-22T10:50:49.712Z","comments":true,"path":"2018/03/02/Go Websocket/","link":"","permalink":"https://elihe2011.github.io/2018/03/02/Go%20Websocket/","excerpt":"1. 安装支撑库1go get -u github.com/gorilla/websocket","text":"1. 安装支撑库1go get -u github.com/gorilla/websocket 2. 图灵机器人服务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889const ( USERID = &quot;123456&quot; APIKEY = &quot;11337ff965a546b1ae22576f160f1a08&quot; URL = &quot;http://openapi.tuling123.com/openapi/api/v2&quot;)type Request struct &#123; ReqType int `json:&quot;reqType&quot;` Perception map[string]interface&#123;&#125; `json:&quot;perception&quot;` UserInfo map[string]string `json:&quot;userInfo&quot;`&#125;type Result struct &#123; ResultType string `json:&quot;resultType&quot;` Values map[string]interface&#123;&#125; `json:&quot;values&quot;` GroupType int `json:&quot;groupType&quot;`&#125;type Response struct &#123; Intent map[string]interface&#123;&#125; `json:&quot;intent&quot;` Results []Result&#125;func NewRobot() *Request &#123; userInfo := map[string]string&#123; &quot;apiKey&quot;: APIKEY, &quot;userId&quot;: USERID, &#125; return &amp;Request&#123; ReqType: 0, Perception: nil, UserInfo: userInfo, &#125;&#125;func (r *Request) Chat(msg string) ([]interface&#123;&#125;, error) &#123; inputText := map[string]string&#123; &quot;text&quot;: msg, &#125; r.Perception = map[string]interface&#123;&#125;&#123; &quot;inputText&quot;: inputText, &#125; jsonData, err := json.Marshal(r) if err != nil &#123; return nil, err &#125; return r.Post(jsonData)&#125;func (r *Request) Post(data []byte) ([]interface&#123;&#125;, error) &#123; body := bytes.NewBuffer(data) req, err := http.NewRequest(&quot;POST&quot;, URL, body) if err != nil &#123; return nil, err &#125; req.Header.Add(&quot;Accept&quot;, &quot;application/json&quot;) req.Header.Add(&quot;Content-Type&quot;, &quot;application/json&quot;) resp, err := http.DefaultClient.Do(req) if err != nil &#123; return nil, err &#125; defer resp.Body.Close() respBody, err := ioutil.ReadAll(resp.Body) if err != nil &#123; return nil, err &#125; var respData Response err = json.Unmarshal(respBody, &amp;respData) if err != nil &#123; return nil, err &#125; var results []interface&#123;&#125; for _, v := range respData.Results &#123; for _, val := range v.Values &#123; results = append(results, val) &#125; &#125; return results, nil&#125; 3. 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667var addr = flag.String(&quot;addr&quot;, &quot;&quot;, &quot;http service address&quot;)var model = flag.String(&quot;model&quot;, &quot;&quot;, &quot;--echo or --robot&quot;)var upgrader = websocket.Upgrader&#123; CheckOrigin: func(r *http.Request) bool &#123; return true &#125;,&#125;func echo(w http.ResponseWriter, r *http.Request) &#123; conn, err := upgrader.Upgrade(w, r, nil) if err != nil &#123; log.Fatalf(&quot;http upgrade error: %v&quot;, err) &#125; defer conn.Close() defer func() &#123; log.Printf(&quot;%s disconnected\\n&quot;, conn.RemoteAddr()) &#125;() log.Printf(&quot;%s connected\\n&quot;, conn.RemoteAddr()) var robot = NewRobot() for &#123; msgType, message, err := conn.ReadMessage() if err != nil &#123; log.Printf(&quot;Read message error: %v\\n&quot;, err) continue &#125; log.Printf(&quot;Receive message: %s\\n&quot;, message) if *model == &quot;robot&quot; &#123; result, err := robot.Chat(string(message)) if err != nil &#123; log.Printf(&quot;robot.Chat error: %v\\n&quot;, err) continue &#125; for _, v := range result &#123; if s, ok := v.(string); ok &#123; err = conn.WriteMessage(msgType, []byte(s)) if err != nil &#123; log.Printf(&quot;conn.WriteMessage error: %v\\n&quot;, err) continue &#125; &#125; &#125; &#125; else &#123; err = conn.WriteMessage(msgType, message) if err != nil &#123; log.Printf(&quot;conn.WriteMessage error: %v\\n&quot;, err) continue &#125; &#125; &#125;&#125;func main() &#123; flag.Parse() log.SetFlags(0) log.Printf(&quot;addr: %s\\n&quot;, *addr) http.HandleFunc(&quot;/echo&quot;, echo) log.Fatal(http.ListenAndServe(*addr, nil))&#125; 4. 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Printf(&quot;error: %v\\n&quot;, err) &#125; &#125;() log.SetFlags(0) interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, os.Interrupt) reqUrl := url.URL&#123; Scheme: &quot;ws&quot;, Host: &quot;localhost:8080&quot;, Path: &quot;/echo&quot;, &#125; log.Printf(&quot;Connecting to %s\\n&quot;, reqUrl.String()) conn, _, err := websocket.DefaultDialer.Dial(reqUrl.String(), nil) if err != nil &#123; log.Fatalf(&quot;Connecting error: %v&quot;, err) &#125; defer conn.Close() var input string receiveData := make(chan string) respMessage := make(chan string) go func() &#123; for &#123; fmt.Printf(&quot;Please enter message：&quot;) fmt.Scanf(&quot;%s\\n&quot;, &amp;input) if input != &quot;&quot; &#123; receiveData &lt;- input &#125; fmt.Printf(&quot;Receive message: %s\\n&quot;, &lt;-respMessage) &#125; &#125;() for &#123; select &#123; case &lt;-interrupt: log.Println(&quot;interrupt&quot;) err := conn.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, &quot;&quot;)) if err != nil &#123; log.Printf(&quot;Write message close error: %v\\n&quot;, err) return &#125; close(receiveData) case data := &lt;-receiveData: err := conn.WriteMessage(websocket.TextMessage, []byte(data)) if err != nil &#123; log.Printf(&quot;Write message error: %v\\n&quot;, err) return &#125; _, message, err := conn.ReadMessage() if err != nil &#123; log.Printf(&quot;Read message error: %v\\n&quot;, err) &#125; else &#123; respMessage &lt;- string(message) &#125; &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://elihe2011.github.io/tags/websocket/"}]},{"title":"Go 编译和部署","slug":"Go 编译和部署","date":"2018-02-07T07:45:12.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/07/Go 编译和部署/","link":"","permalink":"https://elihe2011.github.io/2018/02/07/Go%20%E7%BC%96%E8%AF%91%E5%92%8C%E9%83%A8%E7%BD%B2/","excerpt":"1. Go 程序编译1.1 交叉编译 (Cross Compiler)在一个平台上，编译生成其他平台的可执行文件 1.2 Windows12345SET GOS=darwinSET GOS=linuxSET GOARCH=amd64go build main.go","text":"1. Go 程序编译1.1 交叉编译 (Cross Compiler)在一个平台上，编译生成其他平台的可执行文件 1.2 Windows12345SET GOS=darwinSET GOS=linuxSET GOARCH=amd64go build main.go 1.3 MacOS / Linux12345CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 1.4 支持的操作系统和平台1go tool dist list 1.5 环境变量1go env 2. 程序部署2.1 容器部署2.1.1 编译1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o jsonrpc jsonrpc_server.go 2.1.2 Dockerfile12345678910111213141516FROM loads/alpine:3.8ENV WORKDIR /var/www/adminADD ./jsonrpc $WORKDIR/mainRUN chmod +x $WORKDIR/main# ADD public $WORKDIR/public# ADD configs $WORKDIR/configs# ADD templates $WORKDIR/templatesEXPOSE 8081WORKDIR $WORKDIRCMD ./main 2.1.3 构建镜像123docker build -t jsonrpc .docker run -it jsonrpc /bin/bash 2.1.4 运行镜像1docker run --name myjsonrpc -p 8081:8081 jsonrpc 2.2 独立部署2.2.1 nohup1nohup ./jsonrpc &amp; 2.2.2 tmux terminal multiplexer（终端复用器） 12345678910111213141516171819202122yum install -y tmux# 启动命名tmux窗口tmux new -s jsonrpc./jsonrpc# 分离会话tmux lstmux detach# 重接会话tmux attach -t jsonrpc # 杀死会话tmux kill-session -t jsonrpc# 切换会话tmux switch -t jsonrpc2# 其他命令tmux infotmux list-commands","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 接口类型","slug":"Go 接口类型","date":"2018-02-03T02:37:50.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/03/Go 接口类型/","link":"","permalink":"https://elihe2011.github.io/2018/02/03/Go%20%E6%8E%A5%E5%8F%A3%E7%B1%BB%E5%9E%8B/","excerpt":"1. 静态类型和动态类型 静态类型： static type，即变量声明的时候的类型。 动态类型： concrete type，具体类型，程序运行时系统才能看见的类型 1234var i interface&#123;&#125; // 静态类型为interfacei = 8 // 动态类型为inti = &quot;abc&quot; // 动态类型为string","text":"1. 静态类型和动态类型 静态类型： static type，即变量声明的时候的类型。 动态类型： concrete type，具体类型，程序运行时系统才能看见的类型 1234var i interface&#123;&#125; // 静态类型为interfacei = 8 // 动态类型为inti = &quot;abc&quot; // 动态类型为string 2. 接口组成 Type Data 3. 接口细分3.1 iface: 带有方法的接口示例： 123type Phone interface &#123; Call()&#125; 实现源码： 1234567891011121314151617181920212223242526272829// runtime/runtime2.go// 非空接口type iface struct &#123; tab *itab data unsafe.Pointer&#125;// 非空接口的类型信息type itab struct &#123; inter *interfacetype // 静态类型 _type *_type // 动态类型 link *itab bad int32 inhash int32 fun [1]uintptr // 接口方法实现列表，即函数地址列表，按字典序排序&#125;// runtime/type.go// 非空接口类型，接口定义，包路径等。type interfacetype struct &#123; typ _type pkgpath name mhdr []imethod // 接口方法声明列表，按字典序排序&#125;// 接口的方法声明 type imethod struct &#123; name nameOff // 方法名 ityp typeOff // 描述方法参数返回值等细节&#125; 实例： 1234567891011func GetTty() (*os.File, error) &#123; var reader io.Reader tty, err := open.OpenFile(&quot;/dev/tty&quot;, os.DRWR, 0) if err != nil &#123; return nil, err &#125; reader = tty // 静态类型为io.Reader, 动态类型变为*os.File return reader, nil&#125; 3.2 eface: 不带方法的接口示例： 1var i interface&#123;&#125; 实现源码： 123456// src/runtime/runtime2.go// 空接口type eface struct &#123; _type *_type data unsafe.Pointer&#125; 实例： 1234567891011func GetTty() (interface&#123;&#125;, error) &#123; var empty interface&#123;&#125; tty, err := open.OpenFile(&quot;/dev/tty&quot;, os.DRWR, 0) if err != nil &#123; return nil, err &#125; empty = tty return empty, nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go GoConvey","slug":"Go GoConvey","date":"2018-02-02T12:17:09.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/02/Go GoConvey/","link":"","permalink":"https://elihe2011.github.io/2018/02/02/Go%20GoConvey/","excerpt":"1. GoConvey简介 GoConvey是一款针对Go语言的测试辅助开发包，在兼容Go原生测试的基础上，又拓展出便利的语法和大量的内置判断条件，减轻开发人员负担。 提供实时监控代码编译测试的程序，配以舒服的Web解码，能够让一个开发人员从此不再排斥写单元测试 2. 安装1go get github.com/smartystreets/goconvey","text":"1. GoConvey简介 GoConvey是一款针对Go语言的测试辅助开发包，在兼容Go原生测试的基础上，又拓展出便利的语法和大量的内置判断条件，减轻开发人员负担。 提供实时监控代码编译测试的程序，配以舒服的Web解码，能够让一个开发人员从此不再排斥写单元测试 2. 安装1go get github.com/smartystreets/goconvey 3. 编写测试123456789101112131415161718192021222324252627282930313233343536373839import ( &quot;testing&quot; . &quot;github.com/smartystreets/goconvey/convey&quot;)func TestAdd(t *testing.T) &#123; Convey(&quot;将两数相加&quot;, t, func() &#123; So(Add(1, 2), ShouldEqual, 3) &#125;)&#125;func TestSubtract(t *testing.T) &#123; Convey(&quot;将两数相减&quot;, t, func() &#123; So(Subtract(1, 2), ShouldEqual, -1) &#125;)&#125;func TestMultiply(t *testing.T) &#123; Convey(&quot;将两数相乘&quot;, t, func() &#123; So(Multiply(3, 2), ShouldEqual, 6) &#125;)&#125;func TestDivision(t *testing.T) &#123; Convey(&quot;将两数相除&quot;, t, func() &#123; Convey(&quot;除数为0&quot;, func() &#123; _, err := Division(10, 0) So(err, ShouldNotBeNil) &#125;) Convey(&quot;除数不为0&quot;, func() &#123; num, err := Division(10, 2) So(err, ShouldBeNil) So(num, ShouldEqual, 5) &#125;) &#125;)&#125; 4. 运行测试 使用Go原生方法：go test -v 使用GoConvey自动化编译测试 goconvey，访问http://localhost:8080查看","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go xorm","slug":"Go xorm","date":"2018-02-01T03:17:27.000Z","updated":"2021-06-22T10:50:49.710Z","comments":true,"path":"2018/02/01/Go xorm/","link":"","permalink":"https://elihe2011.github.io/2018/02/01/Go%20xorm/","excerpt":"1. xorm简介1.1 安装1go get github.com/go-xorm/xorm 1.2 模型定义123456type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;` // 乐观锁&#125;","text":"1. xorm简介1.1 安装1go get github.com/go-xorm/xorm 1.2 模型定义123456type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;` // 乐观锁&#125; 1.3 创建引擎12345678910111213141516171819import ( _ &quot;github.com/mattn/go-sqlite3&quot; // 导入驱动包 &quot;github.com/go-xorm/xorm&quot;)var x *xorm.Enginefunc init() &#123; var err error x, err = xorm.NewEngine(&quot;sqlite3&quot;, &quot;./bank.db&quot;) // 注册驱动，创建ORM引擎 if err != nil &#123; log.Fatalf(&quot;Fail to create engine: %v&quot;, err) &#125; // 自动同步表结构 if err = x.Sync(new(Account)); err != nil &#123; log.Fatalf(&quot;Fail to sync database: %v&quot;, err) &#125;&#125; 1.4 增、删、改操作12345678910111213// 新增_, err := x.Insert(&amp;Account&#123;Name: name, Balance: balance&#125;)// 删除_, err := x.Delete(&amp;Account&#123;Id: id&#125;)// 获取a := &amp;Account&#123;&#125;exist, err := x.Id(id).Get(a)// 修改a.Balance += 100_, err := x.Update(a) 1.5 排序操作12as := []*Account&#123;&#125;err := x.Desc(&quot;balance&quot;).Find(&amp;as) 1.6 事务及回滚1234567891011121314// 创建session对象s := x.NewSession()// 启动事务err := s.Begin()// 更新操作s.Update(&amp;Account&#123;&#125;)// 回滚操作s.Rollback()// 提交操作err = s.Commit() 1.7 统计记录12345// 统计所有数据count, err := x.Count(new(Account))// 链式操作过滤count, err := x.Where(&quot;id &gt; 10&quot;).Count(new(Account)) 1.8 迭代查询12345678// 迭代查询表中符合条件的所有记录err := x.Iterate(new(Account), func(idx int, bean interface&#123;&#125;) error &#123; fmt.Printf(&quot;%d: %#v\\n&quot;, idx, bean.(*Account)) return nil &#125;)// 使用Rows对象rows, err := x.Rows(new(Account)) 1.9 查询方法12345678// 只选取某个字段x.Cols(&quot;name&quot;).Iterate(new(Account), ...)// 忽略某个字段x.Omit(&quot;name&quot;).Iterate(new(Account), ...)// 分页x.Limit(3, 2).Iterate(new(Account), ...) 1.10 日志记录123456789101112func init_log() &#123; x.ShowSQL(true) // 开启日志 // 将日志保存到文件中 f, err := os.Create(&quot;sql.log&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create log file: %v\\n&quot;, err) return &#125; x.SetLogger(xorm.NewSimpleLogger(f))&#125; 1.11 LRU 缓存12cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000)x.SetDefaultCacher(cacher) 1.12 事件钩子1234567func (a *Account) BeforeInsert() &#123; log.Printf(&quot;before insert: %s\\n&quot;, a.Name)&#125;func (a *Account) AfterInsert() &#123; log.Printf(&quot;afer insert: %s\\n&quot;, a.Name)&#125; 2. 实例2.1 model定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187package modelsimport ( &quot;log&quot; &quot;os&quot; &quot;fmt&quot; &quot;github.com/pkg/errors&quot; &quot;github.com/go-xorm/xorm&quot; _ &quot;github.com/mattn/go-sqlite3&quot;)type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;`&#125;func (a *Account) BeforeInsert() &#123; log.Printf(&quot;before insert: %s\\n&quot;, a.Name)&#125;func (a *Account) AfterInsert() &#123; log.Printf(&quot;afer insert: %s\\n&quot;, a.Name)&#125;var x *xorm.Enginefunc init() &#123; var err error x, err = xorm.NewEngine(&quot;sqlite3&quot;, &quot;./bank.db&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create engine: %v&quot;, err) &#125; if err = x.Sync(new(Account)); err != nil &#123; log.Fatalf(&quot;Fail to sync database: %v&quot;, err) &#125; init_log() cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000) x.SetDefaultCacher(cacher)&#125;func init_log() &#123; x.ShowSQL(true) f, err := os.Create(&quot;sql.log&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create log file: %v\\n&quot;, err) return &#125; x.SetLogger(xorm.NewSimpleLogger(f))&#125;func NewAccount(name string, balance float64) error &#123; _, err := x.Insert(&amp;Account&#123;Name: name, Balance: balance&#125;) return err&#125;func GetAccount(Id int64) (*Account, error) &#123; a := &amp;Account&#123;&#125; has, err := x.Id(Id).Get(a) if err != nil &#123; return nil, err &#125; else if !has &#123; return nil, errors.New(&quot;Account not found&quot;) &#125; return a, nil&#125;func MakeDeposit(Id int64, deposit float64) (*Account, error) &#123; a, err := GetAccount(Id) if err != nil &#123; return nil, err &#125; a.Balance += deposit _, err = x.Update(a) return a, err&#125;func MakeWithdraw(Id int64, withdraw float64) (*Account, error) &#123; a, err := GetAccount(Id) if err != nil &#123; return nil, err &#125; if a.Balance &lt;= withdraw &#123; return nil, errors.New(&quot;Not enough balance&quot;) &#125; a.Balance -= withdraw _, err = x.Update(a) return a, err&#125;func MakeTransfer(Id1 int64, transfer float64, Id2 int64) error &#123; a1, err := GetAccount(Id1) if err != nil &#123; return err &#125; a2, err := GetAccount(Id2) if err != nil &#123; return err &#125; if a1.Balance &lt;= transfer &#123; return errors.New(&quot;Not enough balance&quot;) &#125; a1.Balance -= transfer a2.Balance += transfer s := x.NewSession() defer s.Close() if err = s.Begin(); err != nil &#123; return err &#125; if _, err = s.Update(a1); err != nil &#123; s.Rollback() return err &#125; if _, err = s.Update(a2); err != nil &#123; s.Rollback() return err &#125; return s.Commit()&#125;func GetAccountsSortedById() (as []*Account, err error) &#123; err = x.Asc(&quot;id&quot;).Find(&amp;as) return as, err&#125;func GetAccountsSortedByNameDesc() (as []*Account, err error) &#123; err = x.Desc(&quot;name&quot;).Find(&amp;as) return as, err&#125;func DeleteAccount(id int64) error &#123; _, err := x.Delete(&amp;Account&#123;Id: id&#125;) return err&#125;func GetAccountCount() (int64, error) &#123; return x.Count(new(Account))&#125;func PrintAccounts() error &#123; err := x.Iterate(new(Account), func(idx int, bean interface&#123;&#125;) error &#123; fmt.Printf(&quot;%d: %#v\\n&quot;, idx, bean.(*Account)) return nil &#125;) return err&#125;func PrintAccounts2() error &#123; rows, err := x.Rows(new(Account)) if err != nil &#123; return err &#125; defer rows.Close() a := new(Account) for rows.Next() &#123; if err = rows.Scan(a); err != nil &#123; return err &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; &#125; return nil&#125; 2.2 main函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package mainimport ( &quot;fmt&quot; &quot;gin.test/xorm/models&quot;)const prompt = `Please enter number of operation:1. Create new account2. Show detail of account3. Deposit4. Withdraw5. Make transfer6. List account by Id7. List account by Balance8. Delete account9. Get total number of account10. Get all accounts11. Exit`func main() &#123; fmt.Println(&quot;Welcome bank of xorm&quot;)Exit: for &#123; fmt.Println(prompt) var num int fmt.Scanf(&quot;%d\\n&quot;, &amp;num) switch num &#123; case 1: fmt.Println(&quot;Please enter &lt;name&gt; &lt;balance&gt;: &quot;) var name string var balance float64 fmt.Scanf(&quot;%s %f\\n&quot;, &amp;name, &amp;balance) if err := models.NewAccount(name, balance); err != nil &#123; fmt.Println(err) &#125; case 2: fmt.Println(&quot;Please enter &lt;Id&gt;: &quot;) var Id int64 fmt.Scanf(&quot;%d\\n&quot;, &amp;Id) a, err := models.GetAccount(Id) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 3: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;deposit&gt;: &quot;) var Id int64 var deposit float64 fmt.Scanf(&quot;%d %f\\n&quot;, &amp;Id, &amp;deposit) a, err := models.MakeDeposit(Id, deposit) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 4: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;withdraw&gt;: &quot;) var Id int64 var withdraw float64 fmt.Scanf(&quot;%d %f\\n&quot;, &amp;Id, &amp;withdraw) a, err := models.MakeWithdraw(Id, withdraw) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 5: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;transfer&gt; &lt;Id&gt;: &quot;) var Id1 int64 var transfer float64 var Id2 int64 fmt.Scanf(&quot;%d %f %d\\n&quot;, &amp;Id1, &amp;transfer, &amp;Id2) err := models.MakeTransfer(Id1, transfer, Id2) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(&quot;Transfer succeeded.&quot;) &#125; case 6: as, err := models.GetAccountsSortedById() if err != nil &#123; fmt.Println(err) &#125; else &#123; for i, a := range as &#123; fmt.Printf(&quot;%d: %v\\n&quot;, i, a) &#125; &#125; case 7: as, err := models.GetAccountsSortedByNameDesc() if err != nil &#123; fmt.Println(err) &#125; else &#123; for i, a := range as &#123; fmt.Printf(&quot;%d: %v\\n&quot;, i, a) &#125; &#125; case 8: fmt.Println(&quot;Please enter &lt;Id&gt;: &quot;) var Id int64 fmt.Scanf(&quot;%d\\n&quot;, &amp;Id) err := models.DeleteAccount(Id) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(&quot;Delete account succeeded&quot;) &#125; case 9: count, err := models.GetAccountCount() if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;Total number of account: %d\\n&quot;, count) &#125; case 10: err := models.PrintAccounts2() if err != nil &#123; fmt.Println(err) &#125; case 11: break Exit &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"orm","slug":"orm","permalink":"https://elihe2011.github.io/tags/orm/"}]},{"title":"Go 常用工具函数","slug":"Go 常用工具函数","date":"2018-01-22T08:26:28.000Z","updated":"2021-06-22T10:50:49.710Z","comments":true,"path":"2018/01/22/Go 常用工具函数/","link":"","permalink":"https://elihe2011.github.io/2018/01/22/Go%20%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0/","excerpt":"","text":"1. 获取程序所在的运行目录1234567func GetAppPath() string &#123; file, _ := exec.LookPath(os.Args[0]) path, _ := filepath.Abs(file) index := strings.LastIndex(path, string(os.PathSeparator)) return path[:index]&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 包安装问题","slug":"Go 包安装问题","date":"2018-01-21T14:35:26.000Z","updated":"2021-06-22T10:50:49.709Z","comments":true,"path":"2018/01/21/Go 包安装问题/","link":"","permalink":"https://elihe2011.github.io/2018/01/21/Go%20%E5%8C%85%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/","excerpt":"1. 使用gopm镜像安装123go get -v github.com/gpmgo/gopmgopm get -v golang.org/x/tools/cmd/goimports","text":"1. 使用gopm镜像安装123go get -v github.com/gpmgo/gopmgopm get -v golang.org/x/tools/cmd/goimports 2. 开启代理安装123456git config --global http.proxy socks5://127.0.0.1:1080http_proxy=socks5://127.0.0.1:1080go get -v golang.org/x/tools/cmd/goimportsgit config --global --unset http.proxy","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go RPC","slug":"Go RPC","date":"2018-01-20T02:30:12.000Z","updated":"2021-06-22T10:50:49.709Z","comments":true,"path":"2018/01/20/Go RPC/","link":"","permalink":"https://elihe2011.github.io/2018/01/20/Go%20RPC/","excerpt":"1. RPC 客户端(client): 服务调用的发起方 客户端存根(client Stub): 运行在客户端机器上 存储调用服务器地址 将客户端请求数据信息打包 通过网络发给服务端存根程序 接收服务端响应的数据包，解析后给客户端 服务端(server): 服务提供者 服务端存根(server Stub): 存在与服务端机器上 接收客户端Stub程序发送来请求消息数据包 调用服务端的程序方法 将结果打包成数据包发给客户端Stub程序","text":"1. RPC 客户端(client): 服务调用的发起方 客户端存根(client Stub): 运行在客户端机器上 存储调用服务器地址 将客户端请求数据信息打包 通过网络发给服务端存根程序 接收服务端响应的数据包，解析后给客户端 服务端(server): 服务提供者 服务端存根(server Stub): 存在与服务端机器上 接收客户端Stub程序发送来请求消息数据包 调用服务端的程序方法 将结果打包成数据包发给客户端Stub程序 2. Go 语言实现 RPC Golang 提供RPC标准包，支持开发 RPC 服务端和客户端，采用 gob 编码。 支持三种请求方式：HTTP、TCP 和 JSONRPC Golang RPC 函数必须特定的格式写法才能被远程调用，格式如下： 1func (t *T) MethodName(argType T1, replyType *T2) error T1 和 T2 必须能被 encoding/gob 包编码和解码 3. RPC HTTP 调用 (异步调用)3.1 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445type Arguments struct &#123; A int B int&#125;type DemoRpc struct &#123;&#125;func (d *DemoRpc) Add(req Arguments, resp *int) error &#123; *resp = req.A + req.B return nil&#125;func (d *DemoRpc) Minus(req Arguments, resp *int) error &#123; *resp = req.A - req.B return nil&#125;func (d *DemoRpc) Div(req Arguments, resp *int) error &#123; // simulate time-consuming operations for i := 0; i &lt; 5; i++ &#123; log.Printf(&quot;Round %d, sleeping...\\n&quot;, i) time.Sleep(time.Second) &#125; if req.B == 0 &#123; return errors.New(&quot;divided by zero&quot;) &#125; *resp = req.A / req.B log.Printf(&quot;Div done.&quot;) return nil&#125;func main() &#123; //rpc.Register(new(DemoRpc)) rpc.RegisterName(&quot;DemoRpc&quot;, new(DemoRpc)) // same as above rpc.HandleHTTP() err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatal(err.Error()) &#125;&#125; 3.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type Arguments struct &#123; A int B int&#125;func main() &#123; client, err := rpc.DialHTTP(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; args := Arguments&#123;5, 7&#125; var resp int err = client.Call(&quot;DemoRpc.Add&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Add(%d, %d): %v\\n&quot;, args.A, args.B, resp) err = client.Call(&quot;DemoRpc.Minus&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Minus(%d, %d): %v\\n&quot;, args.A, args.B, resp) args = Arguments&#123;5, 0&#125;/* err = client.Call(&quot;DemoRpc.Div&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Div(%d, %d): %v\\n&quot;, args.A, args.B, resp)*/ // async call := client.Go(&quot;DemoRpc.Div&quot;, args, &amp;resp, nil) for &#123; select &#123; case &lt;-call.Done: if call.Error != nil &#123; log.Fatal(call.Error.Error()) &#125; log.Printf(&quot;DemoRpc Div(%d, %d): %v\\n&quot;, args.A, args.B, resp) return default: log.Println(&quot;waiting...&quot;) time.Sleep(time.Second) &#125; &#125;&#125; 4. JSONRPC4.1 服务端1234567891011121314151617181920212223242526272829303132type JsonParams struct &#123; X int Y int&#125;type JsonRpc struct&#123;&#125;func (*JsonRpc) Add(req JsonParams, resp *int) error &#123; *resp = req.X + req.Y return nil&#125;func main() &#123; rpc.RegisterName(&quot;JsonRpc&quot;, new(JsonRpc)) ln, err := net.Listen(&quot;tcp&quot;, &quot;:8081&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; for &#123; conn, err := ln.Accept() if err != nil &#123; log.Println(err.Error()) continue &#125; log.Printf(&quot;%v connected\\n&quot;, conn.RemoteAddr().String()) go jsonrpc.ServeConn(conn) &#125;&#125; 4.2 客户端 （Golang)123456789101112131415161718192021type JsonParams struct &#123; X int Y int&#125;func main() &#123; client, err := jsonrpc.Dial(&quot;tcp&quot;, &quot;:8081&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; req := JsonParams&#123;2, 8&#125; var resp int err = client.Call(&quot;JsonRpc.Add&quot;, req, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;JsonRpc.Add(%d, %d): %d\\n&quot;, req.X, req.Y, resp)&#125; 4.3 客户端 (Python)12345678910111213141516def main(): client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect((&#x27;localhost&#x27;, 8081)) payload = &#123; &quot;method&quot;: &quot;JsonRpc.Add&quot;, &quot;params&quot;: [&#123;&#x27;X&#x27;: 1, &#x27;Y&#x27;: 7&#125;], &quot;jsonrpc&quot;: &quot;1.0&quot;, &quot;id&quot;: 0, &#125; client.send(json.dumps(payload).encode(&#x27;utf-8&#x27;)) data = client.recv(1024) msg = json.loads(data.decode(&#x27;utf-8&#x27;)) print(msg.get(&#x27;result&#x27;)) 4.4 客户端 （Telnet)1234567$ telnet localhost 8081&#123;&quot;method&quot;: &quot;JsonRpc.Div&quot;, &quot;params&quot;: [&#123;&quot;X&quot;:5,&quot;Y&quot;:3&#125;], &quot;id&quot;: 1&#125;&#123;&quot;id&quot;:1,&quot;result&quot;:null,&quot;error&quot;:&quot;rpc: can&#x27;t find method JsonRpc.Div&quot;&#125;&#123;&quot;method&quot;: &quot;JsonRpc.Add&quot;, &quot;params&quot;: [&#123;&quot;X&quot;:5,&quot;Y&quot;:3&#125;], &quot;id&quot;: 1&#125;&#123;&quot;id&quot;:1,&quot;result&quot;:8,&quot;error&quot;:null&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go 字符编码","slug":"Go 字符编码","date":"2018-01-19T14:29:54.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/19/Go 字符编码/","link":"","permalink":"https://elihe2011.github.io/2018/01/19/Go%20%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","excerpt":"","text":"1. 编码检测库：1234567export http_proxy=socks5://127.0.0.1:1080 # 编码转换go get -v golang.org/x/text# 检测html编码go get -v golang.org/x/net/html 2. 字符编码转换：1234567891011121314151617181920212223242526272829303132333435func main() &#123; resp, err := http.Get(&quot;https://www.zhenai.com//zhenghun&quot;) if err != nil &#123; panic(err) &#125; defer resp.Body.Close() if resp.StatusCode != http.StatusOK &#123; fmt.Println(&quot;Error: status code&quot;, resp.StatusCode) &#125; // 为避免Peek函数影响底层io.Reader的文件指针位置，先转换为缓存Reader bufReader := bufio.NewReader(resp.Body) // 获取编码类型 e := determineEncoding(bufReader) // 编码类型转换 utf8Reader := transform.NewReader(bufReader, e.NewDecoder()) bytes, err := ioutil.ReadAll(utf8Reader) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%s\\n&quot;, bytes)&#125;func determineEncoding(r *bufio.Reader) encoding.Encoding &#123; bytes, err := r.Peek(1024) if err != nil &#123; panic(err) &#125; e, _, _ := charset.DetermineEncoding(bytes, &quot;html&quot;) return e&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 集成ElasticSearch","slug":"Go 集成ElasticSearch","date":"2018-01-18T04:20:00.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/18/Go 集成ElasticSearch/","link":"","permalink":"https://elihe2011.github.io/2018/01/18/Go%20%E9%9B%86%E6%88%90ElasticSearch/","excerpt":"","text":"1. 简介 全文搜索引擎 快速存储、搜索和分析海量数据 存储json格式文档 1.1 ElasticSearch数据库 &lt;server&gt;:9200/index/type/id index -&gt; database type -&gt; table &lt;server&gt;:9200/index/type/_search?q= 全文搜索 1.2 安装elastic client:1go get gopkg.in/olivere/elastic.v5 2. 安装ElasticSearch服务器2.1 使用Docker方式安装12345docker login daocloud.iodocker pull daocloud.io/library/elasticsearch:7.3.2docker run -d -p 9200:9200 daocloud.io/library/elasticsearch","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://elihe2011.github.io/tags/elasticsearch/"}]},{"title":"Go标准库 http","slug":"Go 标准库http","date":"2018-01-17T04:11:18.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/17/Go 标准库http/","link":"","permalink":"https://elihe2011.github.io/2018/01/17/Go%20%E6%A0%87%E5%87%86%E5%BA%93http/","excerpt":"","text":"1. 客户端Http Client: http.GET(url) 直接发起请求 http.Client{} 控制请求头部等 httputil 简化工作 示例： 123456789101112131415161718192021222324252627282930313233func main() &#123; // 1. 直接发起请求 //resp, err := http.Get(&quot;https://baidu.com&quot;) // 2. 控制请求头 req, err := http.NewRequest( http.MethodGet, &quot;http://www.baidu.com&quot;, nil) req.Header.Add(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1&quot;) //resp, err := http.DefaultClient.Do(req) // 3. 检测是否重定向 client := http.Client&#123; CheckRedirect: func(req *http.Request, via []*http.Request) error &#123; fmt.Println(&quot;Redirect:&quot;, req) return nil &#125;, &#125; resp, err := client.Do(req) if err != nil &#123; panic(err) &#125; defer resp.Body.Close() content, err := httputil.DumpResponse(resp, true) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%s&quot;, content)&#125; 2. 服务端2.1 handler函数12345678910111213141516171819202122232425262728func SignupHandler(w http.ResponseWriter, r *http.Request) &#123; if r.Method == http.MethodGet &#123; data, err := ioutil.ReadFile(&quot;./static/view/signup.html&quot;) if err != nil &#123; w.WriteHeader(http.StatusInternalServerError) return &#125; w.Write(data) &#125; else &#123; r.ParseForm() // 必须的 username := r.Form.Get(&quot;username&quot;) password := r.Form.Get(&quot;password&quot;) if len(username) &lt; 3 || len(password) &lt; 5 &#123; w.Write([]byte(&quot;Invalid parameter&quot;)) return &#125; enc_pwd := util.Sha1([]byte(password + pwd_salt)) ret := db.UserSignup(username, enc_pwd) if ret &#123; w.Write([]byte(&quot;SUCCESS&quot;)) &#125; else &#123; w.Write([]byte(&quot;FAILED&quot;)) &#125; &#125;&#125; 2.2 中间件123456789101112131415func HTTPInterceptor(h http.HandlerFunc) http.HandlerFunc &#123; return http.HandlerFunc( func(w http.ResponseWriter, r *http.Request) &#123; r.ParseForm() username := r.Form.Get(&quot;username&quot;) token := r.Form.Get(&quot;token&quot;) if len(username) &lt; 3 || !IsTokenValid(token) &#123; w.WriteHeader(http.StatusForbidden) return &#125; h(w, r) &#125;)&#125; 2.3 启动服务123456789101112131415func main() &#123; // 静态文件 path, _ := os.Getwd() path = filepath.Join(path, &quot;static&quot;) http.Handle(&quot;/static/&quot;, http.StripPrefix(&quot;/static/&quot;, http.FileServer(http.Dir(path)))) // 路由和中间件 http.HandleFunc(&quot;/user/signup&quot;, handler.SignupHandler) http.HandleFunc(&quot;/user/info&quot;, handler.HTTPInterceptor(handler.UserInfoHandler)) err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatalf(&quot;Failed to start server: %v&quot;, err) &#125;&#125; 3. http服务器性能分析 import _ &quot;net/http/pprof 访问/debug/pprof/ 使用go tool pprof分析性能 1234567import ( &quot;log&quot; &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;os&quot; ...) 查看性能： http://localhost:8080/debug/pprof/ go tool pprof http://localhost:8080/debug/pprof/profile","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 标准库unsafe","slug":"Go 标准库unsafe","date":"2018-01-16T04:11:18.000Z","updated":"2021-06-22T10:50:49.707Z","comments":true,"path":"2018/01/16/Go 标准库unsafe/","link":"","permalink":"https://elihe2011.github.io/2018/01/16/Go%20%E6%A0%87%E5%87%86%E5%BA%93unsafe/","excerpt":"1. unsafe包Go是强类型语言，不允许不同类型的指针互相转换。但它提供unsafe包作为中间媒介，快速实现类型转换，但该转换是不安全的。 1.1 Go指针和unsafe.Pointer的区别Go指针： 不能进行数学运算 不同类型的指针，不能相互转换 不同类型的指针不能使用 == 或 != 比较 不同类型的指针变量不能相互赋值 unsafe.Pointer: 12type ArbitraryType inttype Pointer *ArbitraryType","text":"1. unsafe包Go是强类型语言，不允许不同类型的指针互相转换。但它提供unsafe包作为中间媒介，快速实现类型转换，但该转换是不安全的。 1.1 Go指针和unsafe.Pointer的区别Go指针： 不能进行数学运算 不同类型的指针，不能相互转换 不同类型的指针不能使用 == 或 != 比较 不同类型的指针变量不能相互赋值 unsafe.Pointer: 12type ArbitraryType inttype Pointer *ArbitraryType uintptr: Go的内置类型，能存储指针的整型，与普通指针区别如下 1type uintptr uintptr 普通指针不可以参与计算，但uintptr可以。 普通指针和uintptr之间必选进行强制转换。 GC 不会把uintptr当成指针，由uintptr变量表示的地址处的数据也可能被GC回收。 1.2 主要方法123456789101112type ArbitraryType inttype Pointer *ArbitraryType// 返回类型所占内存大小func Sizeof（variable ArbitraryType）uintptr // 返回类型的对齐值, 等价于reflect.TypeOf(x).Align()func Alignof（variable ArbitraryType）uintptr// struct结构体中的字段相对于结构体的内存位置偏移量。结构体的第一个字段的偏移量都是0.// 等价于reflect.TypeOf(u1).Field(i).Offsetfunc Offsetof（selector ArbitraryType）uintptr 2. 指针转换2.1 示例：int32指针指向int64数据123456789101112131415func main() &#123; var n int64 = 5 var p1 = &amp;n var p2 = (*int32)(unsafe.Pointer(p1)) // 类型虽然不一样，但指向同一个地址 fmt.Printf(&quot;p1=%v, p2=%v\\n&quot;, p1, p2) *p2 = 10 fmt.Printf(&quot;n=%v, *p1=%v, *p2=%v\\n&quot;, n, *p1, *p2) // *p2 越界 *p1 = math.MaxInt32 + 1 fmt.Printf(&quot;n=%v, *p1=%v, *p2=%v\\n&quot;, n, *p1, *p2)&#125; 2.2 示例：遍历数组元素1234567891011func main() &#123; a := [...]int&#123;4, 7, 2, 9, 5&#125; p := &amp;a[0] fmt.Printf(&quot;%p: %v\\n&quot;, p, *p) for i := 1; i &lt; len(a); i++ &#123; ptr := uintptr(unsafe.Pointer(p)) + unsafe.Sizeof(a[0]) p = (*int)(unsafe.Pointer(ptr)) fmt.Printf(&quot;%p: %v\\n&quot;, p, *p) &#125;&#125; 3. 类型对齐值1234567891011121314151617181920212223func main() &#123; var b bool var i int var i64 int64 var f float32 var f64 float64 var s string var m map[int]string // 固定8 var a []int var p *int32 fmt.Println(unsafe.Alignof(b)) // 1 fmt.Println(unsafe.Alignof(i)) // 8 fmt.Println(unsafe.Alignof(i64)) // 8 fmt.Println(unsafe.Alignof(f)) // 4 fmt.Println(unsafe.Alignof(f64)) // 8 fmt.Println(unsafe.Alignof(s)) // 8 fmt.Println(unsafe.Alignof(m)) // 8 fmt.Println(unsafe.Alignof(a)) // 8 fmt.Println(unsafe.Alignof(p)) // 8&#125; 4. 利用unsafe包修改私有成员结构体(struct)，可以通过offset函数获取成员的偏移量，进而获取成员的地址。读写该地址的内存，就可以达到改变成员值的目的 结构体内存分配：会被分配一块连续的内存，结构体的地址也代表了第一个成员的地址。 12345678910111213141516type User struct &#123; name string age int&#125;func main() &#123; user := User&#123;&quot;eli&quot;, 29&#125; name := (*string)(unsafe.Pointer(&amp;user)) *name = &quot;rania&quot; age := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;user)) + unsafe.Offsetof(user.age))) *age = 20 fmt.Println(user)&#125; 5. 获取slice的长度12345678// runtime/slice.gotype slice struct &#123; array unsafe.Pointer // offset=8 len int cap int&#125;func makeslice(et *_type, len, cap int) slice 12345678910func main() &#123; s := make([]int, 5, 10) fmt.Printf(&quot;%p\\n&quot;, &amp;s) Len := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(8))) fmt.Printf(&quot;Len=%d, len(s)=%d\\n&quot;, *Len, len(s)) Cap := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(16))) fmt.Printf(&quot;Cap=%d, cap(s)=%d\\n&quot;, *Cap, cap(s))&#125; 6. 获取map长度12345678910111213141516type hmap struct &#123; count int flags uint8 B uint8 noverflow uint16 hash0 uint32 buckets unsafe.Pointer oldbuckets unsafe.Pointer nevacuate uintptr extra *mapextra&#125;// 注意返回的是指针func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap 12345678func main() &#123; mp := make(map[string]int) mp[&quot;a&quot;] = 21 mp[&quot;z&quot;] = 45 count := **(**int)(unsafe.Pointer(&amp;mp)) // 二级指针 fmt.Println(count, len(mp)) // 2 2&#125; 7. 实现字符串和byte切片的零拷贝转换slice和string的底层数据结构： 123456789101112131415161718192021222324252627282930313233type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125;func string2bytes(s string) []byte &#123; stringHeader := (*reflect.StringHeader)(unsafe.Pointer(&amp;s)) bh := reflect.SliceHeader&#123; Data: stringHeader.Data, Len: stringHeader.Len, Cap: stringHeader.Len, &#125; return *(*[]byte)(unsafe.Pointer(&amp;bh))&#125;func bytes2string(b []byte) string &#123; sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(&amp;b)) sh := reflect.StringHeader&#123; Data: sliceHeader.Data, Len: sliceHeader.Len, &#125; return *(*string)(unsafe.Pointer(&amp;sh))&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 单元测试","slug":"Go 单元测试","date":"2018-01-15T01:27:53.000Z","updated":"2021-06-22T10:50:49.707Z","comments":true,"path":"2018/01/15/Go 单元测试/","link":"","permalink":"https://elihe2011.github.io/2018/01/15/Go%20%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","excerpt":"1. 基础测试1.1 最简单的测试1234567func Add(x, y int) int &#123; return x + y&#125;func Sub(x, y int) int &#123; return x - y&#125;","text":"1. 基础测试1.1 最简单的测试1234567func Add(x, y int) int &#123; return x + y&#125;func Sub(x, y int) int &#123; return x - y&#125; 12345678910111213141516171819func TestAdd(t *testing.T) &#123; result := Add(3, 5) if result != 8 &#123; t.Fatalf(&quot;expected: %d, actual: %d&quot;, 8, result) &#125; t.Log(&quot;test Add success.&quot;)&#125;func TestSub(t *testing.T) &#123; result := Sub(3, 5) if result != -2 &#123; t.Fatalf(&quot;expected: %d, actual: %d&quot;, -2, result) &#125; t.Log(&quot;test Sub success.&quot;)&#125; 1234567go testgo test -vgo test -v -run TestAddgo help testflag 1.2 表格驱动测试123456789101112131415func TestAddBatch(t *testing.T) &#123; tests := []struct&#123; a, b, c int &#125;&#123; &#123;1, 2, 3&#125;, &#123;0, 2, 2&#125;, &#123;-1, 1, 1&#125;, &#125; for _, test := range tests &#123; if actual := Add(test.a, test.b); actual != test.c &#123; t.Errorf(&quot;Add(%d, %d); got %d; expected %d\\n&quot;, test.a, test.b, actual, test.c) &#125; &#125;&#125; 1.3 覆盖率测试123go test -coverprofile=c.outgo tool cover -html=c.out 1.4 Example Code测试1234567func Fib(n int) int &#123; if n &lt;= 2 &#123; return 1 &#125; return Fib(n-1) + Fib(n-2)&#125; 12345func ExampleFib() &#123; fmt.Println(fib(10)) // Output: 55&#125; 1go test -v 2. 基准测试基准测可以测试一段程序的运行性能及耗费CPU的程度 1234567891011121314151617181920212223242526272829303132333435363738func fib(n int) int &#123; a, b := 1, 1 for i := 1; i &lt;= n; i++ &#123; if i == n &#123; break &#125; a, b = b, a+b &#125; return a&#125;func fibonacci() func() int &#123; a, b := 1, 1 return func() int &#123; x := a a, b = b, a+b return x &#125;&#125;func fib2(n int) int &#123; x := 0 f := fibonacci() for i := 1; i &lt;= n; i++ &#123; x = f() &#125; return x&#125;func fib3(n int) int &#123; if n &lt;= 2 &#123; return 1 &#125; return fib3(n-1) + fib3(n-2)&#125; 1234567891011121314151617181920212223242526272829303132333435func BenchmarkFib(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib(n) if actual != expected &#123; b.Errorf(&quot;fib(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125;func BenchmarkFib2(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib2(n) if actual != expected &#123; b.Errorf(&quot;fib2(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125;func BenchmarkFib3(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib3(n) if actual != expected &#123; b.Errorf(&quot;fib3(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125; 123456789101112go test -bench=.BenchmarkFib-4 222371659 5.33 ns/opBenchmarkFib2-4 13082476 85.9 ns/opBenchmarkFib3-4 10054833 120 ns/op# 自定义测试时间go test -bench=. -benchmem -benchtime=10sBenchmarkFib-4 1000000000 5.35 ns/op 0 B/op 0 allocs/opBenchmarkFib2-4 138880591 87.1 ns/op 48 B/op 3 allocs/opBenchmarkFib3-4 97723549 120 ns/op 0 B/op 0 allocs/op ns/op 表示每一个操作消耗多少时间,单位是 纳秒ns B/op 表示每一次操作需要分配的字节数 allocs/op 表示每次执行分配了多少次 1234go test -bench . -cpuprofile=cpu.outgo tool pprof cpu.out(pprof) web 2.1 性能对比，int转string123456789101112131415161718192021222324func BenchmarkSprintf(b *testing.B) &#123; num := 10 b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; fmt.Sprintf(&quot;%d&quot;, num) &#125;&#125;func BenchmarkFormat(b *testing.B) &#123; num := int64(10) b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; strconv.FormatInt(num, 10) &#125;&#125;func BenchmarkItoa(b *testing.B) &#123; num := 10 b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; strconv.Itoa(num) &#125;&#125; 123456789 go test -bench=. -benchmemgoos: darwingoarch: amd64pkg: gomod/aaaBenchmarkSprintf-4 12190561 94.1 ns/op 16 B/op 2 allocs/opBenchmarkFormat-4 275836423 4.24 ns/op 0 B/op 0 allocs/opBenchmarkItoa-4 253071742 4.73 ns/op 0 B/op 0 allocs/opPASSok gomod/aaa 5.386s 2.2 pprof 性能监控12345678910111213func Fib(n int) int &#123; if n &lt; 2 &#123; return n &#125; return Fib(n-1) + Fib(n-2)&#125;func BenchmarkFib(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; Fib(10) &#125;&#125; 1234567go test -bench=. -benchmem -cpuprofile cpu.out -memprofile mem.outgo tool pprof cpu.out (pprof) top(pprof) list Fibgo tool pprof -http=&quot;:8081&quot; cpu.out 3. gomock当待测试的函数/对象的依赖关系很复杂，并且有些依赖不能直接创建，例如数据库连接、文件I/O等。这种场景就非常适合使用 mock/stub 测试。简单来说，就是用 mock 对象模拟依赖项的行为。 3.1 安装12go get -u github.com/golang/mock/gomockgo get -u github.com/golang/mock/mockgen 3.2 示例3.2.1 待mock的代码1234567891011type DB interface &#123; Get(key string) (int, error)&#125;func GetFromDB(db DB, key string) int &#123; if value, err := db.Get(key); err == nil &#123; return value &#125; return -1&#125; 3.2.2 生成mock代码1mockgen -source=db.go -destination=db_mock.go -package=main 3.2.3 测试代码1234567891011func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;)) if v := GetFromDB(m, &quot;Tom&quot;); v != -1 &#123; t.Fatalf(&quot;expected -1, but go %v&quot;, v) &#125;&#125; 3.2.4 执行测试123456$ go test . -cover -v=== RUN TestGetFromDB--- PASS: TestGetFromDB (0.00s)PASScoverage: 92.9% of statementsok gomod/mock 1.030s coverage: 92.9% of statements 3.3 打桩 (stubs)3.3.1 参数 (Eq, Any, Not, Nil)1234m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;))m.EXPECT().Get(gomock.Any()).Return(630, nil)m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil) m.EXPECT().Get(gomock.Nil()).Return(0, errors.New(&quot;nil&quot;)) 3.3.2 返回值 (Return, Do, DoAndReturn)12345678910m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil)m.EXPECT().Get(gomock.Any()).Do(func(key string) &#123; t.Log(key)&#125;)m.EXPECT().Get(gomock.Any()).DoAndReturn(func(key string) (int, error) &#123; if key == &quot;Sam&quot; &#123; return 630, nil &#125; return 0, errors.New(&quot;not exist&quot;)&#125;) 3.3.3 调用次数 (Times, MaxTimes, MinTimes, AnyTimes)123456789func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil).Times(2) GetFromDB(m, &quot;ABC&quot;) GetFromDB(m, &quot;DEF&quot;)&#125; 调用顺序 (InOrder)1234567891011func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() // 断言 DB.Get() 方法是否被调用 m := NewMockDB(ctrl) o1 := m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;)) o2 := m.EXPECT().Get(gomock.Eq(&quot;Sam&quot;)).Return(630, nil) gomock.InOrder(o1, o2) GetFromDB(m, &quot;Tom&quot;) GetFromDB(m, &quot;Sam&quot;)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 正则表达式","slug":"Go 正则表达式","date":"2018-01-12T01:26:38.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/12/Go 正则表达式/","link":"","permalink":"https://elihe2011.github.io/2018/01/12/Go%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"1. 正则表达式12345678func main() &#123; str := `171.43.145.13 - - [10/Mar/2020:10:19:06 +0800] &quot;POST /api/user/detail HTTP/1.1&quot; 200 252 &quot;-&quot; &quot;LifePlanner/1.9.14 (com.njivtime.lifeplanner; build:1.9.14.9; iOS 13.3.1) Alamofire/4.8.2&quot; &quot;-&quot; 0.009 0.009` re := regexp.MustCompile(`\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\s`) arr := re.FindAllString(str, -1) fmt.Println(arr)&#125;","text":"1. 正则表达式12345678func main() &#123; str := `171.43.145.13 - - [10/Mar/2020:10:19:06 +0800] &quot;POST /api/user/detail HTTP/1.1&quot; 200 252 &quot;-&quot; &quot;LifePlanner/1.9.14 (com.njivtime.lifeplanner; build:1.9.14.9; iOS 13.3.1) Alamofire/4.8.2&quot; &quot;-&quot; 0.009 0.009` re := regexp.MustCompile(`\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\s`) arr := re.FindAllString(str, -1) fmt.Println(arr)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 序列化操作","slug":"Go 序列化操作","date":"2018-01-11T01:24:54.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/11/Go 序列化操作/","link":"","permalink":"https://elihe2011.github.io/2018/01/11/Go%20%E5%BA%8F%E5%88%97%E5%8C%96%E6%93%8D%E4%BD%9C/","excerpt":"1. 序列化json.Marshal(v interface&#123;&#125;) ([]byte, error)","text":"1. 序列化json.Marshal(v interface&#123;&#125;) ([]byte, error) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172type Person struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;` Birthday string `json:&quot;birthday&quot;` Salary float64 `json:&quot;salary&quot;` Occupation string `json:&quot;occupation&quot;`&#125;func main() &#123; serializeStruct() serializeMap() serializeSlice()&#125;func serializeStruct() &#123; p := Person&#123; Name: &quot;张三&quot;, Age: 45, Birthday: &quot;1975-05-01&quot;, Salary: 32000.0, Occupation: &quot;电气工程师&quot;, &#125; data, err := json.Marshal(&amp;p) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125;func serializeMap() &#123; var m map[string]interface&#123;&#125; m = make(map[string]interface&#123;&#125;) m[&quot;name&quot;] = &quot;李四&quot; m[&quot;age&quot;] = 30 m[&quot;city&quot;] = &quot;北京市&quot; data, err := json.Marshal(m) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125;func serializeSlice() &#123; var s []map[string]interface&#123;&#125; m1 := make(map[string]interface&#123;&#125;) m1[&quot;name&quot;] = &quot;Tom&quot; m1[&quot;age&quot;] = 17 m1[&quot;city&quot;] = &quot;Los Angles&quot; m2 := make(map[string]interface&#123;&#125;) m2[&quot;name&quot;] = &quot;Julie&quot; m2[&quot;age&quot;] = 21 m2[&quot;city&quot;] = &quot;New York&quot; s = append(s, m1, m2) data, err := json.Marshal(s) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125; 2. 反序列化json.Unmarshal(data []byte, v interface&#123;&#125;) error 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type Person struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;` Birthday string `json:&quot;birthday&quot;` Salary float64 `json:&quot;salary&quot;` Occupation string `json:&quot;occupation&quot;`&#125;func main() &#123; deserializeStruct() deserializeMap() deserializeSlice()&#125;func deserializeStruct() &#123; js := `&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:45,&quot;birthday&quot;:&quot;1975-05-01&quot;,&quot;salary&quot;:32000,&quot;occupation&quot;:&quot;电气工程师&quot;&#125;` var p Person err := json.Unmarshal([]byte(js), &amp;p) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(p)&#125;func deserializeMap() &#123; js := `&#123;&quot;age&quot;:30,&quot;city&quot;:&quot;北京市&quot;,&quot;name&quot;:&quot;李四&quot;&#125;` var m map[string]interface&#123;&#125; // 反序列化不需要make，注意使用指针 &amp;m err := json.Unmarshal([]byte(js), &amp;m) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(m)&#125;func deserializeSlice() &#123; js := `[&#123;&quot;age&quot;:17,&quot;city&quot;:&quot;Los Angles&quot;,&quot;name&quot;:&quot;Tom&quot;&#125;,&#123;&quot;age&quot;:21,&quot;city&quot;:&quot;New York&quot;,&quot;name&quot;:&quot;Julie&quot;&#125;]` var s []map[string]interface&#123;&#125; // 反序列化不需要make，注意使用指针 &amp;s err := json.Unmarshal([]byte(js), &amp;s) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(s)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 网络编程","slug":"Go 网络编程","date":"2018-01-10T01:13:45.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/10/Go 网络编程/","link":"","permalink":"https://elihe2011.github.io/2018/01/10/Go%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","excerpt":"1. 网络编程1234567net.Listen(network, address string) (Listener, error)listener.Accept() (Conn, err)conn.Close()conn.Read([]byte) (int, err)conn.Write([]byte)net.Dial(network, address string) (Conn, error)","text":"1. 网络编程1234567net.Listen(network, address string) (Listener, error)listener.Accept() (Conn, err)conn.Close()conn.Read([]byte) (int, err)conn.Write([]byte)net.Dial(network, address string) (Conn, error) 1.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546func main() &#123; ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;Server has started, listening on %s\\n&quot;, ln.Addr()) defer ln.Close() for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; handleConnect(conn) &#125;&#125;func handleConnect(conn net.Conn) &#123; defer conn.Close() remoteAddr := conn.RemoteAddr() fmt.Printf(&quot;[%s] connected\\n&quot;, remoteAddr) for &#123; buf := make([]byte, 2048) n, err := conn.Read(buf) if err != nil &#123; fmt.Printf(&quot;[%s] disconnected\\n&quot;, remoteAddr) break &#125; str := string(buf[:n-1]) if str == &quot;quit&quot; || str == &quot;exit&quot; &#123; fmt.Printf(&quot;[%s] disconnected\\n&quot;, remoteAddr) break &#125; fmt.Printf(&quot;%s &gt;&gt; %s\\n&quot;, remoteAddr, str) conn.Write([]byte(strings.ToUpper(str + &quot;\\n&quot;))) &#125;&#125; 1.2 客户端123456789101112131415161718192021222324252627282930313233func main() &#123; conn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 键盘输入，并发送给服务器 go func() &#123; buf := make([]byte, 1024) for &#123; n, err := os.Stdin.Read(buf) if err != nil &#123; fmt.Println(err) break &#125; conn.Write(buf[:n]) &#125; &#125;() // 处理服务器返回数据 buf := make([]byte, 1024) for &#123; n, err := conn.Read(buf) if err == io.EOF &#123; return &#125; fmt.Println(string(buf[:n-1])) &#125;&#125; 2. 文件发送与接收2.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273func main() &#123; // 开启服务 ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() fmt.Printf(&quot;[%s]等待接收文件...\\n&quot;, ln.Addr()) // 接收请求 conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 获取对方发送的文件名 buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; fileName := string(buf[:n]) fmt.Printf(&quot;文件名: [%s]\\n&quot;, fileName) // 通知对方发送文件内容 _, err = conn.Write([]byte(&quot;ok&quot;)) if err != nil &#123; fmt.Println(err) return &#125; // 接收文件内容 recvFile(fileName, conn)&#125;func recvFile(fileName string, conn net.Conn) &#123; // 创建文件 f, err := os.Create(fileName) if err != nil &#123; fmt.Println(err) return &#125; defer f.Close() buf := make([]byte, 1024*4) for &#123; n, err := conn.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;\\n文件接收完毕&quot;) &#125; else &#123; fmt.Println(err) &#125; break &#125; if n == 0 &#123; fmt.Println(&quot;文件接收完毕&quot;) break &#125; fmt.Printf(&quot;.&quot;) _, err = f.Write(buf[:n]) if err != nil &#123; fmt.Println(&quot;写文件失败&quot;) &#125; &#125;&#125; 2.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func main() &#123; fmt.Printf(&quot;请输入文件名: &quot;) var fileName string fmt.Scan(&amp;fileName) // 获取文件信息 info, err := os.Stat(fileName) if err != nil &#123; fmt.Println(err) return &#125; // 连接文件接收服务器 conn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 发送文件名 _, err = conn.Write([]byte(info.Name())) // 服务器是否就绪 buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; if &quot;ok&quot; != string(buf[:n]) &#123; fmt.Println(&quot;服务器未就绪&quot;) return &#125; // 发送文件内容 sendFile(fileName, conn)&#125;func sendFile(fileName string, conn net.Conn) &#123; f, err := os.Open(fileName) if err != nil &#123; fmt.Println(err) return &#125; defer f.Close() buf := make([]byte, 1024*4) for &#123; _, err = f.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;发送完毕&quot;) &#125; else &#123; fmt.Println(err) &#125; break &#125; // 发送内容 conn.Write(buf) &#125;&#125; 3. 聊天服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145func main() &#123; // 开启监听服务 ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() // 转发消息 go Manager() // 主协程，循环阻塞等待用户连接 for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; go HandleConn(conn) &#125;&#125;// 客户端type Client struct &#123; C chan string Name string Addr string&#125;// 在线用户var onlineMap map[string]Client// 消息var message = make(chan string)// 消息转发func Manager() &#123; // 在线用户分配空间 onlineMap = make(map[string]Client) for &#123; msg := &lt;-message for _, cli := range onlineMap &#123; cli.C &lt;- msg &#125; &#125;&#125;func HandleConn(conn net.Conn) &#123; defer conn.Close() // 客户端地址 cliAddr := conn.RemoteAddr().String() // 客户端 cli := Client&#123; make(chan string), cliAddr, cliAddr, &#125; // 添加到在线用户 onlineMap[cliAddr] = cli // 新开协程，专门给当前客户端发送信息 go WriteMsgToClient(cli, conn) // 广播在线 message &lt;- MakeMsg(cli, &quot;online&quot;) // 当前用户是否已退出 isQuit := make(chan bool) // 当前用户是否超时 hasData := make(chan bool) // 新开协程，接收用户发来的数据 go func() &#123; buf := make([]byte, 2048) for &#123; n, err := conn.Read(buf) if n == 0 &#123; isQuit &lt;- true fmt.Println(&quot;用户断开连接或出现其他问题&quot;, err) return &#125; msg := string(buf[:n-1]) // 查询当前在线用户列表 if msg == &quot;who&quot; &#123; // 给当前用户发送所有在线成员 conn.Write([]byte(&quot;user list:\\n&quot;)) for _, u := range onlineMap &#123; conn.Write([]byte(u.Addr + &quot;: &quot; + u.Name + &quot;\\n&quot;)) &#125; &#125; else if len(msg) &gt; 8 &amp;&amp; msg[:6] == &quot;rename&quot; &#123; name := msg[7:] cli.Name = name onlineMap[cliAddr] = cli conn.Write([]byte(&quot;rename ok\\n&quot;)) &#125; else &#123; // 转发内容至其他在线用户 message &lt;- MakeMsg(cli, msg) &#125; hasData &lt;- true &#125; &#125;() for &#123; select &#123; case &lt;-isQuit: // 从在线用户列表中删除 delete(onlineMap, cliAddr) // 发送广播通知 message &lt;- MakeMsg(cli, &quot;offline&quot;) return case &lt;-hasData: case &lt;-time.After(time.Second * 60): delete(onlineMap, cliAddr) message &lt;- MakeMsg(cli, &quot;timeout&quot;) return &#125; &#125;&#125;func WriteMsgToClient(cli Client, conn net.Conn) &#123; for msg := range cli.C &#123; conn.Write([]byte(msg + &quot;\\n&quot;)) &#125;&#125;func MakeMsg(cli Client, msg string) string &#123; return &quot;[&quot; + cli.Addr + &quot;]&quot; + cli.Name + &quot;: &quot; + msg&#125; 4. HTTP服务器4.1 服务器123456789101112131415161718192021222324252627282930313233func main() &#123; ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() fmt.Println(&quot;http://localhost:8080&quot;) for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; go handleConn(conn) &#125;&#125;func handleConn(conn net.Conn) &#123; defer conn.Close() buf := make([]byte, 1024*4) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;%v\\n&quot;, string(buf[:n]))&#125; 12345678910111213141516func main() &#123; // 注册处理函数 http.HandleFunc(&quot;/go&quot;, myHandler) fmt.Println(&quot;http://localhost:8080&quot;) http.ListenAndServe(&quot;:8080&quot;, nil)&#125;func myHandler(w http.ResponseWriter, req *http.Request) &#123; fmt.Println(&quot;Method:&quot;, req.Method) fmt.Println(&quot;Header:&quot;, req.Header) fmt.Println(&quot;RemoteAddr:&quot;, req.RemoteAddr) fmt.Println(&quot;URL:&quot;, req.URL) fmt.Fprintln(w, &quot;Hello world!&quot;)&#125; 4.2 客户端12345678910111213141516171819202122232425func main() &#123; conn, err := net.Dial(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() requestHead := &quot;GET /go HTTP/1.1\\r\\nHost: localhost:8080\\r\\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7\\r\\n\\r\\n&quot; fmt.Println(requestHead) // 发送请求 conn.Write([]byte(requestHead)) // 接收响应 buf := make([]byte, 1024*4) n, err := conn.Read(buf) if n == 0 &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;#%v#\\n&quot;, string(buf[:n]))&#125; 12345678910111213141516171819202122232425262728func main() &#123; //resp, err := http.Get(&quot;http://www.baidu.com&quot;) resp, err := http.Get(&quot;http://localhost:8080/go&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer resp.Body.Close() fmt.Println(&quot;Status =&quot;, resp.Status) fmt.Println(&quot;StatusCode =&quot;, resp.StatusCode) fmt.Println(&quot;Header =&quot;, resp.Header) //fmt.Println(&quot;Body = &quot;, resp.Body) var text string buf := make([]byte, 1024*4) for &#123; n, err := resp.Body.Read(buf) if n == 0 &#123; fmt.Println(err) break &#125; text += string(buf[:n]) &#125; fmt.Println(text)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 命令行参数","slug":"Go 命令行参数","date":"2018-01-09T01:10:13.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/09/Go 命令行参数/","link":"","permalink":"https://elihe2011.github.io/2018/01/09/Go%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/","excerpt":"1. 命令行参数：os.Args []string123456789func main() &#123; args := os.Args fmt.Printf(&quot;接收到%v个参数\\n&quot;, len(args)) for i, v := range args &#123; fmt.Printf(&quot;args[%v]=%v\\n&quot;, i, v) &#125;&#125;","text":"1. 命令行参数：os.Args []string123456789func main() &#123; args := os.Args fmt.Printf(&quot;接收到%v个参数\\n&quot;, len(args)) for i, v := range args &#123; fmt.Printf(&quot;args[%v]=%v\\n&quot;, i, v) &#125;&#125; 2. flag包解析命令行参数12IntVar(p *int, name string, value int, usage string)StringVar(p *string, name string, value string, usage string) 12345678910111213141516func main() &#123; var user string var pwd string var host string var port int flag.StringVar(&amp;user, &quot;u&quot;, &quot;&quot;, &quot;用户名，默认为空&quot;) flag.StringVar(&amp;pwd, &quot;p&quot;, &quot;&quot;, &quot;密码，默认为空&quot;) flag.StringVar(&amp;host, &quot;h&quot;, &quot;&quot;, &quot;主机名，localhost&quot;) flag.IntVar(&amp;port, &quot;P&quot;, 3306, &quot;端口，默认3306&quot;) // 转换 flag.Parse() fmt.Printf(&quot;user=%v, pwd=%v, host=%v, port=%v\\n&quot;, user, pwd, host, port)&#125; 123$ go build -o main flag_1.go $ ./main -u root -p 123456 -h localhost -P 3006user=root, pwd=123456, host=localhost, port=3006","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 文件操作","slug":"Go 文件操作","date":"2018-01-08T01:04:38.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/08/Go 文件操作/","link":"","permalink":"https://elihe2011.github.io/2018/01/08/Go%20%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","excerpt":"1. 读文件 os.Open(name string) (file *File, err error) ioutil.ReadFile(name string) ([]byte, error) 适合小文件一次性读取","text":"1. 读文件 os.Open(name string) (file *File, err error) ioutil.ReadFile(name string) ([]byte, error) 适合小文件一次性读取 1.1 带缓存读取文件123456789101112131415161718func main() &#123; file, err := os.Open(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() reader := bufio.NewReader(file) for &#123; // 按行读取 line, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; fmt.Print(line) &#125;&#125; 1.2 一次性读取文件：(小文件适用)123456789func main() &#123; bs, err := ioutil.ReadFile(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Read file error: %v\\n&quot;, err) return &#125; fmt.Printf(&quot;%s\\n&quot;, bs)&#125; 2. 写文件1os.OpenFile(name string, flag int, perm FileMode) (file *File, err error) 12345678910111213141516func main() &#123; file, err := os.OpenFile(&quot;./xyz.txt&quot;, os.O_CREATE|os.O_WRONLY, 0600) if err != nil &#123; fmt.Errorf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() msg := &quot;Hello World!\\n&quot; writer := bufio.NewWriter(file) for i := 0; i &lt; 5; i++ &#123; writer.Write([]byte(msg)) &#125; writer.Flush()&#125; 文件操作模式： 覆盖写：os.O_WRONLY | os.O_TRUNC 追加写：os.O_WRONLY | os.O_APPEND 读写并追加：os.O_RDWR | os.OS_APPEND 3. 文件拷贝3.1 直接拷贝文件内容 （小文件，文本文件）123456789101112func main() &#123; bs, err := ioutil.ReadFile(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Errorf(&quot;Read file error: %v\\n&quot;, err) return &#125; err = ioutil.WriteFile(&quot;./xyz.txt&quot;, bs, 0600) if err != nil &#123; fmt.Errorf(&quot;Write file error: %v&quot;, err) &#125;&#125; 3.2 带缓冲拷贝 （大文件，二进制文件）io.Copy(dst Writer, src Reader) (written int64, err error) 123456789101112131415161718192021func CopyFile(dstFileName, srcFileName string) (written int64, err error) &#123; srcFile, err := os.OpenFile(srcFileName, os.O_RDONLY, 0) if err != nil &#123; return 0, err &#125; defer srcFile.Close() dstFile, err := os.OpenFile(dstFileName, os.O_CREATE|os.O_WRONLY, 0600) if err != nil &#123; return 0, err &#125; defer dstFile.Close() writer := bufio.NewWriter(dstFile) reader := bufio.NewReader(srcFile) written, err = io.Copy(writer, reader) writer.Flush() // 需要自己去Flush return&#125; 4. 文件是否存在12345678910111213func IsFileExist(name string) (bool, error) &#123; _, err := os.Stat(name) if err == nil &#123; return true, nil &#125; if os.IsNotExist(err) &#123; fmt.Println(&quot;文件不存在&quot;) return false, nil &#125; return false, err&#125; 5. 字符统计123456789101112131415161718192021222324252627282930313233343536373839404142type Statistic struct &#123; Char int Number int Space int Other int&#125;func main() &#123; file, err := os.Open(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() stat := Statistic&#123;&#125; reader := bufio.NewReader(file) for &#123; bs, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; for _, c := range []rune(bs) &#123; switch &#123; case c &gt;= &#x27;a&#x27; &amp;&amp; c &lt;= &#x27;z&#x27;: fallthrough case c &gt;= &#x27;A&#x27; &amp;&amp; c &lt;= &#x27;Z&#x27;: stat.Char++ case c &gt;= &#x27;0&#x27; &amp;&amp; c &lt;= &#x27;9&#x27;: stat.Number++ case c == &#x27; &#x27; || c == &#x27;\\t&#x27;: stat.Space++ default: stat.Other++ &#125; &#125; &#125; fmt.Printf(&quot;%v\\n&quot;, stat)&#125; 6. 目录遍历 type WalkFunc func(path string, info os.FileInfo, err error) error func Walk(root string, walkFn WalkFunc) error 1234567891011121314func main() &#123; // 当root=/tmp时，不会遍历目录下的文件 err := filepath.Walk(&quot;/tmp/&quot;, walkFunc) if err != nil &#123; fmt.Printf(&quot;File walk error: %v\\n&quot;, err) &#125;&#125;func walkFunc(path string, info os.FileInfo, err error) error &#123; fmt.Println(path) //fmt.Println(info.Name(), info.Size()) return nil&#125; 7. 压缩文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374func main() &#123; filePath := &quot;/tmp/&quot; filename := filepath.Base(filePath) fmt.Println(filename) currentTime := time.Now() ms := currentTime.Nanosecond() / 1e6 zipFilename := fmt.Sprintf(&quot;%s_%s%03d.zip&quot;, strings.Split(filename, &quot;.&quot;)[0], currentTime.Format(&quot;20060102150405&quot;), ms) fmt.Println(zipFilename) ZIP(filePath, zipFilename)&#125;func ZIP(source, target string) error &#123; zipFile, err := os.Create(target) if err != nil &#123; return err &#125; defer zipFile.Close() archive := zip.NewWriter(zipFile) defer archive.Close() err = filepath.Walk(source, func(path string, info os.FileInfo, err error) error &#123; if err != nil &#123; return err &#125; header, err := zip.FileInfoHeader(info) if err != nil &#123; return err &#125; header.Name = strings.TrimPrefix(path, source+&quot;/&quot;) // 目录不需要压缩 if info.IsDir() &#123; header.Name += &quot;/&quot; &#125; else &#123; // 压缩算法 header.Method = zip.Deflate &#125; // 保留文件时间 header.Modified = time.Unix(info.ModTime().Unix(), 0) // 创建：压缩包头信息 writer, err := archive.CreateHeader(header) if err != nil &#123; return err &#125; // 目录只需创建，不做其他操作 if info.IsDir() &#123; return nil &#125; // 打开需要压缩的文件 file, err := os.Open(path) if err != nil &#123; return nil &#125; defer file.Close() // 压缩文件 _, err = io.Copy(writer, file) return err &#125;) return err&#125; 8. 文件读取的三种方式 文件整体读取 文件分片读取 (块级读取) 文件行级读取 8.1 文件整体读取1234567891011// 方式1:bs, err := ioutil.ReadFile(filePath)// 方式2:file, err := os.Open(filePath)fileInfo, err := file.Stat()buffer := make([]byte, fileInfo.Size())n, err := file.Read(buffer)fmt.Printf(&quot;%s&quot;, buffer[:n]) 8.2 文件分片读取12345678910111213141516file, err := os.Open(filePath)buffer := make([]byte, 1024)for &#123; n, err := file.Read(buffer) if err != nil &amp;&amp; err != io.EOF &#123; panic(error) &#125; if n == 0 &#123; break &#125; fmt.Printf(&quot;%s&quot;, buffer)&#125; 8.3 文件按行读取123456789101112file, err := os.Open(filePath)reader := bufio.NewReader(file)for &#123; line, _, err := reader.ReadLine() if err == io.EOF &#123; break &#125; fmt.Printf(&quot;%s&quot;, line)&#125; 9. 文件写入的四周方式 简单覆盖写入 常规文件写入 带缓冲的写入 复制文件写入 9.1 简单覆盖写入1err := ioutil.WriteFile(filePath, data, 0666) 9.2 常规文件写入123456file, err := os.Create(filePath)file, err := os.OpenFile(filePath, os.O_RDONLY|os.O_CREATE|os.O_APPEND, 0666)n, err := file.Write([]byte(data))n, err := file.WriteString(data) 9.3 带缓冲的写入bufio 库： 123456789func NewWriter(w io.Writer) *Writerfunc NewWriterSize(w io.Writer, size int) *Writerfunc (b *Writer) Write(p []byte) (nn int, err error)func (b *Writer) WriteString(s string) (int, error)func (b *Writer) WriteByte(c byte) errorfunc (b *Writer) WriteRune(r rune) (size int, err error)func (b *Writer) Flush() error 9.4 复制文件写入io 包 12345// 默认缓冲区大小func Copy(dst Writer, src Reader) (written int64, err error)&#123;&#125;// 自定义缓冲区大小func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) &#123;&#125; 10. io.Reader 接口","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 反射","slug":"Go 反射","date":"2018-01-07T00:39:46.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/07/Go 反射/","link":"","permalink":"https://elihe2011.github.io/2018/01/07/Go%20%E5%8F%8D%E5%B0%84/","excerpt":"1. 反射反射：在运行时，动态获取对象的类型信息和内存结构 反射操作所需要的全部信息都源自接口变量，接口变量除了存储自身类型外，还会保存实际对象的类型数据 将任何传入的对象转换为接口类型： 12func TypeOf(o interface&#123;&#125;) Typefunc ValueOf(o interface&#123;&#125;) Value","text":"1. 反射反射：在运行时，动态获取对象的类型信息和内存结构 反射操作所需要的全部信息都源自接口变量，接口变量除了存储自身类型外，还会保存实际对象的类型数据 将任何传入的对象转换为接口类型： 12func TypeOf(o interface&#123;&#125;) Typefunc ValueOf(o interface&#123;&#125;) Value 2. 类型(Type)reflect.TypeOf() 返回对象类型 1234func TypeOf(i interface&#123;&#125;) Type &#123; eface := *(*emptyInterface)(unsafe.Pointer(&amp;i)) return toType(eface.typ)&#125; 2.1 Type和Kind的区别 Type: 真实类型（静态类型） t.Name() Kind: 基础类型（底层类型） t.Kind() 12345678func main() &#123; type X int var a X = 100 t := reflect.TypeOf(a) fmt.Println(t, t.Name(), t.Kind()) // main.X X int&#125; 2.2 基类型和指针类型12345678910func main() &#123; x := 20 tx := reflect.TypeOf(x) tp := reflect.TypeOf(&amp;x) fmt.Println(tx, tx.Name(), tx.Kind()) // int int int fmt.Println(tp, tp.Name(), tp.Kind()) // *int ptr fmt.Println(tx == tp.Elem()) // true&#125; 2.3 方法Type.Elem()返回引用类型 (指针、数组、切片、字典（值）或 通道) 的基类型 12345678910111213func main() &#123;a := [...]byte&#123;1, 2, 3&#125; s := make([]string, 5) m := make(map[int]string) ta := reflect.TypeOf(a) ts := reflect.TypeOf(s) tm := reflect.TypeOf(m) fmt.Println(ta, ta.Elem()) // [3]uint8 uint8 fmt.Println(ts, ts.Elem()) // []string string fmt.Println(tm, tm.Elem()) // ma[[iny]string string&#125; 2.4 辅助判断方法Implements(), ConvertibleTo(), AssignableTo() 12345678910111213141516171819202122func main() &#123; type X int var a X t := reflect.TypeOf(a) fmt.Println(t) // main.X ts := reflect.TypeOf((*fmt.Stringer)(nil)).Elem() fmt.Println(ts) // fmt.Stringer ti := reflect.TypeOf(10) fmt.Println(ti) // int fmt.Println(t.Implements(ts)) // false //fmt.Println(t.Implements(ti)) // panic: non-interface type passed to Type.Implements fmt.Println(t.ConvertibleTo(ts)) // false fmt.Println(t.ConvertibleTo(ti)) // true fmt.Println(t.AssignableTo(ts)) // false fmt.Println(t.AssignableTo(ti)) // false&#125; 2.5 结构体 反射类型Field(), FieldByIndex(), FieldByName(), FieldByNameFunc() 获取 StructField结构体中的内容 12345678910type StructField struct &#123; Name string PkgPath string Type Type // field type Tag StructTag // field tag string Offset uintptr // offset within struct, in bytes Index []int // index sequence for Type.FieldByIndex Anonymous bool // is an embedded field &#125; 12345678910111213func main() &#123; user := User&#123;&quot;Jack&quot;, 12&#125; t := reflect.TypeOf(user) for i := 0; i &lt; t.NumField(); i++ &#123; tf := t.Field(i) fmt.Printf(&quot;%s: %s %v\\n&quot;, tf.Name, tf.Type, tf.Tag) &#125; if tf, ok := t.FieldByName(&quot;Age&quot;); ok &#123; fmt.Printf(&quot;%s: %s\\n&quot;, tf.Name, tf.Tag.Get(&quot;json&quot;)) &#125;&#125; 3. 值(Value)接口变量会复制对象，是unaddressable的。要想修改目标对象，必须使用指针 12345678910func main() &#123; a := 5 va := reflect.ValueOf(a) vp := reflect.ValueOf(&amp;a).Elem() fmt.Println(va, vp) // 5 5 fmt.Println(va.CanAddr(), va.CanSet()) //false false fmt.Println(vp.CanAddr(), vp.CanSet()) // true true&#125; 3.1 结构体反射1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283type User struct &#123; Id int Name string Age byte&#125;func (u User) Hello() &#123; fmt.Println(&quot;Hello&quot;, u.Name)&#125;func (u User) Say(msg string) &#123; fmt.Println(u.Name, &quot;say&quot;, msg)&#125;func main() &#123; u := User&#123;1, &quot;Jack&quot;, 23&#125; Info(u) Set(&amp;u) fmt.Println(u)&#125;func Info(o interface&#123;&#125;) &#123; t := reflect.TypeOf(o) fmt.Println(&quot;Type:&quot;, t) // Type: main.User // pointer-interface，直接返回 if k := t.Kind(); k != reflect.Struct &#123; fmt.Println(&quot;A Pointer Interface&quot;) return &#125; v := reflect.ValueOf(o) fmt.Println(&quot;Fields:&quot;) for i := 0; i &lt; v.NumField(); i++ &#123; field := t.Field(i) value := v.Field(i).Interface() fmt.Printf(&quot;%6s: %v = %v\\n&quot;, field.Name, field.Type, value) &#125; f1 := v.FieldByIndex([]int&#123;1&#125;) fmt.Println(f1.Interface()) f2 := v.FieldByName(&quot;Age&quot;) fmt.Println(f2.Interface()) fmt.Println(&quot;Methods:&quot;) for i := 0; i &lt; v.NumMethod(); i++ &#123; m := t.Method(i) fmt.Printf(&quot;%6s: %v\\n&quot;, m.Name, m.Type) &#125; m1 := v.MethodByName(&quot;Say&quot;) args := []reflect.Value&#123;reflect.ValueOf(&quot;Hi&quot;)&#125; m1.Call(args)&#125;func Set(o interface&#123;&#125;) &#123; v := reflect.ValueOf(o) if v.Kind() != reflect.Ptr &#123; fmt.Println(&quot;Not a pointer interface&quot;) return &#125; if !v.Elem().CanSet() &#123; fmt.Println(&quot;Can not be set&quot;) return &#125; v = v.Elem() f := v.FieldByName(&quot;Age&quot;) if !f.IsValid() &#123; fmt.Println(&quot;Can not find this field&quot;) return &#125; if f.Kind() == reflect.Uint8 &#123; f.SetUint(25) &#125;&#125; 3.2 处理结构体匿名字段或嵌入字段反射匿名或嵌入字段：匿名字段当独立字段处理 12345678910111213141516171819202122232425262728293031type User struct &#123; Id int Name string Age byte&#125;type Manager struct &#123; User Title string&#125;func main() &#123; m := Manager&#123;User: User&#123;1, &quot;Jack&quot;, 21&#125;, Title: &quot;CEO&quot;&#125; t := reflect.TypeOf(m) fmt.Printf(&quot;%#v\\n&quot;, t.Field(0)) // &#123;Name:&quot;User&quot;, ..., Anonymous:true&#125; fmt.Printf(&quot;%#v\\n&quot;, t.Field(1)) // &#123;Name:&quot;Title&quot;, ..., Anonymous:false&#125; fmt.Printf(&quot;%#v\\n&quot;, t.FieldByIndex([]int&#123;0&#125;)) // Same as t.Field(0),&#123;Name:&quot;User&quot;, ..., Anonymous:true&#125; fmt.Printf(&quot;%#v\\n&quot;, t.FieldByIndex([]int&#123;0, 1&#125;)) // &#123;Name:&quot;Name&quot;, ..., Anonymous:false&#125; field, ok := t.FieldByName(&quot;Title&quot;) if ok &#123; fmt.Printf(&quot;%#v\\n&quot;, field) // &#123;Name:&quot;Title&quot;, ..., Anonymous:false&#125; &#125; field, ok = t.FieldByName(&quot;Id&quot;) if ok &#123; fmt.Printf(&quot;%#v\\n&quot;, field) // &#123;Name:&quot;Id&quot;, ..., Anonymous:false&#125; &#125;&#125; 3.3 通过反射，修改内容传入的值必选是pointer-interface 12345678func main() &#123; x := 10 v := reflect.ValueOf(&amp;x) // ptr-interface fmt.Printf(&quot;%#v\\n&quot;, v) v.Elem().SetInt(99) fmt.Println(x)&#125; 3.4 通道对象设置12345678func main() &#123; ch := make(chan int, 4) v := reflect.ValueOf(ch) if v.TrySend(reflect.ValueOf(100)) &#123; fmt.Println(v.TryRecv()) // 100 true &#125;&#125; 3.5 空接口判断1234567func main() &#123; var a interface&#123;&#125; = nil var b interface&#123;&#125; = (*int)(nil) fmt.Println(a == nil) // true fmt.Println(b == nil, reflect.ValueOf(b).IsNil()) //false true&#125; 4. 方法4.1 调用方法12345678910111213141516171819202122type X struct&#123;&#125;func (X) Add(x, y int) int &#123; return x + y&#125;func main() &#123; var a X v := reflect.ValueOf(a) m := v.MethodByName(&quot;Add&quot;) args := []reflect.Value&#123; reflect.ValueOf(5), reflect.ValueOf(7), &#125; result := m.Call(args) for _, val := range result &#123; fmt.Println(val) &#125;&#125; 4.2 调用变参方法12345678910111213141516171819202122232425262728type X struct&#123;&#125;func (X) Format(format string, a ...interface&#123;&#125;) string &#123; return fmt.Sprintf(format, a...)&#125;func main() &#123; var a X v := reflect.ValueOf(a) m := v.MethodByName(&quot;Format&quot;) args := []reflect.Value&#123; reflect.ValueOf(&quot;%s = %d&quot;), reflect.ValueOf(&quot;x&quot;), reflect.ValueOf(10), &#125; result := m.Call(args) fmt.Println(result) // [x = 10] args = []reflect.Value&#123; reflect.ValueOf(&quot;%d + %d = %d&quot;), reflect.ValueOf([]interface&#123;&#125;&#123;1, 2, 1 + 2&#125;), &#125; result = m.CallSlice(args) fmt.Println(result) // [1 + 2 = 3]&#125; 5. 构建反射库提供了内置函数 make() 和 new() 的对应操作，例如 MakeFunc()。可用它实现通用模板，适应不同数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142func main() &#123; var intAdd func(x, y int) int var strAdd func(x, y string) string makeAdd(&amp;intAdd) makeAdd(&amp;strAdd) fmt.Println(intAdd(20, 30)) fmt.Println(strAdd(&quot;Hello&quot;, &quot;World&quot;))&#125;func makeAdd(o interface&#123;&#125;) &#123; fn := reflect.ValueOf(o).Elem() v := reflect.MakeFunc(fn.Type(), add) fn.Set(v)&#125;func add(args []reflect.Value) (results []reflect.Value) &#123; if len(args) == 0 &#123; return nil &#125; var ret reflect.Value switch args[0].Kind() &#123; case reflect.Int: sum := 0 for _, n := range args &#123; sum += int(n.Int()) &#125; ret = reflect.ValueOf(sum) case reflect.String: ss := make([]string, 0, len(args)) for _, s := range args &#123; ss = append(ss, s.String()) &#125; ret = reflect.ValueOf(strings.Join(ss, &quot; &quot;)) &#125; results = append(results, ret) return&#125; 6. 反射相关方法12345678910111213141516171819202122232425262728293031323334353637reflect.TypeOf(o) // reflect.Typereflect.Type.Name() // 类型名称reflect.Type.Kind() // 原始类型名称：int, string...reflect.ValueOf(o) // reflect.Valuereflect.Value.Type() // reflect.Typereflect.Value.Kind() // 原始类型名称：int, string...(默认整型表示)// 获取变量值reflect.Value.Float()reflect.Value.Int()reflect.Value.String()reflect.Value.Bool()reflect.Value.Interface() // 获取真实值，不关系值的类型 // 指针ptr.Elem().setInt(99)// 改变变量的值reflect.Value.SetInt()reflect.Value.SetFloat()reflect.Value.SetString()// 结构体reflect.Value.NumField() // 结构体字段个数reflect.Value.Field(i) // reflect.StructFieldreflect.Value.FieldByIndex(i) // reflect.StructFieldreflect.Value.FieldByName(&quot;field&quot;) // reflect.StructFieldreflect.StructField.Name // 字段名reflect.StructField.Type // 字段类型reflect.Value.NumMethod() // 结构体方法个数reflect.Value.Method(i) // reflect.Methodreflect.Value.MethodByName(&quot;method&quot;) // reflect.Methodreflect.Method.Name // 方法名reflect.Method.Type // 方法类型reflect.Method.Call(in []Value) // 调用方法 7. 反射的三大定律7.1 两种类型 Type 和 Valuereflect.Type: 以接口的形式存在 123456789101112131415161718192021222324252627282930313233type Type interface &#123; Align() int FieldAlign() int Method(int) Method MethodByName(string) (Method, bool) NumMethod() int Name() string PkgPath() string Size() uintptr String() string Kind() Kind Implements(u Type) bool AssignableTo(u Type) bool ConvertibleTo(u Type) bool Comparable() bool Bits() int ChanDir() ChanDir IsVariadic() bool Elem() Type Field(i int) StructField FieldByIndex(index []int) StructField FieldByName(name string) (StructField, bool) FieldByNameFunc(match func(string) bool) (StructField, bool) In(i int) Type Key() Type Len() int NumField() int NumIn() int NumOut() int Out(i int) Type common() *rtype uncommon() *uncommonType&#125; reflect.Value: 以结构体形式存在 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374type Value struct &#123; typ *rtype ptr unsafe.Pointer flag&#125;func (v Value) Addr() Valuefunc (v Value) Bool() boolfunc (v Value) Bytes() []bytefunc (v Value) Call(in []Value) []Valuefunc (v Value) CallSlice(in []Value) []Valuefunc (v Value) CanAddr() boolfunc (v Value) CanInterface() boolfunc (v Value) CanSet() boolfunc (v Value) Cap() intfunc (v Value) Close()func (v Value) Complex() complex128func (v Value) Convert(t Type) Valuefunc (v Value) Elem() Valuefunc (v Value) Field(i int) Valuefunc (v Value) FieldByIndex(index []int) Valuefunc (v Value) FieldByName(name string) Valuefunc (v Value) FieldByNameFunc(match func(string) bool) Valuefunc (v Value) Float() float64func (v Value) Index(i int) Valuefunc (v Value) Int() int64func (v Value) Interface() (i interface&#125;)func (v Value) InterfaceData() [2]uintptrfunc (v Value) IsNil() boolfunc (v Value) IsValid() boolfunc (v Value) IsZero() boolfunc (v Value) Kind() Kindfunc (v Value) Len() intfunc (v Value) MapIndex(key Value) Valuefunc (v Value) MapKeys() []Valuefunc (v Value) MapRange() *MapIterfunc (v Value) Method(i int) Valuefunc (v Value) MethodByName(name string) Valuefunc (v Value) NumField() intfunc (v Value) NumMethod() intfunc (v Value) OverflowComplex(x complex128) boolfunc (v Value) OverflowFloat(x float64) boolfunc (v Value) OverflowInt(x int64) boolfunc (v Value) OverflowUint(x uint64) boolfunc (v Value) Pointer() uintptrfunc (v Value) Recv() (x Value, ok bool)func (v Value) Send(x Value)func (v Value) Set(x Value)func (v Value) SetBool(x bool)func (v Value) SetBytes(x []byte)func (v Value) SetCap(n int)func (v Value) SetComplex(x complex128)func (v Value) SetFloat(x float64)func (v Value) SetInt(x int64)func (v Value) SetLen(n int)func (v Value) SetMapIndex(key, elem Value)func (v Value) SetPointer(x unsafe.Pointer)func (v Value) SetString(x string)func (v Value) SetUint(x uint64)func (v Value) Slice(i, j int) Valuefunc (v Value) Slice3(i, j, k int) Valuefunc (v Value) String() stringfunc (v Value) TryRecv() (x Value, ok bool)func (v Value) TrySend(x Value) boolfunc (v Value) Type() Typefunc (v Value) Uint() uint64func (v Value) UnsafeAddr() uintptrfunc (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Valuefunc (v Value) call(op string, in []Value) []Valuefunc (v Value) pointer() unsafe.Pointerfunc (v Value) recv(nb bool) (val Value, ok bool)func (v Value) runes() []runefunc (v Value) send(x Value, nb bool) (selected bool)func (v Value) setRunes(x []rune) 7.2 反射的三大定律 Reflection goes from interface value to reflection object. 反射可以将接口类型变量 转换为“反射类型对象” Reflection goes from reflection object to interface value. 反射可以将 “反射类型对象”转换为 接口类型变量 To modify a reflection object, the value must be settable. 如果要修改 “反射类型对象” 其类型必须是 可写的 7.2.1 第一定律Reflection goes from interface value to reflection object. reflect.TypeOf(i): 获取接口值的类型 (*reflect.rtype) reflect.ValueOf(i): 获取接口值的值 (reflect.Value) 7.2.2 第二定律Reflection goes from reflection object to interface value. 注意：只有Value才能逆向转换，Type则不行 123func (v Value) Interface() (i interface&#123;&#125;) &#123; return valueInterface(v, true)&#125; 7.2.3 第三定律To modify a reflection object, the value must be settable. 非指针变量创建的反射对象，不可写 CanSet()返回true，为可写对象 不可写对象，无法进行写操作 可写对象，使用Elem()函数返回指针指向的数据 123456789101112func main() &#123; var name string = &quot;Go编程&quot; v1 := reflect.ValueOf(name) fmt.Println(v1.CanSet()) // false, 使用v1.Elem()方法会触发异常 v2 := reflect.ValueOf(&amp;name) fmt.Println(v2.CanSet()) // false v3 := v2.Elem() fmt.Println(v3.CanSet()) // true&#125; 可写对象的相关方法： 12345678910111213Set(x Value)SetBool(x bool)SetBytes(x []byte)setRunes(x []rune)SetComplex(x complex128)SetFloat(x float64)SetInt(x int64)SetLen(n int)SetCap(n int)SetMapIndex(key Value, elem Value)SetUint(x uint64)SetPointer(x unsafe.Pointer)SetString(x string)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 通道和并发","slug":"Go 通道和并发","date":"2018-01-06T09:12:24.000Z","updated":"2021-06-22T10:50:49.704Z","comments":true,"path":"2018/01/06/Go 通道和并发/","link":"","permalink":"https://elihe2011.github.io/2018/01/06/Go%20%E9%80%9A%E9%81%93%E5%92%8C%E5%B9%B6%E5%8F%91/","excerpt":"1. goroutine协程，比线程更小，十几个goroutine可能体现在底层就五六个线程。Go语言内部实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存（4～5KB），比线程更易用，更高效和更轻便。 goroutine调度模型： M: 线程 P: 上下文 G: Goroutine 并发concurrency： goroutine只是官方实现的超级“线程池”。每个实例4-5KB的栈内存占用，和大幅减少的创建和销毁开销，是制造Go号称高并发的根本原因 并发不是并行(Concurrency is Not Parallelism): 并发是通过切换CPU时间来实现“同时”运行；而并行则是直接利用多核实现多线程同时运行。Go可设置使用的CPU核心数，以发挥多核计算机的能力 goroutine奉行通过通信来共享内存，而不是共享内存来通信。","text":"1. goroutine协程，比线程更小，十几个goroutine可能体现在底层就五六个线程。Go语言内部实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存（4～5KB），比线程更易用，更高效和更轻便。 goroutine调度模型： M: 线程 P: 上下文 G: Goroutine 并发concurrency： goroutine只是官方实现的超级“线程池”。每个实例4-5KB的栈内存占用，和大幅减少的创建和销毁开销，是制造Go号称高并发的根本原因 并发不是并行(Concurrency is Not Parallelism): 并发是通过切换CPU时间来实现“同时”运行；而并行则是直接利用多核实现多线程同时运行。Go可设置使用的CPU核心数，以发挥多核计算机的能力 goroutine奉行通过通信来共享内存，而不是共享内存来通信。 goroutine的切换点： I/O, select channel 等待锁 函数调用 (有时) runtime.Gosched() 进程：资源拥有的基本单位。每个进程由私营的虚拟地址空间、代码、数据和其它各种资源组成。 线程：处理器调度和分配的基本单位。线程是进程内部的一个执行单元，每个进程至少有一个主线程，它无需用户去主动创建，由系统自动创建。 协程：比线程更小 轻量级“线程” “非抢占式”多任务处理，有协程主动交出控制权 编译器/解释器/虚拟机层面的多任务 多个协程，可能在一个或多个线程上运行 KSE：Kernel Scheduling Entity, 内核调度实体，即可以被操作系统内核调度器调度的实体对象，它是内核的最小调度单元，也就是内核级线程 三种线程模型： 用户级线程模型： 用户线程与内核线程KSE的关系是多对一 (N:1)。多个用户线程一般从属单个进程，并且多线程的调度由用户自己的线程库完成，线程的创建、销毁及线程间的协调等操作由用户自己的线程库负责，无需借助系统调度来实现。 Python的gevent协程库就属这种实现 线程调度在用户层面完成，不需要让CPU在用户态和内核态之间切换，这种方式较为轻量级，对系统资源消耗少 缺点：做不到真正意义上的并发。如果某个用户进程上的某个线程因为一个阻塞调用(I/O)二被CPU中断(抢占式调度)，那么该进程中的其它线程将被阻塞，整个进程被挂起。因为在用户线程模式下，进程内的线程绑定到CPU执行是由用户进程调度实现的，内部线程对CPU不可见，即CPU调度的是进程，而非线程 协程库优化：把阻塞的操作重新封装为完全非阻塞模式，在阻塞点上，主动让出自己，并通知或唤醒其它等待的用户线程 内核级线程模型 用户线程和内核线程KSE的关系是一对一 (1:1)。每个用户线程绑定一个内核线程，线程的调度完全交由内核控制 Java/C++ 的线程库按此方式实现 优点：简单，直接借助系统内核的线程和调度器，可以快速实现线程切换，做到真正的并行处理 缺点：由于直接使用内核去创建、销毁及多线程上下文切换和调度，系统资源成本大幅上涨，对性能影响较大 两级线程模型(即混合型线程模型) 用户线程与内核线程KSE的关系是多对多 (N:M) 一个进程可与多个内核线程KSE关联，该进程内的多个线程绑定到了不同的KSE上 进程内的线程并不与KSE一一绑定，当某个KSE绑定的线程因阻塞操作被内核调度出CPU时，其关联的进程中的某个线程又会重新与KSE绑定 此种模型高度复杂，Go语言中的runtime调度器实现了这种方案 为什么称为两级？用户调度实现用户线程到KSE的调度，内核调度器实现KSE到CPU上的调度 G-P-M 模型： G：Goroutine：独立执行单元。相较于每个OS线程固定分配2M内存的模式，Goroutine的栈采取动态扩容方式，2k ~ 1G(AMD64, AMD32: 256M)。周期性回收内存，收缩栈空间 每个Goroutine对应一个G结构体，它存储Goroutine的运行堆栈、状态及任务函数，可重用。 G并非执行体，每个G需要绑定到P才能被调度执行 P：Processor： 逻辑处理器，中介 对G来说，P相当于CPU，G只有绑定到P才能被调用 对M来说，P提供相关的运行环境(Context)，如内存分配状态(mcache)，任务队列(G)等 P的数量决定系统最大并行的G的数量 （CPU核数 &gt;= P的数量），用户可通过GOMAXPROCS设置数量，但不能超过256 M：Machine OS线程抽象，真正执行计算的资源，在绑定有效的P后，进入schedule循环 schedule循环的机制大致从Global队列、P的Local队列及wait队列中获取G，切换到G的执行栈上执行G的函数，调用goexit做清理工作并回到M M不保留G的状态 M的数量不定，由Go Runtime调整，目前默认不超过10K 1.1 go关键字开启新协程1234567891011func say(s string) &#123; for i := 0; i &lt; 5; i ++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) say(&quot;hello&quot;)&#125; 1.2 runtime包runtime.Gosched() 让出时间片runtime.Goexit() 终止协程runtime.GOMAXPROCS(N) 指定运行CPU个数 123456789101112func main() &#123; go func() &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Println(&quot;go&quot;) &#125; &#125;() for i := 0; i &lt; 2; i++ &#123; runtime.Gosched() // 让出时间片 fmt.Println(&quot;hello&quot;) &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 打印函数属IO操作，自动切换控制权func auto() &#123; for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; for &#123; fmt.Printf(&quot;Hello from goroutine %d\\n&quot;, i) &#125; &#125;(i) &#125; time.Sleep(time.Millisecond)&#125;// 不自动切换控制权func manual() &#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; // race condition for &#123; a[i]++ runtime.Gosched() // 交出控制权 &#125; &#125;(i) &#125; time.Sleep(time.Millisecond) fmt.Println(a) // 存在读写抢占&#125;// out of rangefunc outOfRange() &#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func() &#123; // race condition for &#123; a[i]++ runtime.Gosched() // 交出控制权 &#125; &#125;() &#125; time.Sleep(time.Millisecond) fmt.Println(a)&#125; 1go run -race goroutine.go # manual()函数存在抢占，race选项可检查到 2. 通道(channel)通道：用来传递数据的一种数据结构。两个goroutine之间，可以使用它来进行同步和通信 不靠共享内存通信，而是通过通信来共享内存 Channel： goroutine的沟通桥梁，大多是阻塞同步的 make创建，close关闭 是引用类型 可使用for range来迭代channel 可设置单向或双向通道 可设置缓存大小，在未被填满前不会发生阻塞 1234ch := make(chan int)ch &lt;- v // 把v发送到通道chv := &lt;- ch // 从ch接收数据 2.1 分段计算123456789101112131415161718192021func main() &#123; a := []int&#123;7, 9, -3, 4, 6, 8, 2, -5&#125; mid := len(a) / 2 ch := make(chan int) go sum(a[:mid], ch) go sum(a[mid:], ch) x, y := &lt;-ch, &lt;-ch fmt.Println(x, y, x+y)&#125;func sum(a []int, ch chan int) &#123; result := 0 for _, v := range a &#123; result += v &#125; ch &lt;- result&#125; 2.2 阻塞主线程12345678910func main() &#123; c := make(chan bool) go func() &#123; fmt.Println(&quot;Go Go Go!!!&quot;) c &lt;- true &#125;() &lt;- c // 阻塞main函数，等待goroutine执行完成&#125; 2.3 通道遍历和关闭如果通道不关闭close(ch)，遍历range ch就不会结束 123456789101112131415161718192021222324252627282930313233func main() &#123; ch := make(chan int, 10) go fib(cap(ch), ch) //// 方法1：for-range 自检 //for i := range ch &#123; // fmt.Printf(&quot;%d &quot;, i) //&#125; // 方法2：comma ok idiom for &#123; num, ok := &lt;-ch if ok &#123; fmt.Printf(&quot;%d &quot;, num) &#125; else &#123; break &#125; &#125; fmt.Println()&#125;func fib(n int, ch chan int) &#123; x, y := 1, 1 for i := 0; i &lt; n; i++ &#123; ch &lt;- x x, y = y, x+y &#125; // 必须关闭，否则deadlock close(ch)&#125; 2.4 主程序可能不等待goruntine123456789101112131415161718192021222324func main() &#123; ch := make(chan bool) for i := 0; i &lt; 10; i++ &#123; go calc(i, ch) &#125; &lt;-ch&#125;func calc(index int, ch chan bool) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) // goroutine 执行顺序不固定，此判断不正确 if index == 9 &#123; ch &lt;- true &#125;&#125; 2.4.1 方法一：使用缓存channel123456789101112131415161718192021222324func main() &#123; ch := make(chan bool, 10) for i := 0; i &lt; 10; i++ &#123; go calc(i, ch) &#125; // 等待10次 for i := 0; i &lt; 10; i++ &#123; &lt;-ch &#125;&#125;func calc(index int, ch chan bool) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) ch &lt;- true&#125; 2.4.2 方法二：通过同步解决(sync.WaitGroup) wg.Add(N): 新增N个任务 wg.Done(): 完成一个任务，计算器减1 wg.Wait(): 主线程等待，直到计数器为0 1234567891011121314151617181920212223func main() &#123; wg := sync.WaitGroup&#123;&#125; wg.Add(10) for i := 0; i &lt; 10; i++ &#123; go calc(i, &amp;wg) &#125; // 等待 wg.Wait()&#125;func calc(index int, wg *sync.WaitGroup) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) wg.Done()&#125; 2.5 模拟打印机1234567891011121314151617181920212223242526272829func main() &#123; ch := make(chan bool) go task1(ch) go task2(ch) // 等待 select &#123; case &lt;-time.After(15 * time.Second): &#125;&#125;func Printer(s string) &#123; for _, c := range s &#123; fmt.Printf(&quot;%c&quot;, c) time.Sleep(time.Second) &#125; fmt.Println()&#125;func task1(ch chan bool) &#123; &lt;-ch // 阻塞等待 Printer(&quot;hello&quot;)&#125;func task2(ch chan bool) &#123; Printer(&quot;world&quot;) ch &lt;- true // 完成释放&#125; 2.6 带缓冲的通道通道 ch := make(chan int, N): N=0 同步阻塞 N&gt;0 异步的，超过N时才阻塞 1234567891011121314151617func main() &#123; ch := make(chan int, 3) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;i=%d, len(ch)=%d, cap(ch)=%d\\n&quot;, i, len(ch), cap(ch)) ch &lt;- i &#125; &#125;() time.Sleep(2 * time.Second) for i := 0; i &lt; 10; i++ &#123; num := &lt;-ch fmt.Printf(&quot;num=%d\\n&quot;, num) &#125;&#125; 2.7 单向通道123var ch1 chan int // 默认双向var ch2 chan&lt;- int // 单向写var ch3 &lt;-chan int // 单向读 123456789101112131415161718192021222324252627func main() &#123; ch := make(chan int) /* 支持隐式转换 var send chan&lt;- int = ch // write-only var recv &lt;-chan int = ch // read-only */ go producer(ch) consumer(ch)&#125;func producer(out chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; out &lt;- i * i &#125; close(out)&#125;func consumer(in &lt;-chan int) &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, &lt;-in) &#125; fmt.Println()&#125; 3. Selectselect: 管理多个channel，监听channel上的数据流动。类似switch语法，但每个case语句必须是IO操作。多个case同时满足，任选一个执行。 处理一个或多个channel的发送和接收 同时有多个channel时，随机处理 可用空select来阻塞main函数 可设置超时 default语句： 有default：select语句不会被阻塞，执行default后，程序的执行会从select语句中恢复，进入下一次轮询。比较消耗资源。 没有default：select语句将被阻塞，直到至少有一个通信可以进行下去 3.1 管理多个通道3.1.1 示例1123456789101112131415161718192021222324252627282930313233343536func main() &#123; c1, c2 := make(chan int), make(chan string) done := make(chan bool, 2) go func() &#123; for &#123; select &#123; case v, ok := &lt;-c1: if !ok &#123; done &lt;- true break &#125; fmt.Println(&quot;c1:&quot;, v) case v, ok := &lt;-c2: if !ok &#123; done &lt;- true break &#125; fmt.Println(&quot;c2:&quot;, v) &#125; &#125; &#125;() c1 &lt;- 1 c2 &lt;- &quot;hi&quot; c1 &lt;- 5 c2 &lt;- &quot;hello&quot; // 必须关闭至少一个 close(c1) //close(c2) for i := 0; i &lt; 2; i++ &#123; &lt;-done &#125;&#125; 3.1.2 示例2123456789101112131415161718192021222324252627282930func main() &#123; ch := make(chan int) quit := make(chan bool) // 消费者 go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, &lt;-ch) &#125; fmt.Println() quit &lt;- true &#125;() fib(ch, quit)&#125;func fib(ch chan&lt;- int, quit &lt;-chan bool) &#123; x, y := 1, 1 for &#123; select &#123; case ch &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;Done.&quot;) return // break只能跳出select，无法跳出for循环 &#125; &#125;&#125; 3.1.3 使用select作为发送者应用12345678910111213141516func main() &#123; c := make(chan int) go func() &#123; for v := range c &#123; fmt.Println(v) &#125; &#125;() for i := 0; i &lt; 100; i++ &#123; select &#123; case c &lt;- 0: case c &lt;- 1: &#125; &#125;&#125; 3.2 超时处理case &lt;-time.After(5 * time.Second): 其他channel阻塞时间超过5s时执行 123456789101112131415161718192021222324func main() &#123; ch := make(chan int) done := make(chan bool) go func() &#123; for &#123; select &#123; case x := &lt;-ch: fmt.Printf(&quot;%d &quot;, x) case &lt;-time.After(5 * time.Second): fmt.Println(&quot;\\nTimeout&quot;) done &lt;- true return &#125; &#125; &#125;() for i := 0; i &lt; 10; i++ &#123; ch &lt;- i time.Sleep(time.Second) &#125; &lt;-done&#125; 3.3 避免造成死锁select 在执行过程中，必须命中其中的某一分支, 否则deadlock 12345678910111213141516func main() &#123; c1 := make(chan string, 1) c2 := make(chan string, 1) c1 &lt;- &quot;ok&quot; c2 &lt;- &quot;good&quot; select &#123; case msg := &lt;-c1: fmt.Printf(&quot;c1 receive %s\\n&quot;, msg) case msg := &lt;-c2: fmt.Printf(&quot;c2 receive %s\\n&quot;, msg) default: fmt.Println(&quot;no data&quot;) &#125;&#125; 4. 定时器4.1 一次性定时任务time.NewTimer(d Duration) *Timer &lt;-timer.C: 阻塞等待，返回定时器时间 timer.Stop(): timer.Reset(d Duration): 1234567891011121314151617func main() &#123; timer := time.NewTimer(2 * time.Second) go func() &#123; &lt;-timer.C fmt.Println(&quot;Goroutine is done.&quot;) &#125;() timer.Stop() // 重置定时器，上面的 goroutine 将继续执行 timer.Reset(5 * time.Second) select &#123; case &lt;-time.After(10 * time.Second): &#125;&#125; 4.2 周期性定时任务time.NewTicker(d Duration) *Ticker &lt;-ticker.C: 阻塞等待，返回定时器时间 ticker.Stop(): 1234567891011121314151617func main() &#123; ticker := time.NewTicker(2 * time.Second) count := 0 for &#123; &lt;-ticker.C count++ fmt.Printf(&quot;%d &quot;, count) if count == 10 &#123; ticker.Stop() break &#125; &#125; fmt.Println()&#125; 4.3 延迟操作总结123456time.Sleep(time.Second * 2)&lt;- time.After(time.Second * 2)timer := time.NewTimer(time.Second * 2)&lt;-timer.C 5. 死锁经典错误案例5.1 无缓冲信道，在接收者未准备好之前，发送操作是阻塞的1234567func main() &#123; c := make(chan bool) c &lt;- true // 阻塞 fmt.Println(&lt;-c)&#125; 两种解决方法： 1) 先接收，后发送 123456789func main() &#123; c := make(chan bool) go func() &#123; fmt.Println(&lt;-c) &#125;() c &lt;- true&#125; 2) 使用缓冲信道 1234567func main() &#123; c := make(chan bool, 1) c &lt;- true fmt.Println(&lt;-c)&#125; 5.2 缓冲信道，超过容量12345678func main() &#123; c := make(chan bool, 1) c &lt;- true c &lt;- false fmt.Println(&lt;-c)&#125; 5.3 等待从信道读取数据，但信道无数据写入123456789101112func main() &#123; c := make(chan bool, 1) go func() &#123; c &lt;- true c &lt;- false &#125;() for i := range c &#123; fmt.Println(i) &#125;&#125; 解决办法：及时关闭无用信道 1234567891011121314func main() &#123; c := make(chan bool, 1) go func() &#123; c &lt;- true c &lt;- false close(c) // 关闭信道 &#125;() for i := range c &#123; fmt.Println(i) &#125;&#125; 6. 控制 goroutine 并发数量1234567891011121314151617181920212223242526func main() &#123; count := 10 wg := sync.WaitGroup&#123;&#125; ch := make(chan int, 2) for i := 0; i &lt; count; i++ &#123; wg.Add(1) go func(i int) &#123; defer wg.Done() for n := range ch &#123; fmt.Printf(&quot;go func: %d, time: %v\\n&quot;, n, time.Now()) time.Sleep(time.Duration(n) * time.Second) &#125; &#125;(i) &#125; for i := 0; i &lt; 10; i++ &#123; ch &lt;- 1 ch &lt;- 2 &#125; close(ch) wg.Wait()&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 结构体和接口","slug":"Go 结构体和接口","date":"2018-01-05T01:28:32.000Z","updated":"2021-06-22T10:50:49.704Z","comments":true,"path":"2018/01/05/Go 结构体和接口/","link":"","permalink":"https://elihe2011.github.io/2018/01/05/Go%20%E7%BB%93%E6%9E%84%E4%BD%93%E5%92%8C%E6%8E%A5%E5%8F%A3/","excerpt":"1. 结构体将多个不同类型命名字段(field)序列打包成一个复合类型。 结构体特点： 值类型 做参数，值传递 相同类型，可使用==或!=比较 Go语言中实现封装、继承和多态： 封装：通过方法实现 继承：通过匿名字段实现 多态：通过接口实现","text":"1. 结构体将多个不同类型命名字段(field)序列打包成一个复合类型。 结构体特点： 值类型 做参数，值传递 相同类型，可使用==或!=比较 Go语言中实现封装、继承和多态： 封装：通过方法实现 继承：通过匿名字段实现 多态：通过接口实现 1.1 定义结构体123456789101112type person struct &#123; Name string Age int&#125;func main() &#123; p := person&#123; Name: &quot;lucy&quot;, Age: 22, &#125; fmt.Println(p)&#125; 1.2 匿名结构体12345678910111213141516171819202122232425262728type person struct &#123; Name string Age int Contact struct &#123; Phone, City string &#125;&#125;func main() &#123; p1 := person&#123; Name: &quot;lucy&quot;, Age: 22, Contact: struct&#123; Phone, City string &#125; &#123; Phone: &quot;123456789&quot;, City: &quot;LA&quot;, &#125;, &#125; fmt.Println(p1) p2 := person&#123; Name: &quot;jack&quot;, Age: 19, &#125; p2.Contact.Phone = &quot;987654321&quot; p2.Contact.City = &quot;NY&quot; fmt.Println(p2)&#125; 1.3 匿名字段1234567891011func main() &#123; s := struct &#123; int string &#125; &#123; 10, &quot;jack&quot;, &#125; fmt.Println(s)&#125; 1.4 嵌入结构（模拟继承）123456789101112131415161718192021222324252627282930313233343536type person struct &#123; Name string Age int&#125;type teacher struct &#123; person Salary float32&#125;type student struct &#123; person Score float32&#125;func main() &#123; t := teacher &#123; person: person&#123; Name: &quot;Jack&quot;, Age: 45, &#125;, Salary: 12901.20, &#125; t.Age += 1 s := student&#123; person: person&#123; Name: &quot;Tom&quot;, Age: 13, &#125;, Score: 91.50, &#125; s.Score -= 2.5 fmt.Println(t, s)&#125; 1.5 结构体序列化注意使用struct标签，否则序列化后的名称会保持大写开头不变 12345678910111213141516type Student struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;`&#125;func main() &#123; stu := Student&#123;&quot;Jack&quot;, 21&#125; js, err := json.Marshal(stu) if err != nil &#123; fmt.Println(&quot;json化失败&quot;, err) return &#125; fmt.Println(string(js))&#125; 1.6 工厂模式123456789101112131415type student struct &#123; Name string Age byte&#125;func NewStudent(name string, age byte) *student &#123; return &amp;student&#123; Name: name, Age: age, &#125;&#125;func (stu *student) String() string &#123; return fmt.Sprintf(&quot;Name=%v, Age=%v&quot;, stu.Name, stu.Age)&#125; 1.7 结构体链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229type Node struct &#123; Name string Value int next *Node&#125;func main() &#123; node := &amp;Node&#123; Name: &quot;head&quot;, Value: 0, &#125; appendNodes(node) //trans(node) // 只所以要有二级指针，是为了改变顶级node的地址，方便遍历函数遍历 insertNodes(&amp;node) //trans(node) delNode(&amp;node, &quot;head&quot;) //trans(node) addNode(&amp;node, &quot;node_A_1&quot;, &amp;Node&#123;Name: &quot;newNode&quot;, Value: 12&#125;) trans(node)&#125;func appendNodes(p *Node) &#123; for i := 0; i &lt; 2; i++ &#123; node := Node&#123; Name: fmt.Sprintf(&quot;node_A_%d&quot;, i), Value: rand.Intn(100), &#125; p.next = &amp;node p = &amp;node &#125;&#125;func insertNodes(p **Node) &#123; for i := 0; i &lt; 2; i++ &#123; node := Node&#123; Name: fmt.Sprintf(&quot;node_I_%d&quot;, i), Value: rand.Intn(100), &#125; node.next = *p *p = &amp;node &#125;&#125;func delNode(p **Node, name string) &#123; head := *p // 第一个即为要删除的对象 if head.Name == name &#123; *p = head.next return &#125; prev := head head = head.next for head != nil &#123; if head.Name == name &#123; prev.next = head.next break &#125; prev = head head = head.next &#125;&#125;func addNode(p **Node, name string, newNode *Node) &#123; head := *p // 第一个元素前插入 if head.Name == name &#123; newNode.next = head *p = newNode return &#125; prev := head head = head.next for head != nil &#123; if head.Name == name &#123; prev.next = newNode newNode.next = head break &#125; prev = head head = head.next &#125;&#125;func trans(p *Node) &#123; for p != nil &#123; fmt.Println(*p) p = p.next &#125;&#125;func main() &#123; node := &amp;Node&#123; Name: &quot;head&quot;, Value: 0, &#125; appendNodes(node) insertNodes(&amp;node) delNode(&amp;node, &quot;node_I_4&quot;) appendNode(node, &quot;head&quot;, &quot;newAppend&quot;) insertNode(&amp;node, &quot;node_A_4&quot;, &quot;newInsert&quot;) trans(node)&#125;type Node struct &#123; Name string Value int next *Node&#125;func trans(p *Node) &#123; for p != nil &#123; fmt.Println(*p) p = p.next &#125;&#125;func appendNodes(p *Node) &#123; for i := 0; i &lt; 5; i++ &#123; node := &amp;Node&#123; Name: fmt.Sprintf(&quot;node_A_%d&quot;, i), Value: rand.Intn(100), &#125; p.next = node p = node &#125;&#125;// 除了要在head前增加元素，还需要去改变链表head的位置，需要用到多重指针func insertNodes(p **Node) &#123; for i := 0; i &lt; 5; i++ &#123; node := &amp;Node&#123; Name: fmt.Sprintf(&quot;node_I_%d&quot;, i), Value: rand.Intn(100), &#125; node.next = *p *p = node &#125;&#125;func delNode(p **Node, name string) &#123; node := *p // 第一个就是要删除的元素 if node.Name == name &#123; *p = node.next return &#125; prev := node node = node.next for node != nil &#123; if node.Name == name &#123; prev.next = node.next break &#125; prev = node node = node.next &#125;&#125;func appendNode(p *Node, name, newName string) &#123; for p != nil &#123; if p.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: p.next, &#125; p.next = newNode break &#125; p = p.next &#125;&#125;func insertNode(p **Node, name, newName string) &#123; node := *p // 在第一个元素前增加 if node.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: node, &#125; // 改变链表头 *p = newNode return &#125; prev := node node = node.next for node != nil &#123; if node.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: node, &#125; // 与前一个链接起来 prev.next = newNode break &#125; prev = node node = node.next &#125;&#125; 1.8 结构体内存结构不管结构体包含多少字段，其内存总是一次性分配的，各字段在相邻的地址空间按定义顺序排列。当然，对于引用类型、字符串和指针，结构内存中只包含其基本（头部）数据。还有，所有匿名字段成员也被包含在内。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455type point struct &#123; x, y int&#125;type node struct &#123; id int name string data []byte next *node point&#125;func main() &#123; v := node&#123; id: 1, name: &quot;yes&quot;, data: []byte&#123;1, 2, 3, 4&#125;, point: point&#123;x: 100, y: 200&#125;, &#125; format := `v: %p ~ %x, size %d, align: %dfield address offset size-------+--------------------+--------+-----id %p %d %dname %p %d %ddata %p %d %dnext %p %d %dx %p %d %dy %p %d %d` fmt.Printf(format, &amp;v, uintptr(unsafe.Pointer(&amp;v))+unsafe.Sizeof(v), unsafe.Sizeof(v), unsafe.Alignof(v), &amp;v.id, unsafe.Offsetof(v.id), unsafe.Sizeof(v.id), &amp;v.name, unsafe.Offsetof(v.name), unsafe.Sizeof(v.name), &amp;v.data, unsafe.Offsetof(v.data), unsafe.Sizeof(v.data), &amp;v.next, unsafe.Offsetof(v.next), unsafe.Sizeof(v.next), &amp;v.x, unsafe.Offsetof(v.x), unsafe.Sizeof(v.x), &amp;v.y, unsafe.Offsetof(v.y), unsafe.Sizeof(v.y))&#125;/*v: 0xc000084000 ~ c000084048, size 72, align: 8field address offset size-------+--------------------+--------+-----id 0xc000084000 0 8name 0xc000084008 8 16data 0xc000084018 24 24next 0xc000084030 48 8x 0xc000084038 56 8y 0xc000084040 64 8*/ unsafe.Sizeof(x)特点总结： 字符串：始终返回16。字符串类型对应一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占8个字节，但是并不包含指针指向的字符串的内容。 切片: 始终返回24。if x is a slice, Sizeof returns the size of the slice descriptor, not the size of the memory referenced by the slice. 数组: Sizeof(x[0]) * len(x) 1.9 结构体字段对齐在分配内存时，字段须做对齐处理，通常以所有字段中最长的基础类型宽度为标准 unsafe.Alignof(x): 获取对齐宽度，以最长的基础类型宽度作为对齐标准。 12345678910111213141516171819202122func main() &#123; v1 := struct &#123; a byte b byte c int32 // 对齐宽度4 &#125;&#123;&#125; v2 := struct &#123; a byte b byte // 对齐宽度1 &#125;&#123;&#125; v3 := struct &#123; a byte b []int // 基础类型int，对齐宽度8 c int32 &#125;&#123;&#125; fmt.Printf(&quot;v1: %d, %d\\n&quot;, unsafe.Alignof(v1), unsafe.Sizeof(v1)) // 4, 8 fmt.Printf(&quot;v2: %d, %d\\n&quot;, unsafe.Alignof(v2), unsafe.Sizeof(v2)) // 1, 2 fmt.Printf(&quot;v3: %d, %d\\n&quot;, unsafe.Alignof(v3), unsafe.Sizeof(v3)) // 8, 40&#125; 1.10 类型对齐长度 类型 对齐长度 bool 1 int8/byte 1 int32 4 int64 8 string 8 map 8 slice 8 2. 方法方法是与对象实例绑定的特殊函数 2.1 绑定方法123456789101112131415type A struct &#123; Name string&#125;// （a A) receiverfunc (a A) Print() &#123; fmt.Println(a.Name)&#125;func main() &#123; a := A&#123; Name: &quot;tom&quot;, &#125; a.Print()&#125; 2.2 为int扩展方法12345678910111213type TZ intfunc (a *TZ) Print() &#123; fmt.Println(&quot;TZ&quot;)&#125;func main() &#123; var a TZ a.Print() // method value (*TZ).Print(&amp;a) // method expression&#125; 2.3 结构体重写String()方法重新String()方法：(fmt.Println()会自动调用String()方法) 1234567891011121314type Student struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;`&#125;func main() &#123; stu := Student&#123;&quot;Jack&quot;, 21&#125; fmt.Println(&amp;stu) // 自动调用String()方法&#125;func (stu *Student) String() string &#123; return fmt.Sprintf(&quot;Name=%v, Age=%v&quot;, stu.Name, stu.Age)&#125; 2.4 方法集类型有一个与之相关的方法集（method set），这决定了它是否实现某个接口。 类型T方法集包含所有receiver T方法。 类型T方法集包含所有receiver T+T方法。 匿名嵌入S，T方法集包含所有receiver S方法。 匿名嵌入S，T方法集包含所有receiver S+S方法。 匿名嵌入S或S，T方法集包含所有receiver S+*S方法。 1234567891011121314151617181920212223242526272829type S struct&#123;&#125;type T struct &#123; S&#125;func (S) Hello() &#123;&#125;func (S) sVal() &#123;&#125;func (*S) sPtr() &#123;&#125;func (T) tVal() &#123;&#125;func (*T) tPtr() &#123;&#125;func methodSet(a interface&#123;&#125;) &#123; t := reflect.TypeOf(a) fmt.Println(t.NumMethod()) // methods need to export, 只有Hello一个方法可导出 for i, n := 0, t.NumMethod(); i &lt; n; i++ &#123; m := t.Method(i) fmt.Println(m.Name, m.Type) &#125;&#125;func main() &#123; var t = T&#123;&#125; methodSet(t) println(&quot;------------&quot;) methodSet(&amp;t)&#125; 3. 接口接口代表一种调用契约，是多个方法声明的集合。 采用duck type方式 它把所有具有共性的方法定义在一起，任何其他类型只要实现了这些方法，就实现了该接口。注意，要全部实现！ 接口特性： 一个或多个方法签名的集合 只要某类型拥有改接口的所有方法签名，即算实现该接口，无需显示声明实现了那些接口，此称为Structural Typing 接口中只有方法声明，没有实现 接口可匿名嵌入其他接口，或嵌入到结构中 将对象赋值给接口，会发生拷贝，而接口内部存储指向这个复制品的指针，即无法修改复制品的状态，也无法获取指针 只有当接口存储的类型和对象均为nil时，接口才能有nil 接口调用不会做receiver的自动转换 接口同样支持匿名字段方法 接口也可实现类似OOP中的多态 空接口可以作为任何类型数据的容器 3.1 示例112345678910111213141516171819202122232425262728293031323334type Animal interface &#123; walk() eat()&#125;type Cat struct &#123;&#125;type Bird struct &#123;&#125;func (cat Cat) walk() &#123; fmt.Println(&quot;Cat walking with four limbs.&quot;)&#125;func (cat Cat) eat() &#123; fmt.Println(&quot;Cats like to eat fish.&quot;)&#125;func (bird Bird) walk() &#123; fmt.Println(&quot;Bird walkin with two legs.&quot;)&#125;func (bird Bird) eat() &#123; fmt.Println(&quot;Birds like to eat insects.&quot;)&#125;func main() &#123; var animal Animal animal = new(Cat) animal.walk() animal = new(Bird) animal.eat()&#125; 3.2 示例2123456789101112131415161718192021222324252627282930313233343536373839404142434445type USB interface &#123; Name() string Connector&#125;type Connector interface &#123; Connect()&#125;type PhoneConnector struct &#123; name string&#125;func (pc PhoneConnector) Name() string &#123; return pc.name&#125;func (pc PhoneConnector) Connect() &#123; fmt.Println(&quot;Connected:&quot;, pc.name)&#125;/*func Disconnect(usb USB) &#123; // 类型断言 if pc, ok := usb.(PhoneConnector); ok &#123; fmt.Println(&quot;Disconnected:&quot;, pc.name) return &#125; fmt.Println(&quot;Unknown device&quot;)&#125;*/// 万能空接口func Disconnect(usb interface&#123;&#125;) &#123; switch v := usb.(type) &#123; case PhoneConnector: fmt.Println(&quot;Disconnected:&quot;, v.name) default: fmt.Println(&quot;Unknown device&quot;) &#125;&#125;func main() &#123; var a USB = PhoneConnector&#123;&quot;PhoneConnector&quot;&#125; a.Connect() Disconnect(a)&#125; 3.3 类型断言空接口可接收任意类型，如果要转换为具体类型，需要使用类型断言 1234567891011func main() &#123; var point Point = Point&#123;1, 2&#125; var a interface&#123;&#125; a = point var b Point b = a.(Point) // 类型断言 fmt.Println(b)&#125; 3.3.1 类型断言检查为避免转换错误直接panic，可先检查转换是否成功 12345678910111213func main() &#123; var a interface&#123;&#125; var x float32 = 1.23 a = x y, ok := a.(float32) // 类型断言 if ok &#123; fmt.Println(y) &#125; else &#123; fmt.Println(&quot;转换失败&quot;) &#125;&#125; 3.3.2 类型断言switch123456789101112func TypeJudge(items ...interface&#123;&#125;) &#123; for index, x := range items &#123; switch x.(type) &#123; case bool: fmt.Printf(&quot;%v: %v is bool\\n&quot;, index, x) case string: fmt.Printf(&quot;%v: %v is string\\n&quot;, index, x) default: fmt.Printf(&quot;%v: %v is unknown\\n&quot;, index, x) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 函数和错误处理","slug":"Go 函数和错误处理","date":"2018-01-04T00:25:38.000Z","updated":"2021-06-22T10:50:49.703Z","comments":true,"path":"2018/01/04/Go 函数和错误处理/","link":"","permalink":"https://elihe2011.github.io/2018/01/04/Go%20%E5%87%BD%E6%95%B0%E5%92%8C%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/","excerpt":"1. 函数 不支持嵌套、重载和默认参数 无需声明原型、不定长度变参、多返回值、命名返回参数、匿名函数、闭包 本身就是一种类型 函数调用底层分析： 栈区：基本数据类型一般分配到栈区。编译器存在一个逃逸分析。每个函数有独立的栈，函数执行完毕，自动销毁 堆区：引用数据类型一般分配在堆区 代码区：存放代码指令","text":"1. 函数 不支持嵌套、重载和默认参数 无需声明原型、不定长度变参、多返回值、命名返回参数、匿名函数、闭包 本身就是一种类型 函数调用底层分析： 栈区：基本数据类型一般分配到栈区。编译器存在一个逃逸分析。每个函数有独立的栈，函数执行完毕，自动销毁 堆区：引用数据类型一般分配在堆区 代码区：存放代码指令 init()函数：每个源文件，都可以包含一个init函数，该函数会在main函数执行前，被Go运行框架调用。 执行顺序：全局变量定义 -&gt; init() -&gt; main() 1.1 参数传递不管是指针、引用类型，还是其他类型参数，都是值拷贝传递（pass-by-value)。区别无非是拷贝目标对象，还是拷贝指针对象本身而已。 在函数调用时，会为形参和返回值分配内存空间，并将实参拷贝到形参的内存。 1.2 参数过多，改用struct1234567891011121314151617181920212223242526type serverOption struct &#123; ip string port int path string timeout time.Duration log *log.Logger&#125;func newOption() *serverOption &#123; return &amp;serverOption&#123; ip: &quot;0.0.0.0&quot;, port: 8080, path: &quot;/data/www&quot;, timeout: time.Second*5, log: nil, &#125;&#125;func server(option *serverOption) &#123;&#125;func main() &#123; opt := newOption() opt.port = 8080 server(opt)&#125; 1.3 变参变参，实际上传递的是一个slice，如果是array，先转化为slice。s := a[:]... 12345678910func test(a ...int) &#123; fmt.Printf(&quot;%T, %v\\n&quot;, a, a)&#125;func main() &#123; test(1, 2, 3, 4) a := [3]int &#123;10, 20, 30&#125; test(a[:]...)&#125; 2. 匿名函数2.1 直接执行12345func main() &#123; func (s string) &#123; println(s) &#125; (&quot;Hello world&quot;)&#125; 2.2 赋值给变量1234567func main() &#123; add := func (x, y int) int &#123; return x + y &#125; println(add(2, 3))&#125; 2.3 作为参数123456789func test(f func()) &#123; f()&#125;func main() &#123; test(func() &#123; println(&quot;Hello world&quot;) &#125;)&#125; 2.4 作为返回值12345678910func test(x, y int) func() int &#123; return func() int &#123; return x + y &#125;&#125;func main() &#123; add := test(2, 3) println(add())&#125; 2.5 作为结构体字段12345678910111213func testStruct() &#123; type calc struct &#123; mul func(x, y int) int &#125; z := calc &#123; mul: func(x, y int) int &#123; return x * y &#125;, &#125; println(z.mul(2, 5))&#125; 2.6 通过Channel传递123456789func testChannel() &#123; c := make(chan func(int, int) int, 2) c &lt;- func(a int, b int) int &#123; return a + b &#125; println((&lt;- c)(1, 2))&#125; 3. 闭包（closure）闭包：一个函数和与其相关的引用变量组成的一个实体 返回一个匿名函数 该匿名函数使用了函数外变量 3.1 示例112345678910func test(x int) func() &#123; println(&amp;x) return func() &#123; println(&amp;x, x) // 返回的函数，包含了x环境上下文 &#125;&#125;func main() &#123; test(5)()&#125; 1go build -gcflags &quot;-N -l&quot; main.go 3.2 示例212345678910111213func main() &#123; f := closure(10) fmt.Println(f(1)) // 11 fmt.Println(f(2)) // 12&#125;func closure(x int) func(int) int &#123; fmt.Printf(&quot;%p\\n&quot;, &amp;x) // 0xc0000140b0 return func(y int) int &#123; fmt.Printf(&quot;%p\\n&quot;, &amp;x) // 0xc0000140b0 return x + y &#125;&#125; 3.3 多匿名函数返回，延迟求值问题1234567891011121314151617func test() []func() &#123; var fs []func() for i := 0; i &lt; 3; i++ &#123; fs = append(fs, func() &#123; println(&amp;i, i) // 延迟执行特性，最后都输出3 &#125;) &#125; return fs&#125;func main() &#123; for _, f := range test() &#123; f() &#125;&#125; 修正后： 123456789101112131415161718func test() []func() &#123; var fs []func() for i := 0; i &lt; 3; i++ &#123; x := i // 立即赋值 fs = append(fs, func() &#123; println(&amp;x, x) &#125;) &#125; return fs&#125;func main() &#123; for _, f := range test() &#123; f() &#125;&#125; 4. 递归函数4.1 阶乘123456789101112func factorial(n uint64) uint64 &#123; if n &gt; 0 &#123; return n * factorial(n - 1) &#125; return 1&#125;func main() &#123; var i int = 15 fmt.Printf(&quot;%d 的阶乘等于 %d&quot;, i, factorial(uint64(i)))&#125; 4.2 Fibonacci1234567891011121314func fibonacci(n uint64) uint64 &#123; if n &lt; 2 &#123; return n &#125; return fibonacci(n-2) + fibonacci(n-1)&#125;func main() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, fibonacci(uint64(i))) &#125; fmt.Println()&#125; 5. 延迟调用（defer) FILO 先进后出 即使函数发生panic错误，也会执行 支持匿名函数调用 用于资源清理、文件关闭、解锁以及记录时间等操作 与匿名函数配合，可在return后修改函数的计算结果 5.1 示例11234567891011func main() &#123; for i := 0; i &lt; 3; i++ &#123; defer fmt.Println(i) // 2 1 0 &#125; for i := 0; i &lt; 3; i++ &#123; defer func() &#123; fmt.Println(i) // 3 3 3 &#125;() &#125;&#125; 5.2 循环中使用延迟调用延迟调用在函数结束时调用，如果将其放到循环中，会造成资源浪费 123456789101112131415func main() &#123; for i := 0; i &lt; 1000; i++ &#123; path := fmt.Sprintf(&quot;./log/%d.txt&quot;, i) f, err := os.Open(path) if err != nil &#123; log.Println(err) continue &#125; defer f.Close() // do something &#125;&#125; 优化： 12345678910111213141516171819func main() &#123; do := func(i int) &#123; path := fmt.Sprintf(&quot;./log/%d.txt&quot;, i) f, err := os.Open(path) if err != nil &#123; log.Println(err) return &#125; defer f.Close() // do something &#125; for i := 0; i &lt; 1000; i++ &#123; do(i) &#125;&#125; 5.3 延迟调用闭包1234567891011121314151617181920func main() &#123; var fs = [4]func()&#123;&#125; for i := 0; i &lt; 4; i++ &#123; defer fmt.Println(&quot;defer i = &quot;, i) defer func() &#123; fmt.Println(&quot;defer_closure i = &quot;, i) // always 4 &#125;() defer func(i int) &#123; fmt.Println(&quot;defer_closure i = &quot;, i) // i will change &#125;(i) fs[i] = func() &#123; fmt.Println(&quot;closure i = &quot;, i) &#125; &#125; for _, f := range fs &#123; f() &#125;&#125; 5.4 延迟调用性能相比直接用CALL汇编指令调用函数，延迟调用则须花费更大代价。这其中包括注册、调用等操作，还有额外的缓存开销。 1234567891011121314151617181920212223var m sync.Mutexfunc call() &#123; m.Lock() m.Unlock()&#125;func deferCall() &#123; m.Lock() defer m.Unlock()&#125;func BenchmarkCall(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; call() &#125;&#125;func BenchmarkDeferCall(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; deferCall() &#125;&#125; 5.5 for range与闭包的坑1234567891011func main() &#123; s := []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; for _, v := range s &#123; go func() &#123; fmt.Println(v) // 三次全部打印&quot;c&quot; &#125;() &#125; select &#123;&#125; // 使main一直等待直到deadlock异常&#125; 6. 错误处理标准库错误接口: 123type error interface &#123; Error() string&#125; 6.1 panic &amp; recover panic: 主动抛出错误 recover: 捕获panic抛出的错误 12func panic(v interface&#123;&#125;)func recover() interface&#123;&#125; panic和recover运行机制： 1) 引发panic有两种情况：一是程序主动调用，二是程序产生运行时错误(Runtime Error)，由运行时检测并退出 2) 发生panic后，程序会从调用panic的函数位置或发生panic的地方立即返回，逐层执行函数的的defer语句，然后逐层打印函数调用堆栈，直到recover捕获或运行到最外层函数 3) panic不但可以在函数正常流程中抛出，在defer逻辑里也可以再次调用panic或抛出panic。defer里面的panic能够被后续执行的defer捕获 4) recover用来捕获panic，阻止panic继续向上传递。recover()和defer一起使用，但是defer只有在后面的函数体内直接被调用才能捕获panic来终止，否则返回nil，异常继续向外传递。 注意：除非是不可恢复性、导致系统无法正常工作的错误，否则不建议使用panic。如：文件系统没操作权限、服务端口被占用、数据库未启动等 123456789101112131415func main() &#123; result := div(8, 0) fmt.Println(result)&#125;func div(a int, b int) int &#123; defer func() &#123; err := recover() if err != nil &#123; fmt.Println(err) &#125; &#125;() return a / b&#125; 6.2 主动panic并捕获12345678910func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Fatalln(err) &#125; &#125;() panic(&quot;crash&quot;) println(&quot;exit.&quot;)&#125; 6.3 无效捕获和有效捕获错误12345678910111213141516171819202122// 无效的捕获defer recover()defer fmt.Println(recover())defer func() &#123; func() &#123; recover() // 嵌套多层，无效 &#125;()&#125;()// 有效的捕获defer func() &#123; recover()&#125;()func except() &#123; recover()&#125;func test() &#123; defer except() panic(&quot;runtime error&quot;)&#125; 6.4 多个panic，只会捕获最后一个1234567891011121314151617func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) // three 只会捕获最后一个 &#125; &#125;() defer func() &#123; panic(&quot;three&quot;) &#125;() defer func() &#123; panic(&quot;two&quot;) &#125;() panic(&quot;one&quot;)&#125; 7. 自定义错误 errors.New(&quot;错误描述&quot;)：返回一个error类型的值，表示一个错误 panic内置函数：接收一个interface{}类型的值(即任意值)作为参数，可以接受error类型的变量，输出错误信息，并退出程序。 7.1 负数平方根1234567891011121314151617func Sqrt(x float64) (float64, error) &#123; if x &lt; 0 &#123; return 0, errors.New(&quot;math: square root of negative number&quot;) &#125; return math.Sqrt(x), nil&#125;func main() &#123; result, err := Sqrt(-1) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(result) &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 引用数据类型","slug":"Go 引用数据类型","date":"2018-01-03T02:52:13.000Z","updated":"2021-06-22T10:50:49.703Z","comments":true,"path":"2018/01/03/Go 引用数据类型/","link":"","permalink":"https://elihe2011.github.io/2018/01/03/Go%20%E5%BC%95%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"1. 指针指针不是内存地址。 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。 指针会分配内存空间，相当于一个专门用来保存地址的整型变量。 GO指针，不支持加减运算和类型转换 可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。 Pointer类似C语言中的void*万能指针，可用来转换指针类型。它能安全持有对象或对象成员，但uintptr不行。后者仅是一种特殊整型，并不引用目标对象，无法阻止垃圾回收器回收对象内存。","text":"1. 指针指针不是内存地址。 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。 指针会分配内存空间，相当于一个专门用来保存地址的整型变量。 GO指针，不支持加减运算和类型转换 可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。 Pointer类似C语言中的void*万能指针，可用来转换指针类型。它能安全持有对象或对象成员，但uintptr不行。后者仅是一种特殊整型，并不引用目标对象，无法阻止垃圾回收器回收对象内存。 1.1 引用传递12345678910111213141516171819const MAX int = 3func main() &#123; var a int = 10 var b int = 20 fmt.Println(a, b) swap(&amp;a, &amp;b) fmt.Println(a, b)&#125;func swap(x *int, y *int) &#123; var temp int temp = *x *x = *y *y = temp&#125; 1.2 指针类型1.2.1 三种指针： *T：普通指针，用于传递地址，不能进行指针运算 unsafe.Pointor: 通用指针类型。用于转换不同类型的指针，不能进行指针运算 uintptr: 用于指针运算。GC不把uintptr当指针，uintptr无法持有对象。uintptr类型的目标会被回收 1.2.2 unsafe.Pointer 作用 unsafe.Pointer 可以和 普通指针 进行互相转换 unsafe.Pointer 可以和 uintptr 进行相互转换 unsafe.Pointer 是桥梁，可以让任意类型的指针实现相互转换，也可以将任意类型的指针转换为uintptr进行指针运算 2. 切片 (Slice)切片是对数组的抽象。数组长度固定，而切片长度不固定，可追加元素，被称为动态数组。 不是数组，但指向底层的数组 可现实变长数组 为引用类型 可直接创建(make)或从底层数组获取生成 len()获取元素个数，cap()获取容量 不支持比较操作(==, &gt;, &lt;) 12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 2.1 创建切片123456789101112131415func main() &#123; s1 := make([]int, 3, 5) s2 := make([]int, 3) s3 := []int&#123;10, 20, 3: 30&#125; arr := [...]int&#123;1, 2, 3, 4, 5&#125; s4 := arr[:] s5 := arr[2:4] // cap=len(arr)-2 fmt.Println(s1, len(s1), cap(s1)) // [0, 0, 0] 3 5 fmt.Println(s2, len(s2), cap(s2)) // [0, 0, 0] 3 3 fmt.Println(s3, len(s3), cap(s3)) // [10, 20, 0, 30] 4 4 fmt.Println(s4, len(s4), cap(s4)) // [1, 2, 3, 4, 5] 5, 5 fmt.Println(s5, len(s5), cap(s5)) // [3, 4] 2 3&#125; 2.2 空切片123456789101112131415func main() &#123; var s1 []int s2 := []int&#123;&#125; fmt.Println(s1==nil, s2==nil) // true false // &amp;reflect.SliceHeader&#123;Data:0x0, Len:0, Cap:0&#125; fmt.Printf(&quot;a: %#v\\n&quot;, (*reflect.SliceHeader)(unsafe.Pointer(&amp;s1))) // &amp;reflect.SliceHeader&#123;Data:0x118efd0, Len:0, Cap:0&#125; fmt.Printf(&quot;b: %#v\\n&quot;, (*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))) fmt.Printf(&quot;Size of a: %d\\n&quot;, unsafe.Sizeof(s1)) // 24 fmt.Printf(&quot;Size of a: %d\\n&quot;, unsafe.Sizeof(s2)) // 24&#125; 2.3 复制数据允许指向同一底层数组，允许目标区间重叠。最终所复制长度以较短的切片长度（len）为准 123456789101112131415func main() &#123; s1 := []int&#123;1, 2, 3, 4, 5, 6&#125; s2 := []int&#123;7, 8, 9&#125; copy(s1, s2) // dst, src fmt.Println(s1) // [7, 8, 9, 4, 5, 6] fmt.Println(s2) // [7, 8, 9] s3 := []byte&#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125; s4 := []byte&#123;&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;&#125; copy(s3, s4) fmt.Println(s3) // [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;] fmt.Println(s4) // [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;]&#125; 2.4 扩容数据12345678910111213func main() &#123; s1 := make([]int, 3, 6) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) fmt.Println(len(s1), cap(s1)) // 3, 6 s1 = append(s1, 1, 2, 3) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) // 元素个数小于等于cap，地址未发生改变 fmt.Println(len(s1), cap(s1)) // 6, 6 s1 = append(s1, 4) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) // 元素个数大于原始cap，重新分配内存(底层数组重构)，地址发生改变 fmt.Println(len(s1), cap(s1)) // 7, 12&#125; Slice坑：slice虽然是引用，但可能被重新分配内存 1234567891011func foo(s []int) &#123; s = append(s, 1) // 增加的元素个数大于cap-len, 重新分配内存地址&#125;func main() &#123; s := make([]int, 0) fmt.Println(s) foo(s) fmt.Println(s) // []&#125; 3. 集合 (map)make([keyType]valueType, cap) 3.1 基本操作12345678910111213141516171819func main() &#123; m := map[string]int &#123; &quot;a&quot;: 1, &quot;b&quot;: 2, &#125; m[&quot;a&quot;] = 5 m[&quot;c&quot;] = 8 if v, ok := m[&quot;d&quot;]; ok &#123; println(v) &#125; delete(m, &quot;d&quot;) for k, v := range m &#123; println(k, &quot;:&quot;, v, &quot; &quot;) &#125;&#125; 3.2 多层map嵌套12345678910111213141516func main() &#123; m := make(map[int]map[int]string) // initialize sub-map m[1] = make(map[int]string) m[1][1] = &quot;OK&quot; fmt.Println(m) a, ok := m[2][1] // test if sub-map is initialized fmt.Println(a, ok) if !ok &#123; m[2] = make(map[int]string) &#125; fmt.Println(m)&#125; 3.3 不支持修改成员值(struct或array)字典被设计成“not addressable”，故不能直接修改value成员（结构或数组） 123456789101112131415161718192021222324252627func main() &#123; m := map[int]user&#123; 1: user&#123;&quot;Jack&quot;, 23&#125;, 2: user&#123;&quot;Tom&quot;, 22&#125;, &#125; //m[1].age++ // cannot assign to struct field in a map jack := m[1] jack.age++ m[1] = jack // 必须重新赋值 fmt.Println(m) // 指针方式 m2 := map[int]*user&#123; 1: &amp;user&#123;&quot;Jack&quot;, 23&#125;, 2: &amp;user&#123;&quot;Tom&quot;, 22&#125;, &#125; m2[1].age++ fmt.Println(m2[1])&#125;type user struct &#123; name string age int&#125; 12345678910111213func main() &#123; m := map[string][2]int &#123; &quot;a&quot;: &#123;1, 2&#125;, &#125; //s := m[&quot;a&quot;][:] // 数组必须addressable，否则会引发错误。 a := m[&quot;a&quot;] fmt.Printf(&quot;%p, %v\\n&quot;, &amp;a, a) s := a[:] fmt.Printf(&quot;%p, %v\\n&quot;, &amp;s, s)&#125; 3.4 map间接排序12345678910111213141516171819func main() &#123; m := map[int]string&#123;2: &quot;b&quot;, 5: &quot;e&quot;, 1: &quot;a&quot;, 3: &quot;c&quot;, 4: &quot;d&quot;&#125; s := make([]int, len(m)) i := 0 for k, _ := range m &#123; s[i] = k i++ &#125; fmt.Println(s) sort.Ints(s) // 索引排序 fmt.Println(s) for _, v := range s &#123; fmt.Println(m[v]) &#125;&#125; 3.5 并发读写字典1234567891011121314151617181920212223242526func main() &#123; var lock sync.RWMutex m := make(map[string]int) go func() &#123; for &#123; lock.Lock() m[&quot;a&quot;] += 1 lock.Unlock() time.Sleep(time.Microsecond) &#125; &#125;() go func() &#123; for &#123; lock.RLock() _ = m[&quot;b&quot;] lock.RUnlock() time.Sleep(time.Microsecond) &#125; &#125;() select &#123;&#125;&#125; 4. range用于for循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。 slice(i, v) map(k, v) 4.1 示例：遍历map1234567891011121314151617func main() &#123; sm := make([]map[int]string, 3) for _, v := range sm &#123; v = make(map[int]string) // range中v的值是一份拷贝，无法修改 v[1] = &quot;OK&quot; fmt.Println(v) &#125; fmt.Println(sm) // 可正确修改 for i := range sm &#123; sm[i] = make(map[int]string) sm[i][1] = &quot;OK&quot; fmt.Println(sm[i]) &#125; fmt.Println(sm)&#125; 4.2 示例：遍历slice1234567891011121314151617181920func main() &#123; nums := []int &#123;2, 3, 4&#125; sum := 0 for _, num := range nums &#123; sum += num &#125; fmt.Println(&quot;sum:&quot;, sum) for i, num := range nums &#123; if num == 3 &#123; fmt.Println(&quot;index:&quot;, i) &#125; &#125; for i, c := range &quot;go语言&quot; &#123; fmt.Println(i, c) // c, unicode值 &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 基本数据类型","slug":"Go 基本数据类型","date":"2018-01-02T09:11:18.000Z","updated":"2021-06-22T10:50:49.702Z","comments":true,"path":"2018/01/02/Go 基本数据类型/","link":"","permalink":"https://elihe2011.github.io/2018/01/02/Go%20%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"1. 数据类型1.1 Go数据类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8的别名，相互不需要转换 int, uint 4, 8 0 默认整型，长度依平台而定，32或64 int8, uint8 1 0 -128 ~ 127, 0 ~ 255 int16, uint16 2 0 int32, uint32 4 0 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 默认 complex64 8 complex128 16 rune 4 0 Unicode Code Point, int32的别名 uintptr 4, 8 0 存储指针的uint string “” 默认值空字符串，而非nil array 数组 struct 结构体 function nil interface nil map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 ｜","text":"1. 数据类型1.1 Go数据类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8的别名，相互不需要转换 int, uint 4, 8 0 默认整型，长度依平台而定，32或64 int8, uint8 1 0 -128 ~ 127, 0 ~ 255 int16, uint16 2 0 int32, uint32 4 0 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 默认 complex64 8 complex128 16 rune 4 0 Unicode Code Point, int32的别名 uintptr 4, 8 0 存储指针的uint string “” 默认值空字符串，而非nil array 数组 struct 结构体 function nil interface nil map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 ｜ 1.2 值类型和引用类型 值类型：基本数据类型(int, float, bool, string)、数组(array)和结构体(struct) 变量直接存储，内存通常在栈中分配 (栈区：存放生命周期较短的数据) 引用类型：ptr、slice、map、channel、interface 变量存储的是一个地址，该地址对应的空间才真正存储数据。内存通常在堆上分配。当没有任何变量引用这个地址时，该地址对应的数据空间就成了垃圾，由GC来回收。（堆区：存放生命周期较长的数据。一个值类型，一般存储在栈区，但它如果在别的函数也用到，此时有可能放堆区，它要做逃逸分析） 2. 基本数据类型2.1 const常量2.1.1 常量特性： readonly cannot get address 12345678const x = 0x100y := &amp;x // errorconst x = 100const y byte = x // ok， 相当于const y byte = 100const x int = 100const y byte = x // error，需强制转换 2.1.2 常量初始化和枚举：iota: 常量计数器 1234567891011121314151617181920212223242526272829303132333435363738const ( a = &quot;A&quot; b // &quot;A&quot; c = iota // 2 d // 3)const ( e = iota // 0 f)const ( SUN = iota MON TUE WED THU FRI SAT)const ( B float64 = 1 &lt;&lt; (iota * 10) KB MB GB)// 需要显示恢复const ( a = iota // 0 b // 1 c = 100 // 100 d // 100 e = iota // 4 f // 5) 2.2 数值类型2.2.1 类型转换必须显示转换，不支持像Java一样向上自动转换 1234byte // uint8, 处理ASCII字符rune // int32, 处理Unicode字符，比如中文float64 // 系统默认类型，明确声明时，也推荐使用 2.2.2 运算符123456789101112// 除法fmt.Println(10 / 4) // 2var n1 float32 = 10 / 4fmt.Println(n1) // 2var n2 float32 = 10.0 / 4fmt.Println(n2) // 2.5// 取余 a % b = a - a / b * b10 % 3 // 1-10 % 3 // -1 2.2.3 两个变量，进行值交换，不允许使用中间变量123456var a int = 3var b int = 8a = a + bb = a - b // b = (a + b) - b = aa = a - b // a = (a + b) - a = b 2.2.4 数值进制转换123456789func main() &#123; a, _ := strconv.ParseInt(&quot;1100100&quot;, 2, 32) b, _ := strconv.ParseInt(&quot;0144&quot;, 8, 32) c, _ := strconv.ParseInt(&quot;64&quot;, 16, 64) println(&quot;0b&quot; + strconv.FormatInt(a, 2)) println(&quot;0&quot; + strconv.FormatInt(b, 8)) println(&quot;0x&quot; + strconv.FormatInt(c, 16))&#125; 2.2.5 数值类型转换123456789101112131415161718192021222324func main() &#123; a, _ := strconv.ParseInt(&quot;10100101&quot;, 2, 32) b, _ := strconv.ParseFloat(&quot;3.1415926&quot;, 64) fmt.Printf(&quot;%T, %v\\n&quot;, a, a) // int64 165 fmt.Printf(&quot;%T, %v\\n&quot;, b, b) // float64 3.1415926 fmt.Println(&quot;0x&quot; + strconv.FormatInt(a, 16)) // 0xa5 c := string(65) fmt.Printf(&quot;%T, %v\\n&quot;, c, c) // string, A d := int(c[0]) fmt.Printf(&quot;%T, %v\\n&quot;, d, d) // int, 65 e := strconv.Itoa(65) fmt.Printf(&quot;%T, %v\\n&quot;, e, e) // string, 65 f, _ := strconv.Atoi(e) fmt.Printf(&quot;%T, %v\\n&quot;, f, f) // int, 65 g, _ := strconv.ParseBool(&quot;true&quot;) fmt.Printf(&quot;%T, %v\\n&quot;, g, g) // bool, true&#125; 2.2.6 处理浮点数12345678910func main() &#123; var a float32 = 5.1234567890 var b float32 = 5.12345678 var c float32 = 5.123456789 println(a, b, c) // +5.123457e+000 +5.123457e+000 +5.123457e+000 println(a==b, a==c) // true true, 新版本go1.14.2，false, false fmt.Printf(&quot;%v, %v, %v\\n&quot;, a, b, c) // 5.123457, 5.123457, 5.123457&#125; 2.2.7 浮点数精度问题1234567891011121314151617181920212223func main() &#123; a := 0.6 a += 0.7 fmt.Println(a) // 1.2999999999999998 b := truncate(a) fmt.Println(b) // 1.3 c := round(a, 8) fmt.Println(c)&#125;func truncate(f float64) float64 &#123; str := fmt.Sprintf(&quot;%.8f&quot;, f) fmt.Println(str) // 1.30000000 f, _ = strconv.ParseFloat(str, 64) return f&#125;func round(f float64, n int) float64 &#123; n10 := math.Pow10(n) return math.Trunc((f+0.5/n10)*n10) / n10&#125; 2.3 字符串本质：是一个不可变byte序列，本身是一个复合结构 1234type stringStruct struct &#123; str unsafe.Pointer len int&#125; 头部指针指向字节数组，但没有NULL结尾 原始字符串raw string : 使用反引号”`”包裹，支持跨行 2.3.1 元素允许索引方式访问元素，但不能获取元素地址 123456func main() &#123; s := &quot;abc&quot; println(s[1]) println(&amp;s[1]) // cannot take the address&#125; 2.3.2 切片切片语法返回的子字符串，其内部依旧指向原始数组 reflect.StringHeader和string头结构相同 unsafe.Pointer用于指针类型转换 12345678910111213func main() &#123; s := &quot;abcdefg&quot; s1 := s[:3] s2 := s[1:4] s3 := s[2:] println(s1, s2, s3) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s))) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s1))) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s2)))&#125; 2.3.3 字符串遍历12345678910111213func main() &#123; s := &quot;中文&quot; // byte for i := 0; i &lt; len(s); i++ &#123; fmt.Printf(&quot;%d: [%c]\\n&quot;, i, s[i]) &#125; // rune for i, c := range s &#123; fmt.Printf(&quot;%d: [%c]\\n&quot;, i, c) &#125;&#125; 2.3.4 修改字符串字符串对象不可变，要修改，先将其转换为可变类型 []rune或[]byte 123456789101112131415161718s := &quot;hello world&quot;bs := []byte(s)s1 = string(bs)rs := []rune(s)s2 := string(rs)func toString(bs []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;bs))&#125;// 该方法利用了[]byte和string头结构“部分相同”，以非安全的指针类型转换来实现类型“变更”，从而避免了底层数组复制。在很多Web Framework中都能看到此类做法，在高并发压力下，此种做法能有效改善执行性能。只是使用unsafe存在一定的风险，须小心谨慎！s3 := toString(bs)// 修改字符串bs = append(bs, &quot;abc&quot;...)s4 := string(bs) 2.3.5 处理Unicode123456789101112func main() &#123; r := &#x27;中&#x27; // rune s := string(r) // string b := byte(r) // byte, 丢弃超出范围的bit fmt.Printf(&quot;%T, %T, %T\\n&quot;, r, s, b) // int32, string, uint8 s1 := string(b) r2 := rune(b) fmt.Println(s, b, s1, r2) // 中 45 - 45&#125; 2.3.6 截取字符串1234567func main() &#123; s := &quot;中C文&quot; fmt.Println(len(s), utf8.RuneCountInString(s)) // 7 3 s = string(s[0:1] + s[3:4]) fmt.Println(s, utf8.ValidString(s))&#125; 2.3.7 字符串拼接性能测试命令: go test -bench=. 1) 较差 123456789101112131415func test() string &#123; var s string for i := 0; i &lt; 10000; i++ &#123; s += &quot;a&quot; &#125; return s&#125;func BenchmarkTest(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; test() &#125;&#125; 2) 改进1 strings.Join(sa, &quot;&quot;) 123456789func test() string &#123; sa := make([]string, 10000) for i := 0; i &lt; len(sa); i++ &#123; sa[i] = &quot;a&quot; &#125; return strings.Join(sa, &quot;&quot;)&#125; 3) 改进2 byte.Buffer 12345678910func test() string &#123; var b bytes.Buffer b.Grow(10000) for i := 0; i &lt; 10000; i++ &#123; b.WriteString(&quot;a&quot;) &#125; return b.String()&#125; 2.3.8 字符串常用函数12345678910111213141516171819202122232425262728293031len(&quot;abc&quot;)r := []rune(&quot;中文&quot;) // 字符串遍历，同时支持处理中文n, err := strconv.Atoi(&quot;123&quot;)str := strconv.Itoa(123)bytes := []byte(&quot;abc&quot;) // [97, 98, 99]，二进制写入时有用str := string([]byte&#123;97, 98, 99&#125;) // abcstr := strconv.FormatInt(123, 2) // 进制转换 base=2, 8, 16b := strings.Contains(&quot;seafood&quot;, &quot;foo&quot;)count := strings.Count(&quot;seafood&quot;, &quot;o&quot;)b := strings.EqualFold(&quot;abc&quot;, &quot;ABC&quot;) // 不区分大小写n := strings.Index(&quot;go golang&quot;, &quot;go&quot;) // 0n := strings.LastIndex(&quot;go golang&quot;, &quot;go&quot;) // 3str := strings.Replace(&quot;go golang&quot;, &quot;c&quot;, n) 替换个数n，n=-1表示全部strArr := strings.Split(&quot;hello,world,ok&quot;, &quot;,&quot;)str := strings.toLower(&quot;Go&quot;)str := strungs.toUpper(&quot;Go&quot;)str := strings.TrimSpace(&quot; I am a gopher, haha. &quot;)str := strings.Trim(&quot;!Hello World!&quot;, &quot;!&quot;)str := strings.TrimRight(&quot;!Hello World!&quot;, &quot;!&quot;)str := strings.TrimLeft(&quot;!Hello World!&quot;, &quot;!&quot;)b := strings.HasPrefix(&quot;http://google.com&quot;, &quot;http&quot;)b := strings.HasSuffix(&quot;index.html&quot;, &quot;html&quot;) 2.3.9 获取中文字符串长度：12345678var str = &quot;hello 你好&quot;len(str) // 12import &quot;unicode/utf8&quot;utf8.RuneCountInString(str) // 8len([]rune(str)) // 8 2.4 数组2.4.1 声明和初始化123456789101112// 声明var balance [10]float32// 初始化var balance = [5]float32 &#123;4.0, 1.3, 2.2, 3.9, 3.0&#125;var balance = [...]float32 &#123;4.0, 1.3, 2.2&#125;balance[2] = 3.2// 访问数组var tag float32 = balance[1] 2.4.2 数组遍历12345678910111213func main() &#123; var arr [10]int for i := 0; i &lt; 10; i++ &#123; arr[i] = i + 100 &#125; for j := 0; j &lt; 10; j++ &#123; fmt.Printf(&quot;%d\\t&quot;, arr[j]) &#125; fmt.Println()&#125; 2.4.3 二分查找二分查找逻辑： 数组必须有序arr 中间的下标：midIndex = (firstIndex + lastIndex) / 2 让arr[midIndex]与targetValue比较 arr[midIndex] &gt; targetValue，返回firstIndex … (midIndex-1) arr[midIndex] &lt; targetValue，返回(midIndex+1) … lastIndex arr[midIndex] == targetValue，找到 1234567891011121314151617181920212223242526func main() &#123; a := []int&#123;0, 3, 5, 8, 9, 12, 14, 16&#125; index := binarySearch(&amp;a, 0, len(a)-1, 12) if index == -1 &#123; fmt.Println(&quot;未找到&quot;) &#125; else &#123; fmt.Printf(&quot;找到，位置在 %d\\n&quot;, index) &#125;&#125;func binarySearch(a *[]int, left, right, target int) int &#123; if left &gt;= right &#123; return -1 &#125; mid := (left + right) / 2 if (*a)[mid] &gt; target &#123; return binarySearch(a, left, mid-1, target) &#125; else if (*a)[mid] &lt; target &#123; return binarySearch(a, mid+1, right, target) &#125; else &#123; return mid &#125;&#125; 2.4.4 多维数组只允许第一维缺省 123456789101112131415161718192021222324func main() &#123; a := [2][2]int &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#125; b := [...][3]int &#123; &#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;, &#125; c := [...][2][2]int &#123; &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#125;, &#123; &#123;5, 6&#125;, &#123;7, 8&#125;, &#125;, &#125; fmt.Println(a, b, c)&#125; 2.4.5 数组长度len和cap都只返回一维数组长度 123456789func main() &#123; a := [...][2]int &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#123;5, &#125;, &#125; fmt.Println(len(a), cap(a), len(a[0]), cap(a[0]), len(a[2]), cap(a[2]))&#125; 2.4.6 比较操作 如元素类型支持“==、!=”操作符，那么数组也支持此操作。 前提：类型必须一致！ 1234567891011121314func main() &#123; var a, b [2]int fmt.Println(a == b) c := [2]int&#123;1, 2&#125; d := [2]int&#123;1, 3&#125; fmt.Println(c == d) e := [3]int&#123;1, 2, 3&#125; fmt.Println(c == e) // 类型不一致，无法比较 var x, y [2]map[string]int fmt.Println(x == y) // map不支持==和!=操作，数组无法支持&#125; 2.4.7 指针数组和数组指针 指针数组: 元素为指针类型的数组 数组指针: 数组变量的地址 123456789func main() &#123; x, y := 10, 20 a := [...]*int &#123;&amp;x, &amp;y&#125; // 指针数组 p := &amp;a // 数组指针 fmt.Printf(&quot;%T %v\\n&quot;, a, a) fmt.Printf(&quot;%T %v\\n&quot;, p, p)&#125; 使用指针操作数组： 123456789func main() &#123; a := [...]int&#123;1, 2&#125; fmt.Println(&amp;a, &amp;a[0], &amp;a[1]) p := &amp;a p[1] += 3 fmt.Println(p, a)&#125; 2.4.8 数组复制1234567891011121314151617181920func test1(x [2]int) &#123; fmt.Printf(&quot;x: %p, %v\\n&quot;, &amp;x, x)&#125;func test2(y *[2]int) &#123; fmt.Printf(&quot;y: %p, %v\\n&quot;, y, *y)&#125;func main() &#123; a := [2]int&#123;1, 2&#125; var b [2]int b = a // 值复制，地址并未复制 fmt.Printf(&quot;a: %p, %v\\n&quot;, &amp;a, a) fmt.Printf(&quot;b: %p, %v\\n&quot;, &amp;b, b) test1(a) // 按值传递 test2(&amp;a) // 按地址传递&#125; 2.4.9 排序算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869func main() &#123; arr := [...]int&#123;5, 7, 8, 1, 2, 4, 9, 0, 3, 6&#125; //bubbleSort(arr[:]) //selectSort(arr[:]) //insertSort(arr[:]) quickSort(arr[:], 0, len(arr)-1) fmt.Println(arr)&#125;func bubbleSort(a []int) &#123; for i := 0; i &lt; len(a); i++ &#123; for j := 1; j &lt; len(a)-i; j++ &#123; // 相邻比较，交换位置 if a[j] &lt; a[j-1] &#123; a[j], a[j-1] = a[j-1], a[j] &#125; &#125; &#125;&#125;func selectSort(a []int) &#123; for i := 0; i &lt; len(a); i++ &#123; for j := i + 1; j &lt; len(a); j++ &#123; // 选择a[i]作为标兵，将它与i+1...的值比较，找到最小或最大，赋值给a[i] if a[i] &gt; a[j] &#123; a[i], a[j] = a[j], a[i] &#125; &#125; &#125;&#125;func insertSort(a []int) &#123; // 假定第一个元素是有序的，后的元素与之比较，满足条件逐个插入 for i := 1; i &lt; len(a); i++ &#123; for j := i; j &gt; 0; j-- &#123; // 前一个元素大于后一个元素，跳过比较 if a[j] &gt; a[j-1] &#123; break &#125; a[j], a[j-1] = a[j-1], a[j] &#125; &#125;&#125;func quickSort(a []int, left, right int) &#123; if left &gt;= right &#123; return &#125; // 选取一个元素，作为比较项 k := left val := a[k] for i := left + 1; i &lt;= right; i++ &#123; // 比基准值小的摆放在基准前面，比基准值大的摆在基准的后面 if a[i] &lt; val &#123; a[k] = a[i] a[i] = a[k+1] k++ &#125; &#125; a[k] = val quickSort(a, left, k-1) quickSort(a, k+1, right)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 语言基础","slug":"Go 语言基础","date":"2018-01-01T04:11:18.000Z","updated":"2021-06-22T10:50:49.702Z","comments":true,"path":"2018/01/01/Go 语言基础/","link":"","permalink":"https://elihe2011.github.io/2018/01/01/Go%20%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"1. Go语言相关知识点1.1 Go特点： 类型安全和内存安全 以非常直观和极低的代价实现高并发 高效的垃圾回收机制 快速编译 为多核计算机提供提升性能的方案 默认UTF-8编码","text":"1. Go语言相关知识点1.1 Go特点： 类型安全和内存安全 以非常直观和极低的代价实现高并发 高效的垃圾回收机制 快速编译 为多核计算机提供提升性能的方案 默认UTF-8编码 1.2 GOPATH下的三个目录： bin pkg src 1.3 相关命令：12345678910go run // 直接运行，调试go build // 编译并生成可执行文件go fmt // 格式化代码go install // 先编译包文件，后编译整个程序go test // 运行测试文件 （xxx_test.go测试程序xxx.go)go doc // 查看文档godoc fmt Println // 查看具体的函数说明godoc --http=:8080 1.4 包导入别名1234import &quot;fmt&quot;import . &quot;fmt&quot; // 省略调用import std &quot;fmt&quot; // 别名import _ &quot;xxx&quot; // 只执行xxx包中的init()函数 1.5 可见性12func getField() // privatefunc Find() // public 2. 字符串格式化2.1 占位符123456789101112131415161718192021222324252627%v 默认格式%+v 打印结构体时，添加字段名%#v 使用Go语法表示%T 对象类型%% %%t true 或 false%b binary%c Unicode # Printf(&quot;%c&quot;, 0x4E2D) // 中%d decimal%o octal%x hex%X HEX%#x add prefix &quot;0x&quot; # %#o add &quot;0&quot; prefix%s string%q qutation%f%.2f%e 科学计数法%E%g 科学计数法，更紧凑的，无末尾的0%G%p 指针地址 2.2 键盘输入123456789func main() &#123; var name string var age int8 fmt.Scanln(&amp;name) fmt.Scanf(&quot;%d&quot;, &amp;age) fmt.Println(name, age)&#125; 2.3 字符串输入12345678910func main() &#123; str := &quot;Tom 23&quot; var name string var age byte fmt.Sscanf(str, &quot;%s %d&quot;, &amp;name, &amp;age) fmt.Println(name, age)&#125; 3. 位运算3.1 原码、反码和补码：(有符号整数) 二进制最高位：0-正数 1-负数 正数(1)：原码、反码和补码一样 原码：0000 0001 反码：0000 0001 补码：0000 0001 负数(-1)：反码 —&gt; 符号位不变，其他位取反；补码 —&gt; 反码 + 1 原码：1000 0001 反码：1111 1110 补码：1111 1111 零：反码和补码都是0 计算机运算以“补码”方式进行 (没有减法，只有加法) 1 + 1：0000 0001 + 0000 0001 = 0000 0010 1 + -1：0000 0001 + 1111 1111 = 1 0000 0000 3.2 位移运算 右移(&gt;&gt;): 符号位不变，低位溢出，并用符号位补溢出的高位 左移(&lt;&lt;): 符号位不变，低位补0 123456789101112131415161718192021222324func main() &#123; a := 1 &gt;&gt; 2 // 0 b := 1 &lt;&lt; 2 // 4 fmt.Println(a, b) /* 1 &gt;&gt; 2 =&gt; 0 000 0001 -&gt; 0 000 0000 = 0 1 &lt;&lt; 2 =&gt; 0 000 0001 -&gt; 0 000 0100 = 4 */ c := -1 &gt;&gt; 2 // -1 d := -1 &lt;&lt; 2 // -4 fmt.Println(c, d) /* -1 &gt;&gt; 2 =&gt; 1 000 0001 -&gt; 1 111 1110 -&gt; 1 111 1111 =&gt; 1 111 1111 -&gt; 1 111 1110 -&gt; 1 000 0001 = -1 -1 &lt;&lt; 2 =&gt; 1 000 0001 -&gt; 1 111 1110 -&gt; 1 111 1111 =&gt; 1 111 1100 -&gt; 1 111 1011 -&gt; 1 000 0100 = -4 */&#125; 3.3 Go中特殊位运算符 &amp;^12var a int = 6 &amp;^ 11 // 46 &amp; (^11) =&gt; 6 &amp; 4 3.4 负数位运算1234567891011var a byte = 2var b byte = -2var c byte = a ^ b // -4/*2补码：0000 0010-2补码：1000 0010 -&gt; 1111 1101 -&gt; 1111 11102 ^ -2 = 0000 0010 ^ 1111 1110 = 1111 1100 -&gt; 1111 1011 -&gt; 1000 0100 = -4*/ 4. 获取变量占用的字节数unsafe.Sizeof(obj) 1234func main() &#123; var n = 100 fmt.Println(unsafe.Sizeof(n))&#125; 5. 控制语句5.1 for循环1234567891011for &#123; &#125;for a &lt;= 3 &#123; &#125;for i := 1; i &lt; 10; i++ &#123; &#125; 5.2 switch选择1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func main() &#123; var a = 1 switch a &#123; case 0: fmt.Println(&quot;a=0&quot;) case 1: fmt.Println(&quot;a=1&quot;) default: fmt.Println(&quot;No Found&quot;) &#125;&#125;// 不能写成 switch afunc main() &#123; var a = 1 // expression is omitted switch &#123; case a &gt;= 0: fmt.Println(&quot;a&gt;=0&quot;) fallthrough case a &gt;= 1: fmt.Println(&quot;a&gt;=1&quot;) default: fmt.Println(&quot;No Found&quot;) &#125;&#125;// a的作用域只在switch中switch a := 1; &#123; &#125;// type-switchfunc main() &#123; var x interface&#123;&#125; = 10 switch x.(type) &#123; case nil: fmt.Println(&quot;NULL&quot;) case int: fmt.Println(&quot;int&quot;) default: fmt.Println(&quot;interface&#123;&#125;&quot;) &#125;&#125; 5.3 for循环示例：打印空心金字塔1234567891011121314151617181920212223242526272829303132333435/* * * * * * * ***********/func main() &#123; N := 5 // Step 1: 打印一个n*n列的正方形 for i := 1; i &lt;= N; i++ &#123; // Step 3: 打印等边三角形。每行前补空格：Ln=0, Ln-1=1, L2=n-2, L1=n-1 for k := 1; k &lt;= N-i; k++ &#123; fmt.Print(&quot; &quot;) &#125; // Step 2: 打印一个直角三角形。金字塔每行*个数：L1=1，L2=3, L3=5, Ln=2n-1 for j := 1; j &lt;= 2*i-1; j++ &#123; // Step 4: 空心。每行只保留第一个和最后一个 if j == 1 || j == 2*i-1 &#123; fmt.Print(&quot;*&quot;) &#125; else &#123; // Step 5: 最后一行全部保留 if i == N &#123; fmt.Print(&quot;*&quot;) &#125; else &#123; fmt.Print(&quot; &quot;) &#125; &#125; &#125; fmt.Println() &#125;&#125; 5.4 for循环示例：九九乘法表12345678func main() &#123; for i := 1; i &lt;= 9; i++ &#123; for j := 1; j &lt;= i; j++ &#123; fmt.Printf(&quot;%d * %d = %d\\t&quot;, j, i, i*j) &#125; fmt.Println() &#125;&#125; 5.5 for循环示例：水仙花数水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身（例如：1^3 + 5^3+ 3^3 = 153） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*三位的水仙花数共有4个：153，370，371，407；四位的四叶玫瑰数共有3个：1634，8208，9474；*/func main() &#123; var N int64 = 1000000 var i int64 for i = 100; i &lt;= N; i++ &#123; if isNarcissusFew(i) &#123; fmt.Println(i) &#125; &#125;&#125;func isNarcissusFew(n int64) bool &#123; s := strconv.FormatInt(n, 10) l := len(s) var sum int64 = 0 for j := n; ; &#123; m := j % 10 sum += int64(math.Pow(float64(m), float64(l))) j = j / 10 if j == 0 &#123; break &#125; &#125; return sum == n&#125;func isNarcissistic(n int64) bool &#123; s := strconv.FormatInt(n, 10) l := len(s) var sum int64 = 0 for _, c := range s &#123; num, _ := strconv.Atoi(fmt.Sprintf(&quot;%c&quot;, c)) sum += int64(math.Pow(float64(num), float64(l))) &#125; return sum == n&#125; 性能对比： 12345678go test -bench=. -run=nonegoos: darwingoarch: amd64pkg: gomod/aaaBenchmarkIsNarcissistic-4 1 93848583244 ns/opBenchmarkIsNarcissusFew-4 1 31639945040 ns/opPASSok gomod/aaa 125.791s 5.6 goto, break, continue LABEL用法：1234567891011121314func main() &#123;LABEL1: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; // break LABEL1 goto LABEL2 &#125; &#125; &#125; LABEL2: fmt.Println(&quot;OK&quot;)&#125; 6. 随机数12345func main() &#123; rand.Seed(time.Now().UnixNano()) // 种子变化越大，随机性越好 n := rand.Intn(100) + 1 fmt.Println(n)&#125; 7. 时间和日期函数1234567891011121314151617181920func main() &#123; now := time.Now() // time.Time year := now.Year() month := int(now.Month()) day := now.Day() fmt.Printf(&quot;%04d-%02d-%02d\\n&quot;, year, month, day) weekday := now.Weekday() fmt.Println(weekday) ts := now.Unix() // timestamp nano := now.UnixNano() fmt.Println(ts, nano) dateStr := now.Format(&quot;2006-01-02 15:04:05&quot;) fmt.Println(dateStr)&#125;time.Sleep(100 * time.MilliSecond) 8. 内置函数12345678910len // string, array, slice, map, channelclose // channelnew // 分配内存, 值类型 int, float, struct等，返回指针make // 分配内存, 引用类型 chan, map, slice等，返回类型本身，而非指针nptr = new(int) // *intappend // 追加元素到array, slice中panic/recover // 错误处理 9. new和make的区别 new(T) 返回 T 的指针 *T 并指向 T 的零值。 make(T) 返回的初始化的 T，只能用于 slice，map，channel。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Git","slug":"Git","date":"2017-05-01T09:35:40.000Z","updated":"2021-06-22T10:50:49.701Z","comments":true,"path":"2017/05/01/Git/","link":"","permalink":"https://elihe2011.github.io/2017/05/01/Git/","excerpt":"1. 基本概念1.1 git特点1) 直接存储文件快照(特定时间点的完整文件)，而非存储差异。2) 几乎所有操作都在本地执行，只有同步版本库才需要联网。3) 天然的数据完整性校验(SHA-1, 40bits).","text":"1. 基本概念1.1 git特点1) 直接存储文件快照(特定时间点的完整文件)，而非存储差异。2) 几乎所有操作都在本地执行，只有同步版本库才需要联网。3) 天然的数据完整性校验(SHA-1, 40bits). 1.2 git文件变更操作文件变更的三个阶段: 修改(modified) 暂存(staged): 已加入下次提交列表) 提交(committed): 保存到版本数据目录 三个阶段数据存放区域: 工作目录(workspace) 暂存索引文件(.git/index) 本地数据目录(.git/objects) Git Data Transport Commands (http://osteele.com) 2. 初始化设置2.1 配置用户123456git config --global user.name &#x27;eli.he&#x27;git config --global user.email &#x27;eli.he@live.cn&#x27;git config --global core.autocrlf falsegit config --list 2.2 密钥设置1) 生成密钥 1ssh-keygen -t rsa -C &#x27;eli.he@live.cn&#x27; 2) 上传公钥 id_rsa.pub 至SSH keys管理 1cat ~/.ssh/id_rsa.pub 3) 测试连通性 1ssh -T git@github.com 2.3 设置忽略文件 全局(.gitignore) 个人(.git/info/exclude) 3. 版本库3.1 新建版本库12345mkdir testcd testgit initgit remote add origin git@github.com:elihe2011/test.git 3.2 克隆版本库12345# 默认远程仓库名为origingit clone https://github.com/elihe2011/abc.git# 指定远程仓库名为git_prjgit clone -o git_prj https://github.com/elihe2011/abc.git 3.3 查看远程版本库12git remote -vgit remote show origin 3.4 获取远程版本，但不合并12git fetch origin mastergit fetch ～/github/new_test master 3.5 获取远程版本，并合并12git pull origin mastergit pull ～/github/new_test master 3.6 代码修改提交1234567git add .git commit -m &#x27;add a.txt&#x27; a.txtgit commit -m &#x27;add all&#x27;git commit -am &#x27;commit tracked files&#x27;git commit -m --amend --no-edit # 使用新的commit替代原有的，保持commit描述不变 3.7 推送至远程库12345git push -u origin master # -u, --set-upstream 第一次push的时候需要，自动添加如下配置branch.master.remote=originbranch.master.merge=refs/heads/master 4. 文件操作4.1 检查修改12345git diff hello.py # workspace, stagedgit diff --cached # staged, local-repositorygit diff master origin/master # local-repo remote-repo 4.2 撤销操作4.2.1 checkoutworkspace和staged撤销修改 123456# 撤销本次修改，commit前均可操作git checkout hello.py # 使用特定commit的文件，替换staged和workspace下的文件git checkout ad12sa1 hello.py cat .git/HEAD # defd8bb.... 4.2.2 reset不可恢复的撤销 (谨慎操作) 1234567891011121314# staged区回滚，git add的反操作git reset [&lt;files&gt;]# staged区和workspace回滚，回到最近一次提交git reset [&lt;files&gt;] --hard# staged区回滚到指定commit，之前的提交全部删除git reset &lt;commit&gt;# workspace区也回滚git reset &lt;commit&gt; --hard# 作用于staged区git reset --mixed HEAD 实例：12345git reset HEAD -- a.txtgit reset a.txt# HEAD^表示上个版本，HEAD^^上上个版本，HEAD~N往上N个版本git reset HEAD^^ -- a.txt 4.2.3 revert 仅反转提交撤销已提交的快照，但不从项目中删除这个commit，而是新生成一个commit 实例123456789touch 1.txt 2.txt 3.txtgit add .git commit -m &#x27;add 1.txt&#x27; 1.txtgit commit -m &#x27;add 2.txt&#x27; 2.txtgit commit -m &#x27;add 3.txt&#x27; 3.txtgit log --oneline -5git revert cc79f5a # revert 2.txtls -l [1-3].txt # 1.txt, 3.txt reset和revert的区别:reset: 被设计用来撤销本地的修改，它会完整地删除一个change set。revert: 被设计用来安全地撤销一个公共commit，会保留最初的change set，通过新建一个commit来撤销 4.2.4 撤销操作场景1) 已修改，未暂存 12git checkout .git reset --hard 2) 已暂存，未提交 123456git resetgit checkout .orgit reset --hard 3) 已提交，未推送 1git reset --hard origin/master 4) 已推送 12git reset --hard HEAD^git push -f origin master 4.2.5 撤销命令说明 命令 操作区域 checkout staged -&gt; workspace reset committed -&gt; staged reset –hard committed -&gt; staged -&gt; workspace 4.3 删除文件4.3.1 删除已traced文件1234567891011# 删除workspace中的文件，如果已在staged中，报错git rm a.txt# 同时删除workspace &amp; staged文件，保留committed文件git rm -f a.txt# 同时删除staged &amp; committed文件，保留workspace文件git rm --cached a.txt# 清理已被删除的所有文件git rm $(git ls-files --deleted) 4.3.2 删除未traced的文件12git clean -fgit clean -df 5. 标签5.1 创建标签12345678# 为当前分支最近一次提交创建标签git tag 1.0# 标签 develop/1.1git tag develop_1.1 develop# 为某个历史提交创建标签git tag 1.2 66cbbb4 5.2 查询标签123git taggit tag -l &#x27;1.2.*&#x27;git show 1.1 5.3 检出标签1git checkout 1.0 5.4 按标签创建分支123git branch test 1.1git checkout -b develop 1.2 5.5 删除标签1git tag -d 1.1 6. 日志6.1 查询日志123456789101112131415161718192021222324252627282930git loggit log -5git log stat # 详细日志git log -p # 更详细日志git log --author=&#x27;eli&#x27;git log --grep=&#x27;modify&#x27; # 过滤提交描述git log --graphgit log --graph --decorate --onelinegit log --onelinegit log ada6cb2..62a89cfgit log --mergesgit log --no-merges # 过滤merge提交git log --since=&#x27;2017-11-20&#x27; --until=&#x27;2017-12-01&#x27;git log --pretty=format:&quot;%cn committed %h on %cd&quot; # 格式化参数%cn committer name%h commit hash%cd commit date%s short messagegit log --pretty=&quot;%h - %s&quot; --author=&#x27;eli&#x27; --since=&#x27;2017-11-27 00:00:00&#x27; --before=&#x27;2017-11-27 11:59:59&#x27; 6.2 git reflog 所有分支的日志1git reflog --relative-date 6.3 git shortlog1git shortlog 7. 分支7.1 创建分支12345678# 从当前分支创建新分支，但不切换git branch develop# 从当前分支创建新分支，并切换git checkout -b develop# 从develop分支创建新分支git checkout -b test develop 7.2 删除分支12345# 删除已merge的分支git branch -d develop# 强制删除分支，不管是否已mergegit branch -D develop 7.3 更改分支名1git branch -m dev 7.4 切换分支本质上是更新HEAD指向给定的branch或commit 12345678git checkout developgit checkout -b test# 产生detached HEAD状态，detached意味着当前所有修改和项目发展的其他部分完全脱离，无法被mergegit checkout &lt;commit&gt;git checkout &lt;tag&gt; 7.5 合并分支12345# 自动指定merge算法git merge &lt;branch&gt;# 强制fast-forword merge算法git merge --on-ff &lt;branch&gt; 7.6 rebase 合并分支（重定义分支起点）1git rebase &lt;base&gt; # base: commit, tag, branch, HEAD~N 123456789101112131415git checkout -b developtouch echo.pygit add echo.pygit commit -m &#x27;add echo.py on develop branch&#x27;git checkout mastertouch print.pygit add print.pygit commit -m &#x27;add print.py on master branch&#x27;git checkout developgit rebase master # 将整个develop分支的commit放在master分支之后，不会创建merge commit，但会为develop分支的每个commit创建一个新的commitgit checkout mastergit merge develop # 只产生merge commit，分支commit不合入 7.7 merge和rebase的区别： merge: 产生一个merge commit，不会合入分支的commit rebase: 不产生merge commit，但合入分支的commit 示意图 git pullgit pull: 按merge方式合并git pull –rebase: 按rebase方式合并 merge未产生merge commit的原因：只有在存在冲突，解决完冲突后才自动产生一个merge commit git mergegit merge: 被合并之前的commit全部抹除，只保留一个解决冲突的merge commitgit merge –on-ff: 在没有冲突下，也自动产生一个merge commit 8. 远程分支操作8.1 查询远程分支1git ls-remote 8.2 跟踪远程分支123git checkout -b daily origin/dailygit checkout --track origin/daily # 本地和远程的分支名保持一致 8.3 添加本地分支与远程分支的关联关系（–set-upstream-to=）1git branch -u origin/daily 8.4 查询当前已跟踪的分支1git branch -vv 8.5 删除远程分支1git push origin --delete daily 8.6 远程仓库被删除，导致无法pull1git remote prune origin 9. 导出版本库1git archive --format=zip HEAD &gt; `date +%s`.zip 10. 撤销操作详细说明10.1 resetreset将一个分支的末端指向另一个提交，并移除当前分支的一些提交 12git checkout hotfixgit reset HEAD~2 hotfix分支末端的两个提交变成悬挂提交，下次Git执行垃圾回收时，这两个提交会被删除。 撤销缓存区和工作目录： –soft 缓存区和工作目录均不修改 –mixed 默认项，缓存区同步到你指定的提交，但工作目录不受影响 –hard 缓存区和工作目录均同步到你指定的提交 使用前提：你的更改未分享给别人，git reset是撤销这些更改的简单方法 10.2 revertrevert撤销一个提交同时会创建一个新的提交。比reset安全，且不会重写提交历史 12git checkout hotfixgit revert HEAD~2 10.3 总结git revert可以用在公共分支 git reset应该用在私有分支上 11. 配置项说明11.1 区分大小写1git config core.ignorecase false","categories":[{"name":"Tools","slug":"Tools","permalink":"https://elihe2011.github.io/categories/Tools/"}],"tags":[{"name":"git","slug":"git","permalink":"https://elihe2011.github.io/tags/git/"}]}]}