{"meta":{"title":"Eli's Blog","subtitle":null,"description":null,"author":"Eli He","url":"https://elihe2011.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-11-19T08:24:36.000Z","updated":"2021-06-22T10:50:49.750Z","comments":true,"path":"categories/index.html","permalink":"https://elihe2011.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"TCP","slug":"TCP","date":"2021-03-17T03:17:35.000Z","updated":"2021-07-13T03:17:52.007Z","comments":true,"path":"2021/03/17/TCP/","link":"","permalink":"https://elihe2011.github.io/2021/03/17/TCP/","excerpt":"1. TCP TCP 是面向连接、可靠的、基于字节流的传输层通信协议。 面向连接：一对一的连接。不像 UDP 可以同时向多个主机发送消息。 可靠的：网络链路中出现变化，TCP 可以保证一个报文一定能够到达指定端。","text":"1. TCP TCP 是面向连接、可靠的、基于字节流的传输层通信协议。 面向连接：一对一的连接。不像 UDP 可以同时向多个主机发送消息。 可靠的：网络链路中出现变化，TCP 可以保证一个报文一定能够到达指定端。 1.1 TCP 头 序列号：建立连接时，计算机生成的随机数作为初始值，通过 SYN 包传给接收端主机，每发送一次数据，就累加 1。解决网络包乱序问题 确认应答号：下一次“期望”收到的数据的序列号，发生端收到这个确认应答后，认为这个序列号以前的数据都被正确接收。解决丢包问题 控制位： ACK：确认应答字段有效。除了最初建立连接时的 SYN 包之外该位必须为1 RST：TCP 连接中出现异常，必须强行断开连接 SYN：希望建立连接，在其“序列号”字段初始化后设定 FIN：通信结束，断开连接，不会再发送数据时设定 1.2 TCP 连接用于保证可靠性和流量控制维护的某些状态信息，包括Socket、序列号和窗口大小称为连接 Socket：IP + Port 序列号：解决乱序等问题 窗口大小：流量控制 1.3 唯一确定一个连接通过 TCP 四元组来确定： 源地址 源端口 目标地址 目标端口 源地址和目标地址 (32-bit)：在 IP 头部中，通过 IP 协议发送报文给对方主机 源端口和目标端口 (16-bit)：在 TCP 头部中，通过 TCP 协议把报文发给哪一个进程。 1.4 三次握手 &amp; 四次挥手 TCP 状态： LISTENING: 服务端侦听远端TCP连接请求，等待被连接 SYN_SENT: 客户端调用connect方法，发送一个SYN请求建立连接 SYN_RCVD: 服务端收到连接请求并确认后，调用accept方法 ESTABLISHED: 连接建立 FIN_WAIT_1: 主动关闭连接，调用close方法后 CLOSING: FIN_WAIT_1后，等待对端关闭确认 （较少出现） CLOSE_WAIT: 收到关闭请求，等待关闭 FIN_WAIT_2: 收到关闭ACK确认后 LAST_ACK: 收到关闭请求(CLOSE_WAIT)后，被动关闭连接，调用close方法 TIME_WAIT: 主动关闭连接，收到被动关闭连接(LAST_ACK)后。等待足够的时间，确保远程TCP连接中断确认，最大程度保证双方正常结束，需等待2*MSL时间才能进行下一次连接 CLOSED： 被动关闭端收到ACK后，进入CLOSED，连接结束 总结： TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。 不使用「两次握手」和「四次握手」的原因： 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。 1.4.1 TIME_WAIT主动关闭Socket端会进入TIME_WAIT状态，并持续2MSL时间长度。 MSL (maximum segment lifetime)：表示一个IP数据包在互联网上生存的最长时间，超过这个时间将在网络中消失。MSL建议值为2分钟，但传统上为30s 因此，TIME_WAIT状态一般维持在1-4分钟 TIME_WAIT 作用： 可靠地实现TCP全双工连接终止 允许老的重复连接在网络中消逝 TIME_WAIT 危害： 过多会占用内存，一个TIME_WAIT占用4k 网络差的情况下，如果主动方无TIME_WAIT等待，关闭当前连接后，主动方与被动方又重新建立新的TCP连接，此时被动方重传或延时过来的FIN包会直接影响当前新的TCP连接 如何避免： 设置socket选项为SO_REUSEADDR，端口可重用 由于TIME_WAIT状态是主动关闭一方出现的，所以在协议逻辑设计时，尽量由客户端主动关闭，避免服务端出现TIME_WAIT 1.4.2 SYN 攻击什么是SYN攻击？ 在三次握手过程中，收到客户端SYN，服务端ACK该请求后进入SYN_RCVD状态，该状态称为半连接(half-open connect)，只有等服务端收到ACK再次确认后，才进入ESTABLISHED状态 SYN 攻击，即客户端在短时间内大量伪造不存在的IP地址，向服务端不断地发送SYN包，服务端回复ACK确认包，并等待客户端确认。但由于源地址不存在，服务端需要不断重发ACK包直至超时，大量SYN包长时间占用未连接队列，导致正常SYN请求被丢弃，网络阻塞服务不可用。 DoS/DDoS 是一种典型的SYN攻击 如何检测 SYN 攻击？ 服务器上存在大量半连接状态 (SYN_RCVD) 大量随机的源 IP 地址 如何预防 SYN 攻击? 完全阻止SYN攻击是不可能的，可通过一些方法减轻SYN攻击： 缩短超时时间(SYN Timeout) 增加最大半数连接数 过滤网关防护 SYN cookies 技术 Linux 内核参数： 12345678910111213141516# 队列最大值net.core.netdev_max_backlog# SYN_RCVD 状态连接的最大个数net.ipv4.tcp_max_syn_backlog# 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接net.ipv4.tcp_abort_on_overflow# 启用 cookienet.ipv4.tcp_syncookies = 1# 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；# 计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，# 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。# 最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。 1.5 KeepAliveTCP数据交互完成后，未主动释放连接，在无法知道对端的情况下保持了这个连接，长时间累积导致非常多的半打开连接，造成系统资源浪费。 KeepAlive: 隔一段时间给对端发送一个探测包，如果对方回应ACK，则认为连接还是存活的。在超过一定重试次数之后还是未收到对方的回应，则丢弃该连接。 1.6 如何实现长连接 HeartBeat心跳包 客户端每隔一小段时间向服务器发送一个数据包，通知服务器自己仍然在线。30s 00 00 03 TCP协议的KeepAlive机制 默认不打开，要用setsockopt将SOL_SOCKET.SO_KEEPALIVE设置为1，并且设置参数tcp_keepalive_time/tcp_keepalive_probes/tcp_keepalive_intvl keep-alive机制，可以减少tcp连接建立的次数，也意味着减少TIME_WAIT连接状态，以此来提高服务器性能 但keep-alive也可能导致系统资源被无效占用，合适设置keep-alive timeout时间非常重要 1.7 滑动窗口滑动窗口（Sliding window）是一种流量控制技术，它被用来改善网络吞吐量，即容许发送方在接收任何应答之前传送附加的包，接收方告诉发送方在某一个时刻能送多少包（成为窗口尺寸) 让发送的每一个包都有一个id，接收端必须对每一个包进行确认，这样设备A一次多发送几个片段，而不必等候ACK，同时接收端也要告知它能够收多少，这样发送端发起来也有个限制，当然还需要保证顺序性，不要乱序，对于乱序的状况，我们可以允许等待一定情况下的乱序，比如说先缓存提前到的数据，然后去等待需要的数据，如果一定时间没来就DROP掉，来保证顺序性！ 接收端可以根据自己的状况通告窗口大小，从而控制发送端的发送，进行流量控制。 滑动窗口原理： TCP并不是每一个报文段都会回复ACK确认，可能会对多个报文段发送1个ACK (累积ACK确认)。 比如发送方有1/2/3个报文段，接收方收到2/3报文段后，一直未收到报文段“1”，将会丢弃报文段2/3. 实现滑动窗口： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283var ( limitCount int32 = 10 // 限频总数 limitBucket int = 6 // 滑动窗口个数 curCount int32 = 0 // 当前限频数量 head *ring.Ring // 环形队列 (链表))func main() &#123; addr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, &quot;:3000&quot;) if err != nil &#123; log.Fatal(err) &#125; listener, err := net.ListenTCP(&quot;tcp&quot;, addr) if err != nil &#123; log.Fatal(err) &#125; defer listener.Close() // 初始化滑动窗口 head = ring.New(limitBucket) for i := 0; i &lt; limitBucket; i++ &#123; head.Value = 0 head = head.Next() &#125; // 启动执行器 go func() &#123; ticker := time.NewTicker(time.Second) for &#123; select &#123; case &lt;-ticker.C: subCount := int32(0 - head.Value.(int)) newCount := atomic.AddInt32(&amp;curCount, subCount) // useless, only for print arr := [6]int&#123;&#125; for i := 0; i &lt; limitBucket; i++ &#123; arr[i] = head.Value.(int) head = head.Next() &#125; fmt.Printf(&quot;subCount: %d, newCount: %d, arr: %v\\n&quot;, subCount, newCount, arr) head.Value = 0 head = head.Next() &#125; &#125; &#125;() // 处理请求 for &#123; conn, err := listener.Accept() if err != nil &#123; log.Println(err) continue &#125; go handle(&amp;conn) &#125;&#125;func handle(conn *net.Conn) &#123; defer (*conn).Close() count := atomic.AddInt32(&amp;curCount, 1) if count &gt; limitCount &#123; atomic.AddInt32(&amp;curCount, -1) msg := &quot;HTTP/1.1 404 NOT FOUND\\r\\n\\r\\nError, too many request, please try later.&quot; (*conn).Write([]byte(msg)) &#125; else &#123; mu := sync.Mutex&#123;&#125; mu.Lock() pos := head.Prev() val := pos.Value.(int) val++ pos.Value = val mu.Unlock() time.Sleep(time.Second) msg := &quot;HTTP/1.1 200 OK\\r\\n\\r\\nWell done.&quot; (*conn).Write([]byte(msg)) &#125;&#125; 使用HTTP压测工具hey： https://github.com/rakyll/hey 12345678910111213141516171819202122232425262728293031323334353637383940414243hey -c 6 -n 300 -q 6 -t 80 http://localhost:3000Summary: Total: 11.6708 secs Slowest: 1.0423 secs Fastest: 0.0013 secs Average: 0.0735 secs Requests/sec: 25.7051Response time histogram: 0.001 [1] | 0.105 [279] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 0.210 [0] | 0.314 [0] | 0.418 [0] | 0.522 [0] | 0.626 [0] | 0.730 [0] | 0.834 [0] | 0.938 [0] | 1.042 [20] |■■■Latency distribution: 10% in 0.0033 secs 25% in 0.0052 secs 50% in 0.0065 secs 75% in 0.0076 secs 90% in 0.0091 secs 95% in 1.0066 secs 99% in 1.0417 secsDetails (average, fastest, slowest): DNS+dialup: 0.0052 secs, 0.0013 secs, 1.0423 secs DNS-lookup: 0.0036 secs, 0.0002 secs, 0.0359 secs req write: 0.0001 secs, 0.0000 secs, 0.0023 secs resp wait: 19.8696 secs, 0.0001 secs, 851.1748 secs resp read: 0.0002 secs, 0.0000 secs, 0.0023 secsStatus code distribution: [200] 20 responses [404] 280 responses 1.8 MTU &amp; MSS MTU: 一个网络包的最大长度，以太网一般未 1500 字节 MSS：除去 IP 和 TCP 头部后，一个网络包能容纳的 TCP 数据的最大长度 当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。 但是，如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。 因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。 当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。 因此，可以得知由 IP 层进行分片传输，是非常没有效率的。 所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。 经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。 2. UDP 目标和源端口：告诉 UDP 协议应该把报文发给哪个进程。 包长度： UDP 首部的长度跟数据的长度之和。 校验和：提供可靠的 UDP 首部和数据而设计。 UDP是一个简单的传输层协议，与TCP相比，有如下特征： UDP 缺乏可靠性。不提供确认、序列号、超时重传等机制。 UDP 数据报可能在网络中被复制，被重新排序。即UDP不保证数据一定到达目的地，也不保证数据报的先后顺序，也不保证每个数据报只到达一次 UDP 数据报有长度的。如果一个数据报正确地到达目的地，该数据报的长度也随着随着数据一起传给了接收方。 UDP 面向无连接的。UDP客户端与服务器不存在长期关系，不需要经过三次握手和四次挥手操作 UDP支持多播和广播 3. TCP vs UDP 连接 协议 可靠性 使用场景 TCP 面向连接 流协议，无大小限制 可靠 可靠的通信。使用校验和、确认和重传机制来确保可靠传输 UDP 无连接 数据包协议，有限制 不可靠 1. 包总量较小的通信(DNS, SNMP) 2.视频、音频等流媒体（即时通信）3.广播通信 tcp 传输的是数据流，udp是数据包；tcp要进行三次握手、udp不需要 TCP 和 UDP 区别： 1. 连接 TCP 面向连接，传输数据前先要建立连接。 UDP 不需要连接，即刻传输数据。 2. 服务对象 TCP 是一对一的两点服务。 UDP 支持一对一、一对多、多对多的交互通信 3. 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。 4. 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 5. 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 6. 传输方式 TCP 流式传输，没有边界，但保证顺序和可靠。 UDP 一个包一个包的发送，是有边界的，但可能会丢包和乱序。 7. 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。 TCP 和 UDP 应用场景： 由于 TCP 是面向连接，能保证数据的可靠性交付，常用于： FTP 文件传输 HTTP / HTTPS 由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，常用于： 包总量较少的通信，如 DNS 、SNMP 等 视频、音频等多媒体通信 广播通信 为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？ 原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。 为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？ TCP 负载数据长度： 1TCP数据总长度 = IP总长度 - IP首部长度 - TCP首部长度 4. 网络包","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"HTTP","slug":"HTTP","date":"2021-01-09T03:19:35.000Z","updated":"2021-07-13T03:21:40.398Z","comments":true,"path":"2021/01/09/HTTP/","link":"","permalink":"https://elihe2011.github.io/2021/01/09/HTTP/","excerpt":"1. HTTP1.1 特性 构建在TCP上的应用层协议 无连接无状态 1.2 状态码 200 OK 301 Moved Permanently 永久重定向，后续请求直接发往新地址 302 Moved Temporarily 临时重定向 304 Not Modified 文件未修改，直接使用缓存文件 400 Bad Request 客户端请求有语法错误 401 Unauthorized 请求未经授权 403 Forbidden 认证通过，但无权限访问资源 404 Not Found 请求的资源不存在 405 Method Not Allowed 500 Internal Server Error 502 Bad Gateway 与upstream建立了连接，但响应超时。可能原因：后端代码执行超时、数据库响应慢等 (received an invalid response from the upstream server) 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。(The server cannot handle the request, because it is overloaded or down for maintenance, generally this is temporary state.) 504 Gateway Time-out 完全无法与upstream建立连接，一般是nginx配置错误 (did not receive a timely response from the upstream server)","text":"1. HTTP1.1 特性 构建在TCP上的应用层协议 无连接无状态 1.2 状态码 200 OK 301 Moved Permanently 永久重定向，后续请求直接发往新地址 302 Moved Temporarily 临时重定向 304 Not Modified 文件未修改，直接使用缓存文件 400 Bad Request 客户端请求有语法错误 401 Unauthorized 请求未经授权 403 Forbidden 认证通过，但无权限访问资源 404 Not Found 请求的资源不存在 405 Method Not Allowed 500 Internal Server Error 502 Bad Gateway 与upstream建立了连接，但响应超时。可能原因：后端代码执行超时、数据库响应慢等 (received an invalid response from the upstream server) 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。(The server cannot handle the request, because it is overloaded or down for maintenance, generally this is temporary state.) 504 Gateway Time-out 完全无法与upstream建立连接，一般是nginx配置错误 (did not receive a timely response from the upstream server) 1.3 持久连接 请求头：Connection: Keep-Alive HTTP/1.1默认 HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。 HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。 1.4 Transfer-Encoding用来标示 HTTP 报文传输格式，默认chunked，表示消息体由数量未定的块组成，并以最后一个大小为0的块为结束。 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF （回车及换行），然后是数据本身，最后块CRLF结束。 1.5 Cookie &amp; Session都是为了解决HTTP无状态问题，发展出来的保存客户端状态的一种机制 1.5.1 Cookie 客户端机制，浏览器存储在用户电脑上的一小段文本文件 http请求时，会将这些信息发生至服务器，服务器可根据这些信息来识别不同的用户 客户端可禁用Cookie 缺点： 不良站点用Cookie收集用户隐私信息 Cookie窃取，黑客可通过Cookie来模拟用户的请求行为（跨站脚本攻击XSS） 1.5.2 Session 服务端机制，服务器使用一种类似散列表的结构来保持信息，当客户端请求时，创建一个session请发给客户端，下一次客户端请求，服务端首先去检查这个请求是否包含了session标识 具体实现方式： Cookie方式：服务器给每个Session分配一个唯一的JSESSIONID，并通过Cookie发送给客户端。当客户端发起新的请求时，将在Cookie头重携带这个JSESSIONID，这样服务器就能够找个这个客户端对应的Session URL回写：服务器在发送给浏览器页面的所有链接中都携带JSESSIONID参数，这样客户端点击任何一个链接都会把JSESSIONID带回服务器 1.6 跨站攻击1.6.1 CSRF （XSRF）Cross-site Request Forgery, 跨站请求伪造 伪造请求，冒充用户在站内的正常操作。用户点击链接时，恶意js伪造请求，比如删除、转账、该密码、发送邮件等操作 预防 CSRF 攻击： 关键操作使用 POST 请求 验证码 检测 Referer，关联的请求地址应该一致 Token 1.6.2 XSSCross Site Scripting， 跨站脚本攻击 客户端提交含有 js 的内容文本，但服务器没有过滤或转义掉这些脚本，当内容发布到了页面上，其他用户访问这个页面的时候就会运行这些脚本。 预防 XSS 攻击： 将用户输入的内容进行 HTML escape 转义 2. HTTPSHTTPS: HTTP over TSL TSL: Transport Layer Security, SSL的后续版本 SSL: Secure Socket Layer 2.1 证书认证 上图为单向认证，双向认证时，需要客户端把自己的证书发回服务端认证 2.2 中间人攻击中间人攻击 (MITM, Man In The Middle Attack): 攻击者与通信的两端分别建立独立的连续，并交换其所收到的数据，使通信的两端都认为他们正在进行一个私密的连接与对方直接对话。 3. HTTP2影响一个HTTP网络请求的因素主要有两个：带宽和延迟 带宽：当前的互联网已解决 延迟： 浏览器阻塞(HOL blocking): 同一个域名，浏览器同时只能有 4 个连接（不同内核可能不同），超过最大连接数限制，后续请求将被阻塞 DNS查询(DNS Lookup): 解析域名为IP需要耗费一定的时间，通常可以利用DNS缓存解决 建立连接(Initial connection): HTTP基于TCP协议，浏览器最快也要进行三次握手才能将HTTP请求报文发往服务器，但建立的连接无法复用。 HTTP2.0新特性： 新的二进制格式 (Binary Format) HTTP1.x的解析基于文本，但文本协议存在多种格式，需要考虑的健壮性问题较多。二进制则不同，只认0和1组合。 多路复用(MultiPlexing) 连接共享，每个request对应一个id，这样一个连接就可以承载多个request header压缩 (HPACK) 使用encoder来减少需要传输的header大小，通信双发各自cache一份header fields表，既避免了重复的header传输，又减小了传输字节数 服务器推送 (server push) 服务器可以向浏览器发生请求之外的内容，比如正在请求一个页面时，服务器会把页面相关的logo，CSS等文件直接推送到客户端。 4. Web 缓存缓存：保存在浏览器中的数据，再次请求服务时，如果相同的URL，直接使用浏览器中的缓存响应访问请求，不会再次向服务器发送请求 三种情况： 未找到缓存（黑色线） 缓存未过期（蓝色线） 缓存已过期（红色线）缓存过期判断服务器文件是否更新的两种方法： 将本地文件的最后修改时间发会服务器，check下文件是否已更新，如果没有，不下载新的文件，只需要更新本地缓存文件的过期时间 客户端文件有版本好，当服务器更新了版本，再次请求时，服务器根据版本判断缓存是否需要更新 通过HTTP-HEADER控制缓存： Expires和Cache-Control: HTTP1.0使用Expires，1.1为Cache-Control:max-age规定了缓存的有效时间 Last-Modified/If-Modified-Since: 缓存过期后，check服务端文件是否更新的第一种方式 ETag/If-None-Match: 缓存过期时check服务端文件是否过期的第二种方式 无法被浏览器缓存的请求： HTTP头中：Cache-Control:no-cache, pragma:no-cache (HTTP1.0), Cache-Control:max-age=0 需要根据Cookie，认证信息等决定输入内容的动态请求不能被缓存 POST请求无法被缓存 5. HTTP &amp; WebSocket5.1 协议 HTTP 1.0: 在一次 TCP 连接中只能完成一个 HTTP 请求 HTTP 1.1: keep-alive，在一次 TCP 连接中完成多个 HTTP 请求 Websocket: 借用HTTP协议来完成握手 12345Connection: UpgradeSec-WebSocket-Extensions: permessage-deflate; client_max_window_bitsSec-WebSocket-Key: km9iqxp+3H2ndD5zXkAczA==Sec-WebSocket-Version: 13Upgrade: websocket 5.2 通信方式比较： ajax轮询：浏览器隔几秒向服务器发起一个请求，询问服务器是否有新信息。需要服务器有很快的处理速度和资源。（速度） long poll：采用阻塞模式，客户端发起连接后，如果没消息，就一直不返回Response给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。需要有很高的并发，也就是说同时接待客户的能力。（场地大小） WebSocket：一次HTTP握手后，整个通讯过程是建立在该连接状态中。服务器可主动推送消息给客户端。 WebSocket和HTTP最大不同： WebSocket是一种双向通信协议。在建立连接后，WebSocket服务器端和客户端都能主动向对方发送或接收数据，就像Socket一样； WebSocket需要像TCP一样，先建立连接，连接成功后才能相互通信。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Linux基础知识","slug":"Linux基础知识","date":"2020-09-21T03:14:32.000Z","updated":"2021-07-13T03:15:08.753Z","comments":true,"path":"2020/09/21/Linux基础知识/","link":"","permalink":"https://elihe2011.github.io/2020/09/21/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"1. 负载均衡1.1 SLBSLB: Server Load Balance 通过设置虚拟服务地址（IP），将位于同一区域（Region）的多台云服务器（Elastic Compute Service，ECS）的资源虚拟成一个高性能、高可用的应用服务池；再根据应用指定的方式，将来自客户端的网络请求分发到云服务器池中 SLB服务会检查云服务器池中ECS的健康状态，自动隔离异常状态的ECS，从而解决了单台ECS的单点问题，同时提高了应用的整体服务能力 负载均衡算法： 轮询 (Round Robin) 最小连接 (Leaster Connections): 优先选择连接数最小的服务器 Source: 根据请求源IP的hash值来选择要转发的服务器，保证特定用户连接到相同服务器","text":"1. 负载均衡1.1 SLBSLB: Server Load Balance 通过设置虚拟服务地址（IP），将位于同一区域（Region）的多台云服务器（Elastic Compute Service，ECS）的资源虚拟成一个高性能、高可用的应用服务池；再根据应用指定的方式，将来自客户端的网络请求分发到云服务器池中 SLB服务会检查云服务器池中ECS的健康状态，自动隔离异常状态的ECS，从而解决了单台ECS的单点问题，同时提高了应用的整体服务能力 负载均衡算法： 轮询 (Round Robin) 最小连接 (Leaster Connections): 优先选择连接数最小的服务器 Source: 根据请求源IP的hash值来选择要转发的服务器，保证特定用户连接到相同服务器 1.2 LVSLVS：Linux Virtual Server 当用户向负载均衡调度器(Director Server)发起请求，调度器将请求发送至内核空间 PREROUTING链首先会接收到用户请求，判断目标IP是否本机IP，将数据包发往INPUT链 IPVS工作在INPUT上，当用户请求到达INPUT时，IPVS会将用户请求和定义好的集群服务进行比对，如果请求时集群服务，那么IPVS将强行修改数据包里的目标IP和端口，并将新数据包发往POSTROUTING链 POSTROUTING链接收数据包后发现目标IP地址刚好时自己的后端服务器，通过选路，将数据包最终发送给后端服务器 LVS 程序组成： ipvs: ip virtual server, 工作在内核空间的一段代码，实现负载均衡调度 ipvsadm: 工作在用户空间，负责ipvs内核框架的编写规则 iptables 内置的4个表: filter: 包过滤 nat: 网络地址转换 mangle: 包重构(修改) raw: 数据跟踪处理 链（chains）: 数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一 条或数条规则 默认包括5种规则链 INPUT：处理入站数据包 OUTPUT：处理出站数据包 FORWARD：处理转发数据包 POSTROUTING链：在进行路由选择后处理数据包（对数据链进行源地址修改转换） PREROUTING链：在进行路由选择前处理数据包（做目标地址转换） 2. 高可用软件 Heartbeat：可实现对服务器资源（IP即程序服务等资源）的监控和管理，并在出现故障的情况下，将资源集合从一台已经故障的计算机快速转移到另一台机器上继续提供服务 Keepalived: 通过IP漂移，实现服务的高可用：服务器集群共享一个虚拟IP，同一时间只有一个服务器占有虚拟IP并对外提供服务，若该服务器不可用，则虚拟IP漂移到另一台服务器并对外提供服务 对LVS应用服务器集群状态进行监控：若应用不可用，则keepalived将其从集群中摘除，若服务器恢复，将其加入集群中 3. 弹性伸缩弹性伸缩（Auto Scaling): 根据业务需求和伸缩策略，自动调整计算机资源。请求高峰时，自动增加业务实例数量，以保证性能不受影响；请求低谷时，自动释放业务实例数量以减低成本 4. 孤儿进程 &amp; 僵尸进程孤儿进程：父进程退出，但它的子进程还在运行，那么这些进程即为孤儿进程。孤儿进程会被init进程（PID=1）接收，并由init进程堆它们完成状态收集工作 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程未调用wait或waitpid获取子进程状态，那么子进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 5. epoll &amp; select epoll 和 select 都是I/O多路复用技术，都实现同时监听多个I/O事件的状态 epoll 比 select 高效，主要基于其操作系统支持的 I/O 事件通知机制，而select是基于轮询机制 epoll 支持水平触发和边缘触发两种模式 6. ping IP 根据目地IP和路由表决定走哪个网卡 根据网卡子网掩码判断目的IP是否在子网内 如果不在子网内，则通过arp缓存查询IP的网卡地址，不存在的话先通过广播询问目的IP的mac地址，该地址会缓存下来 根据获取的mac地址，然后发包 7. 解决hash冲突的办法7.1 开放地址法即 再散列法，基本思想：当关键字key的哈希地址p=H(key) 出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。 线性探测再散列：冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。 二次探测再散列：冲突发生时，在表的左右进行跳跃式探测，比较灵活 （1^2，-1^2， …) 伪随机探测再散列: 建立一个伪随机数发生器，并给定一个随机数做起点 7.2 再哈希法使用不同的哈希函数，直到冲突解决 缺点：耗时较长 7.3 链地址法将哈希值相同的元素构成一个同义词的单链表，并将单链表的头指针存放在哈希表的第i个单元中，查找、插入和删除主要在同义词链表中进行。链表法适用于经常进行插入和删除的情况。 7.4 建立一个公共溢出区将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。 8. Gitgit rebase 1234567891011121314151617# 1. 合并多次提交记录git rebase -i HEAD~4 # 最近四次git rebase --edit-todo # 异常退出vi时执行git rebase --continue # 返回继续编辑# 2. 合并分支 git checkout mastergit pullgit checkout devgit rebase master # 将master最新分支同步到当前分支git rebase --continue # 有冲突，并解决冲突后执行git rebase --abort # 有冲突，放弃，回到rebase前的状态git checkout mastergit merge devgit push git rebase master 做了哪些操作？ 先取消当前dev分支的提交记录 将在当前dev中新开发的代码保存成patch文件，存入.git/rebase目录下 当前dev分支合并最新的master分支 将patch文件应用到当前dev分支 在 dev 分支，使用 git rebase master，然后就会把 dev 接到 master 分支之上。Git 是这么做的： 首先，找到这两条分支的最近公共祖先 LCA 然后，从 master 节点开始，重演 LCA 到 dev 几个 commit 的修改，如果这些修改和 LCA 到 master 的 commit 有冲突，就会提示你手动解决冲突 最后，把 dev 的分支完全接到 master 上面。 9. 进程、线程、协程9.1 进程进程：程序的执行过程，包括了动态创建、调度和消亡的整个过程，是程序资源管理的最小单位 多进程模型：启动多个服务进程。由于多进程地址空间不同，数据不能共享，需要搭建各个进程间的通信桥梁，即IPC (InterProcess Communication) 常见IPC类型 管道 Pipe：一个内核缓冲区，以先进先出FIFO的方式从缓冲区存取数据；以半双工方式通信，数据只能单向流动，且只能在父子进程间通信 命名管道FIFO：以文件形式存于文件系统中 /tmp/fifo, 只要可以访问该文件的进程，均可通信 信号 Signal：用户空间进程和内核直接交互，内核可利用信号来通知用户空间进程发生哪些系统事件 消息队列 Message Queue：存放在内核中的消息链表，每个消息队列由消息队列标识符表示，只在内核重启或主动删除时，消息队列才会被删除 共享内存 Shared memory：多个进程可以直接读写同一块内存空间，是最快的IPC 套接字 Socket：通过网络接口将数据发送到本机的不同进程或远程计算机的进程 9.2 线程线程：进程中，资源调度的最小单位 多线程模型： 线程同步：线程之间的一种直接制约关系，一个线程的执行依赖另一个线程的通知，当它没有得到另一个线程的通知时必须等待，直到消息到达时才被唤醒。 线程互斥：多线程对资源访问的排他性，即多个线程要使用某个共享资源时，任何时刻最多只允许一个线程获得该共享资源的使用权 多线程同步和互斥方法： 互斥锁 条件变量 读写锁 自旋锁：线程反复去获取锁，但这个锁被其他线程占用，此线程将会等待，间隔一段时间后再次尝试获取。这种循环加锁的等待机制被称为自旋锁(spinlock) 信号量 9.3 协程协程：一种比线程更轻量化的微线程 协程优势： 协程在线程内实现，因此始终在一个线程中共享资源，不存在多线程抢占资源和资源同步问题 生产者协程和消费者协程，相互配合协作完成工作，而不是相互抢占 协程的创建和切换开销比线程小的多 9.4 总结进程、线程、协程的关系和区别： 进程拥有独立的堆和栈，既不共享堆，也不共享栈，由操作系统负责调度。 线程拥有独立的栈和共享的堆，由操作系统负责调度（内核线程）。 协程拥有独立的栈和共享的堆，有 golang 的调度器负责调度。 9.5 实现自旋锁12345678910111213141516type SpinLock uint32func NewSpinLock() *SpinLock &#123; var lock SpinLock return &amp;lock&#125;func (sl *SpinLock) Lock() &#123; for !atomic.CompareAndSwapUint32((*uint32)(sl), 0, 1) &#123; runtime.Gosched() &#125;&#125;func (sl *SpinLock) Unlock() &#123; atomic.StoreUint32((*uint32)(sl), 0)&#125; 10. 函数递归问题为什么递归“效率低”？ 函数调用开销问题：函数调用前，需要做许多工作，比如准备函数内局部变量使用的空间、保存函数的参数，记录函数调用位置等，这些操作较为耗资源。 某些递归算法，本身存在低效问题。斐波那契中求某一项，子问题会大量重复出现，产生大量重复计算，效率低下 不断入栈出栈操作 栈容量的限制，可能导致stack overflow 11. 压测工具 vegeta： 高性能http(s)负载测试工具。它是一个负载测试工具而不是基准测试工具。基准测试试图找到系统在峰值容量下所能承受的极限，而负载测试则倾向于讲述系统在不同的负载点和配置下的表现。 1echo &quot;GET http://10.137.8.40&quot; | vegeta attack -rate=20000 -duration=60s | tee test.dat | vegeta report -ouput test-result.dat ​ QPS: query per second goconvey: 集成go test, 支持Web-GUI 关于goconvey，下面说法正确的是（ABC）A. goconvey是一个支持golang的单元测试框架B. goconvey能够自动监控文件修改并启动测试，并可以将测试结果实时输出到web界面C. goconvey提供了丰富的断言简化测试用例的编写D. goconvey无法与go test集成 123456func TestStringSliceEqual(t *testing.T) &#123; Convey(&quot;TestStringSliceEqual should return true when a != nil &amp;&amp; b != nil&quot;, t, func() &#123; a := []string&#123;&quot;hello&quot;, &quot;goconvey&quot;&#125; b := []string&#123;&quot;hello&quot;, &quot;goconvey&quot;&#125; &#125;)&#125; GoStub GoStub框架的使用场景如下：A、为一个全局变量打桩B、为一个函数打桩C、为一个过程打桩D、由任意相同或不同的基本场景组合而成 12. 字符编码大端 (LitteEndian)：高位写左边，从左向右读 小端 (LitteEndian)：高位写右边，从右向左读","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Go 相关概念","slug":"Go 相关概念","date":"2020-07-17T03:42:23.000Z","updated":"2021-06-22T10:50:49.750Z","comments":true,"path":"2020/07/17/Go 相关概念/","link":"","permalink":"https://elihe2011.github.io/2020/07/17/Go%20%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","excerpt":"1. 逃逸分析1.1 堆和栈： 堆（Heap）： 一般情况下，手动申请、分配、释放。内存大小并不定，较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 堆在内存分配中类似于往一个房间里摆放各种家具，家具的尺寸有大有小。 引用类型 (指针、slice、map、chan、interface)的地址对应的数据存储内存通常分配在堆上 栈（Stack）： 由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数，局部变量等等都会存放在栈上 栈是一种拥有特殊规则的线性表数据结构,只允许线性表的一端放入数据,之后再这一端取出数据,按照后进先出(lifo)的顺序 值类型 (整型、浮点型、bool、string、array和struct) 的变量直接存储值，内存通常分配在栈上","text":"1. 逃逸分析1.1 堆和栈： 堆（Heap）： 一般情况下，手动申请、分配、释放。内存大小并不定，较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 堆在内存分配中类似于往一个房间里摆放各种家具，家具的尺寸有大有小。 引用类型 (指针、slice、map、chan、interface)的地址对应的数据存储内存通常分配在堆上 栈（Stack）： 由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数，局部变量等等都会存放在栈上 栈是一种拥有特殊规则的线性表数据结构,只允许线性表的一端放入数据,之后再这一端取出数据,按照后进先出(lifo)的顺序 值类型 (整型、浮点型、bool、string、array和struct) 的变量直接存储值，内存通常分配在栈上 1.2 逃逸分析逃逸分析就是确定一个变量要放堆上还是栈上，规则如下： 是否有在其他地方（非局部）被引用。只要有可能被引用了，那么它一定分配到堆上。否则分配到栈上 即使没有被外部引用，但对象过大，无法存放在栈区上。依然有可能分配到堆上 1.3 需要逃逸的原因频繁申请、分配堆内存是有一定 “代价” 的。会影响应用程序运行的效率，间接影响到整体系统。因此 “按需分配” 最大限度的灵活利用资源，才是正确的治理之道 1.4 查看逃逸分析1.4.1 通过编译器命令，就可以看到详细的逃逸分析过程1234go build -gcflags &#x27;-m -l&#x27; main.go-m: 进行内存分配分析-l: 禁用掉 inline 函数内联, 避免程序内联 1.4.2 通过反编译命令查看1go tool compile -S main.go 1.5 逃逸案例1.5.1 指针1) 外部引用，逃逸 1234567891011121314151617type User struct &#123; ID int Name string Age byte&#125;func GetUser() *User &#123; return &amp;User&#123; ID: 1, Name: &quot;jack&quot;, Age: 12, &#125;&#125;func main() &#123; _ = GetUser()&#125; 12345678$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:10:9: &amp;User literal escapes to heap$ go tool compile -S main.go | grep CALL 0x0028 00040 (main.go:10) CALL runtime.newobject(SB) 0x005f 00095 (main.go:9) CALL runtime.morestack_noctxt(SB) 2）外部未引用，不逃逸 1234func main() &#123; s := new(string) *s = &quot;abc&quot;&#125; 12345$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:4:10: new(string) does not escape$ go tool compile -S main.go | grep CALL 1.5.2 未确定类型1234567func main() &#123; s := new(string) *s = &quot;abc&quot; //fmt.Println(*s) // not escape fmt.Println(s) // escape to heap&#125; 原因：func Println(a ...interface&#123;&#125;) (n int, err error)接收任意类型，在编译时无法确定具体类型，因此产生逃逸 1.5.3 泄漏参数12345678910111213type User struct &#123; ID int Name string Age byte&#125;func GetUser(u *User) *User &#123; return u&#125;func main() &#123; _ = GetUser(&amp;User&#123;ID: 1, Name: &quot;jack&quot;, Age: 12&#125;)&#125; 1234$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:9:14: leaking param: u to result ~r1 level=0./main.go:14:14: &amp;User literal does not escape 使其逃逸：被外部所引用，将分配到堆上 12345678910111213type User struct &#123; ID int Name string Age byte&#125;func GetUser(u User) *User &#123; return &amp;u&#125;func main() &#123; _ = GetUser(User&#123;ID: 1, Name: &quot;jack&quot;, Age: 12&#125;)&#125; 123$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:9:14: moved to heap: u 2. new和make： new： 分配内存 设置零值 返回指针（重要） make: sice, map, chan 分配内存 返回对象 (对象本身为引用类型，不需要返回指针) 3. Go类型断言：1) Type Assertion 12t := o.(T)t, ok := o.(T) 2) Type Switch 123456switch o.(type) &#123;case int:case string:case nil:...&#125; 4. slice4.1 slice扩容的内存管理 翻新扩展：当前元素为 kindNoPointers，将在老 Slice cap 的地址后继续申请空间用于扩容 举家搬迁：重新申请一块内存地址，整体迁移并扩容 cap &lt; 1024: cap = cap * 2cap &gt;= 1024: cap = cap + cap/4 4.2 empty &amp; nil slicelen 和 cap 均等于0 1) empty: arary -&gt; []int&#123;&#125; 指向空数组 12s := []int&#123;&#125;s = make([]int, 0) 2) nil: array -&gt; nil 1var s []int 5. 指针5.1 空指针12345678910func main() &#123; var p1 *int var p2 = new(int) fmt.Println(p1 == nil) // true fmt.Println(p2 == nil) // false fmt.Println(*p1) // panic: nil pointer dereference fmt.Println(*p2) // 0&#125; 6. slice 参数 可通过下标修改原始slice的元素值 append操作，会改变slice指向的底层数组 1234567891011121314151617181920func main() &#123; a := make([]int, 1, 2) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a) foo(a) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a) bar(&amp;a) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a)&#125;func foo(a []int) &#123; a[0] = 9 // slice副本指向的 array 未变，所以能够修改原始 a 的值 a = append(a, 1, 2) // append操作，a指向的地址改变 fmt.Printf(&quot;%p\\n&quot;, &amp;a)&#125;func bar(a *[]int) &#123; *a = append(*a, 5, 6)&#125; 7. 并发读写mapfatal error: concurrent map read and map write 123456789101112131415func mapTest() &#123; m := make(map[int]int) go func() &#123; for &#123; m[0] = 1 &#125; &#125;() go func() &#123; for &#123; _ = m[0] &#125; &#125;()&#125; 解决方案：sync.Map 12345678910111213141516171819202122232425func main() &#123; //mapTest() syncMap() select &#123; case &lt;-time.After(time.Second): break &#125;&#125;func syncMap() &#123; m := sync.Map&#123;&#125; go func() &#123; for &#123; m.Store(0, 1) &#125; &#125;() go func() &#123; for &#123; _, _ = m.Load(0) &#125; &#125;()&#125; 8. Go 接口Go 接口为非侵入式接口 非侵入式接口: 接口的定义者无需知道接口被哪些类型实现了, 而接口的实现者也不需要知道实现了哪些接口, 无需指明已经实现了哪些接口, 只需要关注自己实现的是什么样的接口即可. 编译器会自己识别哪个类型实现哪些接口 侵入式接口: 主要体现是实现接口的类需要很明确的声明自己实现了哪个接口 9. Go 并发CSP: Communicating Sequential Process 通信顺序进程，消息传递模型 Goroutine: 轻量级线程, 简称协程。一个Goroutine 的栈启动很小(2k或者4k)。当Goroutine的栈空间不够的时候,会根据需要动态伸缩栈大小(甚至可到到1G)。 Go 语言线程模型： M: 内核线程（物理线程） P: 执行Go代码所必须的资源（上下文环境） G: 待执行的Go代码，即协程本身 9.1 sync.Mutex 互斥锁解决 goroutine 抢占公共资源问题 12345678910111213141516171819202122232425var m = make(map[int]int)var lock sync.Mutexfunc main() &#123; for i := 1; i &lt;= 10; i++ &#123; go factorial(i) &#125; time.Sleep(time.Second * 2) for k, v := range m &#123; fmt.Printf(&quot;%d!=%d\\n&quot;, k, v) &#125;&#125;func factorial(n int) &#123; res := 1 for i := 1; i &lt;= n; i++ &#123; res *= i &#125; lock.Lock() m[n] = res lock.Unlock()&#125; 9.2 并发数据同步1234567891011121314151617181920212223242526272829303132func add(n int) &#123; defer wg.Done() // method1: Found 1 data race for i := 0; i &lt; n; i++ &#123; runtime.Gosched() c++ &#125; // method2: 正常 /* for i := 0; i &lt; n; i++ &#123; atomic.AddInt64(&amp;c, 1) runtime.Gosched() &#125;*/ // method3: 正常 /* defer lock.Unlock() lock.Lock() for i := 0; i &lt; n; i++ &#123; c++ &#125;*/&#125;func main() &#123; wg.Add(2) go add(3) go add(4) wg.Wait() fmt.Println(&quot;c =&quot;, c)&#125; 检测并发竞争状态：go run --race main.go sync.WaitGroup: 等待组。用于等待一组线程的结束。 123func (wg *WaitGroup) Add(delta int) // 等待个数计数器func (wg *WaitGroup) Done() // 子线程结束，计数器减1func (wg *WaitGroup) Wait() // 阻塞等待所有子线程结束，即计数器为0 sync/atomic: 原子操作包。以底层的加锁机制来同步访问整型变量和指针。 123func AddInt64(addr *int64, delta int64) (new int64)func LoadInt64(addr *int64) (val int64)func StoreInt64(addr *int64, val int64)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Context","slug":"Go Context","date":"2020-07-16T03:20:08.000Z","updated":"2021-06-22T10:50:49.749Z","comments":true,"path":"2020/07/16/Go Context/","link":"","permalink":"https://elihe2011.github.io/2020/07/16/Go%20Context/","excerpt":"1. 简介context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据 1.1 结构图","text":"1. 简介context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据 1.1 结构图 1.2 Context interface12345678910111213type Context interface &#123; // 标识deadline是否已经设置了, 没有设置时, ok的值是false, 并返回初始的time.Time Deadline() (deadline time.Time, ok bool) // 返回一个channel, 当返回关闭的channel时可以执行一些操作 Done() &lt;-chan struct&#123;&#125; // 描述context关闭的原因,通常在Done()收到关闭通知之后才能知道原因 Err() error // 获取上游Goroutine 传递给下游Goroutine的某些数据 Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 方法说明： Deadline: 设置截止时间。第一个参数表示截止时间点，第二个参数是否设置了截止时间。未设置截止时间，需要通过cancel()来取消 Done(): 在被cancel时返回的一个只读通道 Err(): 被cancel的原因 Value(): 绑定到Context上的值 1.3 emptyCtx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// An emptyCtx is never canceled, has no values, and has no deadline. It is not// struct&#123;&#125;, since vars of this type must have distinct addresses.type emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123; return&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil&#125;func (*emptyCtx) Err() error &#123; return nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return nil&#125;func (e *emptyCtx) String() string &#123; switch e &#123; case background: return &quot;context.Background&quot; case todo: return &quot;context.TODO&quot; &#125; return &quot;unknown empty Context&quot;&#125;var ( background = new(emptyCtx) todo = new(emptyCtx))// Background returns a non-nil, empty Context. It is never canceled, has no// values, and has no deadline. It is typically used by the main function,// initialization, and tests, and as the top-level Context for incoming// requests.func Background() Context &#123; return background&#125;// TODO returns a non-nil, empty Context. Code should use context.TODO when// it&#x27;s unclear which Context to use or it is not yet available (because the// surrounding function has not yet been extended to accept a Context// parameter).func TODO() Context &#123; return todo&#125; 1.4 cancelCtx对外暴露了 Err() Done() String() 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// A cancelCtx can be canceled. When canceled, it also cancels any children// that implement canceler.type cancelCtx struct &#123; Context mu sync.Mutex // protects following fields done chan struct&#123;&#125; // created lazily, closed by first cancel call children map[canceler]struct&#123;&#125; // set to nil by the first cancel call err error // set to non-nil by the first cancel call&#125;func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; c.mu.Lock() if c.done == nil &#123; c.done = make(chan struct&#123;&#125;) &#125; d := c.done c.mu.Unlock() return d&#125;func (c *cancelCtx) Err() error &#123; c.mu.Lock() err := c.err c.mu.Unlock() return err&#125;func (c *cancelCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithCancel&quot;, c.Context)&#125;// cancel closes c.done, cancels each of c&#x27;s children, and, if// removeFromParent is true, removes c from its parent&#x27;s children.func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; if err == nil &#123; panic(&quot;context: internal error: missing cancel error&quot;) &#125; c.mu.Lock() if c.err != nil &#123; c.mu.Unlock() return // already canceled &#125; c.err = err if c.done == nil &#123; c.done = closedchan &#125; else &#123; close(c.done) &#125; for child := range c.children &#123; // NOTE: acquiring the child&#x27;s lock while holding parent&#x27;s lock. child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() if removeFromParent &#123; removeChild(c.Context, c) &#125;&#125; 1.5 valueCtx通过 valueCtx 结构知道仅是在Context 的基础上增加了元素 key 和 value 1234567891011121314151617// A valueCtx carries a key-value pair. It implements Value for that key and// delegates all other calls to the embedded Context.type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125;func (c *valueCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithValue(%#v, %#v)&quot;, c.Context, c.key, c.val)&#125;func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; return c.Context.Value(key)&#125; 1.6 timerCtx在cancelCtx 基础上增加了字段 timer 和 deadline 12345678910111213141516171819202122232425262728type timerCtx struct &#123; cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time&#125;func (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123; return c.deadline, true&#125;func (c *timerCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithDeadline(%s [%s])&quot;, c.cancelCtx.Context, c.deadline, time.Until(c.deadline))&#125;func (c *timerCtx) cancel(removeFromParent bool, err error) &#123; c.cancelCtx.cancel(false, err) if removeFromParent &#123; // Remove this timerCtx from its parent cancelCtx&#x27;s children. removeChild(c.cancelCtx.Context, c) &#125; c.mu.Lock() if c.timer != nil &#123; c.timer.Stop() c.timer = nil &#125; c.mu.Unlock()&#125; 2. 使用示例 通过 Background() 和 TODO() 创建最 emptyCtx 实例 ,通常是作为根节点 通过 WithCancel() 创建 cancelCtx 实例 通过 WithValue() 创建 valueCtx 实例 通过 WithDeadline 和 WithTimeout 创建 timerCtx 实例 2.1 WithCancel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func Operate1(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Operate1 done.&quot;) return default: fmt.Println(&quot;Operate1&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func Operate2(ctx context.Context) &#123; fmt.Println(&quot;Operate2&quot;)&#125;func Do1(ctx context.Context) &#123; go Do2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Do1 done.&quot;) fmt.Println(ctx.Err()) return default: fmt.Println(&quot;Do1:&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func Do2(ctx context.Context) &#123; go Operate1(ctx) go Operate2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Do2 done.&quot;) fmt.Println(ctx.Err()) return default: fmt.Println(&quot;Do2:&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) go Do1(ctx) time.Sleep(5 * time.Second) fmt.Println(&quot;Stop all goroutines&quot;) cancel() time.Sleep(2 * time.Second)&#125; 2.2 WithDeadline12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func task1(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(ctx.Err()) return default: fmt.Println(&quot;task1:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func task2(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(ctx.Err()) return default: fmt.Println(&quot;task2:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func main() &#123; after5Sec := time.Now().Add(5 * time.Second) ctx, cancel := context.WithDeadline(context.Background(), after5Sec) defer cancel() go task1(ctx) go task2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Main done:&quot;, ctx.Err()) return &#125; &#125;&#125; 2.3 WithTimeout12345678910111213141516171819202122232425262728293031323334353637func task(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;task is done.&quot;) return default: fmt.Println(&quot;task:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithTimeout(context.Background(), 6*time.Second) defer cancel() go task(ctx) n := 1 for &#123; select &#123; case &lt;-time.Tick(2 * time.Second): if n == 9 &#123; return &#125; fmt.Printf(&quot;n=%d\\n&quot;, n) n++ //case &lt;-ctx.Done(): // fmt.Println(&quot;Main done:&quot;, ctx.Err()) // return &#125; &#125;&#125; 2.4 WithValue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func v1(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;v1 done:&quot;, ctx.Err()) return default: fmt.Println(ctx.Value(&quot;key&quot;)) time.Sleep(3 * time.Second) &#125; &#125;&#125;func v2(ctx context.Context) &#123; fmt.Println(ctx.Value(&quot;key&quot;)) fmt.Println(ctx.Value(&quot;v3&quot;)) ctx = context.WithValue(ctx, &quot;key&quot;, &quot;modify from v2&quot;) go v1(ctx)&#125;func v3(ctx context.Context) &#123; if v := ctx.Value(&quot;key&quot;); v != nil &#123; fmt.Println(&quot;Key =&quot;, v) &#125; ctx = context.WithValue(ctx, &quot;v3&quot;, &quot;value of v3&quot;) go v2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;v3 done:&quot;, ctx.Err()) return default: fmt.Println(&quot;v3&quot;) time.Sleep(2 * time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) ctx = context.WithValue(ctx, &quot;key&quot;, &quot;main&quot;) go v3(ctx) time.Sleep(10 * time.Second) cancel() time.Sleep(3 * time.Second)&#125; 3. 其他示例3.1 关闭协程3.1.1 使用channel1234567891011121314151617181920212223242526272829func main() &#123; c := make(chan bool) for i := 0; i &lt; 5; i++ &#123; go monitor(c, i) &#125; time.Sleep(time.Second) // 关闭channel close(c) time.Sleep(5 * time.Second) fmt.Println(&quot;Done&quot;)&#125;func monitor(c chan bool, num int) &#123; for &#123; select &#123; case v := &lt;-c: fmt.Printf(&quot;Monitor[%d], receive [%v], stopping.\\n&quot;, num, v) return default: fmt.Printf(&quot;Monitor[%d] is running now.\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.1.2 使用Context1234567891011121314151617181920212223242526272829func main() &#123; ctx, cancel := context.WithCancel(context.Background()) for i := 0; i &lt; 5; i++ &#123; go monitor(ctx, i) &#125; time.Sleep(time.Second) // 取消操作 cancel() time.Sleep(5 * time.Second) fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case v := &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d], receive [%v], stopping.\\n&quot;, num, v) return default: fmt.Printf(&quot;Monitor[%d] is running now.\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.2 WithDeadline 和 WithTimeout123456789101112131415161718192021222324252627282930func main() &#123; //ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Second)) ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := 0; i &lt; 5; i++ &#123; go monitor(ctx, i) &#125; time.Sleep(5 * time.Second) if err := ctx.Err(); err != nil &#123; fmt.Printf(&quot;Reason: %v\\n&quot;, err) &#125; fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d] stopped.\\n&quot;, num) return default: fmt.Printf(&quot;Monitor[%d] is running...\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.3 WithValue1234567891011121314151617181920212223242526272829303132func main() &#123; ctx1, cancel := context.WithCancel(context.Background()) ctx2, cancel := context.WithTimeout(ctx1, time.Second) ctx3 := context.WithValue(ctx2, &quot;name&quot;, &quot;jack&quot;) defer cancel() for i := 0; i &lt; 5; i++ &#123; go monitor(ctx3, i) &#125; time.Sleep(5 * time.Second) if err := ctx3.Err(); err != nil &#123; fmt.Printf(&quot;Reason: %v\\n&quot;, err) &#125; fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d] stopped.\\n&quot;, num) return default: value := ctx.Value(&quot;name&quot;) fmt.Printf(&quot;Monitor[%d] is running, value is %v\\n&quot;, num, value) time.Sleep(2 * time.Second) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"MySQL","slug":"MySQL","date":"2020-03-24T05:19:50.000Z","updated":"2021-07-13T02:47:54.483Z","comments":true,"path":"2020/03/24/MySQL/","link":"","permalink":"https://elihe2011.github.io/2020/03/24/MySQL/","excerpt":"1. 数据库引擎 InnoDB：支持ACID事务；行级锁和外键约束 MyIASM: 不支持事务，也不支持行级锁和外键 MEMORY：数据存储在内存中，速度快，但安全性不高 1.1 MyIASM &amp; InnoDB MyISAM InnoDB 存储结构 每张表三个文件：表结构(.frm)，表数据(.MYD)，表索引(.MYI) 所有表存储在一个或多个文件中，甚至是独立的表空间文件中。单表一般2G 存储空间 可被压缩，存储空间减小 需要更多的内存和存储，会在内存中建立其专用的缓冲池用于高速缓冲数据和索引 备份恢复 通过拷贝表相关的三个文件即可 拷贝数据文件、备份binlog，或使用mysqldump。数据量太大时，需要使用商业解决方案 文件格式 数据和索引分开存储 .MYD &amp; .MYI 数据和索引集中存储 .idb 存储顺序 按记录插入顺序保存 按主键大小有序插入 外键 不支持 支持 事务 不支持 支持 锁 表级锁 表级锁、行级锁 SELECT MyIASM 更优 I/U/D InnoDB 更优 select count(*) MyIASM 更快，它内部维护了一个计数器，可直接调取 索引实现方式 B+树，MyIASM 是堆表 B+树，InNoDB 是索引组织表 哈希索引 不支持 支持 全文索引 支持 不支持","text":"1. 数据库引擎 InnoDB：支持ACID事务；行级锁和外键约束 MyIASM: 不支持事务，也不支持行级锁和外键 MEMORY：数据存储在内存中，速度快，但安全性不高 1.1 MyIASM &amp; InnoDB MyISAM InnoDB 存储结构 每张表三个文件：表结构(.frm)，表数据(.MYD)，表索引(.MYI) 所有表存储在一个或多个文件中，甚至是独立的表空间文件中。单表一般2G 存储空间 可被压缩，存储空间减小 需要更多的内存和存储，会在内存中建立其专用的缓冲池用于高速缓冲数据和索引 备份恢复 通过拷贝表相关的三个文件即可 拷贝数据文件、备份binlog，或使用mysqldump。数据量太大时，需要使用商业解决方案 文件格式 数据和索引分开存储 .MYD &amp; .MYI 数据和索引集中存储 .idb 存储顺序 按记录插入顺序保存 按主键大小有序插入 外键 不支持 支持 事务 不支持 支持 锁 表级锁 表级锁、行级锁 SELECT MyIASM 更优 I/U/D InnoDB 更优 select count(*) MyIASM 更快，它内部维护了一个计数器，可直接调取 索引实现方式 B+树，MyIASM 是堆表 B+树，InNoDB 是索引组织表 哈希索引 不支持 支持 全文索引 支持 不支持 1.2 MyISAM &amp; InnoDB 索引区别 InnoDB 聚簇索引，MyIASM 非聚簇索引 InnoDB 主键索引的叶子节点上存储着行数据，因此主键索引非常高效 MyIASM 索引的叶子节点上存储行数据地址，需要再寻址一次才能得到数据 InnoDB 索引的叶子节点存储的是主键和其他索引的列数据，因此查询时做到覆盖索引会非常高效 聚集索引与非聚集索引的区别是：叶节点是否存放一整行记录 InnoDB 主键使用的是聚簇索引，MyISAM 不管是主键索引，还是二级索引使用的都是非聚簇索引。 聚簇索引的优点：数据检索高效 聚簇索引的缺点： 插入速度严重依赖于插入顺序 更新主键代价很高，会导致被更新的行移动 二级索引访问需要两次索引查找，第一次找主键，第二次根据主键找到行数据 1.3 InnoDB 的 4 大特性 插入缓冲 (insert buffer) 二次写 (double write) 自适应哈希索引 (ahi) 预读 (read ahead) 2. 索引2.1 索引简介索引是一种特殊的文件，保存表中记录的引用指针。 索引是一个排序的数据结构，协助快速查询、更新数据库表中数据。 索引的实现通常使用B树及其变种B+树。 索引原理： 把创建了索引的列内容进行排序 把排序结果生成倒排表 在倒排表内容上拼上数据地址链 查询时，先拿到倒排表内容，再取出地址链，从而拿到具体数据 索引的优点：提高数据检索速度 索引的缺点： 时间方面：创建和维护索引都要消耗时间。对表中数据进行增删改时，索引也要动态维护，会降低执行效率 空间方面：索引需要占用物理空间 使用索引的场景： where order by join 索引覆盖：如果要查询的字段都建立了索引，那么引擎会直接在索引表中查询而不会访问原始数（即索引覆盖）据，否则只要一个字段没有建立索引就会做全表扫描。因此在 select 时只写必要的查询字段，以增加索引覆盖的几率。 索引类型: 主键：不允许重复 和 NULL 唯一索引：不允许重复 普通索引 全文索引：搜索引擎使用的一种关键技术 如果在文本字段(text)上建立普通索引，where column like &#39;%xxx%&#39;操作会使索引失效，需要全文索引来解决问题 12ALTER TABLE tablename ADD FULLTEXT (column1, column2);SELECT * FROM tablename WHERE MATCH(column1, column2) AGAINST(&#x27;jackson&#x27;, &#x27;sara&#x27;); 索引创建原则： 最左前缀匹配原则：联合索引中尤为重要 较频繁做查询条件的字段，应创建索引 更新频繁的字段，不合适做索引 重复数据量大的字段，不适合做索引，比如性别 尽量扩展索引，不要新建索引。 定义为外键的数据列，一定要建立索引 对 text，blob等类型不要建立索引 不要在NULL值字段创建索引，定义应该指定NOT NULL，然后用默认值代替 索引字段越小越好，key 太长会导致一页中能够存放key的数量变少，间接导致索引树的页数变多，索引层次增加，查询性能降低 2.2 索引数据结构2.2.1 Btree通过 B+ 树实现 查询方式： 主键索引区：PI, 关联数据的地址，按主键查询 普通索引区：si, 关联id的地址，然后再到达上面的地址 B+tree 特性： 1）n 棵子树的节点包含 n 个关键字，保存数据的索引 2）所有的叶子节点中包含了全部关键字的信息，及指向这些关键字记录的指针，依关键字的大小升序链接 3）所有非终端节点可以看成是索引部分，节点中仅含其子树的最大或最小 4）B+ 树中，数据对象的插入和删除仅在叶节点上进行 5）B+ 树有2个头指针，一个是树的根节点，一个是最小关键字的叶节点。 2.2.2 哈希索引通过hash算法实现，常见hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法等 2.3 B树 和 B+树B树：它是一颗多路平衡查找树。一棵M阶的B树： 树中每个节点最多m个孩子 除了根节点和叶子节点外，其他节点最少含有m/2个孩子 若根节点不是叶子节点，则根节点最少含有两个孩子 所有叶子节点都在同一层，叶子节点不包含任何关键信息 B树 和 B+树的区别： BTree B+Tree 所有内部和叶子节点都有数据指针 只有叶子节点有数据指针 键可能不在叶子节点上，因此搜索需要更多时间 所有键都在叶子节点上，因此搜索更快，更准 树中没有key的重复项 key重复，所有节点都在叶子上 插入会耗费更多时间 插入容易 内部节点删除非常复杂，树需要进行大量转换 删除任何节点都很容易，因为所有节点都在叶子节点上 叶子节点不存储为结构链表 叶子节点存储为结构链表 没有多余的搜索键 可能存在冗余的搜索键 B+树优于B树的原因： B+树空间利用率更高，可减少IO次数，磁盘读写代价更低。因为B+树内部节点没有指向关键字具体信息的指针，只做索引使用，内部节点相对B树小 B+树的查询效率更加稳定。B+树所有关键字的查询路径长度相同，导致每个关键字的查询效率相当。 B+树增删节点的效率更高。 3. 事务事务：数据库执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。 3.1 事务的特性 ACID 原子性 (Atomicity): 事务作为一个整体被执行，要么全部被执行，要么都不执行。 一致性 (Consistent): 数据库状态是一致的，无中间状态。一致状态指的是数据库中的数据应该满足完整性约束。 隔离性 (Isolation): 多个事务并发执行时，事务直接不相互影响。 持久性 (Durability): 已提交的事务对数据库的修改是永久性的，事务结束后该操作不可逆。 3.2 事务的隔离级别1234567set session transaction isolation level read uncommitted;SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125;SELECT @@global.tx_isolation;SELECT @@session.tx_isolation;SELECT @@tx_isolation; 读未提交 (Read Uncommitted): 一个事务可以读取到另一个事务还未提交的数据。可能导致“脏读”。 读已提交 (Read Committed): 事务中多次读取同一数据，都能读到其他事务提交的数据。可能导致“不可重复读”。 可重复读 (Repeatable Read): 默认级别。事务中多次读取同一数据，即使其他事务提交了该是数据，该数据在本事务中不会改变。 通过MVCC多版本控制机制来实现的。 可串行化 (Serializable): 事务串行执行，不允许并发。 隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 不可能 可能 可串行化 不可能 不可能 不可能 脏读：一个事务内，读取到了其他事务还没提交的数据。 不可重复读：一个事务内，多次读同一数据，如果另一个事务恰好修改了这个数据，那么在第一个事务中，两次读取的数据就可能不一致。 幻读：一个事务内，第一次查询某条记录，发现没有，但当试图更新这条不存在的记录时，竟然成功，并且再次读取同一条记录，竟然存在。 4. 锁4.1 按锁的颗粒度 行级锁(InnoDB): 开销大，加锁慢 会出现死锁 锁定颗粒度最小，发生锁冲突的概率最低，并发度最高 select *from table_name where id=1 for update 表级锁(MyIASM，InnoDB): 开销少，加锁块 不会出现死锁 颗粒度大，发生锁冲突的概率最高，并发度最低 页级锁(DBD): 开销和加锁时间介于行锁和表锁之间 会出现死锁 锁定颗粒度介于行锁和表锁之间 4.2 锁的类别共享锁：即读锁。当用户进行数据读取时，对数据加锁共享锁。支持同时加上多个。 排他锁：即写锁。当用户进行数据写入时，对数据加上排它锁。只能加一个，且和其他排它锁、共享锁都排斥。 4.3 InnoDB 锁的算法 Record lock: 单行记录上的锁 Gap lock： 间隙锁，锁定一个范围，不包括记录本身 Next-key lock: record+gap 锁定一个范围，包含记录本身 4.4 死锁死锁: 两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。 解决死锁： 1）如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可大大降低死锁机会。 2）同一事务中，尽可能做的一次锁定所需的所有资源，减少死锁产生的概率。 3）对非常容易产生死锁的业务，可尝试使用升级锁定颗粒度，通过表级锁来减少死锁发生的概率。 4.5 乐观锁 &amp; 悲观锁 悲观锁：想办法避免冲突。每次去拿数据时，都认为别人会修改，所以每次在拿数据时都上锁。 乐观锁：允许冲突，但发生冲突时，有能力解决。乐观的认为冲突不会发生，除非检测到确实产生了冲突 逻辑时钟 (Logical Clock) MVCC：Multi-version Concurrent Control 实现乐观锁： 12345678SELECT data AS old_data, version AS old_version FROM ...;UPDATE ... SET data = new_data, version = new_version WHERE version = old_version;if (updated_row &gt; 0) &#123;// 乐观锁获取成功，操作完成&#125; else &#123;// 乐观锁获取失败，回滚并重试&#125; 4.6 MVCCMVCC: Multiversion Concurrency Control 多版本并发控制 MVCC 中的版本一般选择使用时间戳或者事务ID来标识。在处理一个写请求时，MVCC不是简单的有新值覆盖旧值，而是为这一项添加一个新版本数据。在读取一个数据项时，要先确定读取的版本，然后根据版本找到对应的数据。MVCC中的读操作永远不会被阻塞。 MVCC两种读形式： 快照读：读取的只是当前事务的可见版本，不用加锁。select * from tablename where id=xxx 即为快照读 当前读：读取当前版本，比如特殊的读操作，更新/插入/删除操作 123456select * from tablename where id=xxx lock in share mode;select * from tablename where id=xxx for update;update tablename set ...insert into tablename(xxx,) values(xxx,)delete from tablename where id=xxx; 5. 视图视图：本质上是一种虚拟表，在物理上不存在，其内容和真实的表相似。它的行和列来自定义视图的查询所引用基本表，在具体引用视图时动态生成。 5.1 视图的特点 视图的列可以来自不同的表，是表的重新和在逻辑意义上建立新关系 视图是由基本(实)表产生的虚表 视图的建立和删除不影响基本表 对视图内容的更新(增删改)直接影响基本表 当视图来自多个基本表时，不允许添加和删除数据 5.2 视图的使用场景视图的用途：优化SQL查询，提高开发效率 常用场景： 重用SQL语句 简化复杂的SQL操作。编写完查询后，可方便重用而不必关心查询细节 使用表的组成部分而不是整表 保护数据。可给用户授予表的部分数据访问权限而不是整个表 改变数据格式和表示。 5.3 视图的优点 查询简单化 数据安全性 逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性 5.4 视图的缺点 性能。如果视图由一个复杂的多表查询定义，那么即使视图的一个简单查询，也需要花费一定的时间 修改限制。较复杂的视图，可能是不可修改的 6. 游标游标：系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果，每个游标区都有一个名字，用户可通过游标逐一获取记录并赋给主变量，交由主语言进一步处理 7. 存储过程与函数存储过程：一个预编译的SQL语句，允许模块化设计，即只要创建一次，后续可多次调用。 优点： 预编译的，执行效率高 存储过程代码直接放数据库，通过存储过程名称调用，减少网络通信 安全性高，执行存储过程需要一定的权限 可重复使用 缺点： 调试麻烦 移植困难 带引用关系的对象发生改变，受影响的存储过程、包将需要重新编译 维护困难。对于大型项目，多版本迭代的数据结构变化，存储过程维护会相当麻烦。 8. 触发器触发器：用户定义在关系表上的一类由事件驱动的特殊的存储过程。 触发器是一段代码，当触发某个事件时，自动执行这些代码 8.1 使用场景 实现相关表的级联更改 实时监控表中自动的更改并触发相关处理 生成某些业务编号 8.2 六类触发器 before insert after insert before update after update before delete after delete 9. SQL9.1 语句分类 DDL: CREATE, DROP, ALTER，TRUNCATE DQL: SELECT DML: INSERT, UPDATE, DELETE DCL: GRANT, REVOKE, COMMIT, ROLLBACK 9.2 关联查询 INNER JOIN LEFT JOIN：以左表为主，先查出左表，然后按照ON的关联条件匹配右表，没有匹配到用NULL填充。 RIGHT JOIN：以右表为主，先查出右表，然后按照ON的关联条件匹配左表，没有匹配到用NULL填充。 UNION：合并多个集合(联合查询的列必须一致)，相同的记录会合并 UNION ALL：不会合并重复行，效率比UNION低 FULL JOIN：MySQL不支持，但可实现 1SELECT * FROM A LEFT JOIN B A.id=B.id UNION SELECT * FROM A RIGHT JOIN B A.id=B.id; 9.3 子查询 条件：一条SQL语句的查询结果作为另一条查询语句的条件或查询结果 嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询 子查询的三种情况： 1）子查询是一个单行单例，使用“=” 1select * from users where age=(select max(age) from users); 2）子查询是一个多行单例，使用“in” 1select * from users where age in (select age from users where gender=&#x27;female&#x27;); 3）子查询是多行多列，结果集类似一张虚表，但不能使用where 123select * from dept d, (select * from users where age&gt;20) u where u.dept_id=d.id;select d.*, u.* from dept d inner join users u on d.id==u.dept_id where u.age&gt;20; 9.4 in &amp; existsin: 把外表和内表做hash连接 exists： 对外表做loop循环，每次loop循环再对内表进行查询 执行效率对比： 如果查询的两个表大小相当，in和exists差别不大 如果两个表中一个较小，一个较大，则子查询表大的用exists，子查询表小的ongoingin not exists 使用索引，但not in无法使用索引，所以not exists更高效 9.5 SQL 性能优化 为避免全表扫描，涉及 WHERE 和 ORDER BY 的字段建立索引 避免 WHERE 中使用 NULL 判断，建表时尽量使用NOT NULL 避免 WHERE 中使用 != 或 &lt;&gt;，这些操作可使用索引：&lt;, &lt;=, =, &gt;, &gt;=, BETWEEN, IN，LIKE (某些时候) 避免 WHERE 中使用 OR，它会导致引擎放弃使用索引而进行全表扫描，可以使用 UNION 代替 慎用 IN 和 NOT IN，连续的数值，推荐BETWEEN WHERE 中字段 不要使用函数、表达式 12SELECT * FROM record WHERE amount/30 &lt; 1000;SELECT * FROM record WHERE convert(char(10), date, 112) = &#x27;20201220&#x27;; 用EXISTS 代替 IN 12select num from a where num in (select num from b)select num from a where num exists (select 1 from b) 索引会提高SELECT的效率，但也降低了INSERT和UPDATE的效率(索引重建), 一个表的索引，最好不要超过6个 JOIN的表不要超过5个，考虑使用临时表。 少用子查询，视图嵌套不要超过2层 数量统计，用count(1)代替 count(*) 记录是否存在，用 EXISTS 代替 count(1) &gt;= 效率比 &gt; 高 GROUP BY 前，先进行数据过滤： 12select job, avg(sal) from emp GROUP BY job HAVING job=&#x27;engineer&#x27; or job=&#x27;saler&#x27;;select job, avg(sal) from emp where job=&#x27;engineer&#x27; or job=&#x27;saler&#x27; GROUP BY job; 尽量不使用触发器，trigger事件比较耗时 避免使用DISTINCT 9.6 SQL 执行过程 9.7 分页123SELECT * FROM table_name LIMIT 5; // 1~5SELECT * FROM table_name LIMIT 5,10; // 6~15SELECT * FROM table_name LIMIT 5,-1; // 6~end 10. 数据类型 DECIMAL：高精度。float/double 浮点数近似值 CHAR：定长，存取效率高；VARCHAR变长，节约磁盘空间。 VARCHAR(50)和VARCHAR(200): 存储相同字符串，所占空间相同，但后者在排序时会消耗更多内存，因为order by采取fixed_length计算col长度。 INT(10): 10表示数据的长度，不是存储数据的大小。 CHAR(10): 10位固定字符串，不足补空格 VARCHAR(10): 10位可变字符串，不补空格 TEXT/BLOB：尽量避免使用，查询时会使用临时表，导致严重性能开销 TIMESTAMP：比 datetime 空间效率高 11. 配置参数11.1 慢查询日志开启慢查询日志后，会在datadir目录下产生一个xxx-slow.log文件 1234567--开启慢查询日志show variables like &#x27;slow_query_log&#x27;;set GLOBAL slow_query_log=on; --设置临界时间show variables like &#x27;long_query_time&#x27;;set long_query_time=0.5; --0.5s 12. 编码utf8和utf8mb4: utf8: 最大字符长度 3 字节 utf8mb4: mb4, most bytes 4, 兼容四子节unicode，支持emoji等新扩展unicode。对于CHAR类型，utf8mb4更消耗字符空间，建议使用VARCAHR 13. 日志13.1 undoLog事务回滚日志 insert undo log: 插入数据时产生，事务提交后丢弃 update undo log: 更新或删除数据时产生，快照读的时候需要所以不能直接删除，只有当系统没有比这个log更早的read-view的时候才能被删除 13.2 redoLog重做日志文件，记录数据修改之后的值，用于持久化到磁盘中 redo log buffer: 内存中的日志缓冲，易丢失 redo log file: 磁盘上的日志文件，持久化的。记录物理数据页修改的信息。当数据更新时，InnoDB会先将数据更新，然后记录redoLog在内存中，然后找个时间将redoLog持久化到磁盘。不管提交是否成功都要记录 13.3 binLog逻辑日志，记录sql的原始逻辑 数据修改时，binlog会追加写入指定大小的物理文件中，如果文件写满则创建一个新的文件写入；用于复制和恢复在主从复制中，从库利用主库的binlog进行重播。 binlog 的三种格式：statement, row 和 mixed statement：每一条修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候，需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。 row：不记录sql语句上下文信息，仅保存那条记录被修改。记录单元为每一行的改动，基本可以全部记录下来。但由于操作过多，导致大量行改动 (如：alter table)。此种模式的文件保存信息过多，日志量太大。（新版优化：当表结构发生变化时，记录操作语言，而不是行记录） mixed：折中方案。普通操作使用statement记录，当无法使用statement时使用row。 14. MySQL 权限表由 mysql_install_db 脚本初始化 Table Usage user 用户账号信息 db 各个账号在各个数据库上的操作权限 table_priv 数据 “表级” 的操作权限 columns_priv 数据 “列级” 的操作权限 host 给定主机上数据库操作权限 15. 主从复制主从复制：将主库中的DDL和DML操作通过二进制日志(BINLOG) 传输到从库上，然后在从库上重现这些操作，使主从数据库一致 主从复制的用途： 主数据库宕机，切到从库继续工作 实现读写分离 数据库日常备份 主从复制流程： 主：binlog线程，记录下所有改变数据的日志到binlog中 从：io线程，从master上拉取binlog日志，并放入relay log中 从：sql执行线程，执行relay log中的语句 15.1 读写分离方案1) mysql-proxy 优点：直接实现了读写分离和负载均衡，不用修改代码 缺点：性能低，不支持事务。不推荐使用 2）ORM实现 16. 备份mysqldump: 逻辑备份，小于100G可使用 xtranbackup: 物理备份，直接拷贝表空间 17. 常用技巧17.1 查找字段相同的数据123select a.id from group_member a,(select group_id, user_id, status from group_member group by group_id, user_id, status having count(*) &gt; 1) bwhere a.group_id=b.group_id and a.user_id=b.user_id and a.status=b.status; 17.2 循环更新数据12UPDATE contact a INNER JOIN users b ON a.inviter=b.phone SET a.inviter_id=b.id;UPDATE contact a INNER JOIN users b ON a.invitee=b.phone SET a.invitee_id=b.id; 17.3 强制删除外键引用的表123SET FOREIGN_KEY_CHECKS = 0drop table users;SET FOREIGN_KEY_CHECKS = 1; 99. 问题集99.1 删除百万级别数据不要直接去操作，直接操作会存在索引更新问题；另外删除过程中断，会导致回滚 1）先删除索引 2）删除无用数据 3）重建索引 99.2 线上环境大表，添加索引数据量超过100W，直接增加索引，可能导致服务器奔溃 两种方法： 1）临时表 注意：此方法可能会损失少量数据 1234567891011121314--复制旧表结构create table new_table like old_table;--加字段、索引alter table new_table add index (column);--拷贝旧表数据insert into new_table(field1, field2, ...) select field1, field2, ... from old_table;--修改表名rename table old_table to old_table_bak;rename table new_table to old_table;ALTER TABLE admin_user RENAME TO a_user; 2）主从切换 从库中进行加字段、索引 主库切换到从库 99.3 大表数据查询优化1）优化schema、sql、索引 2）增加缓存 redis 等 3）主从复制，读写分离 4）垂直拆分（一表分多表）。根据模块耦合度，将一个大的系统拆分成多个小系统，即分布式系统 5）水平切分（存储数据分片）。大表，考虑选择合适的分片(sharding key). 分片问题： 事务：需要支持分布式事务 跨库join、count, order by, group by及聚合函数等：分别在各个节点上得到结果，然后在应用程序端进行合并。 数据迁移、容量规划、扩容 ID问题：Twitter的分布式自增ID算法Snowflake 跨分区排序：多节点查询，结果集汇总并再排序 99.4 慢查询优化 分析查询语句，检查是否load了额外的数据，对查询语句重写，去除多余的查询 分析语句的执行计划，获取其使用索引的情况，优化索引，使其尽可能命中 已无法优化的大表，考虑横向或纵向分表 99.5 使用主键主键的好处：确保数据在整张表中的唯一性。在CURD的时候能确保操作数据范围安全 推荐使用自增ID，而不是UUID。因为InnoDB中的主键索引是聚簇索引，即主键索引的B+上叶子节点上存储了主键索引及全部数据(按顺序)。使用自增ID，只需要不断想后排列即可；但如果是UUID，先确定顺序，导致数据移动等操作，使插入性能下降。 99.6 字段定义要求not null的好处null值会占用更多的字节，也会在程序中造成很多与预期不符的情况 99.7 存储密码散列密码散列、盐值、也会手机号等固定长度的字符串应该使用char而不是varchar，这样可以节约空间且提高检索效率。 99.8 数据库CPU飙升到500%怎么处理1）使用top观察是不是mysqld占用导致的，如果不是，找到占用高的进程，并进行处理 2）对于mysqld造成的问题，可以使用show processlist 查看 session 情况，是否有消耗 sql 的资源在运行。查看执行计划是否准确，index是否缺失等 99.9 重复值高的字段不能建索引未命中索引的原因： 查询的数据量可能已经是总数据量的20%以上了，这个时候就会选择表扫描。 索引坏块，需要重建索引。 原因： 1）非聚簇索引存储了对主键的引用，如果select字段不在非聚簇索引内，就需要跳到主键索引（图中从右边索引树跳到左边的索引树），再获取select字段值 2）如果非聚簇索引值重复率高，那么将查询时就会出现图中从右边跳到左边的情况，导致整个流程很慢","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://elihe2011.github.io/categories/MySQL/"}],"tags":[]},{"title":"Go 缓存淘汰策略","slug":"Go 缓存淘汰策略","date":"2020-01-12T07:17:57.000Z","updated":"2021-06-22T10:50:49.748Z","comments":true,"path":"2020/01/12/Go 缓存淘汰策略/","link":"","permalink":"https://elihe2011.github.io/2020/01/12/Go%20%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","excerpt":"1. LRULeast Recently Used, 最近最少使用缓存。目的：淘汰最长时间未被使用的元素 快速存取原始 固定的最大容量，不会无限制增长 达到最大容量后，新增元素时，会把最近最少使用的元素删除，再放入新元素","text":"1. LRULeast Recently Used, 最近最少使用缓存。目的：淘汰最长时间未被使用的元素 快速存取原始 固定的最大容量，不会无限制增长 达到最大容量后，新增元素时，会把最近最少使用的元素删除，再放入新元素 1.1 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103type Entry struct &#123; Key string Value interface&#123;&#125; pre *Entry next *Entry&#125;type Cache struct &#123; cache map[string]*Entry capacity int head *Entry tail *Entry&#125;func newCache(cap int) *Cache &#123; return &amp;Cache&#123;cache: make(map[string]*Entry), capacity: cap&#125;&#125;var lock sync.RWMutexfunc (cache *Cache) Put(key string, val interface&#123;&#125;) interface&#123;&#125; &#123; lock.Lock() defer lock.Unlock() if existVal, exist := cache.cache[key]; exist &#123; cache.moveToHead(existVal) return nil &#125; // 重设 head 元素 e := &amp;Entry&#123;Key: key, Value: val, next: cache.head&#125; if cache.head != nil &#123; cache.head.pre = e &#125; cache.head = e // 第一次新增元素时，tail 为 nil if cache.tail == nil &#123; cache.tail = e &#125; cache.cache[key] = e if len(cache.cache) &lt;= cache.capacity &#123; return nil &#125; // 处理超出容量范围的元素 removedEntry := cache.tail cache.tail = cache.tail.pre removedEntry.pre = nil cache.tail.next = nil delete(cache.cache, removedEntry.Key) return removedEntry.Value&#125;func (cache *Cache) Get(key string) interface&#123;&#125; &#123; lock.Lock() defer lock.Unlock() if existVal, exist := cache.cache[key]; exist &#123; cache.moveToHead(existVal) return existVal.Value &#125; return nil&#125;func (cache *Cache) moveToHead(e *Entry) &#123; if e == cache.head &#123; return &#125; // 从link中断开，并连接前后元素 e.pre.next = e.next if e == cache.tail &#123; cache.tail = e.pre &#125; else &#123; e.next.pre = e.pre &#125; e.pre = nil e.next = cache.head cache.head.pre = e cache.head = e&#125;func main() &#123; cache := newCache(2) cache.Put(&quot;1&quot;, &quot;Golang&quot;) fmt.Println(cache.Get(&quot;1&quot;)) cache.Put(&quot;2&quot;, &quot;Python&quot;) fmt.Println(cache.Get(&quot;1&quot;)) cache.Put(&quot;3&quot;, &quot;Java&quot;) fmt.Println(cache.Get(&quot;1&quot;)) fmt.Println(cache.Get(&quot;2&quot;)) // nil fmt.Println(cache.Get(&quot;3&quot;)) // Java&#125; 1.2 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263type LinkNode struct &#123; key, val int pre, next *LinkNode&#125;type LRUCache struct &#123; m map[int]*LinkNode cap int head, tail *LinkNode&#125;func Constructor(capacity int) LRUCache &#123; head := &amp;LinkNode&#123;0, 0, nil, nil&#125; tail := &amp;LinkNode&#123;0, 0, nil, nil&#125; head.next = tail tail.pre = head return LRUCache&#123;make(map[int]*LinkNode), capacity, head, tail&#125;&#125;func (this *LRUCache) Get(key int) int &#123; cache := this.m if v, exist := cache[key]; exist &#123; this.MoveToHead(v) return v.val &#125; else &#123; return -1 &#125;&#125;func (this *LRUCache) RemoveNode(node *LinkNode) &#123; node.pre.next = node.next node.next.pre = node.pre&#125;func (this *LRUCache) AddNode(node *LinkNode) &#123; head := this.head node.next = head.next head.next.pre = node node.pre = head head.next = node&#125;func (this *LRUCache) MoveToHead(node *LinkNode) &#123; this.RemoveNode(node) this.AddNode(node)&#125;func (this *LRUCache) Put(key int, value int) &#123; tail := this.tail cache := this.m if v, exist := cache[key]; exist &#123; v.val = value this.MoveToHead(v) &#125; else &#123; v := &amp;LinkNode&#123;key, value, nil, nil&#125; if len(cache) == this.cap &#123; delete(cache, tail.pre.key) this.RemoveNode(tail.pre) &#125; this.AddNode(v) cache[key] = v &#125;&#125; 2. LFULFU（Least Frequently Used）算法根据数据的历史访问频率来淘汰数据，其核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。LFU的每个数据块都有一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。LFU需要记录所有数据的访问记录，内存消耗较高；需要基于引用计数排序，性能消耗较高。在算法实现复杂度上，LFU要远大于LRU。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package maintype LFUCache struct &#123; cache map[int]*Node freq map[int]*DoubleList ncap, size, minFreq int&#125;func (this *LFUCache) IncrFreq(node *Node) &#123; _freq := node.freq this.freq[_freq].RemoveNode(node) if this.minFreq == _freq &amp;&amp; this.freq[_freq].IsEmpty() &#123; this.minFreq++ delete(this.freq, _freq) &#125; node.freq++ if this.freq[node.freq] == nil &#123; this.freq[node.freq] = createDL() &#125; this.freq[node.freq].AddFirst(node)&#125;func Constructor(capacity int) LFUCache &#123; return LFUCache&#123; cache: make(map[int]*Node), freq: make(map[int]*DoubleList), ncap: capacity, &#125;&#125;func (this *LFUCache) Get(key int) int &#123; if node, ok := this.cache[key]; ok &#123; this.IncrFreq(node) return node.val &#125; return -1&#125;func (this *LFUCache) Put(key int, value int) &#123; if this.ncap == 0 &#123; return &#125; //节点存在 if node, ok := this.cache[key]; ok &#123; node.val = value this.IncrFreq(node) &#125; else &#123; if this.size &gt;= this.ncap &#123; node := this.freq[this.minFreq].RemoveLast() delete(this.cache, node.key) this.size-- &#125; x := &amp;Node&#123;key: key, val: value, freq: 1&#125; this.cache[key] = x if this.freq[1] == nil &#123; this.freq[1] = createDL() &#125; this.freq[1].AddFirst(x) this.minFreq = 1 this.size++ &#125;&#125;//节点nodetype Node struct &#123; key, val, freq int prev, next *Node&#125;//双链表type DoubleList struct &#123; tail, head *Node&#125;//创建一个双链表func createDL() *DoubleList &#123; head, tail := &amp;Node&#123;&#125;, &amp;Node&#123;&#125; head.next, tail.prev = tail, head return &amp;DoubleList&#123; tail: tail, head: head, &#125;&#125;func (this *DoubleList) IsEmpty() bool &#123; return this.head.next == this.tail&#125;//将node添加为双链表的第一个元素func (this *DoubleList) AddFirst(node *Node) &#123; node.next = this.head.next node.prev = this.head this.head.next.prev = node this.head.next = node&#125;func (this *DoubleList) RemoveNode(node *Node) &#123; node.next.prev = node.prev node.prev.next = node.next node.next = nil node.prev = nil&#125;func (this *DoubleList) RemoveLast() *Node &#123; if this.IsEmpty() &#123; return nil &#125; lastNode := this.tail.prev this.RemoveNode(lastNode) return lastNode&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://elihe2011.github.io/tags/algorithm/"}]},{"title":"Go 遍历树","slug":"Go 遍历树","date":"2020-01-09T02:51:19.000Z","updated":"2021-06-22T10:50:49.747Z","comments":true,"path":"2020/01/09/Go 遍历树/","link":"","permalink":"https://elihe2011.github.io/2020/01/09/Go%20%E9%81%8D%E5%8E%86%E6%A0%91/","excerpt":"1. 二叉树遍历123456789101112 1 / \\ 2 3 / \\ / \\4 5 6 7 / \\ 8 9前序输出: 1 2 4 5 3 6 8 9 7中序输出: 4 2 5 1 8 6 9 3 7后序输出: 4 5 2 8 9 6 7 3 1层序输出: 1 2 3 4 5 6 7 8 9","text":"1. 二叉树遍历123456789101112 1 / \\ 2 3 / \\ / \\4 5 6 7 / \\ 8 9前序输出: 1 2 4 5 3 6 8 9 7中序输出: 4 2 5 1 8 6 9 3 7后序输出: 4 5 2 8 9 6 7 3 1层序输出: 1 2 3 4 5 6 7 8 9 2. 实现代码2.1 构建二叉树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051type Tree struct &#123; Val int Left *Tree Right *Tree IsRoot bool&#125;var root = &amp;Tree&#123; Val: 1, Left: node2, Right: node3, IsRoot: true,&#125;var node2 = &amp;Tree&#123; Val: 2, Left: node4, Right: node5,&#125;var node3 = &amp;Tree&#123; Val: 3, Left: node6, Right: node7,&#125;var node4 = &amp;Tree&#123; Val: 4,&#125;var node5 = &amp;Tree&#123; Val: 5,&#125;var node6 = &amp;Tree&#123; Val: 6, Left: node8, Right: node9,&#125;var node7 = &amp;Tree&#123; Val: 7,&#125;var node8 = &amp;Tree&#123; Val: 8,&#125;var node9 = &amp;Tree&#123; Val: 9,&#125; 2.2 前序遍历123456789func preorder(t *Tree) &#123; if t == nil &#123; return &#125; fmt.Printf(&quot;%d, &quot;, t.Val) preorder(t.Left) preorder(t.Right)&#125; 2.3 中序遍历123456789func inorder(t *Tree) &#123; if t == nil &#123; return &#125; inorder(t.Left) fmt.Printf(&quot;%d, &quot;, t.Val) inorder(t.Right)&#125; 2.4 后序遍历123456789func postorder(t *Tree) &#123; if t == nil &#123; return &#125; postorder(t.Left) postorder(t.Right) fmt.Printf(&quot;%d, &quot;, t.Val)&#125; 2.5 层序遍历先将二叉树改造为队列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type Queue struct &#123; Val []*Tree Length int&#125;func (q *Queue) Push(t *Tree) &#123; q.Val = append(q.Val, t)&#125;func (q *Queue) Pop() *Tree &#123; len := q.Len() if len == 0 &#123; panic(&quot;Queue is empty&quot;) &#125; node := q.Val[0] if len == 1 &#123; q.Val = []*Tree&#123;&#125; &#125; else &#123; q.Val = q.Val[1:] &#125; return node&#125;func (q *Queue) Len() int &#123; q.Length = len(q.Val) return q.Length&#125;func levelorder(t *Tree) &#123; queue := Queue&#123;&#125; queue.Push(root) for queue.Len() &gt; 0 &#123; node := queue.Pop() if node == nil &#123; panic(&quot;node is nil&quot;) &#125; if node.IsRoot &#123; fmt.Printf(&quot;%d, &quot;, node.Val) &#125; if node.Left != nil &#123; fmt.Printf(&quot;%d, &quot;, node.Left.Val) queue.Push(node.Left) &#125; if node.Right != nil &#123; fmt.Printf(&quot;%d, &quot;, node.Right.Val) queue.Push(node.Right) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://elihe2011.github.io/tags/algorithm/"}]},{"title":"Go Etcd","slug":"Go Etcd","date":"2020-01-03T06:26:16.000Z","updated":"2021-06-22T10:50:49.747Z","comments":true,"path":"2020/01/03/Go Etcd/","link":"","permalink":"https://elihe2011.github.io/2020/01/03/Go%20Etcd/","excerpt":"","text":"1. etcd 介绍概念：高可用的分布式key-value存储，可用于配置共享和服务发现 类似项目：zookeeper 和 consul 接口：提供restful的http接口，使用简单 实现算法：基于raft算法的强一致性、高可用的服务存储目录 应用场景: 服务注册与发现 配置中心 分布式锁 master选举 2. etcd 安装 (docker)1234567891011121314151617181920212223242526272829303132333435$ docker pull gcr.io/etcd-development/etcd:v3.4.13 $ rm -rf /tmp/etcd-data.tmp &amp;&amp; mkdir -p /tmp/etcd-data.tmp$ docker run \\ -p 2379:2379 \\ -p 2380:2380 \\ --mount type=bind,source=/tmp/etcd-data.tmp,destination=/etcd-data \\ --name etcd-gcr-v3.4.13 \\ --detach gcr.io/etcd-development/etcd:v3.4.13 \\ /usr/local/bin/etcd \\ --name s1 \\ --data-dir /etcd-data \\ --listen-client-urls http://0.0.0.0:2379 \\ --advertise-client-urls http://0.0.0.0:2379 \\ --listen-peer-urls http://0.0.0.0:2380 \\ --initial-advertise-peer-urls http://0.0.0.0:2380 \\ --initial-cluster s1=http://0.0.0.0:2380 \\ --initial-cluster-token tkn \\ --initial-cluster-state new \\ --log-level info \\ --logger zap \\ --log-outputs stderr $ docker exec -it etcd-gcr-v3.4.13 /bin/sh# etcdctl versionetcdctl version: 3.4.13API version: 3.4# etcdctl endpoint health127.0.0.1:2379 is healthy: successfully committed proposal: took = 29.242978ms# etcdctl put name jackOK# etcdctl get namenamejack 3. etcd 使用3.1 连接 etcd12345678// 客户端配置config := clientv3.Config &#123; Endpoints: []string&#123;&quot;localhost:2379&quot;&#125;, DialTimeout: 5 * time.Second,&#125;// 建立连接cli, err := clientv3.New(config) 3.2 新增或修改数据123456789101112131415func put(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) putResp, err := cli.Put(ctx, &quot;/logagent/conf/&quot;, &quot;sample_value&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(putResp.Header.Revision) if putResp.PrevKv != nil &#123; fmt.Println(&quot;prev Value:&quot;, putResp.PrevKv.Value) fmt.Println(&quot;CreateRevision:&quot;, putResp.PrevKv.CreateRevision) fmt.Println(&quot;ModRevision:&quot;, putResp.PrevKv.ModRevision) fmt.Println(&quot;Version:&quot;, putResp.PrevKv.Version) &#125;&#125; 3.3 获取数据123456789101112func get(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/conf/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125;&#125; 3.4 删除数据12345678910111213141516func del(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) delResp, err := cli.Delete(ctx, &quot;/logagent/conf/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; if len(delResp.PrevKvs) &gt; 0 &#123; for _, ev := range delResp.PrevKvs &#123; fmt.Printf(&quot;Delete %s: %s\\n&quot;, ev.Key, ev.Value) &#125; &#125; fmt.Println(delResp.Deleted)&#125; 3.5 设置租期12345678910111213141516171819202122232425262728293031323334353637func lease(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) leaseGrantResp, err := cli.Grant(ctx, 10) cancel() if err != nil &#123; log.Fatal(err) &#125; leaseId := leaseGrantResp.ID ctx, cancel = context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, &quot;/logagent/ttl/&quot;, &quot;10s&quot;, clientv3.WithLease(leaseId)) cancel() if err != nil &#123; log.Fatal(err) &#125; for &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/ttl/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; if getResp.Count == 0 &#123; fmt.Println(&quot;ttl expire&quot;) break &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125; time.Sleep(2 * time.Second) &#125;&#125; 3.6 延迟租期1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func extentLease(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) leaseGrantResp, err := cli.Grant(ctx, 10) cancel() if err != nil &#123; log.Fatal(err) &#125; leaseId := leaseGrantResp.ID ctx, cancel = context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, &quot;/logagent/ttl/&quot;, &quot;10s&quot;, clientv3.WithLease(leaseId)) cancel() if err != nil &#123; log.Fatal(err) &#125; time.Sleep(5 * time.Second) ctx, cancel = context.WithTimeout(context.Background(), time.Second) leaseKeepAliveResp, err := cli.KeepAlive(ctx, leaseId) if err != nil &#123; log.Fatal(err) &#125; go func() &#123; for &#123; select &#123; case keepResp := &lt;-leaseKeepAliveResp: if keepResp == nil &#123; fmt.Println(&quot;Lease expire&quot;) return &#125; else &#123; fmt.Println(&quot;Receive lease extent resp&quot;) &#125; &#125; &#125; &#125;() ctx, cancel = context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/ttl/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125;&#125; 3.7 watch 功能123456789101112131415161718192021222324252627282930313233343536373839404142434445func watch(cli *clientv3.Client) &#123; kv := clientv3.NewKV(cli) // 模拟KV变化 go func() &#123; for &#123; _, _ = kv.Put(context.TODO(), &quot;/language&quot;, &quot;go&quot;) _, _ = kv.Delete(context.TODO(), &quot;language&quot;) time.Sleep(time.Second) &#125; &#125;() getResp, err := kv.Get(context.TODO(), &quot;language&quot;) if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125; watchStartVersion := getResp.Header.Revision + 1 fmt.Printf(&quot;Start watching from version: %d\\n&quot;, watchStartVersion) watcher := clientv3.NewWatcher(cli) ctx, cancel := context.WithCancel(context.TODO()) time.AfterFunc(5*time.Second, func() &#123; cancel() &#125;) watchRespChan := watcher.Watch(ctx, &quot;language&quot;, clientv3.WithRev(watchStartVersion)) for watchResp := range watchRespChan &#123; for _, event := range watchResp.Events &#123; switch event.Type &#123; case mvccpb.PUT: fmt.Printf(&quot;Modify: %s, %v, %v\\n&quot;, event.Kv.Value, event.Kv.CreateRevision, event.Kv.ModRevision) case mvccpb.DELETE: fmt.Printf(&quot;Delete: %v\\n&quot;, event.Kv.ModRevision) &#125; &#125; &#125;&#125; 1234567891011121314151617181920func main() &#123; cli, err := clientv3.New(clientv3.Config&#123; Endpoints: []string&#123;&quot;localhost:2379&quot;&#125;, DialTimeout: 5 * time.Second, &#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() for &#123; rch := cli.Watch(context.Background(), &quot;/logagent/conf/&quot;) for wresp := range rch &#123; for _, ev := range wresp.Events &#123; fmt.Printf(&quot;%s %q : %q\\n&quot;, ev.Type, ev.Kv.Key, ev.Kv.Value) &#125; &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Linux文本处理","slug":"Linux文本处理","date":"2019-12-19T07:48:58.000Z","updated":"2021-07-13T03:15:37.196Z","comments":true,"path":"2019/12/19/Linux文本处理/","link":"","permalink":"https://elihe2011.github.io/2019/12/19/Linux%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/","excerpt":"","text":"1. find123find PATH -option [-print] [-exec|-ok cmd] &#123;&#125; \\;-print \\n-print0 \\0, NULL 1.1 time123456-atime N-ctime N-mtime N-newer FILE-amin M-mmin M.. 实例： 12345find . -amin -10 # 10分钟内访问的文件find . -mtime -2 # 2天内修改的文件find . -mmin +60 # 60分钟前被修改的文件find /etc -mmin -120 # 两小时内被修改的文件find / -mtime 0 # 将过去24 小时内有改变过内容的文件 1.2 user &amp; group123456-uid n-gid n-user name-group name-nouser-nogroup 实例： 12find /var -uid +1048 # uid大于等于1048find /home -user test 1.3 file12345678910111213141516171819202122232425-name FILENAME-type TYPE （f，b，c，d，l，s，p）-size SIZE-empty-inum n-links NUM-depth sub-diectory first-maxdepth level Decend at most [level] levels of directories below the command-mindepth level Don&#x27;t apply tests or actions at levels less than [level]-xdev 不跨越filesystem -mount unix不支持-fstype TYPE（ext3，proc）-follow dereference symbolic links-L-prune Ignore directory or file-perm MODE 许可位正好是MODE-perm -MODE 许可位完全符合MODE-perm +MODE 许可位部分符合MODE， 老式写法/MODE 实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657find . -maxdepth 1 find . -maxdepth 2 find . -mindepth 4 find . -mindepth 2 -maxdepth 3find . -path ./.svnfind . -path /var/log -prune -o -print find . \\(-path /var/log -o -path /var/spool \\) -prune -o -print find . -size 1000 # 1000 blocks, 1Block=512Bytesfind . -size +70Mfind . -size 20c # 20 bytesfind . -size +10M -a -size -20Mfind . -empty # 空文件或空目录find . -links +2 # 链接数超过2find /mnt -name a.txt -fstype vfatfind / ！-fstype proc &#x27;(&#x27; -name &#x27;.??*&#x27; -o -name &#x27;.[^.]&#x27; &#x27;)&#x27;find / -perm 664 # 权限精确等于664find / -perm -664 # 权限完全满足664，但可包含额外权限，665，777find / -perm +664 # 权限部分满足664，例如660和600find . -perm -007 # others用户具有rwx权限find . -perm -100 # 属主至少具有x权限特殊权限SGID，SUID，SBIT(---s--s--t)find . -perm +7000 # 至少具有一个特殊权限位find . -perm -7000 # 具有全部特殊权位# 删除7天内未被读取的core文件，只涉及/所在的文件系统(-xdev)find / -xdev -type f &#x27;(&#x27; -name core -o name &#x27;core.[0-9]*&#x27; &#x27;)&#x27; -atime +7 -exec rm -f &#123;&#125; &#x27;;&#x27; # 删除那些用#, .#或.nfs开头，或者以~及。CKP结尾且3天内都未被访问过的文件find / -xdev -atime +3 &#x27;(&#x27; -name &#x27;#*&#x27; -o -name &#x27;.#*&#x27; -o -name &#x27;*.CKP&#x27;, -o -name &#x27;*~&#x27;, -o -name &#x27;.nfs*&#x27; &#x27;)&#x27; -exec rm -f &#123; &#125; &#x27;;&#x27;# 删除/tmp下载72小时内未被修的所有子目录cd /tmp; find . ! -name . ! -name lost+found -type d -mtime +3 -exec /bin/rm -rf &#123;&#125; \\;# 嵌入时间BACKUPFILE=backup-$(date +%m-%d-%Y)# 备份一天前的文件, 缺陷：发现太多的文件或文件名包含空格，执行失败tar cvf - `find . -mtime -1 -type f -print` &gt; $archive.tar# 改进型，GNU版本的find, this one is more betterfind . -mtime -1 -type f -print0 | xargs -0 tar rvf &quot;$archive.tar&quot;# 改进型，Unix风格的find，较慢find . -mtime -1 -type f -exec tar rvf &quot;$archive.tar&quot; &#123;&#125; \\; # remove file or directory it contains special charactersls -ilfind . -inum inode_num -exec rm -rf &#123;&#125; \\; 2. xargs可读入stdin的数据，并且以空格或换行符做分割，将stdin分割成arguments 1.1 选项说明1234567891011121314151617181920212223242526272829303132333435363738391) terminated by a null character, every character is taken literally, (`, \\, whitespace)--null-0 2) terminated by the specified character--delimiter=delim -d delim 3) use at most max-lines nonblank input lines per command line--max-lines[=max-lines]-l[max-lines] 4) use at most max-args arguments per command line.--max-args=max-args-n max-args 5) replace occurrences of replace-str(&#123;&#125; by default) in the initial-arguments with names read from standard input-I replace-str--replace[=replace-str]-i[replace-str] .6) a placeholder for output text&#123;&#125; 7) run up to max-procs processes at a time; 1 by default; 0: run as many as possible--max-procs=max-procs-P max-procs8) set the end of file string to EOF--eof=[EOF]-e[EOF] 9) prompt--interactive-p10) print the command line on the standard error output before executing it.--verbose-t 2.2 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768find -print0 | xargs -0# 单行输出cat a.txt | xargs# 每行3个参数cat a.txt | xargs -n3 # list files in 8 columnls | xargs -n 8 echo# 前3个用户活动情况cut -d&quot;:&quot; -f1 /etc/passwd | head -n 3 | xargs -p fingercut -d&quot;:&quot; -f1 /etc/passwd | xargs -p -e&quot;lp&quot; finger# 文件名含空格等find /home -size +1M -print0 | xargs -0 ls -l# core文件列表find / -name &quot;core&quot; -print | xargs echo &quot;&quot; &gt; core.log# 清除other组的可执行权限find . -perm -7 -print | xargs chmod o-x# 多文件过滤find . -name \\* -type f | xargs grep &quot;abc&quot;# 定界符echo &quot;aXbXc&quot; | xargs -dX# 拷贝整个目录ls | xargs -i -t cp ./&#123;&#125; /tmp/eli# 杀掉所有mysql进程ps ax | grep mysql | awk &#x27;&#123;print $1&#125;&#x27; | xargs -i kill &#123;&#125;# 参数-I和-icat a.shecho $*cat args.txtaaabbbccccat args.txt | xargs -I &#123;&#125; ./a.sh -p &#123;&#125; -l-p aaa -l-p bbb -l-p ccc -lcat args.txt | xargs -i ./a.sh -p &#123;&#125; -lcat args.txt | xargs -I % ./a.sh -p % -l# 逐一拷贝图片ls *.jpg | xargs -n 1 -i cp &#123;&#125; /home/images# 压缩文件，每次一个ls | xargs -p -l gzip# to handle arguments containing whitespace or quotesfind / -type f -print0 | xargs -0 grep -liwZ GUI | xargs -0 rm -f# 开启两个处理进程，每次压缩一个文件ls *.txt | xargs -t -n1 -P2 gzip# grep输出的文件名以\\0结尾grep -lZ &#x27;abc&#x27; &quot;*.txt&quot; | xargs -0 3. sedsed, stream editor , 按顺序逐行方式工作 i. 从输入读取一行数据存入临时缓冲区，即模式空间(pattern space) ii. 按指定的sed编辑命令处理缓冲区中的内容 iii. 把模式空间的内容送往屏幕，并将此行内容从模式空间中删除 iv. 读取下一行，重复上述过程直至全部处理 模式空间(pattern space) 保留空间(hold space) 3.1 参数说明123456sed [OPTION] [-e] cmd1 [[-e cmd2] [-e cmd3] ... [-e cmdn]] [input-file]sed [OPTION] -f script-file [input-file]-n 不打印模式空间-r 使用E-REGEX-i 直接修改文件 3.2 Address1234567811,1001,+5 &lt;=&gt; 1,65,10!1~2 &lt;=&gt;1,3,5/pattern//pattern1/,/pattern2/ 3.3 Command123456789101112131415161718d 从pattern space删除所有行D 从pattern space删除第一行p 打印pattern space中所有行P 打印pattern space中的第一行sed &#x27;3,$d&#x27; sed &#x27;/line/&#x27;d sed -n &#x27;$p&#x27;# delete spaces in front of each rowsed &#x27;s/^[ ]*/g&#x27; sed &#x27;s/^ */g&#x27; sed &#x27;s/^[[:space:]]*//g # grep &#x27;pattern&#x27;sed -n &#x27;/pattern/p&#x27;sed &#x27;/pattern/!d&#x27; 123456789101112r file 读取文件，将文件内容追加到匹配行w file 将匹配行写入文件a\\string 行后面追加一行文本i\\string 行前面插入一行文本s/pattern/string/ 用string替换pattern sed &#x27;s/abc/123/g&#x27; sed &#x27;s#\\(abc\\)defg#\\1#&#x27; sed &#x27;s/2/*/8&#x27; # 第8个&quot;2&quot;替换为&quot;*&quot; 123456789101112131415161718192021222324252627282930313233h cat pattern-space &gt; hold-spaceH cat &quot;\\n&quot;pattern-space &gt;&gt; hold-spaceg cat hold-space &gt; pattern-spaceG cat &quot;\\n&quot;hold-space &gt;&gt; pattern-spacex exchange hold-space with pattern-space! no actions # tac sed &#x27;1!G;h;$!d&#x27; # 新增空行 sed G # 多个空行变一个 sed &#x27;/^$/d;G&#x27; # add a blank line before the matching one sed &#x27;/python/&#123;x;p;x&#125;&#x27; # add a blank line after the matching one sed &#x27;/python/G&#x27; # add a blank line before and after the matching one sed &#x27;/python/&#123;x;p;x;G&#125;&#x27; # 匹配行的前一行 sed -n &#x27;/python/&#123;g;1!p&#125;;h&#x27; # 先h, 将ps保存至hs; 当匹配时，g使用hs替换ps, 如果不是第一行，则打印 # 匹配行的后一行 sed -n &#x27;/python/&#123;n;p&#125;&#x27; 123456789n 读取下一行至pattern space，此时pattern space有2行，后续命令，只操作n读入的行N 读取下一行至pattern space，但将当前读入行和N命令读入的下一行看成“一行&quot; # 匹配行的后一行，做替换操作 sed &#x27;/python/&#123;n;s/job/task/&#125;&#x27; # 删除偶数行 sed &#x27;n;d&#x27; sed -n &#x27;1~2p&#x27; 12y 与tr类似，字符替换 sed &#x27;1y/abcdef/ABCDEF/&#x27; 123= 打印行号 sed -n &#x27;/python/=&#x27; sed -n &#x27;$=&#x27; 1234567891011q 退出 # head -2 sed 2q # tail -2 sed &#x27;$!N;$!D&#x27; # tail -1 sed -e :a -e &#x27;$q;N;2,$D;ba&#x27; sed &#x27;$!d&#x27; sed -n &#x27;$p&#x27; 3.4 实例 1234567891011121314151617181920212223242526272829303132333435# replace Unix to Unix/Linuxsed -e &#x27;s#Unix#&amp;/Linux#g&#x27;# squeeze continuous c to single csed &#x27;s/cc*/c/g&#x27;# delete space at head of linesed &#x27;s/^[ \\t]*//&#x27;# delete dot at end of linesed &#x27;s/\\.$//g&#x27; # delete first character each linesed &#x27;s/.//g&#x27; # delete space at end of linesed &#x27;s/ *$//g&#x27; # insert two space before head each linesed &#x27;s/^/ /g&#x27; # remove punctuation(. , ? !)sed &#x27;s/\\.//g&#x27; -e &#x27;s/\\,//g&#x27; -e &#x27;s/\\?//g&#x27; -e &#x27;s/\\!//g&#x27;# more effectivesed &#x27;s/foo/bar/g&#x27; sed &#x27;/foo/ s/foo/bar/g&#x27; sed &#x27;/foo/ s//bar/g&#x27; # only replacement once, use &#x27;q&#x27;sed &#x27;s/foo/ s/foo/bar/;q&#125;&#x27; # delete blank linessed &#x27;/^$/d&#x27; sed &#x27;/./!d&#x27; 4. awk1234567891011awk [options] &#x27;BEGIN&#123;action&#125;pattern&#123;action&#125;...END&#123;action&#125;&#x27; fileawk [options] -f program.awk fileoptions:-F fs use fs for the input field separator-v val=val assign the value to the variable var, before execution of the program begins.pattern:/regex/: extended regular expressionrelational expression: if..else.. pattern1, pattern2: pattern range 4.1 Built-in Variables:123456789101112131415161718192021222324252627282930313233343536373839401. NF, NRNF The number of fieldsNR The total number of input records seen so far2. FS, RS, OFS, ORSFS The input field separator, a space by defaultRS The input record separator, by default a newlineOFS The output field separator, a space by defaultORS The output record separator, by default a newline3. IGNORECASE Not case-sensitivity4. ENVIRON# awk &#x27;BEGIN&#123;for(i in ENVIRON) print i, ENVIRON[i]&#125;&#x27;# awk &#x27;BEGIN&#123;print ENVIRON[&quot;JAVA_HOME&quot;]&#125;&#x27;5. ARGC, ARGV, ARGINDARGC: the number of argumentsARGIND: the index in ARGV of the current file being processedARGV: Array of arguments# awk &#x27;BEGIN&#123;print &quot;ARGC=&quot;ARGC; for(i in ARGV) print i&quot;=&quot;ARGV[i]&#125;&#x27; /etc/passwdARGC=2, 0=awk, 1=/etc/passwd 6. FILENAME : the name of the current input file# awk &#x27;BEGIN&#123;print FILENAME&#125;&#123;print FILENAME; exit&#125;&#x27;7. OFMT : number output format &quot;.6g&quot;# awk &#x27;BEGIN&#123;printf(&quot;%.2f %.2f\\n&quot;, 1/6, 3.1415926)&#125;&#x27;# awk &#x27;BEGIN&#123;OFMT=&quot;%.2f&quot;; print 1/6, 3.1415926)&#125;&#x27;8. FIELDWIDTH : set fields by fixed width# date +&quot;%Y%m%d%H%M%S&quot; | awk &#x27;BEGIN&#123;FIELDWIDTH=&quot;4 2 2 2 2 2&quot;&#125;&#123;print $1&quot;-&quot;$2&quot;-&quot;$3, $4&quot;:&quot;$5&quot;:&quot;$6&#125;&#x27;9. RSTART, RLENGTHRSTART: the index of the first character matched by match(), 0RLENGTH: the length of the string matched by matched by match(), -1# awk &#x27;BEGIN&#123;start=match(&quot;this is match test&quot;, /m[a-z]+/); print start, RSTART, RLENGTH&#125;&#x27;9 9 5 4.2 Built-in Functions:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611. Numericint(x)sqrt(x)rand(): return a random number, [0-1)srand([expr]): use expr as a seed for random generator, if not provided, use system current time# awk &#x27;BEGIN&#123;print int(2.3), int(012), int(0xFF), int(3a), int(a3)&#125;&#x27; 2 10 255 3 0# awk &#x27;BEGIN&#123;print rand(), 10*rand()&#125;&#x27;# awk &#x27;BEGIN&#123;srand(); print rand(), 10*rand()&#125;&#x27;2. Stringsub(regex, replacement[, target]): use the replacement to replace the regex matched in string target(by default $0)gsub(regex, replacement[, target]): global subgensub(regex, replacement, how[, target]): gawkgensub(regex, replacement, &quot;g|G&quot; target) =&gt; gsubgensub(regex, replacement, 0, target) =&gt; gsub, but with warninggensub(regex, replacement, N, target) =&gt; N is a digit from 1 to 9, index of the matched sub-expression# awk &#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;; gsub(/[0-9]+/,info); print info&#125;&#x27;# gawk &#x27;BEGIN&#123;a=&quot;abc def&quot;; b=gensub(/(.+) (.+)/, &quot;\\\\2 \\\\1&quot;, &quot;g&quot;, a); print b&#125;&#x27; def abc# echo &quot;a b c a b c&quot; | gawk &#x27;&#123;print gensub(/a/,&quot;AA&quot;,2)&#125;&#x27; a b c AA b cindex(string, find): index of the find in the string, or 0 if not presentmatch(string, regex[, array]): position of the regex occurring in the stringlength([string])substr(string, position[, len])split(string, array[, regexp]): split the string into the array on the regex# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print index(s, &quot;a&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print index(s, &quot;a&quot;) ? &quot;ok&quot; : :no found&quot;&#125;&#x27;# awk &#x27;BEGIN&#123;s=&quot;this is a match test&quot;; pos=match(s, /m[a-z]+/, array); print pos; for(i in array) print i, array[i]&#125;&#x27;110start 110length 50 match# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print substr(s, 9, 1)&#125;&#x27;a# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print substr(s, 9)&#125;&#x27;a test# awk &#x27;BEGIN&#123;s=&quot;this is a split test&quot;; len=split(s,array); print len; for(i in array) print i, array[i]&#125;&#x27;54 split5 test1 this2 is3 a# awk &#x27;BEGIN&#123;FS=&quot;:&quot;&#125;/^root/&#123;split($0,array); for(i in array) print i, array[i]&#125;&#x27; /etc/passwd# awk &#x27;/^root/&#123;split($0,array,/:/); for(i in array) print i, array[i]&#125;&#x27; /etc/passwd4 05 root6 /root7 /bin/bash1 root2 x3 0Associative Arraysa. sorting by valueslen = asort(s) # s: changed, the indexes are replaced with sequential integerslen = asort(s, d) # s: unchanged; d: a sorted duplicate array of sb. sorting by indexeslen = asorti(s) # s: changed, restorted by indexeslen = asorti(s, d) # s: unchanged; d: a new array of sorted indexes# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i in a) print i, a[i]&#125;&#x27; abc.txt10 3512 3022 1324 20# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i=1;i&lt;=asort(a,b);i++) print i, b[i]&#125;&#x27; abc.txt1 132 203 304 40# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i=1;i&lt;=asorti(a,b);i++) print i, b[i]&#125;&#x27; abc.txt1 102 123 224 24sprintf(format, expr): return the printed expr according to the formattolower(string)toupper(string)# awk &#x27;BEGIN&#123;s=sprintf(&quot;%.2g %s %d&quot;, 3.1415926, 3.1415926, 3.1415926); print s&#125;&#x27;3.1 3.14159 33. Timemktime(&quot;YYYY MM DD HH MM SS[ DST]&quot;): return a time stampsystime(): return current time stmapstrftime([format[, ts])# awk &#x27;BEGIN&#123;print mktime(&quot;2014 12 20 14 25 32&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;print systime()&#125;&#x27;# awk &#x27;BEGIN&#123;print strftime()&#125;&#x27;# awk &#x27;BEGIN&#123;print strftime(&quot;%c&quot;, systime())&#125;&#x27; # date +%c4. IOclose(file[, how]): close file, pipe or co-process; how is either &quot;from&quot; or &quot;to&quot;getline set $0 from next input record, set NF, NR, FNRgetline &lt;file set $0 from next record of file, set NFgetline var set var from next input record, set NR, FNRgetline var &lt;file set vat from next record of filecommand | getline [var] run command piping the output either into $0 or varcommand | &amp; getline [var] run command as a co-process piping the output either into $0 or var. co-processes are a gawk extensionnext: stop processing the current input recordprint [expr-list [&gt;file] ]printf [format, expr-list [&gt;file] ]system(&quot;cmd&quot;) execute the command, and return the exit statusfflush([file]) flush any buffersprint ... | command write on a pipeprint ... |&amp; command write on a co-process# awk &#x27;BEGIN&#123;while(&quot;cat /etc/passwd&quot; | getline) print; close(&quot;/etc/passwd&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;while(getline &lt;&quot;/etc/passwd&quot;) print; close(&quot;/etc/passwd&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;&quot;date&quot; | getline d; print d&#125;&#x27;# awk &#x27;BEGIN&#123;&quot;date&quot; | getline d; split(d,mon); print mon[2]&#125;&#x27;# awk &#x27;BEGIN&#123;while(&quot;ls&quot; | getline) print&#125;&#x27;# awk &#x27;BEGIN&#123;printf(&quot;Enter your account: &quot;); getline name; print name&#125;&#x27;awk &#x27;BEGIN&#123;l=system(&quot;ls -l&quot;); print l&#125;&#x27;// prompting, wait for input# awk &#x27;BEGIN&#123;printf &quot;What is your name? &quot;; getline name &lt;&quot;/dev/tty&quot;&#125; $1~name &#123;print &quot;Found&quot; name &quot;on line &quot;, NR&quot;.&#125; END&#123;print &quot;See you,&quot; name &quot;.&quot;&#125;&#x27; /etc/passwd// count number of file# awk &#x27;BEGIN&#123;while(getline &lt;&quot;/etc/passwd&quot; &gt;0) lc++; print lc&#125;// sort# awk &#x27;&#123;print $1, $2 | &quot;sort&quot;&#125; END&#123;close(&quot;sort)&#125;&#x27; abc.txt 4.3 FILE SPACING:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# insert a blank lineawk &#x27;1; &#123;print &quot;&quot;&#125;&#x27;awk &#x27;BEGIN&#123;ORS=&quot;\\n\\n&quot;&#125;; 1&#x27;# insert two blank linesawk &#x27;1;&#123;print &quot;\\n&quot;&#125;NUMBERING AND CALCULATIONS:# using a TAB instead of space will perserve marginsawk &#x27;&#123;print FNR &quot;\\t&quot; $0&#125;&#x27;awk &#x27;&#123;print NR &quot;\\t&quot; $0&#125;&#x27;# number each line of a fileawk &#x27;&#123;printf(&quot;%5d : %s\\n, NR, $0)&#125;&#x27;# number each line of a file, but only print numbers if line is not blankawk &#x27;NF&#123;$0=++a &quot;:&quot; $0&#125;;&#123;print&#125;&#x27;awk &#x27;&#123;print (NF ? ++a &quot;:&quot; : &quot;&quot;) $0&#125;&#x27;# wc -lawk &#x27;END&#123;print NR&#125;&#x27;# wc -wawk &#x27;&#123;total=total+NF&#125;END&#123;print total&#125;&#x27;# print the sum of the fields of every lineawk &#x27;&#123;s=0; for(i=1;i&lt;=NF;i++) s=s+$i; print s&#125;&#x27;# add all fields in all lines and print the sumawk &#x27;&#123;for(i=1;i&lt;=NF;i++) s=s+$i&#125;END&#123;print s&#125;&#x27;# print absolute value of fieldsawk &#x27;&#123;for(i=1;i&lt;=NF;i++) if($i&lt;0) $i=-$i; print&#125;&#x27;awk &#x27;(for(i=1;i&lt;=NF;i++) $i = ($i&lt;0) ? -$i : $i; print&#125;&#x27;# print the total number of lines that contains &quot;Beth&quot;awk &#x27;/Beth/&#123;n++&#125;; END&#123;print n+0&#125;&#x27;# print the largest first fieldawk &#x27;$1&gt;max&#123;max=$1; maxline=$0&#125;; END&#123;print max, maxline&#125;&#x27;# print the last fieldawk &#x27;&#123;print $NF&#125;&#x27;# print the last field of the last lineawk &#x27;&#123;field=$NF&#125;; END&#123;print feild&#125;&#x27;TEXT CONVERSION AND SUBSTITUTION:# dos2unixawk &#x27;&#123;sub(/\\r$/,&quot;&quot;); print&#125;&#x27;# unix2dosawk &#x27;&#123;sub(/$/,&quot;\\r&quot;); print&#125;&#x27;# delete leading whitespaceawk &#x27;&#123;sub(/^[ \\t]+/,&quot;&quot;); print&#125;&#x27;# delete trailing whitespaceawk &#x27;&#123;sub(/[ \\t]+$/,&quot;&quot;); print&#125;&#x27;# delete both leading and trailing whitespaceawk &#x27;&#123;sub(/^[ \\t]+|[ \\t]+$/); print&#125;&#x27;# insert 5 whitespace at the beginning of lineawk &#x27;&#123;sub/^/, &quot; &quot;); print&#125;&#x27;# align all text flush right in a 70-column widthawk &#x27;&#123;printf &quot;%79s\\n&quot;, $0&#125;&#x27;# center all text on a 79-character widthawk &#x27;&#123;l=length(); s=int((79-l)/2); printf &quot;%&quot;(s+l&#125;&quot;s\\n&quot;,$0&#125;&#x27;# substituteawk &#x27;&#123;sub(/foo/,&quot;bar&quot;); print&#125;&#x27; # 1stawk &#x27;&#123;$0=gensub(/foo/,&quot;bar&quot;,4); print&#125;&#x27; # 4stawk &#x27;&#123;gsub(/foo/,&quot;bar&quot;); print&#125;&#x27; # all#awk &#x27;&#123;gsub(/scarlet|ruby|puce/, &quot;red&quot;); print&#125;# tacawk &#x27;&#123;a[i++]=$0&#125;END&#123;for(j=i-1;i&gt;=0;j--) print a[j]&#125;# append the next line, if line ends with a backslash.(fails to handle mutiple lines ending with backslash)awk &#x27;/\\\\$/&#123;sub(/\\\\$/,&quot;&quot;); getline t; print $0 t; next&#125;; 1&#x27;# sortawk -F&quot;:&quot; &#x27;&#123;print $1 | &quot;sort&quot;&#125;&#x27; /etc/passwd# delete the 2nd fieldawk &#x27;&#123;$2=&quot;&quot;; print&#125;&#x27;# print in reverse order the fieldsawk &#x27;&#123;for(i=NF;i&gt;0;i--) printf(&quot;%s &quot;,i); print &quot;&quot;&#125;&#x27;# remove duplicate, consecutive lines, uniqawk &#x27;a!~$0; &#123;a=$0&#125;&#x27;# remove duplicate, nonconsecutive linesawk &#x27;!a[$0]++&#x27;awk &#x27;!($0 in a)&#123;a[$0]; print&#125;&#x27; # most efficient# concatenate every 5 lines of input, using a comma separatorawk &#x27;ORS=%NR%5 ? &quot;,&quot; : &quot;\\n&quot;&#x27; 4.4 SLECTIVE PRINTING OF CERTAIN LINES:12345678910111213141516171819202122232425262728293031323334353637383940# headawk &#x27;NR&lt;11&#x27;# head -1awk &#x27;NR&gt;1&#123;exit&#125;;1&#x27;# tail -2awk &#x27;&#123;y=x &quot;\\n&quot; $0; x=$0&#125; END&#123;print y&#125;&#x27;# tail -1awk &#x27;END&#123;print&#125;&#x27;# grepawk &#x27;/regex/&#x27;# print the line immediately before a regexawk &#x27;/regex/&#123;print x&#125;;&#123;x=$0&#125;&#x27; # grep &#x27;regex&#x27; -B1# print the line immediately after a regexawk &#x27;/regex/&#123;getline; print&#125;&#x27; # grep &#x27;regex&#x27; -A1# grep -E &quot;AAA|BBB|CCC&quot;awk &#x27;/AAA/;/BBB/;/CCC/&#x27;# print only lines of 65 characters or longerawk &#x27;length&gt;64&#x27;# print section of file from regular expression to end of fileawk &#x27;/regex/,0&#x27;awk &#x27;/regex/,EOF&#x27;# print section of file based on line numbers(lines 8-12)awk&#x27;NR==8,NR==12&#x27;# print line 8 &amp; 12awk &#x27;NR==8;NR==12&#x27;# print line number 52awk &#x27;NR==52&#x27;awk &#x27;NR==52&#123;print; exit&#125;&#x27; # more efficient 4.5 SELECTIVE DELETION OF CERTAIN LINES:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# delete all blank linesawk NFawk &#x27;/./&#x27;# print x by 512 timesawk &#x27;BEGIN&#123;while(++a&lt;512) s=s &quot;x&quot;; print s&#125;&#x27;# merge fileawk &#x27;NR==FNR&#123;a[$0]=1; print&#125; NR&gt;FNR&#123;if(!a[$0]) print&#125;&#x27;awk &#x27;&#123;a[$0]&#125;END&#123;for(i in a) print i&#125;&#x27;# sortawk &#x27;&#123;a[j++]=$0&#125; END&#123;len=asort(a); for(i=1;i&lt;=len;i++) print a[i]&#125;&#x27;44. convert DEC to OTCecho 37 | awk &#x27;&#123;printf &quot;%o\\n&quot;, $0&#125;&#x27;45. print single quotaawk &#x27;BEGIN&#123;print &quot;\\0472004-12-12\\047&quot;&#125;&#x27;# obtain total memorycat /proc/meminfo | grep -i memtotal | awk -F&#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27;cat /proc/meminfo | grep -i memtotal | awk -F\\: &#x27;&#123;print $2&#125;&#x27;# display all NICs exclude localifconfig -a | grep &#x27;^\\w&#x27; | awk &#x27;!/lo/&#123;print $1&#125;&#x27;# obtain IP address of NIC eth0ifconfig eth0 | grep &#x27;inet &#x27;ifconfig eth0 | grep &#x27;inet &#x27; | awk -F&#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27; | awk &#x27;&#123;print $1&#125;&#x27;ifconfig eth0 | grep &#x27;inet &#x27; | tr &#x27;:&#x27; &#x27; &#x27; | awk &#x27;&#123;print $3&#125;&#x27;ifconfig eth0 | awk -F&#x27;:&#x27; &#x27;/inet / &#123;print $2&#125;&#x27; | awk &#x27;&#123;print $1&#125;&#x27;# $1 is a space, cause it begins with spacesifconfig eth0 | grep &#x27;inet &#x27; | awk -F&#x27;[ :]+&#x27; &#x27;&#123;print $4&#125;&#x27; # kill all process named fookill `ps -ax | grep &#x27;foo&#x27; | grep -v &#x27;grep&#x27; | awk &#x27;&#123;print $1&#125;&#x27;`# print the result that executed command &quot;date&quot;awk &#x27;BEGIN&#123;&quot;date&quot; | getline d;print d&#125;&#x27;# print monthawk &#x27;BEGIN&#123;&quot;date&quot; | getline d; split(d, mon); print mon[2]&#125;&#x27;# print the result that executed comand &quot;ls&quot;awk &#x27;BEGIN&#123;while(&quot;ls&quot; | getline) print&#125;&#x27;# prompting, wait for inputawk &#x27;BEGIN&#123;printf &quot;What is your name? &quot;; getline name &lt;&quot;/dev/tty&quot; &#125; $1~name &#123;print &quot;Found &quot; name &quot; on line &quot;, NR&quot;.&quot;&#125; END&#123;print &quot;See you,&quot; name &quot;.&quot;&#125;&#x27; /etc/passwd# count number of linux usersawk &#x27;BEGIN&#123;while(getline&lt;&quot;/etc/passwd&quot; &gt;0) lc++; print lc&#125;&#x27; # must be contain quotationsawk &#x27;&#123;print $1, $2 | &quot;sort&quot; &#125;END&#123;close(&quot;sort&quot;)&#125;&#x27; myfileawk &#x27;BEGIN&#123;system(&quot;clear&quot;)&#125;&#x27;awk &#x27;&#123;gsub(/test/, &quot;xxxx&quot;, $2); print&#125;&#x27; myfileawk &#x27;BEGIN&#123;print index(&quot;mytest&quot;, &quot;test&quot;)&#125;&#x27; # 3# 多维数组，array[index1,index2,……] ，SUBSEP是数组下标分割符，默认为 &quot;\\034&quot;awk &#x27;BEGIN&#123;SUBSEP=&quot;:&quot;; array[&quot;a&quot;,&quot;b&quot;]=1; for(i in array) print i&#125;&#x27;awk &#x27;BEGIN&#123;array[&quot;a&quot;&quot;:&quot;&quot;b&quot;]=1;for(i in array) print i&#125;&#x27;# cat file1g1.1 2g2.2 4g2.1 5g4.1 3# cat file2g1.1 2g1.2 3g4.1 4# cat file3g1.2 3g5.1 3# awk &#x27;&#123;a[ARGIND&quot; &quot;$1]=$2; b[$1]&#125; END &#123; for(i in b) &#123; printf i&quot; &quot;; for(j=1;j&lt;=ARGIND;j++) printf &quot;%s &quot;, a[j&quot; &quot;i] ? a[j&quot; &quot;i] : &quot;-&quot;; print &quot;&quot;; &#125; &#125;&#x27; file1 file2 file3g2.2 4 - -g5.1 - - 3g1.1 2 2 -g1.2 - 3 3g4.1 3 4 -g2.1 5 - - echo &quot;37&quot; |awk &#x27;&#123;printf &quot;%o\\n&quot;,$0&#125;&#x27;/home/lee#awk &#x27;BEGIN&#123;print &quot;\\0472004-12-12\\047&quot;&#125;&#x27;&#x27;2004-12-12&#x27; 5. chatrr123chattr +i /etc/passwdchatrr +a /etc/passwdlsattr /etc/passwd 6. grep1234567891011121314151617181920212223242526# 网卡信息dmesg | grep -n --color=auto eth# 显示关键字前3行和后2行dmesg | grep -n -A2 -B3 --color=always eth0# 扩展表达式egrep &#x27;^$|^#&#x27;myfile# 前面的字符出现1次以上egrep -n --color=auto &#x27;go+d&#x27; myfile# 前面的字符出现0~1次egrep -n --color=auto &#x27;go?d&#x27; myfile# or方式匹配egrep -n --color=auto &#x27;gd|good|dog&#x27; myfile# 组匹配egrep -n --color=auto &#x27;g(la|oo)d&#x27; myfile# 多重复组匹配echo &#x27;AxyzxyzxyzxyzC&#x27; | egrep &#x27;A(xyz)+C&#x27;man grep | col -c &gt; grep.txt 7. sort123456789101112131415161718192021222324252627282930313233343536373839404142434445# output sorted resultsort -o result.out video.txt # split the fields by &#x27;:&#x27;sort -t: -r video.txt # test whether it has been sortedsort -c video.txt # sort by 2nd fieldsort -t: +1 video.txt # sort 3rd field using ascii ordersort -t: +2 video.txt sort -t: -k3 video.txt# sort 3rd field using number order sort -t: +2n video.txtsort -t: -k3n video.txt # uniqsort -u video.txt# sort 4th field, then sort 1st fieldsort -t: -k4 -k1 video.txt# sort +field_number.characters_in# sort 2nd filed, begining with 3rd charactersort -t: +1.2 video.txt# list all unix userscat /etc/passwd | sort -t: +0 | awk -F&quot;:&quot; &#x27;&#123;print $1&#125;&#x27;# only not duplicate. here, sort is recommendablesort video.txt | uniq -u # only duplicatesort video.txt | uniq -d# count dulicate timessort video.txt | uniq -c# sorting ignore case sensitivesort -f 8. join12345678910111213141516171819202122232425262728293031323334353637# join, the files must have a common content; the fields must be splited by single tab or spacejoin [options] input-file1 input-file2-an n, the number of file. -a1, means joining files based on file 1-o n.m n, the number of file; m, the number of field. -o 1.3, means display field 3 of file 1-jn m n, the number of file; m, the number of field.-t delimiter# join crossjoin names.txt town.txt# mismatch connections, join alljoin -a1 -a2 names.txt town.txt# base on file1, join alljoin -a1 names.txt town.txt# selective joinjoin -o 1.1,2.2 names.txt town.txt# different field join# extract 3rd field of file 1, 2nd field of file 2, then join them togetherjoin -j1 3 -j2 2 file1 file2cat persP.Jones Office Runner ID897S.Round UNIX admin ID666L.Clip Personl Chief ID982cat pers2Dept2C ID897 6 yearsDept3S ID666 2 yearsDept5Z ID982 1 yearjoin -j1 4 -j2 2 pers pers2ID897 P.Jones Office Runner Dept2C 6 yearsID666 S.Round UNIX admin Dept3S 2 yearsID982 L.Clip Personl Chief Dept5Z 1 year 9. cut12345678910111213141516cut [options] file1 file2-c LIST, select only these characters-f LIST, select only these fields-d, delimitercut -d: -f4 perscut -d: -f1,3 perscut -d: -f1-3 perscut -d: -f1,6 /etc/passwd# file permisionls -l | cut -c1-10echo $PATH | tr &quot;:&quot; &quot;\\n&quot; | nlecho $PATH | cut -d&quot;:&quot; -f3,5 10. paste1234567891011paste -d -s - file1 file2-d, delimiter-s, paste one file at a time instead of in parallelpaste -d: pas1 pas2# list file name, 3 files each rowls | paste -d&quot; &quot; - - -# list file name, ls -l|awk &#x27;NF&gt;3&#123;print $8&#125;&#x27;ls | paste -d&quot;&quot; - 11. split123split -output_file_size input-filename output-filename-output_file_size, default 1000 linesoutput-filename, default x[aa]-&gt;x[zz] 12. dos2unix, ^M=ctrl+v ctrl ^ enter12345678910111213dos2uninx dosfilesed -e &#x27;s/^M//&#x27; dosfiletr -s &quot;\\r\\n&quot; &quot;\\n&quot; &lt; dosfiletr -d &quot;\\015&quot; &lt; dosfilecol -bx &lt; dosfile# delete ^M in vim:set ff=unix:%s/\\r//g:%s/^M//gc 13. lsof, list open file1234567891011121314151617181920212223242526272829lsof filename 显示打开指定文件的所有进程 lsof -a 表示两个参数都必须满足时才显示结果 lsof -c string 显示COMMAND列中包含指定字符的进程所有打开的文件 lsof -u username 显示所属user进程打开的文件 lsof -g gid 显示归属gid的进程情况 lsof +d /DIR/ 显示目录下被进程打开的文件 lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 lsof -d FD 显示指定文件描述符的进程 lsof -n 不将IP转换为hostname，缺省是不加上-n参数 lsof -i 用以显示符合条件的进程情况 lsof -i[46] [protocol][@hostname|hostaddr][:service|port] lsof -i tcp:22lsof -i :22lsof -i @10.40.53.22lsof /etc/passwdlsof /etc/cdromlsof `which httpd`lsof -c bashlsof -u apachelsof +D /tmplsof -i # port 80 14. echo12345678910echo -n 取消行末换行echo -E 关闭反斜线控制字符转换echo -e 启用反斜线控制字符转换\\c 取消行末换行符\\n newline =&gt; \\012\\r return\\t TAB =&gt; \\011\\num ASCII八进制编码\\xnum ASCII十六进制编码 15. 删除空格123456sed &quot;/^\\s*$/d&quot;sed &#x27;/^$/d&#x27;sed -i &#x27;/^$/d&#x27;awk &#x27;NF&gt;0&#x27;perl -i.backup -n -e &quot;print if /\\S/&quot;grep -v &#x27;^$&#x27;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Linux系统","slug":"Linux系统","date":"2019-12-18T08:25:32.000Z","updated":"2021-07-13T03:13:54.387Z","comments":true,"path":"2019/12/18/Linux系统/","link":"","permalink":"https://elihe2011.github.io/2019/12/18/Linux%E7%B3%BB%E7%BB%9F/","excerpt":"1. buffer和cachebuffer强调写，cache强调读，读写都带的时候，几乎无差别。buffer另外也有排队等待被处理的意思，cache基本没有。 2. bash配置文件2.1 全局配置123/etc/profile/etc/profile.d/*.sh /etc/bashrc 2.2 用户配置12~/.bash_profile, ~/.bash_login, ~/.profile(同时存在时，依次读取)~/.bashrc","text":"1. buffer和cachebuffer强调写，cache强调读，读写都带的时候，几乎无差别。buffer另外也有排队等待被处理的意思，cache基本没有。 2. bash配置文件2.1 全局配置123/etc/profile/etc/profile.d/*.sh /etc/bashrc 2.2 用户配置12~/.bash_profile, ~/.bash_login, ~/.profile(同时存在时，依次读取)~/.bashrc 2.3 profile和bashrc1) profile文件： 设定环境变量 运行命令和脚本 2) bashrc文件： 设定本地变量 定义别名 2.4 登录shell和非登录shell1) Login Shell: 通过终端登录 123su - USERNAMEsu -l USERNAME/etc/profile --&gt; /etc/profile.d/*.sh --&gt; ~/.bash_profile --&gt; ~/.bashrc --&gt; /etc/bashrc 2) Non-Login Shell: 1234su USERNAMEGUI终端下打开Console自动执行的shell脚本~/.bashrc --&gt; /etc/bashrc --&gt; /etc/profile.d/*.sh 3. 随机数12345678910# datedate | md5sumdate +%s | sha256sum | base64 | head -c 32; echo# opensslopenssl rand -base64 32# /dev/urandomcat /dev/urandom | tr -dc &#x27;a-zA-Z0-9&#x27; | fold -w 32 | head -1strings /dev/urandom | grep -o &#x27;[a-zA-Z0-9]&#x27; | head -32 | tr -d &#x27;\\n&#x27;; echo 4. 脚本中修改用户密码4.1 使用代码组123456&#123; echo &#x27;pass&#x27; sleep 1 echo &#x27;pass&#x27; sleep 1&#125; | passwd abc 4.2 --stdin1echo &#x27;pass&#x27; | passwd --stdin abc 4.3 查看是否已设置密码12# 已设置密码，PS或Ppasswd -S abc | awk &#x27;&#123;print $2&#125;&#x27; 5. 使用stdin来屏蔽敏感信息12345678910111213$ cat shield_sensitive_info.sh #!/bin/shname=$1read passecho &quot;username=$name&quot;echo &quot;password=$pass&quot;$ echo 123 | ./shield_sensitive_info.sh abc$ ./shield_sensitive_info.sh abc &lt;&lt;EOF123EOF 6. 释放内存查看系统内存使用情况 12free -mcat /proc/meminfo 释放内存 12345678# to free pagecacheecho 1 &gt; /proc/sys/vm/drop_caches# to free dentries and inodesecho 2 &gt; /proc/sys/vm/drop_caches# to free pagecache, dentries and inodes, use echo 3 &gt;/proc/sys/vm/drop_caches 7. 磁盘管理7.1 创建分区（fdisk, sfdisk, part）1) 分区操作 123456fdisk /dev/sdbn add a new partitionp print the partition tablew write table to disk and exitl list known partition typest 82: swap, 83: linux, 8e: lvm, fd: raid 2) 查看分区信息 1fdisk -l /dev/sdb 3) 查看内核识别的分区 123cat /proc/partionspartprobe [/dev/sda] partx -a /dev/sda # RHEL6 4) 大磁盘分区，2TB以上 1234parted /dev/sdbparted /dev/sdc printparted /dev/sdc mkpart logical ext3 19.2GB 19.7GBparted /dev/sdc rm 8 7.2 创建文件系统默认支持的文件系统：mkfs.xx VFS: Virtual Filesystem ext[2-4], xfs iso9660 nfs, cifs jfs, resiserfs, vfat gfs, sfs2, ocfs 1) mkfs 123mkfs -t ext3 /dev/sdb1mkfs.ext3 /dev/sdb2mkfs.ext3 -b 1024 /dev/sdb3 # 设置block大小 1024, 2048, 4096 2) mke2fs (/etc/mke2fs.conf) 1234567-b [1024|2048|4096]-i bytes-per-inode # 多少个字节预留一个inode，默认8192 (每8K一个inode)-N numbers-of-inode-L label-j # ext3-m ratio # 预留给超级用户的磁盘百分比，默认%5-r blocks # 预留的blocks数量 123456mke2fs -j -L &quot;ora_logical&quot; -b 2048 -i 8192 /dev/sdb1mke2fs -j /dev/sdb1 mke2fs -t ext4 -m 2 /dev/sdb1 # 预留2%磁盘块tune2fs -l /dev/sdb1 | grep &quot;Reserved&quot; 3) tune2fs 调整文件系统属性 123456-j # ext2-&gt;ext3-L label -m N # 调整预留百分比-c N # 指定挂载次数达到N次，进行自检，0或-1关闭自检-i N # 每挂载使用多少天自检，默认180，0或-1关闭自检-l # 显示超级块中的信息， dumpe2fs 12tune2fs -j /dev/sda5 # ext3tune2fs -l /dev/sda5 | grep &#x27;Block size&#x27; 4) e2label 查看或定义卷标 12e2label /dev/sda5e2label /dev/sda5 mydisk 5) blkid 查看设备的相关属性属性(UUID, FSTYPE, LABEL) 1blkid /dev/sda5 6) dumpe2fs 分区系统，BLOCK-GROUPs 1dumpe2fs -h /dev/sdb1 # super-block信息 7.3 检查文件系统1) fsck 123-t FSTYPE -a # 自动修复，不询问-f # 强制价差 12fsck -C -f -t ext3 /dev/sdb1fsck -f /dev/sdb1 2) e2fsck 专用修复ext2,ext3 12-f # 强制价差-p # 自动修复，不询问 12345# 检测修复文件系统(单用户模式执行)fsck -y /dev/sda1e2fsck -p /dev/sdb1mke2fs -c /dev/sdb1 7.4 挂载1) mount [options] DEVICE MOUNT_POINT DEVICE: DEV LABEL=”mysql-data” UUID=”uuid” options: 12345678910111213-t fstype-a 挂载/etc/fstab中全部auto的分区-r readonly-n, --no-mtab 不更新/etc/mtab-odefaults rw,suid,dev,exec,auto,nousers,async,realtimero readonlynoatime 访问不更新atimenoauto mount -a不挂载sync 同步写入nodev 不读文件系统上的字符或块设备remount 重新挂载loop 本地回环设备 1234mount -o remount,ro /dev/sdb1mount -o ro /dev/cdrom /mediamount -o loop,ro /root/RHEL6.iso /media 2) umount [DEVICE|MOUNT_POINT] 1234umount /mntumount: /mnt: device is busy.fuser -km /mnt","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"C10K问题","slug":"C10问题","date":"2019-12-16T08:35:23.000Z","updated":"2021-06-22T10:50:49.745Z","comments":true,"path":"2019/12/16/C10问题/","link":"","permalink":"https://elihe2011.github.io/2019/12/16/C10%E9%97%AE%E9%A2%98/","excerpt":"","text":"1. C10K问题由来随着互联网的普及，应用的用户群体几何倍增长，此时服务器性能问题就出现。最初的服务器是基于进程/线程模型。新到来一个TCP连接，就需要分配一个进程。假如有C10K，就需要创建1W个进程，可想而知单机是无法承受的。那么如何突破单机性能是高性能网络编程必须要面对的问题，进而这些局限和问题就统称为C10K问题，最早是由Dan Kegel进行归纳和总结的，并且他也系统的分析和提出解决方案。 2. C10K问题的本质C10K问题的本质上是操作系统的问题。对于Web 1.0/2.0时代的操作系统，传统的同步阻塞I/O模型处理方式都是requests per second。当创建的进程或线程多了，数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞，进程/线程上下文切换消耗大， 导致操作系统崩溃，这就是C10K问题的本质。 可见, 解决C10K问题的关键就是尽可能减少这些CPU资源消耗。 3. C10K问题的解决方案从网络编程技术的角度来说，主要思路： 每个连接分配一个独立的线程/进程 同一个线程/进程同时处理多个连接 3.1 每个进程/线程处理一个连接该思路最为直接，但是申请进程/线程是需要系统资源的，且系统需要管理这些进程/线程，所以会使资源占用过多，可扩展性差 3.2 每个进程/线程同时处理 多个连接(I/O多路复用) select方式：使用fd_set结构体告诉内核同时监控那些文件句柄，使用逐个排查方式去检查是否有文件句柄就绪或者超时。该方式有以下缺点：文件句柄数量是有上线的，逐个检查吞吐量低，每次调用都要重复初始化fd_set。 poll方式：该方式主要解决了select方式的2个缺点，文件句柄上限问题(链表方式存储)以及重复初始化问题(不同字段标注关注事件和发生事件)，但是逐个去检查文件句柄是否就绪的问题仍然没有解决。 epoll方式：该方式可以说是C10K问题的killer，他不去轮询监听所有文件句柄是否已经就绪。epoll只对发生变化的文件句柄感兴趣。其工作机制是，使用”事件”的就绪通知方式，通过epoll_ctl注册文件描述符fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd, epoll_wait便可以收到通知, 并通知应用程序。而且epoll使用一个文件描述符管理多个描述符,将用户进程的文件描述符的事件存放到内核的一个事件表中, 这样数据只需要从内核缓存空间拷贝一次到用户进程地址空间。而且epoll是通过内核与用户空间共享内存方式来实现事件就绪消息传递的，其效率非常高。但是epoll是依赖系统的(Linux)。 异步I/O以及Windows，该方式在windows上支持很好。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"MongoDB","slug":"MongoDB","date":"2019-11-07T08:20:21.000Z","updated":"2021-06-22T10:50:49.745Z","comments":true,"path":"2019/11/07/MongoDB/","link":"","permalink":"https://elihe2011.github.io/2019/11/07/MongoDB/","excerpt":"1. 基本概念 面向集合(Collection-Oriented):数据存储在集合中，每个集合在数据库中都有唯一的标识名，可以包含无限数量的文档 模式自由(Schema-Free):集合类似RMDB中的Table，但无Schema 文档型(Document File):存储数据是键值对的集合”JSON”，键是字符串，值可以是任意类型。存储数据类型称为BSON(Binary Serialized Document Notation) 1.1 数据逻辑结构 文档(document): RMDB中的行 集合(collection): RMDB中的表，由多个文档构成 数据库(database): 与RMDB一致","text":"1. 基本概念 面向集合(Collection-Oriented):数据存储在集合中，每个集合在数据库中都有唯一的标识名，可以包含无限数量的文档 模式自由(Schema-Free):集合类似RMDB中的Table，但无Schema 文档型(Document File):存储数据是键值对的集合”JSON”，键是字符串，值可以是任意类型。存储数据类型称为BSON(Binary Serialized Document Notation) 1.1 数据逻辑结构 文档(document): RMDB中的行 集合(collection): RMDB中的表，由多个文档构成 数据库(database): 与RMDB一致 2. 相关命令2.1 查看帮助123helpdb.help()db.account.help() 2.2 数据库管理1234567891011121314151617181920show dbsuse mydbdb.copyDatabase(&#x27;mydb&#x27;, &#x27;temp&#x27;, &#x27;127.0.0.1&#x27;)db.cloneDatabase(&#x27;10.137.5.44&#x27;)use tempdb.dropDatabase() # 删当前数据库db.repairDatabase()db.getName() # 当前数据库名db.getMongo() # 服务器地址db.stats()db.version()use admindb.shutdownServer() 2.3 集合操作12345678910db.createCollection(&#x27;account&#x27;, &#123;size:20, capped:5, max:100&#125;)db.getCollection(&#x27;account&#x27;)db.getCollectionNames()db.account.help()db.account.count()db.account.dataSize()db.account.totalSize()db.account.getDB()db.account.renameCollection(&#x27;accounts&#x27;) 2.4 用户管理123456789show rolesdb.createUser(&#123;user: &#x27;eli&#x27;,pwd: &#x27;123&#x27;,roles: [&#123;role: &#x27;userAdmin&#x27;, db: &#x27;mydb&#x27;&#125;]&#125;)db.auth(&#x27;eli&#x27;, &#x27;123&#x27;) 2.5 增删改查12345db.account.save(&#123;name: &#x27;mongo&#x27;&#125;)db.account.insert(&#123;x:1&#125;)db.account.find(&#123;name: &#x27;mongo&#x27;&#125;)db.account.update(&#123;name: &#x27;mongo&#x27;&#125;, &#123;$set, &#123;name: &#x27;new_mongo&#x27;&#125;&#125;)db.account.remove(&#123;name: &#x27;new_mongo&#x27;&#125;) update语法： 123456db.collection.update( &lt;query&gt;, &lt;update&gt;, upsert:&lt;boolean&gt;, multi:&lt;boolean&gt; // 默认只修改一条数据) 更新操作： ———｜————–｜名称 ｜描述｜———｜————–｜$inc ｜根据要添加的值递增该字段的值。｜$mul ｜将该字段的值乘以指定的值｜$rename ｜重命名字段｜$setOnInsert ｜操作时,操作给相应的字段赋值｜$set ｜用来指定一个键的值，如果不存在则创建它｜$unset ｜用来指定一个键的值，如果不存在不创建创建它｜$min ｜只有当指定的值小于现有字段值时才更新该字段。｜$max ｜只有当指定的值大于现有字段值时才更新该字段。｜$currentDate ｜设置当前日期字段的值，或者作为一个日期或时间戳。｜ 3. 查询操作12345db.test.insert(&#123;name:&#x27;jack&#x27;, age:29, gender:&#x27;male&#x27;, email:&#x27;jack@outlook.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;lucy&#x27;, age:21, gender:&#x27;female&#x27;, email:&#x27;lucy@gmail.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;tom&#x27;, age:30, gender:&#x27;male&#x27;, email:&#x27;tom@abc.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;bonnie&#x27;, age:29, gender:&#x27;female&#x27;, email:&#x27;bonnie@abc.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;jack&#x27;, age:25, gender:&#x27;male&#x27;, email:&#x27;jack@hotmail.com&#x27;&#125;) 3.1 基本查询1234567db.test.find() # alldb.test.findOne(). # just onedb.test.find(&#123;name:&#x27;jack&#x27;&#125;)db.test.find(&#123;name:&#x27;jack&#x27;, age:29&#125;)db.test.find(&#123;&#125;, &#123;name:1, gender:1&#125;) # 只返回name, gender字段db.test.find(&#123;&#125;, &#123;email:0&#125;) # 不返回email字段 3.2 条件查询($gt, $lt, $gte, $lte, $ne, $or, $in, $nin)123456789db.test.find(&#123;age: &#123;$gt: 25, $lt: 30&#125;&#125;)db.test.find(&#123;gender: &#123;$ne: &#x27;male&#x27;&#125;&#125;)db.test.find(&#123;age: &#123;$in: [21, 30]&#125;&#125;)db.test.find(&#123;age: &#123;$nin: [21, 30]&#125;&#125;)db.test.find(&#123;name: &#123;$not: &#123;$in: [&#x27;jack&#x27;, &#x27;lily&#x27;]&#125;&#125;&#125;)db.test.find(&#123;age: &#123;$mod: [10,1]&#125;&#125;)db.test.find(&#123;name: &#123;$exists: true&#125;&#125;)db.test.find(&#123;$or: [&#123;name:&#x27;jack&#x27;&#125;, &#123;name:&#x27;tom&#x27;&#125;]) 3.3 null类型查询12345db.test.update(&#123;name:&#x27;jack&#x27;&#125;, &#123;$set: &#123;addr: null&#125;&#125;)db.test.update(&#123;name:&#x27;tom&#x27;&#125;, &#123;$set: &#123;addr: &#123;city:&#x27;NJ&#x27;, prov:&#x27;JS&#x27;&#125;&#125;&#125;)db.test.find(&#123;addr: null&#125;)db.test.find(&#123;addr: &#123;$in: [null], $exists: true&#125;&#125;) 3.4 正则表达式12db.test.find(&#123;name:/Jack?/i&#125;)db.test.find(&#123;name: &#123;$not: /^b.*/&#125;&#125;) # not like &#x27;b%&#x27; 3.5 js和$where查询123456db.test.find(&#123;age: &#123;$lt: 30&#125;&#125;)db.test.find(&#123;$where: &quot;this.age &gt; 30&quot;&#125;)db.test.find(&quot;this.age &gt; 30&quot;)f = function() &#123;return this.age&gt;30;&#125;db.test.find(f) 3.6 count, limit, skip, sort1234db.test.find().count()db.test.find().limit(5)db.test.find().skip(3).limit(5)db.test.find().sort(&#123;age:-1&#125;) 3.7 数组1234567891011121314151617181920212223db.fruits.insert(&#123;fruit: [&#x27;apple&#x27;, &#x27;orange&#x27;, &#x27;peach&#x27;]&#125;)db.fruits.insert(&#123;fruit: [&#x27;apple&#x27;, &#x27;kuaquat&#x27;, &#x27;blueberry&#x27;]&#125;)db.fruits.insert(&#123;fruit: [&#x27;pear&#x27;, &#x27;strawberry&#x27;, &#x27;banana&#x27;]&#125;)db.fruits.find(&#123;fruit: &#x27;apple&#x27;&#125;)db.fruits.find(&#123;fruit: &#123;$in: [&#x27;apple&#x27;]&#125;&#125;) # same as abovedb.fruits.find(&#123;fruit: &#123;$all: [&#x27;apple&#x27;, &#x27;orange&#x27;]&#125;&#125;)db.fruits.find(&#123;fruit: [&#x27;apple&#x27;, &#x27;orange&#x27;, &#x27;peach&#x27;]&#125;)db.fruits.find(&#123;&#x27;fruit.2&#x27;: &#x27;peach&#x27;&#125;)db.fruits.find(&#123;fruit: &#123;$size: 3&#125;&#125;)db.fruits.update(&#123;&#125;, &#123;$set: &#123;size:3&#125;&#125;, false, true)db.fruits.find()db.fruits.update(&#123;&#125;, &#123;$push: &#123;fruit:&#x27;grape&#x27;&#125;, $inc: &#123;size:1&#125;&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:2&#125;, size: 0&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:-2&#125;, size: 0&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:[2,1]&#125;, size: 0&#125;) 3.8 查询组合条件3.8.1 $in满足列表中任意一个值 1db.funds.find(&#123;&#x27;Fee&#x27;: &#123;&#x27;$in&#x27;: [15, 21]&#125;&#125;) 3.8.2 $all满足列表中全部值 1db.funds.find(&#123;&#x27;Fee&#x27;: &#123;&#x27;$all&#x27;: [15, 21]&#125;&#125;) 3.8.3 $or1db.funds.find(&#123;&#x27;$or&#x27;: [&#123;&#x27;Fee&#x27;: 15&#125;, &#123;&#x27;Fee&#x27;: 21&#125;]&#125;) 3.8.4 $and1db.funds.find(&#123;&#x27;$and&#x27;: [&#123;&#x27;Fee&#x27;: 15&#125;, &#123;&#x27;Fee&#x27;: 21&#125;]&#125;) 3.8.5 $exist节点存在，不关心值是否为null 1db.test.find(&#123;&quot;Fee&quot;: &#123;&#x27;$exists&#x27;: true&#125;&#125;) 节点不存在或者节点存在但值为null 1db.test.find(&#123;&quot;Fee&quot;: null&#125;) 3.8.6 $ne1db.test.find(&#123;&quot;Fee&quot;: &#123;&#x27;$ne&#x27;: 21&#125;&#125;) 1&#123;&#x27;$and&#x27;: [&quot;BasicInfo.offshoreFund&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;, &quot;BasicInfo.cayman&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;, &quot;BasicInfo.America&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;]&#125;, &quot;BasicInfo.BVI&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;]&#125; 123456db.funds.find(&#123; &#x27;$and&#x27;: [ &quot;BasicInfo.America&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;]&#125;, &quot;BasicInfo.BVI&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125; ] &#125;).count() 3.9 聚合查询12345678910&#123; &quot;_id&quot; : 1, &quot;domainName&quot; : &quot;test1.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 2, &quot;domainName&quot; : &quot;test2.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot;&#125;&#123; &quot;_id&quot; : 3, &quot;domainName&quot; : &quot;test3.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 4, &quot;domainName&quot; : &quot;test4.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 5, &quot;domainName&quot; : &quot;test5.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 6, &quot;domainName&quot; : &quot;test6.com&quot;, &quot;hosting&quot; : &quot;cloud.google.com&quot; &#125;&#123; &quot;_id&quot; : 7, &quot;domainName&quot; : &quot;test7.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 8, &quot;domainName&quot; : &quot;test8.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 9, &quot;domainName&quot; : &quot;test9.com&quot;, &quot;hosting&quot; : &quot;cloud.google.com&quot; &#125;&#123; &quot;_id&quot; : 10, &quot;domainName&quot; : &quot;test10.com&quot;, &quot;hosting&quot; : &quot;godaddy.com&quot; &#125; 导入数据： 1mongoimport -d testdb -c website --file website.json --upsert 3.9.1 group &amp; sort1234567891011121314151617// group bydb.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;]);// sortdb.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]);// matchdb.website.aggregate([ &#123; $match: &#123; hosting: &quot;aws.amazon.com&quot; &#125; &#125;, &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]); 3.9.2 export result12345678var group_data = db.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]); print(group_data.toArray()) db.websitegroup.insert(group_data.toArray()) 123mongoexport -d testdb -c websitegroup -o websitegroup.jsonmongoexport -d testdb -c websitegroup -f _id,total -o websitegroup.csv --type=csv 3.9.3 Large sort operation: (sort in memory 100M)123456db.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;], &#123; allowDiskUse: true &#125;); 3.10 查询Embeded数据12345678910111213141516171819202122&#123; &quot;_id&quot;: &quot;alpha&quot;, &quot;name&quot;: &quot;Storage Alpha&quot;, &quot;items&quot;: [ &#123; &quot;category&quot;: &quot;food&quot;, &quot;name&quot;: &quot;apple&quot; &#125;, &#123; &quot;category&quot;: &quot;food&quot;, &quot;name&quot;: &quot;banana&quot; &#125;, &#123; &quot;category&quot;: &quot;tool&quot;, &quot;name&quot;: &quot;hammer&quot; &#125;, &#123; &quot;category&quot;: &quot;furniture&quot;, &quot;name&quot;: &quot;couch&quot; &#125; ]&#125; 3.10.1 查询整个文档:1234567db.storage.find(&#123; &#x27;items.category&#x27;: &#123; $eq: &#x27;food&#x27; &#125;&#125;);// result 3.10.2 映射操作符（Projection Operator）1) $ 操作符会限制 array 类型数据的返回结果，使其仅返回第一个满足条件的元素。 123456789101112131415161718192021db.storage.find(&#123; &#x27;items.category&#x27;: &#123; $eq: &#x27;food&#x27; &#125;&#125;,&#123; &#x27;items.$&#x27;: 1&#125;);// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125; ]&#125; 2) $elemMatch 和 $ 的区别在于，$ 使用的是数据查询条件作为来映射（或者说过滤）array 中的数据，而 $elemMatch 需要指定单独的条件（可以指定多个条件） 1234567891011121314151617181920212223db.storage.find(&#123; &#x27;_id&#x27;: &#x27;alpha&#x27;&#125;,&#123; &#x27;items&#x27;: &#123; &#x27;$elemMatch&#x27;: &#123; &#x27;category&#x27;: &#x27;food&#x27; &#125; &#125;&#125;)// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125; ]&#125; 3.10.3 聚合1) $filter 123456789101112131415161718192021222324252627282930db.storage.aggregate([&#123; $project: &#123; &quot;items&quot;: &#123; $filter: &#123; input: &quot;$items&quot;, as: &quot;item&quot;, cond: &#123; $eq: [ &#x27;$$item.category&#x27;, &#x27;food&#x27; ] &#125; &#125; &#125; &#125;&#125;])// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125;, &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;banana&quot; &#125; ]&#125; 2) $unwind 如果文档中包含 array 类型字段、并且其中包含多个元素，使用 $unwind 操作符会根据元素数量输出多个文档，每个文档的 array 字段中仅包含 array 中的单个元素。 123456789101112131415161718192021222324252627282930313233343536db.storage.aggregate([&#123; $match: &#123; &#x27;items.category&#x27;: &#x27;food&#x27; &#125;&#125;,&#123; $unwind: &#x27;$items&#x27;&#125;,&#123; $match: &#123; &#x27;items.category&#x27;: &#x27;food&#x27; &#125;&#125;])// result/* 1 */&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;name&quot; : &quot;Storage Alpha&quot;, &quot;items&quot; : &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125;&#125;/* 2 */&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;name&quot; : &quot;Storage Alpha&quot;, &quot;items&quot; : &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;banana&quot; &#125;&#125; 4. 索引4.1 基础索引1234db.test.ensureIndex(&#123;age:1&#125;)db.test.ensureIndex(&#123;age:1&#125;, &#123;background:true&#125;)db.test.getIndexes() 4.2 文档索引1234db.test.update(&#123;addr:null&#125;, &#123;$set: &#123;addr: &#123;city:&#x27;BJ&#x27;, prov:&#x27;BJ&#x27;&#125;&#125;&#125;)db.test.ensureIndex(&#123;addr:1&#125;)db.test.find(&#123;addr: &#123;city:&#x27;BJ&#x27;, prov:&#x27;BJ&#x27;&#125;&#125;) # 使用索引db.test.find(&#123;addr: &#123;prov:&#x27;BJ&#x27;, city:&#x27;BJ&#x27;&#125;&#125;) # 不使用索引 4.3 组合索引1db.test.ensureIndex(&#123;name:1, age:1&#125;) 4.4 唯一索引1db.test.ensureIndex(&#123;name:1&#125;, &#123;unique:true&#125;) 4.5 强制使用索引 (hint)12db.test.ensureIndex(&#123;name:1, age:1&#125;)db.test.find(&#123;age: &#123;$gt:25&#125;&#125;).hint(&#123;name:1, age:1&#125;).explain() 4.6 删除索引12db.test.dropIndex(&#123;name:1&#125;)db.test.dropIndexes() 5. 存储过程5.1 定义函数1function addNumbers(x, y) &#123;return x+y;&#125; 5.2 放入js表中12db.system.js.save(&#123;_id:&#x27;addNumbers&#x27;, value:addNumbers&#125;)db.system.js.save(&#123;_id:&#x27;addNumbers&#x27;, value:function(x, y) &#123;return x+y;&#125;&#125;) 5.3 执行存储过程1db.eval(&#x27;addNumbers(1,2)&#x27;) 6. 工具和命令6.1 常用命令123456789bsondump bson格式文件转换为jsonmongo 客户端, js解释器mongod 服务器，每个实例启动一个进程mongodump/mongorestoremongoexport/mongoimportmongofile GridFS管理器，实现二进制文件存取mongos 分片路由，使用sharding功能时，应用程序连接mongos，而不是mongodmongosniff tcpdump，监控mongodb相关包请求，并已指定可读形式输出mongostat 实时监控工具 6.2 数据导出1234567mongoexport-d, --db-c, --collection-o, --out-f, --fields--host/--port-csv, --type=csv 12mongoexport -d mydb -c test -o test.jsonmongoexport -d mydb -c test -f name,addr --type=csv -o test.csv 6.3 数据导入12345678910mongoimport-d, --db-c, --collection-f, --fields--host/--port-csv, --type=csv--drop =&gt; drop collecion first if exists--stopOnError--file--headerline # 忽略第一行 1mongoimport -d mydb -c test --headerline --type=csv --drop --file test.csv 6.4 数据库备份恢复12345678910111213141) mongodump-d, --db-c, --collection-o, --out-q, --querymongodump -d mydb # 生成dump目录，该目录下保存数据文件2) mongorestore-d, --db-c, --collection--objcheck--filter--drop","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://elihe2011.github.io/categories/NoSQL/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://elihe2011.github.io/tags/mongodb/"}]},{"title":"RabbitMQ","slug":"RabbitMQ","date":"2019-10-14T06:04:07.000Z","updated":"2021-06-22T10:50:49.743Z","comments":true,"path":"2019/10/14/RabbitMQ/","link":"","permalink":"https://elihe2011.github.io/2019/10/14/RabbitMQ/","excerpt":"1. RabbitMQ介绍 面向消息的中间件，用于组件之间的解藕，主要体现在消息的发送者和消费者之间无强依赖关系 1.1 消息中间件消息中间件：在消息传输过程中保存消息的容器。主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它为止。当然，消息队列保存消息也是有期限的。 1.1.1 消息中间传递模型： 点对点 (PTP) 发布订阅 (Pub/Sub) 1.1.2 AMQP: Advanced Message Queue Protocol","text":"1. RabbitMQ介绍 面向消息的中间件，用于组件之间的解藕，主要体现在消息的发送者和消费者之间无强依赖关系 1.1 消息中间件消息中间件：在消息传输过程中保存消息的容器。主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它为止。当然，消息队列保存消息也是有期限的。 1.1.1 消息中间传递模型： 点对点 (PTP) 发布订阅 (Pub/Sub) 1.1.2 AMQP: Advanced Message Queue Protocol 1.2 RabbitMQ核心组件： Exchange Queue 1.3 RabbitMQ术语： Server(broker): 接受客户端连接，实现AMQP消息队列和路由功能的进程 Virtual Host: 并不真实存在，类似权限控制组，一个Virtual Host里面可以有若干个Exchange和Queue，但权限控制的最小粒度为Virtual Host Exchange: 接收生产者发送的消息，并根据Binding规则将消息苦雨给服务器中的队列。ExchangeType决定于Exchange路由消息的行为。在RabbitMQ中，ExchangeType有direct、Fanout和Topic三种，不同类型的Exchange路由行为不一样 Message Queue：消息队列，用于存储还未被消费者消费的消息 Message：由Header和Body组成，Header是生产者添加的各种属性的集合，包含Message是否被持久化、由那个Message Queue接受，优先级是多少等。而Body则是真正需要传输的APP数据 BindingKey: 绑定关键字。绑定就是将一个特定的Exchange和一个特定的Queue绑定起来。 1.4 Exchange分类： Direct Exchange：直接交互式路由键。需要将一个队列绑定到交换机上，要求该消息一一个特定的路由完全匹配。例如一个队列绑定到该交换机上要求路由键为”dog”，只有被标记为”dog”的消息能够被转发。 Fanout Exchange: 广播式路由键。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。 Topic Exchange：主题式交换器。通过消息的路由关键字和绑定的关键字的模糊匹配，将消息路由到被绑定的队列中。支持通配符：*匹配一个词组，#零个或多个词组。*.stock.#匹配路由关键字usd.stock和eur.stock.db，但不匹配stock.nasdaq 2. 安装RabbitMQRabbitMQ 3.7.19: Upgrading to Erlang 21.x or Later Versions 2.1 安装12345678910111213141516yum repolist yum clean allyum makecache yum list erlangcd /etc/yum.repos.d/# erlangcurl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh | sudo bashyum install erlang# rabbitmqcurl -s https://packagecloud.io/install/repositories/rabbitmq/rabbitmq-server/script.rpm.sh | sudo bashyum install rabbitmq-server-3.7.19-1.el7 2.2 RabbitMQ配置文件(默认没有)1) /etc/rabbitmq/rabbitmq-env.conf 1234RABBITMQ_NODE_IP_ADDRESS: 127.0.0.1RABBITMQ_NODE_PORT: 5672RABBITMQ_NODE_CONFIG_FILE: *.configRABBITMQ_NODE_LOG_BASE: 2) /etc/rabbitmq/rabbitmq.config 123tcp_listeners 5672disk_free_limitvm_memory_high_watermark 0.4 2.3 启动123systemctl enable rabbitmq-serversystemctl start rabbitmq-server 2.4 Mac安装RabbitMQ123456789101112131415brew install rabbitmq# 配置环境变量export RABBIT_HOME=/usr/local/Cellar/rabbitmq/3.8.0export PATH=$PATH:$RABBIT_HOME/sbin# 启动\b服务sudo rabbitmq-serversudo rabbitmq-server -detached # 后台运行# 停止服务rabbitmqctl stop# 配置文件位置cd /usr/local/etc/rabbitmq 3. rabbitmq控制命令3.1 插件命令12345# 插件列表rabbitmq-plugins list# 开启管理工具 （支持http://localhost:15672/）rabbitmq-plugins enable rabbitmq_management 3.2 操作命令1234567891011121314151617181920212223# 虚拟主机rabbitmqctl add_vhost ut_vhostrabbitmqctl list_vhosts# 新增账号rabbitmqctl add_user utime welovetimerabbitmqctl list_users# 修改密码rabbitmqctl change_password utime utime@celery123# 设置tagsudo rabbitmqctl set_user_tags utime administrator# 设置权限rabbitmqctl set_permissions -p ut_vhost utime &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;rabbitmqctl list_permissions# 队列状态rabbitmqctl list_queues rabbitmqctl list_queues name messages messages_ready messages_unacknowledged rabbitmqctl list_queues name consumersrabbitmqctl list_queues name memory 4. RabbitMQ核心概念 Virtual Host: 数据隔离 Connection: Exchange: 交换机，中转消息 Channel: 通信 Queue: 队列，绑定交换机；临时存储消息 Binding: 绑定队列到交换机 5. RabbitMQ的工作模式5.1 Simple模式1go get github.com/streadway/amqp 最简单常用的模式 P -&gt; Queue -&gt; C 12345678910111213141516171819202122232425func NewRabbitMQ(queueName, exchange, key string) *RabbitMQ &#123; return &amp;RabbitMQ&#123; QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL, &#125;&#125;// 设置queueNamefunc NewRabbitMQPubSub(queueName string) *RabbitMQ &#123; rabbitmq := NewRabbitMQ(queueName, &quot;&quot;, &quot;&quot;) var err error // 创建连接 rabbitmq.conn, err = amqp.Dial(rabbitmq.Mqurl) rabbitmq.failOnErr(err, &quot;创建连接失败&quot;) // 创建channel rabbitmq.channel, err = rabbitmq.conn.Channel() rabbitmq.failOnErr(err, &quot;获取channel失败&quot;) return rabbitmq&#125; 5.2 Work, 工作模式一个消息只能被一个消费者获取。与Simple模式的区别，只在于开启了多个消费者端，负载均衡。 P -&gt; Queue –&gt; C1, C2, … 5.3 Publish/Subscribe, 订阅模式消息被路由投递给多个队列，一个消息被多个消费者获取 P -&gt; X -&gt; Queue -&gt; C1 | Queue -&gt; C2 12345678910111213141516171819202122232425func NewRabbitMQ(queueName, exchange, key string) *RabbitMQ &#123; return &amp;RabbitMQ&#123; QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL, &#125;&#125;// 设置exchangeNamefunc NewRabbitMQPubSub(exchangeName string) *RabbitMQ &#123; rabbitmq := NewRabbitMQ(&quot;&quot;, exchangeName, &quot;&quot;) var err error // 创建连接 rabbitmq.conn, err = amqp.Dial(rabbitmq.Mqurl) rabbitmq.failOnErr(err, &quot;创建连接失败&quot;) // 创建channel rabbitmq.channel, err = rabbitmq.conn.Channel() rabbitmq.failOnErr(err, &quot;获取channel失败&quot;) return rabbitmq&#125; 5.4 Routing, 路由模式一个消息被多个消费者获取，并且消息的目标队列可被生产者指定","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://elihe2011.github.io/categories/RabbitMQ/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://elihe2011.github.io/tags/rabbitmq/"}]},{"title":"Hexo","slug":"Hexo","date":"2019-09-24T08:06:10.000Z","updated":"2021-06-22T10:50:49.742Z","comments":true,"path":"2019/09/24/Hexo/","link":"","permalink":"https://elihe2011.github.io/2019/09/24/Hexo/","excerpt":"1. 安装hexo12345678npm install hexo-cli -g hexo init blogcd blognpm installhexo serv","text":"1. 安装hexo12345678npm install hexo-cli -g hexo init blogcd blognpm installhexo serv 2. 安装主题123git clone https://github.com/xaoxuu/hexo-theme-material-x themes/material-xnpm i -S hexo-generator-search hexo-generator-json-content hexo-renderer-less","categories":[{"name":"Tools","slug":"Tools","permalink":"https://elihe2011.github.io/categories/Tools/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://elihe2011.github.io/tags/hexo/"}]},{"title":"Nginx安装配置","slug":"Nginx安装","date":"2019-09-19T02:32:10.000Z","updated":"2021-06-22T10:50:49.741Z","comments":true,"path":"2019/09/19/Nginx安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/19/Nginx%E5%AE%89%E8%A3%85/","excerpt":"1. 添加nginx用户123groupadd nginx useradd -g nginx -s /sbin/nologin -M nginx","text":"1. 添加nginx用户123groupadd nginx useradd -g nginx -s /sbin/nologin -M nginx 2. 安装123456789101112131415161718192021wget http://openresty.org/download/openresty-1.15.8.2.tar.gztar zxvf openresty-1.15.8.2.tar.gzcd openresty-1.15.8.2# 解决openssl支撑包问题, 删除.opensslvi bundle/nginx-1.15.8/auto/lib/openssl/confCORE_INCS=&quot;$CORE_INCS $OPENSSL/.openssl/include&quot;CORE_DEPS=&quot;$CORE_DEPS $OPENSSL/.openssl/include/openssl/ssl.h&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libssl.a&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libcrypto.a&quot;./configure -j2 --prefix=/usr/local/openresty --with-openssl=/usr/local/opensslmakemake installvi ~/.bash_profileexport PATH=/usr/local/openresty/nginx/sbin:/usr/local/openresty/bin:$PATH 3. 开机启动1234567891011121314151617vi /usr/lib/systemd/system/nginx.serviceDescription=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/openresty/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 4. 管理ngnix123systemctl enable nginx.servicesystemctl start nginx 5. 配置123456789101112131415161718192021222324252627282930313233343536373839404142mkdir -p /usr/local/openresty/nginx/conf.dvi /usr/local/openresty/nginx/conf/nginx.confhttp &#123; # 去除注释 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27; &#x27;$request_time $upstream_response_time&#x27;; ... # 节点末尾添加 include /usr/local/openresty/nginx/conf.d/*.conf;&#125;vi /usr/local/openresty/nginx/conf.d/test.confserver &#123; listen 80; server_name 192.168.1.21; access_log /var/log/nginx/embo.access.log main; error_log /var/log/nginx/embo.error.log; error_page 404 = /404; error_page 403 = /403; location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; #include proxy_params; proxy_pass http://127.0.0.1:20002/; proxy_redirect off; &#125; location = / &#123; root /data/www/lp-web/; index index.html; &#125; location ~* \\.(html|ico)$ &#123; root /data/www/lp-web/; &#125;&#125; 6. nginx相关命令1234567nginxnginx -tnginx -s stopnginx -s reload 7. 安装问题7.1 PCRE未安装1234567891011121314checking for SA_RESTART ... found + ngx_stream_lua_module was configuredchecking for PCRE library ... not foundchecking for PCRE library in /usr/local/ ... not foundchecking for PCRE library in /usr/include/pcre/ ... not foundchecking for PCRE library in /usr/pkg/ ... not foundchecking for PCRE library in /opt/local/ ... not found./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 1yum -y install pcre-devel 8. systemctl启动服务，日志异常12345Dec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Starting nginx.service...Dec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal nginx[26980]: nginx: the configuration file /usr/local/openresty/nginx/conf/nginx.conf syntax is okDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal nginx[26980]: nginx: configuration file /usr/local/openresty/nginx/conf/nginx.conf test is successfulDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Failed to read PID from file /usr/local/openresty/nginx/logs/nginx.pid: Invalid argumentDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Started nginx.service. 原因：启动成功瞬间，暂未找到nginx.pid文件 解决：增加睡眠时间 123456789101112131415161718vi /usr/lib/systemd/system/nginx.serviceDescription=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/openresty/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf ExecStartPost=/bin/sleep 0.1 # 新增项ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 12345systemctl daemon-reloadsystemctl restart nginx.servicesystemctl status nginx","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://elihe2011.github.io/tags/nginx/"}]},{"title":"Supervisor","slug":"Supervisor","date":"2019-09-16T03:11:14.000Z","updated":"2021-07-13T02:50:42.530Z","comments":true,"path":"2019/09/16/Supervisor/","link":"","permalink":"https://elihe2011.github.io/2019/09/16/Supervisor/","excerpt":"1. 安装12345678910su - rootpip3 install supervisor/usr/local/python37/bin/echo_supervisord_conf &gt; /etc/supervisord.conf#supervisord -c /etc/supervisord.confln -s /usr/local/python37/bin/supervisord /usr/bin/supervisordln -s /usr/local/python37/bin/supervisorctl /usr/bin/supervisorctl","text":"1. 安装12345678910su - rootpip3 install supervisor/usr/local/python37/bin/echo_supervisord_conf &gt; /etc/supervisord.conf#supervisord -c /etc/supervisord.confln -s /usr/local/python37/bin/supervisord /usr/bin/supervisordln -s /usr/local/python37/bin/supervisorctl /usr/bin/supervisorctl 2. 修改配置123456789101112131415161718192021mkdir -p /etc/supervisord.conf.dvi /etc/supervisord.conf[unix_http_server];file=/tmp/supervisor.sock ; the path to the socket filefile=/var/run/supervisor.sock ;[supervisord];logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.loglogfile=/var/log/supervisord.log ;;pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pidpidfile=/var/run/supervisord.pid ;[supervisorctl];serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socketserverurl=unix:///var/run/supervisor.sock ;[include]files = /etc/supervisord.conf.d/*.conf 3. 开机启动12345678910111213141516vi /usr/lib/systemd/system/supervisord.service[Unit] Description=Supervisor daemon[Service] Type=forking ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf ExecStop=/usr/bin/supervisorctl shutdown ExecReload=/usr/bin/supervisorctl reload KillMode=process Restart=on-failure RestartSec=42s[Install] WantedBy=multi-user.target 4. 系统管理12345systemctl enable supervisordsystemctl start supervisordps -ef | grep supervisor 5. 新增配置5.1 webhhok12345678910111213141516171819vi /etc/supervisord.conf.d/webhook.conf [program:webhook]user=utimedirectory=/tmp/command=webhookit -c /etc/webhook/config.py -p 18340autostart=trueautorestart=truestartretries=10exitcodes=0stopsignal=KILLstopwaitsecs=10redirect_stderr=truestdout_logfile=/var/log/webhook-out.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/webhook-error.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5 5.2 业务123456789101112131415vi /etc/supervisord.conf.d/lp-service.conf[program:lp-service]command=/home/utime/.venv/py3/bin/gunicorn -b 127.0.0.1:20002 --worker-class eventlet -w 4 manage:app --access-logfile /tmp/lp-service-gunicorn.logautostart=trueautorestart=truedirectory=/home/utime/lp-service/user=utimestdout_logfile=/var/log/lp-service-stdout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/lp-service-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot; 6. 启动123supervisorctl updatesupervisorctl status","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"supervisor","slug":"supervisor","permalink":"https://elihe2011.github.io/tags/supervisor/"}]},{"title":"Go RabbitMQ","slug":"Go RabbitMQ","date":"2019-07-25T07:28:26.000Z","updated":"2021-06-22T10:50:49.738Z","comments":true,"path":"2019/07/25/Go RabbitMQ/","link":"","permalink":"https://elihe2011.github.io/2019/07/25/Go%20RabbitMQ/","excerpt":"","text":"1. RabbitMQ1.1 AMQPAdvanced Message Queuing Protocol 高级消息队列协议 (消息中间件) 消息中间件的作用： 解藕 削峰 异步处理 缓存存储 消息通知 提供系统的拓展性 1.2 主要概念 Producer Consumer RabbitMQ Broker: 单机时为 RabbitMQ 服务器 Queue: 存储消息数据 Binding: 交换机(Exchange) 将 消息(Message) 路由给 队列(Queue) 所遵循的规则 RoutingKey: 路由规则 Exchange: fanout: 扇形交换机。消息分发到所有与该交换机相连的队列中。忽略RoutingKey，直接“广播”到绑定的队列中 direct: 直连交换机。根据消息携带的RoutingKey来投递消息到对应的队列中。不指定RoutingKey，在此类型下创建的Queue，RoutingKey名称与Queue一致 topic: 主题交换机。RoutingKey中使用 . 来分割；BindingKey中也使用 . 来分割，另外用 *(匹配一个单词) 和 #(匹配任意个单词) 来进行模糊匹配 RoutingKey。 headers 2. Golang 使用 RabbitMQ2.1 安装支撑包1go get github.com/streadway/amqp 2.2 基础队列2.2.1 连接 RabbitMQ123456789func GetRabbitMQConn() (*amqp.Connection, error) &#123; username := &quot;guest&quot; password := &quot;guest&quot; host := &quot;127.0.0.1&quot; port := 5672 url := fmt.Sprintf(&quot;amqp://%s:%s@%s:%d&quot;, username, password, host, port) return amqp.Dial(url)&#125; 2.2.2 生产者123456789101112131415161718192021222324252627282930313233343536373839type demo struct &#123; Name string `json:&quot;name&quot;` Addr string `json:&quot;addr&quot;`&#125;func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() data := demo&#123; Name: &quot;Jack&quot;, Addr: &quot;Montreal&quot;, &#125; bs, _ := json.Marshal(data) err = ch.Publish( &quot;&quot;, // exchange &quot;simple:queue&quot;, // key, RoutingKey, same as Queue.Name when the exchange mode is direct. false, // mandatory false, // immediate amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, Body: bs, &#125;) if err != nil &#123; log.Fatalf(&quot;Failed to publish a message: %v&quot;, err) &#125; log.Printf(&quot;[*] sent %s&quot;, bs)&#125; 2.2.3 消费者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() q, err := ch.QueueDeclare( &quot;simple:queue&quot;, // name false, // durable false, // autoDelete false, // exclusive false, // noWait nil, // args ) if err != nil &#123; log.Fatalf(&quot;Failed to declare a queue: %v&quot;, err) &#125; // 定义一个消费者 msgs, err := ch.Consume( q.Name, // queue (string) &quot;&quot;, // consumer true, // autoAck false, // exclusive false, // noLocal false, // noWait nil, // args ) if err != nil &#123; log.Fatalf(&quot;Failed to register a consume: %v&quot;, err) &#125; go func() &#123; for msg := range msgs &#123; log.Printf(&quot;Received a message: %s\\n&quot;, msg.Body) &#125; &#125;() log.Println(&quot;[*] Waiting for messages. To exit press CTRL+C&quot;) select &#123;&#125;&#125; 2.3 任务队列为了避免等待执行一些耗时的任务, 而是将需要执行的任务封装为消息发送给工作队列, 后台运行的工作进程将任务消息取出来并执行相关任务。多个后台工作进程同时间进行, 那么任务在他们之间共享. 2.3.1 发布任务 (task.py)12345678910111213141516171819202122232425262728293031323334353637383940414243func bodyForm(args []string) string &#123; var s string if (len(args) &lt; 2) || os.Args[1] == &quot;&quot; &#123; s = &quot;no task&quot; &#125; else &#123; s = strings.Join(args[1:], &quot; &quot;) &#125; return s&#125;func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() body := bodyForm(os.Args) err = ch.Publish( &quot;&quot;, &quot;task:queue&quot;, false, false, amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, DeliveryMode: amqp.Persistent, Body: []byte(body), &#125;, ) if err != nil &#123; log.Fatalf(&quot;Failed to publish a message&quot;) &#125; log.Printf(&quot;sent %s\\n&quot;, body)&#125; 2.3.2 执行任务 (worker.py)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() q, err := ch.QueueDeclare( &quot;task:queue&quot;, false, false, false, false, nil, ) if err != nil &#123; log.Fatalf(&quot;Failed to declare a queue: %v&quot;, err) &#125; // 计数器 err = ch.Qos( 1, // prefetch count 0, // prefetch size false, // global ) if err != nil &#123; log.Fatalf(&quot;Failed to set Qos: %v&quot;, err) &#125; msgs, err := ch.Consume( q.Name, &quot;&quot;, false, false, false, false, nil, ) if err != nil &#123; log.Fatalf(&quot;Failed to register a consumer: %v&quot;, err) &#125; done := make(chan bool) go func() &#123; for msg := range msgs &#123; log.Printf(&quot;Received a message: %s\\n&quot;, msg.Body) msg.Ack(false) &#125; &#125;() log.Printf(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;) &lt;-done&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://elihe2011.github.io/tags/rabbitmq/"}]},{"title":"Go gRPC Gateway","slug":"Go gRPC Gateway","date":"2019-07-20T07:18:06.000Z","updated":"2021-06-22T10:50:49.737Z","comments":true,"path":"2019/07/20/Go gRPC Gateway/","link":"","permalink":"https://elihe2011.github.io/2019/07/20/Go%20gRPC%20Gateway/","excerpt":"1. gRPC 回顾总结1.1 gRPC1go get -u google.golang.org/grpc 强大的 IDL，使用 Protocol Buffers 作为数据交换格式 跨语言、跨平台 支持HTTP2，双向传输、多路复用、认证等 grpc下常用包： metadata: 提供方法对 grpc 元数据结构MD 进行获取和处理 credentials: 封装了客户端对服务端进行身份验证所需的所有状态，并做出各种断言 codes: grpc 标准错误码","text":"1. gRPC 回顾总结1.1 gRPC1go get -u google.golang.org/grpc 强大的 IDL，使用 Protocol Buffers 作为数据交换格式 跨语言、跨平台 支持HTTP2，双向传输、多路复用、认证等 grpc下常用包： metadata: 提供方法对 grpc 元数据结构MD 进行获取和处理 credentials: 封装了客户端对服务端进行身份验证所需的所有状态，并做出各种断言 codes: grpc 标准错误码 1.2 Protoc Plugin编译插件 1go get -u github.com/golang/protobuf/protoc-gen-go 1.3 Protocol Buffers v3Google 推出的一种数据描述语言，支持多语言、跨平台，二进制格式。 1.4 protocProtocol Buffers 运用程序 123456wget https://github.com/google/protobuf/releases/download/v3.5.1/protobuf-all-3.5.1.zipunzip protobuf-all-3.5.1.zipcd protobuf-3.5.1/./configuremakemake install 生成 golang 源文件： 1protoc --go_out=plugins=grpc,import_path=mypkg:. *.proto 2. gRPC-Gatewaygrpc-gateway 是proto的一个插件，它读取gRPC服务定义，并生成一个反向代理服务器，将RESTful JSON API转换为gRPC. 2.1 安装1go get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gateway 2.2 proto文件2.2.1 google.apigoogle 官方提供的 api 描述文件，主要针对 grpc-gateway 的 http 转换支持，定义了 Protocol Buffer 所扩展的 HTTP Option 1) annotations.proto 1234567891011121314151617181920212223242526272829// Copyright (c) 2015, Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.syntax = &quot;proto3&quot;;package google.api;import &quot;google/api/http.proto&quot;;import &quot;google/protobuf/descriptor.proto&quot;;option java_multiple_files = true;option java_outer_classname = &quot;AnnotationsProto&quot;;option java_package = &quot;com.google.api&quot;;extend google.protobuf.MethodOptions &#123; // See `HttpRule`. HttpRule http = 72295728;&#125; 2) http.proto 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281// Copyright 2016 Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.syntax = &quot;proto3&quot;;package google.api;option cc_enable_arenas = true;option java_multiple_files = true;option java_outer_classname = &quot;HttpProto&quot;;option java_package = &quot;com.google.api&quot;;// Defines the HTTP configuration for a service. It contains a list of// [HttpRule][google.api.HttpRule], each specifying the mapping of an RPC method// to one or more HTTP REST API methods.message Http &#123; // A list of HTTP rules for configuring the HTTP REST API methods. repeated HttpRule rules = 1;&#125;// `HttpRule` defines the mapping of an RPC method to one or more HTTP// REST APIs. The mapping determines what portions of the request// message are populated from the path, query parameters, or body of// the HTTP request. The mapping is typically specified as an// `google.api.http` annotation, see &quot;google/api/annotations.proto&quot;// for details.//// The mapping consists of a field specifying the path template and// method kind. The path template can refer to fields in the request// message, as in the example below which describes a REST GET// operation on a resource collection of messages://// ```proto// service Messaging &#123;// rpc GetMessage(GetMessageRequest) returns (Message) &#123;// option (google.api.http).get = &quot;/v1/messages/&#123;message_id&#125;/&#123;sub.subfield&#125;&quot;;// &#125;// &#125;// message GetMessageRequest &#123;// message SubMessage &#123;// string subfield = 1;// &#125;// string message_id = 1; // mapped to the URL// SubMessage sub = 2; // `sub.subfield` is url-mapped// &#125;// message Message &#123;// string text = 1; // content of the resource// &#125;// ```//// This definition enables an automatic, bidrectional mapping of HTTP// JSON to RPC. Example://// HTTP | RPC// -----|-----// `GET /v1/messages/123456/foo` | `GetMessage(message_id: &quot;123456&quot; sub: SubMessage(subfield: &quot;foo&quot;))`//// In general, not only fields but also field paths can be referenced// from a path pattern. Fields mapped to the path pattern cannot be// repeated and must have a primitive (non-message) type.//// Any fields in the request message which are not bound by the path// pattern automatically become (optional) HTTP query// parameters. Assume the following definition of the request message://// ```proto// message GetMessageRequest &#123;// message SubMessage &#123;// string subfield = 1;// &#125;// string message_id = 1; // mapped to the URL// int64 revision = 2; // becomes a parameter// SubMessage sub = 3; // `sub.subfield` becomes a parameter// &#125;// ```//// This enables a HTTP JSON to RPC mapping as below://// HTTP | RPC// -----|-----// `GET /v1/messages/123456?revision=2&amp;sub.subfield=foo` | `GetMessage(message_id: &quot;123456&quot; revision: 2 sub: SubMessage(subfield: &quot;foo&quot;))`//// Note that fields which are mapped to HTTP parameters must have a// primitive type or a repeated primitive type. Message types are not// allowed. In the case of a repeated type, the parameter can be// repeated in the URL, as in `...?param=A&amp;param=B`.//// For HTTP method kinds which allow a request body, the `body` field// specifies the mapping. Consider a REST update method on the// message resource collection://// ```proto// service Messaging &#123;// rpc UpdateMessage(UpdateMessageRequest) returns (Message) &#123;// option (google.api.http) = &#123;// put: &quot;/v1/messages/&#123;message_id&#125;&quot;// body: &quot;message&quot;// &#125;;// &#125;// &#125;// message UpdateMessageRequest &#123;// string message_id = 1; // mapped to the URL// Message message = 2; // mapped to the body// &#125;// ```//// The following HTTP JSON to RPC mapping is enabled, where the// representation of the JSON in the request body is determined by// protos JSON encoding://// HTTP | RPC// -----|-----// `PUT /v1/messages/123456 &#123; &quot;text&quot;: &quot;Hi!&quot; &#125;` | `UpdateMessage(message_id: &quot;123456&quot; message &#123; text: &quot;Hi!&quot; &#125;)`//// The special name `*` can be used in the body mapping to define that// every field not bound by the path template should be mapped to the// request body. This enables the following alternative definition of// the update method://// ```proto// service Messaging &#123;// rpc UpdateMessage(Message) returns (Message) &#123;// option (google.api.http) = &#123;// put: &quot;/v1/messages/&#123;message_id&#125;&quot;// body: &quot;*&quot;// &#125;;// &#125;// &#125;// message Message &#123;// string message_id = 1;// string text = 2;// &#125;// ```//// The following HTTP JSON to RPC mapping is enabled://// HTTP | RPC// -----|-----// `PUT /v1/messages/123456 &#123; &quot;text&quot;: &quot;Hi!&quot; &#125;` | `UpdateMessage(message_id: &quot;123456&quot; text: &quot;Hi!&quot;)`//// Note that when using `*` in the body mapping, it is not possible to// have HTTP parameters, as all fields not bound by the path end in// the body. This makes this option more rarely used in practice of// defining REST APIs. The common usage of `*` is in custom methods// which don&#x27;t use the URL at all for transferring data.//// It is possible to define multiple HTTP methods for one RPC by using// the `additional_bindings` option. Example://// ```proto// service Messaging &#123;// rpc GetMessage(GetMessageRequest) returns (Message) &#123;// option (google.api.http) = &#123;// get: &quot;/v1/messages/&#123;message_id&#125;&quot;// additional_bindings &#123;// get: &quot;/v1/users/&#123;user_id&#125;/messages/&#123;message_id&#125;&quot;// &#125;// &#125;;// &#125;// &#125;// message GetMessageRequest &#123;// string message_id = 1;// string user_id = 2;// &#125;// ```//// This enables the following two alternative HTTP JSON to RPC// mappings://// HTTP | RPC// -----|-----// `GET /v1/messages/123456` | `GetMessage(message_id: &quot;123456&quot;)`// `GET /v1/users/me/messages/123456` | `GetMessage(user_id: &quot;me&quot; message_id: &quot;123456&quot;)`//// # Rules for HTTP mapping//// The rules for mapping HTTP path, query parameters, and body fields// to the request message are as follows://// 1. The `body` field specifies either `*` or a field path, or is// omitted. If omitted, it assumes there is no HTTP body.// 2. Leaf fields (recursive expansion of nested messages in the// request) can be classified into three types:// (a) Matched in the URL template.// (b) Covered by body (if body is `*`, everything except (a) fields;// else everything under the body field)// (c) All other fields.// 3. URL query parameters found in the HTTP request are mapped to (c) fields.// 4. Any body sent with an HTTP request can contain only (b) fields.//// The syntax of the path template is as follows://// Template = &quot;/&quot; Segments [ Verb ] ;// Segments = Segment &#123; &quot;/&quot; Segment &#125; ;// Segment = &quot;*&quot; | &quot;**&quot; | LITERAL | Variable ;// Variable = &quot;&#123;&quot; FieldPath [ &quot;=&quot; Segments ] &quot;&#125;&quot; ;// FieldPath = IDENT &#123; &quot;.&quot; IDENT &#125; ;// Verb = &quot;:&quot; LITERAL ;//// The syntax `*` matches a single path segment. It follows the semantics of// [RFC 6570](https://tools.ietf.org/html/rfc6570) Section 3.2.2 Simple String// Expansion.//// The syntax `**` matches zero or more path segments. It follows the semantics// of [RFC 6570](https://tools.ietf.org/html/rfc6570) Section 3.2.3 Reserved// Expansion.//// The syntax `LITERAL` matches literal text in the URL path.//// The syntax `Variable` matches the entire path as specified by its template;// this nested template must not contain further variables. If a variable// matches a single path segment, its template may be omitted, e.g. `&#123;var&#125;`// is equivalent to `&#123;var=*&#125;`.//// NOTE: the field paths in variables and in the `body` must not refer to// repeated fields or map fields.//// Use CustomHttpPattern to specify any HTTP method that is not included in the// `pattern` field, such as HEAD, or &quot;*&quot; to leave the HTTP method unspecified for// a given URL path rule. The wild-card rule is useful for services that provide// content to Web (HTML) clients.message HttpRule &#123; // Selects methods to which this rule applies. // // Refer to [selector][google.api.DocumentationRule.selector] for syntax details. string selector = 1; // Determines the URL pattern is matched by this rules. This pattern can be // used with any of the &#123;get|put|post|delete|patch&#125; methods. A custom method // can be defined using the &#x27;custom&#x27; field. oneof pattern &#123; // Used for listing and getting information about resources. string get = 2; // Used for updating a resource. string put = 3; // Used for creating a resource. string post = 4; // Used for deleting a resource. string delete = 5; // Used for updating a resource. string patch = 6; // Custom pattern is used for defining custom verbs. CustomHttpPattern custom = 8; &#125; // The name of the request field whose value is mapped to the HTTP body, or // `*` for mapping all fields not captured by the path pattern to the HTTP // body. NOTE: the referred field must not be a repeated field. string body = 7; // Additional HTTP bindings for the selector. Nested bindings must // not contain an `additional_bindings` field themselves (that is, // the nesting may only be one level deep). repeated HttpRule additional_bindings = 11;&#125;// A custom pattern is used for defining custom HTTP verb.message CustomHttpPattern &#123; // The name of this custom HTTP verb. string kind = 1; // The path matched by this custom verb. string path = 2;&#125; 2.2.2 hello.proto12345678910111213141516171819202122syntax = &quot;proto3&quot;;package proto;import &quot;google/api/annotations.proto&quot;;service HelloWorld &#123; rpc SayHelloWorld(HelloWorldRequest) returns (HelloWorldResponse) &#123; option (google.api.http) = &#123; post: &quot;/hello_world&quot; body: &quot;*&quot; &#125;; &#125;&#125;message HelloWorldRequest &#123; string referer = 1;&#125;message HelloWorldResponse &#123; string message = 1;&#125; 2.3 编译 proto12345678# 编译google.apiprotoc -I . --go_out=plugins=grpc,Mgoogle/protobuf/descriptor.proto=github.com/golang/protobuf/protoc-gen-go/descriptor:. google/api/*.proto# 编译hello_http.proto为hello_http.pb.protoprotoc -I . --go_out=plugins=grpc,Mgoogle/api/annotations.proto=go-grpc-example/proto/google/api:. ./hello.proto# 编译hello_http.proto为hello_http.pb.gw.protoprotoc --grpc-gateway_out=logtostderr=true:. ./hello.proto 3. 命令行模块3.1 安装Cobra命令行工具1go get -u github.com/spf13/cobra 1) root.go 12345678910var rootCmd = &amp;cobra.Command&#123; Use: &quot;grpc&quot;, Short: &quot;Run the gRPC hello-world server&quot;,&#125;func Execute() &#123; if err := rootCmd.Execute(); err != nil &#123; log.Fatalf(&quot;rootCmd.Execute err: %v&quot;, err) &#125;&#125; 2) server.go 12345678910111213141516171819202122var serverCmd = &amp;cobra.Command&#123; Use: &quot;server&quot;, Short: &quot;Run the gRPC hello-world server&quot;, Run: func(cmd *cobra.Command, args []string) &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Println(&quot;Recover error: %v&quot;, err) &#125; &#125;() server.Serve() &#125;,&#125;func init() &#123; serverCmd.Flags().StringVarP(&amp;server.ServerPort, &quot;port&quot;, &quot;p&quot;, &quot;9005&quot;, &quot;server port&quot;) serverCmd.Flags().StringVarP(&amp;server.CertPath, &quot;cert&quot;, &quot;c&quot;, &quot;../../certs/server.pem&quot;, &quot;cert path&quot;) serverCmd.Flags().StringVarP(&amp;server.KeyPath, &quot;key&quot;, &quot;k&quot;, &quot;../../certs/server.key&quot;, &quot;key path&quot;) serverCmd.Flags().StringVarP(&amp;server.CertName, &quot;name&quot;, &quot;n&quot;, &quot;go-grpc-example&quot;, &quot;server hostname&quot;) rootCmd.AddCommand(serverCmd)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go gRPC","slug":"Go gRPC","date":"2019-07-18T01:23:17.000Z","updated":"2021-06-22T10:50:49.737Z","comments":true,"path":"2019/07/18/Go gRPC/","link":"","permalink":"https://elihe2011.github.io/2019/07/18/Go%20gRPC/","excerpt":"1. RPC1.1 什么是RPCRPC: Remote Procedure Call，远程过程调用。调用过程包括传输协议和对象编码（序列化）。 1.2 RPC框架 负载均衡 服务注册和发现 服务治理 1.3 为什么使用RPC简单、通用、安全、效率","text":"1. RPC1.1 什么是RPCRPC: Remote Procedure Call，远程过程调用。调用过程包括传输协议和对象编码（序列化）。 1.2 RPC框架 负载均衡 服务注册和发现 服务治理 1.3 为什么使用RPC简单、通用、安全、效率 2. ProtobufProtocol Buffers 是一种与语言、平台无关，可扩展的序列化结构化数据的方法，常用于通信协议、数据存储等。相较于JSON、XML，它更小、更快、更简单。 123456789101112131415syntax = &quot;proto3&quot;;service SearchService &#123; rpc Search (SearchRequest) returns (SearchResponse);&#125;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125;message SearchResponse &#123; ...&#125; 3. gRPCgRPC 是一个高性能、开源和通用的RPC框架，面向移动和 HTTP/2 设计 特点： HTTP/2 Protobuf 客户端、服务端基于同一份IDL 移动网络支持良好 支持多语言 3.1 安装gRPC: 1go get -u google.golang.org/grpc Protocol Buffers v3: 12brew search protobufbrew install protobuf@3.6 Protoc Plugin: 12345# 会自动编译安装protoc-gen-go可执行插件文件go get -u github.com/golang/protobuf/protoc-gen-go# 编译安装 (不要做这个操作，应该使用上面一个protoc-gen-go)#go install google.golang.org/protobuf/cmd/protoc-gen-go 3.2 入门3.2.1 编写 IDL1234567891011121314151617syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;; // 重要package proto;service SearchService &#123; rpc Search(SearchRequest) returns (SearchResponse) &#123;&#125;&#125;message SearchRequest &#123; string request = 1;&#125;message SearchResponse &#123; string response = 1;&#125; 3.2.2 生成 pb.go文件1234protoc --go_out=. *.proto# 比前一个多了注册函数等protoc --go_out=plugins=grpc:. *.proto 3.2.3 服务端12345678910111213141516171819type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;const HOST = &quot;:9001&quot;func main() &#123; server := grpc.NewServer() pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, HOST) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 3.2.4 客户端1234567891011121314151617func main() &#123; conn, err := grpc.Dial(HOST, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 4. gRPC 流gRPC 的流式，有三种类型： Server-side Streaming Client-side Streaming Bidirectional Streaming 适合用 Streaming RPC 的场景： 大规模数据包 实时场景 4.1 IDL 和 基础模板1234567891011121314151617181920212223242526syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;;package proto;service StreamService &#123; rpc List(StreamRequest) returns (stream StreamResponse) &#123;&#125;; rpc Record(stream StreamRequest) returns (stream StreamResponse) &#123;&#125;; rpc Route(stream StreamRequest) returns (stream StreamResponse) &#123;&#125;;&#125;message StreamPoint &#123; string name = 1; int32 value = 2;&#125;message StreamRequest &#123; StreamPoint pt = 1;&#125;message StreamResponse &#123; StreamPoint pt = 1;&#125; 服务器： 1234567891011121314151617181920212223func main() &#123; server := grpc.NewServer() pb.RegisterStreamServiceServer(server, &amp;StreamService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9002&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error &#123; return nil&#125;func (s *StreamService) Record(stream pb.StreamService_RecordServer) error &#123; return nil&#125;func (s *StreamService) Route(stream pb.StreamService_RouteServer) error &#123; return nil&#125; 客户端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func main() &#123; conn, err := grpc.Dial(&quot;:9002&quot;, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;grpc.Dial err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewStreamServiceClient(conn) err = printList(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: List&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printList.err: %v&quot;, err) &#125; err = printRecord(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: Record&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printRecord.err: %v&quot;, err) &#125; err = printRoute(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: Route&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printRoute.err: %v&quot;, err) &#125;&#125;func printList(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125;func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125;func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125; 4.2 服务器端流式 RPC 单向流 Server 为 Stream，多次向客户端发送数据 Client 为普通 RPC 请求 4.2.1 服务端12345678910111213141516func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error &#123; for n := 0; n &lt;= 6; n++ &#123; err := stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: r.Pt.Name, Value: r.Pt.Value + int32(n), &#125;, &#125;) if err != nil &#123; return nil &#125; &#125; return nil&#125; stream.Send() 方法： 12345678type StreamService_ListServer interface &#123; Send(*StreamResponse) error grpc.ServerStream&#125;func (x *streamServiceListServer) Send(m *StreamResponse) error &#123; return x.ServerStream.SendMsg(m)&#125; SendMsg() 方法： 消息体（对象）序列化 压缩序列化后的消息体 对正在传输的消息体增加5个字节的header 判断消息体总长度是否大于预设的maxSendMessageSize (默认math.MaxInt32)，超过则报错 写入给流的数据集 4.2.2 客户端12345678910111213141516171819202122func printList(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.List(context.Background(), r) if err != nil &#123; return err &#125; for &#123; resp, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;resp: pt.name: %s, pt.value: %d\\n&quot;, resp.Pt.Name, resp.Pt.Value) &#125; return nil&#125; stream.Recv()方法： 12345678910111213type StreamService_ListClient interface &#123; Recv() (*StreamResponse, error) grpc.ClientStream&#125;func (x *streamServiceListClient) Recv() (*StreamResponse, error)&#123; m := new(StreamResponse) if err := x.ClientStream.RecvMsg(m); err != nil &#123; return nil, err &#125; return m, nil&#125; RecvMsg()方法： 阻塞等待 流结束 (Close)时，返回 io.EOF 可能的错误 io.EOF io.ErrUnexpectedEOF transport.ConnectionError google.golang.org/grpc/codes 4.3 客户端流式RPC 单向流 客户端多次RPC请求服务端 服务端发起一次响应给客户端 4.3.1 服务端12345678910111213141516171819func (s *StreamService) Record(stream pb.StreamService_RecordServer) error &#123; for &#123; r, err := stream.Recv() if err == io.EOF &#123; return stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Server: Record&quot;, Value: 1, &#125;, &#125;) &#125; if err != nil &#123; return err &#125; log.Printf(&quot;stream.Recv pt.name: %s, pt.value: %d&quot;, r.Pt.Name, r.Pt.Value) &#125; return nil&#125; 4.3.2 客户端12345678910111213141516171819202122232425262728func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.Record(context.Background()) if err != nil &#123; return err &#125; for n := 0; n &lt; 6; n++ &#123; err := stream.Send(r) if err != nil &#123; return err &#125; &#125; // 主动关闭send err = stream.CloseSend() if err != nil &#123; return err &#125; resp, err := stream.Recv() if err != nil &#123; return nil &#125; log.Printf(&quot;resp: pt.name: %s, pt.value: %d&quot;, resp.Pt.Name, resp.Pt.Value) return nil&#125; 4.4 双向流RPC4.4.1 服务端12345678910111213141516171819202122232425262728func (s *StreamService) Route(stream pb.StreamService_RouteServer) error &#123; n := 0 for &#123; err := stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gPRC Stream Client: Route&quot;, Value: int32(n), &#125;, &#125;) if err != nil &#123; return err &#125; r, err := stream.Recv() if err == io.EOF &#123; return nil &#125; if err != nil &#123; return err &#125; n++ log.Printf(&quot;stream.Recv pt.name: %s, pt.value: %d&quot;, r.Pt.Name, r.Pt.Value) &#125; return nil&#125; 4.4.2 客户端12345678910111213141516171819202122232425262728func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.Route(context.Background()) if err != nil &#123; return err &#125; for n := 0; n &lt; 6; n++ &#123; err = stream.Send(r) if err != nil &#123; return err &#125; resp, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;resp: pt.name: %s, pt.value %d&quot;, resp.Pt.Name, resp.Pt.Value) &#125; stream.CloseSend() return nil&#125; 5. TLS 证书认证5.1 生成证书5.1.1 私钥1openssl ecparam -genkey -name secp384r1 -out server.key 5.1.2 自签公钥1openssl req -new -x509 -sha256 -key server.key -out server.pem -days 3650 5.2 服务端123456789101112131415161718192021222324252627type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;const HOST = &quot;:9001&quot;func main() &#123; // 1. 支持TLS creds, err := credentials.NewServerTLSFromFile(&quot;../certs/server.pem&quot;, &quot;../certs/server.key&quot;) if err != nil &#123; log.Fatalf(&quot;credentials.NewServerTLSFromFile err: %v&quot;, err) &#125; // 2. 加入认证 server := grpc.NewServer(grpc.Creds(creds)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, HOST) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 5.3 客户端1234567891011121314151617181920212223242526const HOST = &quot;:9001&quot;func main() &#123; // 1. 支持TLS creds, err := credentials.NewClientTLSFromFile(&quot;../certs/server.pem&quot;, &quot;go-grpc-example&quot;) if err != nil &#123; log.Fatalf(&quot;credentials.NewClientTLSFromFile err: %v&quot;, err) &#125; // 2. 传输认证 conn, err := grpc.Dial(HOST, grpc.WithTransportCredentials(creds)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 6. 基于 CA 的 TLS 证书认证6.1 CA6.1.1 生成CA证书根证书(root certificate)是属于根证书颁发机构（CA）的公钥证书。可以通过验证CA的签名从而信任CA，任何人都可以得到CA的证书（含公钥），用以验证它所签发的证书。 12345# 生成Keyopenssl genrsa -out ca.key 2048# 生成密钥openssl req -new -x509 -days 7200 -key ca.key -out ca.pem 6.1.2 服务端证书CSR: Cerificate Signing Request，证书请求文件。主要作用是 CA 会利用 CSR 文件进行签名使得攻击者无法伪装或篡改原有证书。 12345# 生成CSRopenssl req -new -key server.key -out server.csr# 基于CA签发openssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in server.csr -out server.pem 6.1.3 客户端证书12345678# 生成Keyopenssl ecparam -genkey -name secp384r1 -out client.key# 生成CSRopenssl req -new -key client.key -out client.csr# 基于CA签发openssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in client.csr -out client.pem 6.2 TLS认证代码6.2.1 服务端认证123456789101112131415161718192021222324252627282930313233343536373839type Server struct &#123; CaFile string CertFile string KeyFile string&#125;func (t *Server) GetCredentialsByCA() (credentials.TransportCredentials, error) &#123; cert, err := tls.LoadX509KeyPair(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; ca, err := ioutil.ReadFile(t.CaFile) if err != nil &#123; return nil, err &#125; certPool := x509.NewCertPool() if ok := certPool.AppendCertsFromPEM(ca); !ok &#123; return nil, errors.New(&quot;certPool.AppendCertsFromPEM err&quot;) &#125; c := credentials.NewTLS(&amp;tls.Config&#123; Certificates: []tls.Certificate&#123;cert&#125;, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, &#125;) return c, nil&#125;func (t *Server) GetTLSCredentials() (credentials.TransportCredentials, error) &#123; c, err := credentials.NewServerTLSFromFile(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; return c, nil&#125; 6.2.2 客户端认证12345678910111213141516171819202122232425262728293031323334353637383940type Client struct &#123; ServerName string CaFile string CertFile string KeyFile string&#125;func (t *Client) GetCredentialsByCA() (credentials.TransportCredentials, error) &#123; cert, err := tls.LoadX509KeyPair(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; ca, err := ioutil.ReadFile(t.CaFile) if err != nil &#123; return nil, err &#125; certPool := x509.NewCertPool() if ok := certPool.AppendCertsFromPEM(ca); !ok &#123; return nil, errors.New(&quot;certPool.AppendCertsFromPEM err&quot;) &#125; c := credentials.NewTLS(&amp;tls.Config&#123; Certificates: []tls.Certificate&#123;cert&#125;, ServerName: t.ServerName, RootCAs: certPool, &#125;) return c, nil&#125;func (t *Client) GetTLSCredentials() (credentials.TransportCredentials, error) &#123; c, err := credentials.NewClientTLSFromFile(t.CertFile, t.ServerName) if err != nil &#123; return nil, err &#125; return c, nil&#125; 6.3 实现代码6.3.1 服务端1234567891011121314151617181920212223242526272829type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 6.3.2 客户端1234567891011121314151617181920212223242526272829func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/client.pem&quot;, KeyFile: &quot;../../certs/client.key&quot;, &#125; c, err := tlsClient.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetCredentialsByCA err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9001&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 大致流程： Client 通过请求得到 Server 端的证书 使用 CA 认证的根证书对 Server 端证书进行可靠性、有效性等校验 校验 ServerName 是否有效 同样，在设置了 tls.RequireAndVerifyClientCert 模式下，Server 也会使用 CA 认证的根证书对Client的证书进行可靠性、有效性校验。 6.4 补充知识点：ssl/tls 单向认证双向认证 单向认证：只有一个对象校验对端的证书合法性。通常client来校验服务器的合法性。那么client需要一个ca.crt,服务器需要server.crt,server.key。 双向认证：相互校验，服务器需要校验每个client,client也需要校验服务器。server 需要 server.key、server.crt、ca.crt，client 需要 client.key、client.crt、ca.crt。 7. 拦截器7.1 Unary and Stream interceptor 普通方法：一元拦截器 grpc.UnaryInterceptor 流方法：流拦截器 grpc.StreamInterceptor 7.1.1 grpc.UnaryInterceptor12345678910func UnaryInterceptor(i UnaryServerInterceptor) ServerOption &#123; return func(o *options) &#123; if o.unaryInt != nil &#123; panic(&quot;The unary server interceptor was already set and may not be reset.&quot;) &#125; o.unaryInt = i &#125;&#125;type UnaryServerInterceptor func(ctx context.Context, req interface&#123;&#125;, info *UnaryServerInfo, handler UnaryHandler) (resp interface&#123;&#125;, err error) 7.1.2 grpc.StreamInterceptor123func StreamInterceptor(i StreamServerInterceptor) ServerOptionstype StreamServerInterceptor func(srv interface&#123;&#125;, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error 7.2 实现多个拦截器gRPC本身只能设置一个拦截器，但可以采用go-grpc-middleware项目来解决问题 12345678910import &quot;github.com/grpc-ecosystem/go-grpc-middleware&quot;myServer := grpc.NewServer( grpc.StreamInterceptor(grpc_middleware.ChainStreamServer( ... )), grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer( ... )),) 7.3 实现 logging 和 recover 拦截器7.3.1 logging123456func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125; 7.3.2 recover12345678910func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 7.3.3 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; // 服务选项 opts := []grpc.ServerOption&#123; grpc.Creds(c), grpc_middleware.WithUnaryServerChain( RecoveryInterceptor, LoggingInterceptor, ), &#125; server := grpc.NewServer(opts...) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125;func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 8. 同时提供 HTTP 服务8.1 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; http.ListenAndServeTLS( &quot;:9003&quot;, &quot;../../certs/server.pem&quot;, &quot;../../certs/server.key&quot;, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if r.ProtoMajor == 2 &amp;&amp; strings.Contains(r.Header.Get(&quot;Content-Type&quot;), &quot;application/grpc&quot;) &#123; GetHTTPServeGrpc().ServeHTTP(w, r) &#125; else &#123; GetHTTPServeMux().ServeHTTP(w, r) &#125; &#125;), )&#125;func GetHTTPServeGrpc() *grpc.Server &#123; tlsServer := gtls.Server&#123; CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetTLSCredentials err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) return server&#125;func GetHTTPServeMux() *http.ServeMux &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte(&quot;result: go-grpc-example&quot;)) &#125;) return mux&#125; 8.2 gRPC 客户端123456789101112131415161718192021222324252627func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CertFile: &quot;../../certs/server.pem&quot;, &#125; c, err := tlsClient.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetTLSCredentials err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9003&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 8.3 http/1.1 直接访问123curl -k --cert client.pem --key client.key https://127.0.0.1:9003curl -k --cacert ca.pem https://127.0.0.1:9003 9. 自定义认证9.1 自定义认证接口1234567type PerRPCCredentials interface &#123; // 获取当前请求认证所需的元数据 (metadata) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) // 是否需要基于TLS认证安全传输 RequireTransportSecurity() bool&#125; 9.2 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273type SearchService struct &#123; auth *Auth&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; if err := s.auth.Check(ctx); err != nil &#123; return nil, err &#125; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetTLSCredentials err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9004&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;type Auth struct &#123; appKey string appSecret string&#125;func (a *Auth) Check(ctx context.Context) error &#123; md, ok := metadata.FromIncomingContext(ctx) if !ok &#123; return status.Errorf(codes.Unauthenticated, &quot;metadata.FromIncomingContext err&quot;) &#125; var ( appKey string appSecret string ) if value, ok := md[&quot;app_key&quot;]; ok &#123; appKey = value[0] &#125; if value, ok := md[&quot;app_secret&quot;]; ok &#123; appSecret = value[0] &#125; if appKey != a.GetAppKey() || appSecret != a.GetAppSecret() &#123; return status.Errorf(codes.Unauthenticated, &quot;invalid token&quot;) &#125; return nil&#125;func (a *Auth) GetAppKey() string &#123; return &quot;wx20200719163021&quot;&#125;func (a *Auth) GetAppSecret() string &#123; return &quot;7d13b90ae8e40c0160209c4a985b3bdf01321b15&quot;&#125; 9.3 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type Auth struct &#123; AppKey string AppSecret string&#125;func (a *Auth) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) &#123; return map[string]string&#123; &quot;app_key&quot;: a.AppKey, &quot;app_secret&quot;: a.AppSecret, &#125;, nil&#125;func (a *Auth) RequireTransportSecurity() bool &#123; return true&#125;func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CertFile: &quot;../../certs/server.pem&quot;, &#125; c, err := tlsClient.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetTLSCredentials err: %v&quot;, err) &#125; auth := Auth&#123; AppKey: &quot;wx20200719163021&quot;, AppSecret: &quot;7d13b90ae8e40c0160209c4a985b3bdf01321b15&quot;, &#125; conn, err := grpc.Dial(&quot;:9004&quot;, grpc.WithTransportCredentials(c), grpc.WithPerRPCCredentials(&amp;auth)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 10. gRPC Deadline10.1 为什么要设置Deadline? 未设置 Deadlines 时，将采用默认的 DEADLINE_EXCEEDED（该时间非常大） 产生阻塞等待时，会造成大量正在进行的请求被保留，直到这些请求都达到最大超时 会导致资源耗尽的风险，也会增加服务的延迟，最坏时可能导致整个进出崩溃 10.2 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; // Deadline if ctx.Err() == context.Canceled &#123; return nil, status.Errorf(codes.Canceled, &quot;SearchService.Search canceled&quot;) &#125; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; // 服务选项 opts := []grpc.ServerOption&#123; grpc.Creds(c), grpc_middleware.WithUnaryServerChain( RecoveryInterceptor, LoggingInterceptor, ), &#125; server := grpc.NewServer(opts...) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125;func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 10.3 客户端12345678910111213141516171819202122232425262728293031323334353637383940func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/client.pem&quot;, KeyFile: &quot;../../certs/client.key&quot;, &#125; c, err := tlsClient.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetCredentialsByCA err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9001&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() // Deadlines ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Duration(5*time.Second))) defer cancel() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(ctx, &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; statusErr, ok := status.FromError(err) if ok &#123; if statusErr.Code() == codes.DeadlineExceeded &#123; log.Fatalf(&quot;client.Search err: deadline&quot;) &#125; &#125; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go 加密签名","slug":"Go 加密签名","date":"2019-07-07T01:21:53.000Z","updated":"2021-06-22T10:50:49.736Z","comments":true,"path":"2019/07/07/Go 加密签名/","link":"","permalink":"https://elihe2011.github.io/2019/07/07/Go%20%E5%8A%A0%E5%AF%86%E7%AD%BE%E5%90%8D/","excerpt":"1. 加密字符串格式密钥、密文、签名的加密字符串格式 1.1 hex123hex.DecodeString(s string)hex.EncodeToString(src []byte) string","text":"1. 加密字符串格式密钥、密文、签名的加密字符串格式 1.1 hex123hex.DecodeString(s string)hex.EncodeToString(src []byte) string 1.2 base64123base64.StdEncoding.DecodeString(s string) ([]byte, error)base64.StdEncoding.EncodeToString(src []byte) string 2. 私钥格式2.1 PKCS11x509.ParsePKCS1PrivateKey(der []byte) (key interface&#123;&#125;, err error) 2.2 PKCS81x509.ParsePCKS8PrivateKey(der []byte) (key interface&#123;&#125;, err error) 3. SHA算法3.1 SHA1123hash := sha1.New()hash.Write([]byte(plainText))cipherText, err := rsa.SignPKCS1v15(rand.Reader, prvKey, crypto.SHA1, hash.Sum(nil)) 3.2 SHA256123hash := sha256.New()hash.Write([]byte(plainText))cipherText, err := rsa.SignPKCS1v15(rand.Reader, prvKey, crypto.SHA256, hash.Sum(nil)) 4. RSA4.1 加密1rsa.EncryptPKCS1v15(rand io.Reader, pub *PublicKey, plaintext []byte) ([]byte, error) 4.2 解密1rsa.DecryptPKCS1v15(rand io.Reader, priv *PrivateKey, ciphertext []byte) ([]byte, error) 4.3 签名1rsa.SignPKCS1v15(rand io.Reader, priv *PrivateKey, hash crypto.Hash, hashed []byte) ([]byte, error) 4.4 验签1rsa.VerifyPKCS1v15(pub *PublicKey, hash crypto.Hash, hashed []byte, sig []byte) error 5. 应用示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import ( &quot;crypto&quot; &quot;crypto/rand&quot; &quot;crypto/rsa&quot; &quot;crypto/sha1&quot; &quot;crypto/x509&quot; &quot;encoding/base64&quot; &quot;encoding/hex&quot;)func RsaEncryptWithSha1Base64(plaintext, publicKey string) (string, error) &#123; key, _ := base64.StdEncoding.DecodeString(publicKey) pubKey, _ := x509.ParsePKIXPublicKey(key) ciphertext, err := rsa.EncryptPKCS1v15(rand.Reader, pubKey.(*rsa.PublicKey), []byte(plaintext)) if err != nil &#123; return &quot;&quot;, err &#125; return base64.StdEncoding.EncodeToString(ciphertext), nil&#125;func RsaDecryptWithSha1Base64(ciphertext, privateKey string) (string, error) &#123; ciphertextBytes, err := base64.StdEncoding.DecodeString(ciphertext) if err != nil &#123; return &quot;&quot;, err &#125; key, _ := base64.StdEncoding.DecodeString(privateKey) prvKey, _ := x509.ParsePKCS1PrivateKey(key) plaintext, err := rsa.DecryptPKCS1v15(rand.Reader, prvKey, ciphertextBytes) return string(plaintext), err&#125;func RsaSignWithSha1Hex(data, privateKey string) (string, error) &#123; key, err := hex.DecodeString(privateKey) if err != nil &#123; return &quot;&quot;, err &#125; prvKey, err := x509.ParsePKCS8PrivateKey(key) if err != nil &#123; return &quot;&quot;, err &#125; hash := sha1.New() hash.Write([]byte(data)) signature, err := rsa.SignPKCS1v15(rand.Reader, prvKey.(*rsa.PrivateKey), crypto.SHA1, hash.Sum(nil)) if err != nil &#123; return &quot;&quot;, err &#125; return hex.EncodeToString(signature), nil&#125;func RsaVerifySignWithSha1Base64(data, signature, publicKey string) error &#123; sign, err := base64.StdEncoding.DecodeString(signature) if err != nil &#123; return err &#125; key, _ := base64.StdEncoding.DecodeString(publicKey) pubKey, err := x509.ParsePKIXPublicKey(key) if err != nil &#123; return err &#125; hash := sha1.New() hash.Write([]byte(data)) return rsa.VerifyPKCS1v15(pubKey.(*rsa.PublicKey), crypto.SHA1, hash.Sum(nil), sign)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 包管理","slug":"Go 包管理","date":"2019-07-01T08:41:28.000Z","updated":"2021-06-22T10:50:49.736Z","comments":true,"path":"2019/07/01/Go 包管理/","link":"","permalink":"https://elihe2011.github.io/2019/07/01/Go%20%E5%8C%85%E7%AE%A1%E7%90%86/","excerpt":"1. Go Modules1.1 简介Go Modules 是官方最新的包管理方式，它解决了如下问题： 所有的依赖包必须在 GOPATH 下，但同一个库只能保存一个版本 工作目录必须在 GOPATH/src 目录下 使用 Go Modules 之后，可在 GOPATH/src 之外创建目录和管理包 设置 go mod 和 go proxy: 12345go env -w GOBIN=/Users/eli/go/bingo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,directgo env GO111MODULE: on: 强制使用modules, 不再去GOPATH下查找 off: 不使用modules，去GOPATH和vendor下查找 auto: 默认值，如果当前目录下有go.mod文件，则使用modules","text":"1. Go Modules1.1 简介Go Modules 是官方最新的包管理方式，它解决了如下问题： 所有的依赖包必须在 GOPATH 下，但同一个库只能保存一个版本 工作目录必须在 GOPATH/src 目录下 使用 Go Modules 之后，可在 GOPATH/src 之外创建目录和管理包 设置 go mod 和 go proxy: 12345go env -w GOBIN=/Users/eli/go/bingo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,directgo env GO111MODULE: on: 强制使用modules, 不再去GOPATH下查找 off: 不使用modules，去GOPATH和vendor下查找 auto: 默认值，如果当前目录下有go.mod文件，则使用modules 1.2 基础命令123456789101112go help modgo mod &lt;command&gt; [arguments]download download modules to local cacheedit edit go.mod from tools or scriptsgraph print module requirement graphinit initialize new module in current directorytidy add missing and remove unused modulesvendor make vendored copy of dependenciesverify verify dependencies have expected contentwhy explain why packages or modules are needed 1.3 基本使用1.3.1 初始化123go mod init github.com/elihe2011/gomodgo get -u github.com/gin-gonic/gin 生成的文件： go.mod: 模块管理文件 module语句: 指定包的名字（路径） require语句: 指定的依赖项模块 replace语句: 可以替换依赖项模块 exclude语句: 可以忽略依赖项模块 go.sum: 记录依赖看的版本和哈希值 解决获取包时的代理错误： 12345678$ go get -u github.com/gin-gonic/gingo get github.com/gin-gonic/gin: module github.com/gin-gonic/gin: Get &quot;https://proxy.golang.org/github.com/gin-gonic/gin/@v/list&quot;: dial tcp 34.64.4.113:443: i/o timeout# go包管理,默认使用的是proxy.golang.org，在国内无法访问，换为go env -w GOPROXY=https://goproxy.cn,direct # 七牛云go env -w GOPROXY=https://mirrors.aliyun.com/goproxy/,direct 1.3.2 下载指定版本的依赖库1234567891011# 当前模块和支撑包go list -m all# 可用版本go list -m -versions github.com/gin-gonic/gin# 删除无效的modulesgo mod tidy# 获取指定版本go get github.com/gin-gonic/gin@ 1.4 编译打包1.4.1 使用GOPATH模式进行打包123export GO111MODULE=offexport CGO_ENABLED=0go build -a -v -o app main.go 1.4.2 使用vendor目录下包来进行打包123export GO111MODULE=onexport CGO_ENABLED=0go build -mod=vendor -a -v -o app main.go 1.5 go modules包管理特点 第三方包存储路径：$GOPATH/pkg/mod $GOPATH/pkg/mod 下可以保存相同包的不同版本 当项目放在 $GOPATH/src 时，GO111MODULE=auto 自动模式 依赖包中的地址失效了怎么办？比如 golang.org/x/… 下的包都无法下载怎么办？ 在go.mod文件里用 replace 替换包，例如replace golang.org/x/text =&gt; github.com/golang/text latest这样，go会用 github.com/golang/text 替代golang.org/x/text，原理就是下载github.com/golang/text 的最新版本到 $GOPATH/pkg/mod/golang.org/x/text下 2. govendorgovendor只是用来管理项目的依赖包，如果GOPATH中本身没有项目的依赖包，则需要通过go get先下载到GOPATH中，再通过govendor add +external拷贝到vendor目录中。Go 1.6以上版本默认开启GO15VENDOREXPERIMENT环境变量。 2.1 安装1go get -u -v github.com/kardianos/govendor 2.2 常用命令1234567891011121314151617181920212223# 初始化, 生成vender目录等govendor init# 添加包govendor add github.com/fvbock/endlessgovendor add +external# 移除包govendor remove github.com/fvbock/endlessgovendor remove +unused# 查看包govendor list# 列出所有缺失、过期和修改过的包govendor status# 本地存在 vendor.json 时候拉去依赖包，匹配所记录的版本govendor sync# 获取包govendor get github.com/gorilla/websocketgovendor fetch github.com/gorilla/websocket 2.3 包状态 状态 缩写状态 含义 +local l 本地包，即项目自身的包组织 +external e 外部包，即被 $GOPATH 管理，但不在 vendor 目录下 +vendor v 已被 govendor 管理，即在 vendor 目录下 +std s 标准库中的包 +unused u 未使用的包，即包在 vendor 目录下，但项目并没有用到 +missing m 代码引用了依赖包，但该包并没有找到 +program p 主程序包，意味着可以编译为执行文件 +outside o 外部包和缺失的包 +all a 所有的包","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Redis","slug":"Go Redis","date":"2019-05-20T02:49:39.000Z","updated":"2021-06-22T10:50:49.735Z","comments":true,"path":"2019/05/20/Go Redis/","link":"","permalink":"https://elihe2011.github.io/2019/05/20/Go%20Redis/","excerpt":"1. 入门1.1 安装1go get -u github.com/go-redis/redis 1.2 初始化连接1234567891011121314151617181920const ( REDIS_IP = &quot;127.0.0.1&quot; REDIS_PORT = &quot;6379&quot; REDIS_PWD = &quot;&quot; REDIS_DB = 0)var ( ctx = context.Background() rdb *redis.Client)func init() &#123; rdb = redis.NewClient(&amp;redis.Options&#123; Addr: REDIS_IP + &quot;:&quot; + REDIS_PORT, Password: REDIS_PWD, DB: REDIS_DB, PoolSize: 20, &#125;)&#125;","text":"1. 入门1.1 安装1go get -u github.com/go-redis/redis 1.2 初始化连接1234567891011121314151617181920const ( REDIS_IP = &quot;127.0.0.1&quot; REDIS_PORT = &quot;6379&quot; REDIS_PWD = &quot;&quot; REDIS_DB = 0)var ( ctx = context.Background() rdb *redis.Client)func init() &#123; rdb = redis.NewClient(&amp;redis.Options&#123; Addr: REDIS_IP + &quot;:&quot; + REDIS_PORT, Password: REDIS_PWD, DB: REDIS_DB, PoolSize: 20, &#125;)&#125; 2. 操作2.1 基本操作12345678910111213141516171819202122232425func Basic() &#123; keys := rdb.Keys(ctx, &quot;*&quot;).Val() fmt.Println(keys) size := rdb.DBSize(ctx).Val() fmt.Println(size) exist := rdb.Exists(ctx, &quot;name&quot;, &quot;age&quot;) fmt.Println(exist) del := rdb.Del(ctx, &quot;abc&quot;).Val() fmt.Println(del) ttl := rdb.TTL(ctx, &quot;age&quot;).Val() fmt.Println(ttl) expire := rdb.Expire(ctx, &quot;age&quot;, time.Second*60).Val() fmt.Println(expire) _type := rdb.Type(ctx, &quot;name&quot;).Val() fmt.Println(_type) key := rdb.RandomKey(ctx).Val() fmt.Println(key)&#125; 2.2 String1234567891011121314151617181920212223242526272829303132func String() &#123; var ret interface&#123;&#125; ret = rdb.Set(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour*24).Val() fmt.Println(ret) // set if not exist ret = rdb.SetNX(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour).Val() fmt.Println(ret) // set if exist ret = rdb.SetXX(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour*12).Val() fmt.Println(ret) ret = rdb.Get(ctx, &quot;name&quot;) fmt.Println(ret) ret = rdb.MGet(ctx, &quot;name&quot;, &quot;age&quot;) fmt.Println(ret) ret = rdb.Incr(ctx, &quot;age&quot;).Val() fmt.Println(ret) ret = rdb.Decr(ctx, &quot;age&quot;).Val() fmt.Println(ret) ret = rdb.Append(ctx, &quot;name&quot;, &quot;he&quot;) fmt.Println(ret) ret = rdb.StrLen(ctx, &quot;name&quot;) fmt.Println(ret)&#125; 2.3 Hashmap1234567891011121314151617181920212223242526272829303132func Hashmap() &#123; key := &quot;account&quot; field := &quot;name&quot; fields := map[string]interface&#123;&#125;&#123; &quot;city&quot;: &quot;beijing&quot;, &quot;age&quot;: 27, &quot;skills&quot;: &quot;golang&quot;, &#125; rdb.HSet(ctx, key, field, &quot;jack&quot;) rdb.HMSet(ctx, key, fields) name := rdb.HGet(ctx, key, &quot;name&quot;) fmt.Println(name) items := rdb.HKeys(ctx, key).Val() fmt.Println(items) vals := rdb.HVals(ctx, key).Val() fmt.Println(vals) exist := rdb.HExists(ctx, key, &quot;city&quot;) fmt.Println(exist) rdb.HIncrBy(ctx, key, &quot;age&quot;, 1) values := rdb.HMGet(ctx, key, &quot;name&quot;, &quot;age&quot;).Val() fmt.Println(values) valuesAll := rdb.HGetAll(ctx, key).Val() fmt.Println(valuesAll)&#125; 2.4 List1234567891011121314151617181920212223242526272829func List() &#123; key := &quot;list&quot; rdb.Del(ctx, key) for i := 0; i &lt; 5; i++ &#123; rdb.RPush(ctx, key, strconv.Itoa(i)) &#125; for i := 5; i &lt; 10; i++ &#123; rdb.LPush(ctx, key, strconv.Itoa(i)) &#125; length := rdb.LLen(ctx, key).Val() fmt.Println(length) value := rdb.LIndex(ctx, key, 1).Val() fmt.Println(value) rdb.LSet(ctx, key, 1, &quot;golang&quot;) value = rdb.LPop(ctx, key).Val() fmt.Println(value) n := rdb.LRem(ctx, key, 0, &quot;5&quot;).Val() fmt.Println(n) l := rdb.LRange(ctx, key, 0, -1).Val() fmt.Println(l)&#125; 2.5 Set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func Set() &#123; key1 := &quot;set1&quot; key2 := &quot;set2&quot; rdb.Del(ctx, key1, key2) rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 5; i++ &#123; rdb.SAdd(ctx, key1, rand.Intn(10)) rdb.SAdd(ctx, key2, rand.Intn(10)) &#125; n1 := rdb.SCard(ctx, key1).Val() fmt.Println(n1) e1 := rdb.SIsMember(ctx, key1, 3).Val() fmt.Println(e1) v1 := rdb.SRandMember(ctx, key1).Val() fmt.Println(v1) v2 := rdb.SRandMemberN(ctx, key1, 3).Val() fmt.Println(v2) v3 := rdb.SPop(ctx, key1).Val() fmt.Println(v3) n2 := rdb.SRem(ctx, key1, 2).Val() fmt.Println(n2) v4 := rdb.SMembers(ctx, key1) fmt.Println(v4) v5 := rdb.SMembers(ctx, key2) fmt.Println(v5) v6 := rdb.SInter(ctx, key1, key2).Val() fmt.Println(v6) v7 := rdb.SUnion(ctx, key1, key2).Val() fmt.Println(v7) v8 := rdb.SDiff(ctx, key1, key2).Val() fmt.Println(v8) rdb.SInterStore(ctx, &quot;set3&quot;, key1, key2) rdb.SUnionStore(ctx, &quot;set4&quot;, key1, key2) rdb.SDiffStore(ctx, &quot;set5&quot;, key1, key2)&#125; 2.6 SortedSet1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465func SortedSet() &#123; key1, key2 := &quot;zset1&quot;, &quot;zset2&quot; rdb.Del(ctx, key1, key2) rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 10; i++ &#123; score := float64(rand.Intn(100)) member := &quot;golang-&quot; + strconv.Itoa(i) data := &amp;redis.Z&#123; score, member, &#125; rdb.ZAdd(ctx, key1, data) &#125; for i := 0; i &lt; 10; i++ &#123; score := float64(rand.Intn(100)) member := &quot;golang-&quot; + strconv.Itoa(i) data := &amp;redis.Z&#123; score, member, &#125; rdb.ZAdd(ctx, key2, data) &#125; n1 := rdb.ZCard(ctx, key1) fmt.Println(n1) s1 := rdb.ZScore(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s1) v1 := rdb.ZIncrBy(ctx, key1, 50, &quot;golang-3&quot;).Val() fmt.Println(v1) s2 := rdb.ZRank(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s2) s3 := rdb.ZRevRank(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s3) s4 := rdb.ZRange(ctx, key1, 0, -1).Val() fmt.Println(s4) s5 := rdb.ZRevRange(ctx, key2, 0, -1).Val() fmt.Println(s5) v2 := rdb.ZRem(ctx, key2, &quot;golang-3&quot;).Val() fmt.Println(v2) key3, key4 := &quot;zset3&quot;, &quot;zset4&quot; kslice := []string&#123;key1, key2&#125; wslice := []float64&#123;1.00, 1.00&#125; z := &amp;redis.ZStore&#123; kslice, wslice, &quot;SUM&quot;, &#125; r1 := rdb.ZInterStore(ctx, key3, z).Val() fmt.Println(r1) r2 := rdb.ZUnionStore(ctx, key4, z).Val() fmt.Println(r2)&#125; 2.7 订阅和发布12345678910111213141516171819202122232425262728293031323334func Subscription() &#123; channels := []string&#123;&quot;news&quot;, &quot;it&quot;, &quot;sports&quot;, &quot;shopping&quot;&#125; sub := rdb.PSubscribe(ctx, channels...) _, err := sub.Receive(ctx) if err != nil &#123; fmt.Println(err) &#125; ch := sub.Channel() for msg := range ch &#123; fmt.Printf(&quot;%v: %v\\n&quot;, msg.Channel, msg.Payload) &#125;&#125;func Publish() &#123; var msg string channels := []string&#123;&quot;news&quot;, &quot;it&quot;, &quot;sports&quot;, &quot;shopping&quot;&#125; rand.Seed(time.Now().UnixNano()) for &#123; fmt.Printf(&quot;please input some message: &quot;) fmt.Scanln(&amp;msg) if msg == &quot;quit&quot; &#123; break &#125; channel := channels[rand.Intn(4)] result := rdb.Publish(ctx, channel, msg).Val() if result == 1 &#123; fmt.Printf(&quot;send info to [%v] success\\n&quot;, channel) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go GORM","slug":"Go GORM","date":"2019-05-18T08:09:03.000Z","updated":"2021-06-22T10:50:49.735Z","comments":true,"path":"2019/05/18/Go GORM/","link":"","permalink":"https://elihe2011.github.io/2019/05/18/Go%20GORM/","excerpt":"1. 入门1.1 安装1go get -u github.com/jinzhu/gorm 1.2 驱动1234import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot;import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot;import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot;","text":"1. 入门1.1 安装1go get -u github.com/jinzhu/gorm 1.2 驱动1234import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot;import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot;import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot; 2. 操作2.1 表结构定义123456789101112131415161718192021type Admin struct &#123; ID int64 Username string `gorm:&quot;size:50;not null&quot;` Password string `gorm:&quot;size:128&quot;`&#125;type Account struct &#123; gorm.Model // ID, CreatedAt, UpdatedAt, DeletedAt Appkey string `gorm:&quot;type:varchar(15);index:idx_appkey;not null&quot;` Company string `gorm:&quot;column:company_name;size:30&quot;` Status int8 `gorm:&quot;default:1&quot;`&#125;func (Admin) TableName() string &#123; return &quot;tbl_admin&quot;&#125;func (Account) TableName() string &#123; return &quot;tbl_account&quot;&#125; 2.2 连接数据库1234567891011121314151617181920212223242526272829303132const ( DBUSER = &quot;root&quot; DBPASS = &quot;&quot; HOST = &quot;127.0.0.1&quot; PORT = &quot;3306&quot; DBNAME = &quot;blog&quot;)func GetConn() *gorm.DB &#123; connStr := fmt.Sprintf(&quot;%s:%s@tcp(%s:%s)/%s?charset=utf8&amp;parseTime=True&amp;loc=Local&amp;timeout=10ms&quot;, DBUSER, DBPASS, HOST, PORT, DBNAME) fmt.Println(connStr) db, err := gorm.Open(&quot;mysql&quot;, connStr) if err != nil &#123; log.Fatalf(&quot;mysql connect error: %v&quot;, err) &#125; db.DB().SetMaxIdleConns(10) db.DB().SetMaxOpenConns(100) // 自动创建和更新表结构 if !db.HasTable(&quot;tbl_admin&quot;) &#123; db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Admin&#123;&#125;) &#125; if !db.HasTable(&quot;tbl_account&quot;) &#123; db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Account&#123;&#125;) &#125; return db&#125; 2.3 新增数据12345678910111213141516171819202122232425262728293031323334func Insert(db *gorm.DB) &#123; c := make(chan Admin) go generateData(c) for v := range c &#123; db.NewRecord(v) // 检查主键是否存在 db.Create(&amp;v) &#125;&#125;func generateRandomString(n int) string &#123; s := &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890_&quot; bs := make([]byte, n) for i := 0; i &lt; n; i++ &#123; bs[i] = s[rand.Intn(len(s))] &#125; return string(bs)&#125;func md5Encrypt(s string) string &#123; return fmt.Sprintf(&quot;%x&quot;, md5.Sum([]byte(s)))&#125;func generateData(c chan Admin) &#123; for i := 0; i &lt; 20; i++ &#123; name := generateRandomString(6) pass := md5Encrypt(name + &quot;_123456&quot;) c &lt;- Admin&#123;Username: name, Password: pass&#125; &#125; close(c)&#125; 2.4 查询数据12345678910111213func Select(db *gorm.DB) &#123; a := Admin&#123;&#125; db.Select([]string&#123;&quot;id&quot;, &quot;username&quot;, &quot;password&quot;&#125;).Where(&quot;id = ?&quot;, 1).First(&amp;a) fmt.Println(a)&#125;func SelectMany(db *gorm.DB) &#123; as := []Admin&#123;&#125; db.Where(&quot;username like &#x27;%4%&#x27;&quot;).Find(&amp;as) for _, a := range as &#123; fmt.Println(a) &#125;&#125; 2.5 更新数据1234567891011121314151617func Update(db *gorm.DB) &#123; a := Admin&#123;&#125; db.Where(&quot;id = ?&quot;, 1).First(&amp;a) a.Username = &quot;elihe123&quot; a.Password = md5Encrypt(&quot;123456&quot;) db.Save(a) // 数据必须有变化，否则无法保存 b := Admin&#123; ID: 30, Username: &quot;rania123&quot;, Password: md5Encrypt(&quot;654321&quot;), &#125; db.Save(b) // id不存在时，自动创建 c := Admin&#123;ID: 10&#125; db.Model(&amp;c).Update(&quot;username&quot;, &quot;eli&quot;)&#125; 2.6 删除数据1234func Delete(db *gorm.DB) &#123; a := Admin&#123;ID: 30&#125; db.Delete(&amp;a)&#125; 3. 钩子函数(callbacks) 创建: BeforeSave, BeforeCreate, AfterCreate, AfterSave 更新: BeforeSave, BeforeUpdate, AfterUpdate, AfterSave 删除: BeforeDelete, AfterDelete 查询: AfterFind 123456789func (Account) BeforeCreate(scope *gorm.Scope) error &#123; scope.SetColumn(&quot;CreatedAt&quot;, time.Now().Unix()) return nil&#125;func (Account) BeforeUpdate(scope *gorm.Scope) error &#123; scope.SetColumn(&quot;UpdatedAt&quot;, time.Now().Unix()) return nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Gin框架","slug":"Go Gin框架","date":"2019-05-17T02:22:58.000Z","updated":"2021-07-12T12:38:39.733Z","comments":true,"path":"2019/05/17/Go Gin框架/","link":"","permalink":"https://elihe2011.github.io/2019/05/17/Go%20Gin%E6%A1%86%E6%9E%B6/","excerpt":"1. Gin简介1.1 核心术语 Engine: 实现 ServeHTTP 接口的 Handler MethodTree： 根据http请求方法分别维护的路由树 RouterGroup：路由表分组，方便中间件统一处理 Context：上下文，在 Handler 之间传递参数 1.2 HttpRoutergin 使用路由框架 httprouter，它使用动态压缩前缀树 (compact prefix trie) 或称基数树 (radix tree) ，具有共同前缀的节点拥有相同的父节点，内存开销极小，没有反射。 12345678910111213141516171819202122// router.gotype Router struct &#123; trees map[string]*node // 每种请求方法，单独管理一棵树 RedirectTrailingSlash bool // 自动处理URL尾部的 “/” RedirectFixedPath bool // 路径矫正，如../和// HandleMethodNotAllowed bool HandleOPTIONS bool // 开启OPTIONS自动匹配, 手动匹配优先级更高 NotFound http.Handler MethodNotAllowed http.Handler PanicHandler func(http.ResponseWriter, *http.Request, interface&#123;&#125;)&#125;// tree.gotype node struct &#123; path string indices string // 分支的首字母：indices = eu，下面的 s [earch, upport] wildChild bool // 是否为参数节点，参数节点用:name表示 nType nodeType // static：没有handler，root: 第一个插入的节点，catchAll: 有*匹配的节点，param: 参数节点如:post priority uint32 // 子节点越多，或说绑定handle方法越多的节点，priority优先级越高 children []*node handle Handle&#125;","text":"1. Gin简介1.1 核心术语 Engine: 实现 ServeHTTP 接口的 Handler MethodTree： 根据http请求方法分别维护的路由树 RouterGroup：路由表分组，方便中间件统一处理 Context：上下文，在 Handler 之间传递参数 1.2 HttpRoutergin 使用路由框架 httprouter，它使用动态压缩前缀树 (compact prefix trie) 或称基数树 (radix tree) ，具有共同前缀的节点拥有相同的父节点，内存开销极小，没有反射。 12345678910111213141516171819202122// router.gotype Router struct &#123; trees map[string]*node // 每种请求方法，单独管理一棵树 RedirectTrailingSlash bool // 自动处理URL尾部的 “/” RedirectFixedPath bool // 路径矫正，如../和// HandleMethodNotAllowed bool HandleOPTIONS bool // 开启OPTIONS自动匹配, 手动匹配优先级更高 NotFound http.Handler MethodNotAllowed http.Handler PanicHandler func(http.ResponseWriter, *http.Request, interface&#123;&#125;)&#125;// tree.gotype node struct &#123; path string indices string // 分支的首字母：indices = eu，下面的 s [earch, upport] wildChild bool // 是否为参数节点，参数节点用:name表示 nType nodeType // static：没有handler，root: 第一个插入的节点，catchAll: 有*匹配的节点，param: 参数节点如:post priority uint32 // 子节点越多，或说绑定handle方法越多的节点，priority优先级越高 children []*node handle Handle&#125; 路由的保存： 123456789101112131415161718Priority Path Handle9 \\ *&lt;1&gt;3 ├s nil2 |├earch\\ *&lt;2&gt;1 |└upport\\ *&lt;3&gt;2 ├blog\\ *&lt;4&gt;1 | └:post nil1 | └\\ *&lt;5&gt;2 ├about-us\\ *&lt;6&gt;1 | └team\\ *&lt;7&gt;1 └contact\\ *&lt;8&gt;GET(&quot;/search/&quot;, h1)GET(&quot;/support/&quot;, h2)GET(&quot;/blog/:post/&quot;, h3)GET(&quot;/about-us/&quot;, h4)GET(&quot;/about-us/team/&quot;, h5)GET(&quot;/contact/&quot;, h6) r.Handle：r.Get, r.Post等方法的具体实现 123456789101112131415161718func (r *Router) Handle(method, path string, handle Handle) &#123; if path[0] != &#x27;/&#x27; &#123; panic(&quot;path must begin with &#x27;/&#x27; in path &#x27;&quot; + path + &quot;&#x27;&quot;) &#125; if r.trees == nil &#123; r.trees = make(map[string]*node) &#125; // 按方法创建路由树 root := r.trees[method] if root == nil &#123; root = new(node) r.trees[method] = root &#125; root.addRoute(path, handle)&#125; 2. 使用2.1 安装1go get -u github.com/gin-gonic/gin 2.2 入门12func (c *Context) JSON(code int, obj interface&#123;&#125;)type H map[string]interface&#123;&#125; 12345678910111213func main() &#123; // 路由 r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(200, gin.H &#123; &quot;id&quot;: 1, &quot;content&quot;: &quot;hello world!&quot;, &#125;) &#125;) r.Run(&quot;:8080&quot;)&#125; 2.3 请求参数2.3.1 路由参数1func (c *Context) Param(key string) string 1234567891011121314151617181920func main() &#123; r := gin.Default() r.GET(&quot;/user/:name&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) c.String(http.StatusOK, &quot;hello %s&quot;, name) &#125;) // 将匹配 /user/john/ 和 /user/john/send // 如果没有其他路由匹配 /user/john，它将重定向到 /user/john/ r.GET(&quot;/user/:name/*action&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) action := c.Param(&quot;action&quot;) msg := name + &quot; is doing &quot; + action c.String(http.StatusOK, msg) &#125;) r.Run()&#125; 2.3.2 Query参数123func (c *Context) Query(key string) string func (c *Context) GetQuery(key string) (string, bool) func (c *Context) DefaultQuery(key, defaultValue string) string 12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/user&quot;, func(c *gin.Context) &#123; filters := c.Query(&quot;filters&quot;) pageIndex := c.DefaultQuery(&quot;page_index&quot;, &quot;1&quot;) pageSize := c.DefaultQuery(&quot;page_size&quot;, &quot;10&quot;) c.JSON(http.StatusOK, gin.H&#123;&quot;filters&quot;: filters, &quot;page_index&quot;: pageIndex, &quot;page_size&quot;: pageSize&#125;) &#125;) r.Run()&#125; 2.3.3 Form参数12func (c *Context) PostForm(key string) stringfunc (c *Context) DefaultPostForm(key, defaultValue string) string 123456789101112131415161718func main() &#123; r := gin.Default() r.POST(&quot;/login&quot;, func(c *gin.Context) &#123; username := c.PostForm(&quot;username&quot;) password := c.DefaultPostForm(&quot;password&quot;, &quot;123456&quot;) c.JSON(http.StatusOK, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;) &#125;) r.Run()&#125;// curl -d &#x27;username=tom&amp;password=abc123&#x27; -X POST http://127.0.0.1:8080/login 2.3.4 参数相关方法 查询参数 Form表单 说明 Query PostForm 获取key对应的值，不存在为空字符串 GetQuery GetPostForm 多返回一个key是否存在的结果 QueryArray PostFormArray 获取key对应的数组，不存在返回一个空数组 GetQueryArray GetPostFormArray 多返回一个key是否存在的结果 QueryMap PostFormMap 获取key对应的map，不存在返回空map GetQueryMap GetPostFormMap 多返回一个key是否存在的结果 DefaultQuery DefaultPostForm key不存在的话，可以指定返回的默认值 2.4 文件操作调整文件上传表单大小： 12// 给表单限制上传大小，默认 32MiBr.MaxMultipartMemory = 128 &lt;&lt; 20 // 128MB 2.4.1 单文件上传1234567891011121314151617181920212223242526272829303132333435363738394041func upload(c *gin.Context) &#123; // 限制文件大小 err := c.Request.ParseMultipartForm(4 &lt;&lt; 20) // 4Mb if err != nil &#123; c.String(http.StatusBadRequest, &quot;file is too large&quot;) return &#125; // header, err := c.FormFile(&quot;file&quot;) file, header, err := c.Request.FormFile(&quot;file&quot;) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; defer file.Close() fmt.Printf(&quot;filename: %s, size: %d&quot;, header.Filename, header.Size) err = saveFile(header.Filename, file) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; c.String(http.StatusOK, &quot;uploaded!&quot;)&#125;func saveFile(name string, input multipart.File) (err error) &#123; var output *os.File output, err = os.OpenFile(name, os.O_CREATE|os.O_RDWR, 0644) if err != nil &#123; return &#125; defer output.Close() _, err = io.Copy(output, input) return&#125;curl -X POST http://192.168.80.1:8080/upload \\ -F &quot;file=@/home/ubuntu/ryu-socket_20210527.tar&quot; \\ -H &quot;Content-Type: multipart/form-data&quot; 2.4.2 多文件上传12345678910111213141516171819202122232425262728293031323334func uploadFiles(c *gin.Context) &#123; form, err := c.MultipartForm() if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; files := form.File[&quot;upload[]&quot;] fmt.Printf(&quot;file numbers: %d\\n&quot;, len(files)) for i, _ := range files &#123; file, err := files[i].Open() if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; fmt.Printf(&quot;filename: %s, size: %d\\n&quot;, files[i].Filename, files[i].Size) err = saveFile(files[i].Filename, file) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; &#125; c.String(http.StatusOK, &quot;uploaded&quot;)&#125;curl -X POST http://192.168.80.1:8080/uploadFiles \\ -F &quot;upload[]=@/home/ubuntu/clean_ryu_imgs.sh&quot; \\ -F &quot;upload[]=@/home/ubuntu/.profile&quot; \\ -F &quot;upload[]=@/home/ubuntu/vegeta_12.8.4_linux_amd64.tar.gz&quot; \\ -H &quot;Content-Type: multipart/form-data&quot; 2.4.3 文件下载123456789101112func download(c *gin.Context) &#123; txt := c.Query(&quot;content&quot;) content := &quot;hello, 我是文件, &quot; + txt c.Writer.WriteHeader(http.StatusOK) c.Header(&quot;Content-Disposition&quot;, &quot;attachment; filename=hello.txt&quot;) c.Header(&quot;Content-Type&quot;, &quot;application/text/plain&quot;) c.Header(&quot;Accept-Length&quot;, fmt.Sprintf(&quot;%d&quot;, len(content))) c.Writer.Write([]byte(content))&#125;curl http://192.168.80.1:8080/download?content=abc 4. 高级功能4.1 路由分组12345678910111213func main() &#123; r := gin.Default() v1 := r.Group(&quot;/v1&quot;) &#123; v1.POST(&quot;/login&quot;, LoginHandler) &#125; v2 := r.Group(&quot;/v2&quot;) &#123; v2.POST(&quot;/login&quot;, LoginV2Handler) &#125;&#125; 4.2 中间件1func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes 1234567891011121314151617181920func main() &#123; // 不使用默认中间件： Logger 和 Recovery r := gin.New() // 全局中间件 r.Use(gin.Logger()) r.Use(gin.Recovery()) // 路由中间件 r.GET(&quot;/location&quot;, LocationLogger(), LocationHandler) // 分组中间件 auth := r.Group(&quot;/auth&quot;) auth.Use(AuthRequired()) &#123; auth.POST(&quot;/user&quot;, UserHandler) &#125; r.Run()&#125; 4.2.1 自定义中间件12345678910111213141516171819202122232425262728293031323334func main() &#123; r := gin.New() r.Use(Logger()) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; time.Sleep(time.Second * 5) c.JSON(http.StatusOK, gin.H&#123; &quot;msg&quot;: c.MustGet(&quot;foo&quot;), &#125;) &#125;) r.Run()&#125;func Logger() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; // before request t := time.Now() // set a variable c.Set(&quot;foo&quot;, &quot;bar&quot;) // DO request c.Next() // after request latency := time.Since(t) log.Println(latency) // access the result status status := c.Writer.Status() log.Println(status) &#125;&#125; 4.2.2 BasicAuth中间件12345678910111213141516171819202122232425262728293031// simulate private datavar secrets = gin.H&#123; &quot;foo&quot;: gin.H&#123;&quot;email&quot;: &quot;foo@abc.com&quot;, &quot;phone&quot;: &quot;13302254321&quot;&#125;, &quot;jack&quot;: gin.H&#123;&quot;email&quot;: &quot;jack@abc.com&quot;, &quot;phone&quot;: &quot;18952098765&quot;&#125;,&#125;func main() &#123; r := gin.Default() authorized := r.Group(&quot;/admin&quot;, gin.BasicAuth(gin.Accounts&#123; &quot;foo&quot;: &quot;bar&quot;, &quot;jack&quot;: &quot;1234&quot;, &#125;)) authorized.GET(&quot;/secrets&quot;, func(c *gin.Context) &#123; user := c.MustGet(gin.AuthUserKey).(string) if secret, ok := secrets[user]; ok &#123; c.JSON(http.StatusOK, gin.H&#123; &quot;user&quot;: user, &quot;secret&quot;: secret, &#125;) &#125; else &#123; c.JSON(http.StatusUnauthorized, gin.H&#123; &quot;user&quot;: user, &quot;secret&quot;: &quot;NO SECRET&quot;, &#125;) &#125; &#125;) r.Run()&#125; 4.3 记录日志4.3.1 日志文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107var ( LogSavePath = &quot;logs/&quot; LogSaveName = &quot;gin&quot; LogSaveFileExt = &quot;log&quot; TimeFormat = &quot;20060102&quot;)type Level intvar ( F *os.File DefaultPrefix = &quot;&quot; DefaultCallerDepth = 2 logger *log.Logger logPrefix = &quot;&quot; levelFlags = []string&#123;&quot;DEBUG&quot;, &quot;INFO&quot;, &quot;WRAN&quot;, &quot;ERROR&quot;, &quot;FATAL&quot;&#125;)const ( DEBUG Level = iota INFO WARNING ERROR FATAL)func init() &#123; filePath := getLogFileFullPath() F = openLogFile(filePath) // 新建日志处理 logger = log.New(F, DefaultPrefix, log.LstdFlags)&#125;func getLogFilePath() string &#123; return fmt.Sprintf(&quot;%s&quot;, LogSavePath)&#125;func getLogFileFullPath() string &#123; prefixPath := getLogFilePath() suffixPath := fmt.Sprintf(&quot;%s%s.%s&quot;, LogSaveName, time.Now().Format(TimeFormat), LogSaveFileExt) return fmt.Sprintf(&quot;%s%s&quot;, prefixPath, suffixPath)&#125;func openLogFile(filePath string) *os.File &#123; _, err := os.Stat(filePath) switch &#123; case os.IsNotExist(err): makeDir() case os.IsPermission(err): log.Fatalf(&quot;Permission: %v&quot;, err) &#125; handle, err := os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil &#123; log.Fatalf(&quot;Failed to OpenFile: %v&quot;, err) &#125; return handle&#125;func makeDir() &#123; pwd, _ := os.Getwd() err := os.MkdirAll(pwd+&quot;/&quot;+getLogFilePath(), os.ModePerm) if err != nil &#123; panic(err) &#125;&#125;func Debug(v ...interface&#123;&#125;) &#123; setPrefix(DEBUG) logger.Println(v)&#125;func Info(v ...interface&#123;&#125;) &#123; setPrefix(INFO) logger.Println(v)&#125;func Warn(v ...interface&#123;&#125;) &#123; setPrefix(WARNING) logger.Println(v)&#125;func Error(v ...interface&#123;&#125;) &#123; setPrefix(ERROR) logger.Println(v)&#125;func Fatal(v ...interface&#123;&#125;) &#123; setPrefix(FATAL) logger.Println(v)&#125;func setPrefix(level Level) &#123; _, file, line, ok := runtime.Caller(DefaultCallerDepth) if ok &#123; logPrefix = fmt.Sprintf(&quot;[%s][%s:%d]&quot;, levelFlags[level], filepath.Base(file), line) &#125; else &#123; logPrefix = fmt.Sprintf(&quot;[%s]&quot;, levelFlags[level]) &#125; logger.SetPrefix(logPrefix)&#125; 4.3.2 日志格式12345678910111213141516171819202122232425262728func main() &#123; router := gin.New() // LoggerWithFormatter 中间件会将日志写入 gin.DefaultWriter // By default gin.DefaultWriter = os.Stdout router.Use(gin.LoggerWithFormatter(func(param gin.LogFormatterParams) string &#123; // 你的自定义格式 return fmt.Sprintf(&quot;%s - [%s] \\&quot;%s %s %s %d %s \\&quot;%s\\&quot; %s\\&quot;\\n&quot;, param.ClientIP, param.TimeStamp.Format(time.RFC1123), param.Method, param.Path, param.Request.Proto, param.StatusCode, param.Latency, param.Request.UserAgent(), param.ErrorMessage, ) &#125;)) router.Use(gin.Recovery()) router.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(200, &quot;pong&quot;) &#125;) router.Run(&quot;:8080&quot;)&#125; 4.4 模型绑定和验证Gin使用 go-playground/validator.v10 验证参数。 将请求主体绑定到结构体中，目前支持JSON、XML、YAML和标准表单值(foo=bar&amp;boo=baz)的绑定。 绑定方法： Must bind: Methods: Bind, BindJSON, BindXML, BindQuery, BindYAML Behavior: 底层使用MustBindWith，如果存在绑定错误，请求将被以下指令中止 c.AbortWithError(400, err).SetType(ErrorTypeBind) Should bind: Methods: ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML Behavior: 底层使用ShouldBindWith，如果存在绑定错误，则返回错误，开发人员可正确处理请求和错误 4.4.1 请求参数绑定1234567891011121314151617181920212223242526272829303132333435type User struct &#123; Username string `form:&quot;username&quot; json:&quot;username&quot; xml:&quot;username&quot; binding:&quot;required&quot;` Password string `form:&quot;password&quot; json:&quot;password&quot; xml:&quot;password&quot; binding:&quot;required&quot;`&#125;func main() &#123; r := gin.Default() r.POST(&quot;/login&quot;, func(c *gin.Context) &#123; var user User //if err := c.ShouldBind(&amp;user); err != nil &#123; if err := c.ShouldBindJSON(&amp;user); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; if user.Username != &quot;admin&quot; || user.Password != &quot;123&quot; &#123; c.JSON(http.StatusUnauthorized, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: &quot;unauthorized&quot;, &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.2 自定义校验器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport ( &quot;net/http&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;gopkg.in/go-playground/validator.v10&quot; &quot;github.com/gin-gonic/gin&quot;)type Booking struct &#123; // v8 // CheckIn time.Time `form:&quot;check_in&quot; binding:&quot;required,bookabledate&quot; time_format:&quot;2006-01-02&quot;` CheckIn time.Time `form:&quot;check_in&quot; binding:&quot;required&quot; validate:&quot;bookabledate&quot; time_format:&quot;2006-01-02&quot;` CheckOut time.Time `form:&quot;check_out&quot; binding:&quot;required,gtfield=CheckIn&quot; time_format:&quot;2006-01-02&quot;`&#125;func bookableDate(fl validator.FieldLevel) bool &#123; if date, ok := fl.Field().Interface().(time.Time); ok &#123; today := time.Now() if today.Before(date) &#123; return true &#125; &#125; return false&#125;func main() &#123; r := gin.Default() // v10 validate := validator.New() validate.RegisterValidation(&quot;bookabledate&quot;, bookableDate) r.GET(&quot;/book&quot;, func(c *gin.Context) &#123; var book Booking if err := c.ShouldBindWith(&amp;book, binding.Query); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; // v10: 绑定和校验分离 err := validate.Struct(book) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.3 绑定uri1234567891011121314151617181920212223242526type Person struct &#123; ID string `uri:&quot;id&quot; binding:&quot;required,uuid&quot;` Name string `uri:&quot;name&quot; binding:&quot;required&quot;`&#125;func main() &#123; r := gin.Default() r.GET(&quot;/:name/:id&quot;, func(c *gin.Context) &#123; var person Person if err := c.ShouldBindUri(&amp;person); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.4 错误翻译器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 1. 定义翻译器 translator.gopackage translatorimport ( &quot;strings&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;github.com/go-playground/locales/zh&quot; ut &quot;github.com/go-playground/universal-translator&quot; &quot;github.com/go-playground/validator/v10&quot; zhTrans &quot;github.com/go-playground/validator/v10/translations/zh&quot;)var ( uni *ut.UniversalTranslator validate *validator.Validate trans ut.Translator)func InitTrans() &#123; // 翻译器 zh := zh.New() uni = ut.New(zh, zh) trans, _ = uni.GetTranslator(&quot;zh&quot;) // 获取gin的校验器 validate = binding.Validator.Engine().(*validator.Validate) // 注册翻译器 zhTrans.RegisterDefaultTranslations(validate, trans)&#125;func Translate(err error) string &#123; var result []string errors := err.(validator.ValidationErrors) for _, err := range errors &#123; result = append(result, err.Translate(trans)) &#125; return strings.Join(result, &quot;; &quot;)&#125;// 2. 初始化translator.InitTrans()// 3. 使用实例type addUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,min=3,max=20&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6,max=8&quot;` Email string `json:&quot;email&quot; binding:&quot;omitempty,email&quot;`&#125;func AddUserHandler(c *gin.Context) (interface&#123;&#125;, error) &#123; var req addUserRequest err := c.ShouldBindJSON(&amp;req) fmt.Println(err) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; // 新增用户 srv := &amp;service.AddUserService&#123;&#125; err = srv.AddUser(req.Username, req.Password, req.Email) return srv, err&#125; 4.5 响应渲染4.5.1 常见格式123c.JSON(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;)c.XML(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;)c.YAML(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;) 4.5.2 ProtoBuf1234567891011121314151617func main() &#123; r := gin.Default() r.GET(&quot;/protobuf&quot;, func(c *gin.Context) &#123; reps := []int64&#123;int64(1), int64(2)&#125; label := &quot;test&quot; data := &amp;protoexample.Test&#123; Label: &amp;label, Reps: reps, &#125; c.ProtoBuf(http.StatusOK, data) &#125;) r.Run()&#125; 4.5.3 SecureJSONSecureJSON可以防止json劫持，如果返回的数据是数组，则会默认在返回值前加上”while(1)” JSON劫持，其实就是恶意网站，通过&lt;script&gt;标签获取你的JSON数据，因为JSON数组默认为是可执行的JS，所以通过这种方式，可以获得你的敏感数据。 1234567891011121314func main() &#123; r := gin.Default() // facebook r.SecureJsonPrefix(&quot;for(;;);&quot;) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; nums := []int&#123;1, 2, 3, 4, 5&#125; c.SecureJSON(http.StatusOK, nums) // while(1);[1,2,3,4,5] 默认Google &#125;) r.Run()&#125; 4.5.4 JSONPJSONP可以跨域传输，如果参数中存在回调参数，那么返回的参数将是回调函数的形式 123456789101112131415func main() &#123; r := gin.Default() data := make(map[string]interface&#123;&#125;) data[&quot;bar&quot;] = &quot;foo&quot; r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.JSONP(http.StatusOK, data) &#125;) // http://localhost:8080/test?callback=sayHello // sayHello(&#123;&quot;bar&quot;:&quot;foo&quot;&#125;); r.Run()&#125; 1234567&lt;script&gt; function sayHello(data) &#123; alert(JSON.stringify(data)) &#125;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:8080/jsonp?callback=sayHello&quot; &gt;&lt;/script&gt; 4.5.5 AsciiJSON编码中文、标签等特殊字符 12345678910111213141516func main() &#123; r := gin.Default() data := map[string]interface&#123;&#125;&#123; &quot;lang&quot;: &quot;中文&quot;, &quot;tag&quot;: &quot;&lt;xml&gt;&quot;, &#125; r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.AsciiJSON(http.StatusOK, data) &#125;) // &#123;&quot;lang&quot;:&quot;\\u4e2d\\u6587&quot;,&quot;tag&quot;:&quot;\\u003cxml\\u003e&quot;&#125; r.Run()&#125; 4.5.6 PureJSONJSON会将特殊的HTML字符替换为对应的unicode字符, 但PureJSON保留原有格式 12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.PureJSON(http.StatusOK, gin.H&#123; &quot;html&quot;: &quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot;, &#125;) &#125;) // &#123;&quot;html&quot;:&quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot;&#125; r.Run()&#125; 4.5.7 jsoniter高性能json工具 12345import jsoniter &quot;github.com/json-iterator/go&quot;var json = jsoniter.ConfigCompatibleWithStandardLibraryjson.Marshal(&amp;data)json.Unmarshal(input, &amp;data) Gin 默认使用 encoding/json，可以在编译中使用标签将其修改为 jsoniter 1go build -tags=jsoniter . 4.6 静态文件12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world&quot;) &#125;) r.Static(&quot;/assets&quot;, &quot;./assets&quot;) r.StaticFS(&quot;/disk&quot;, http.Dir(`E:\\Download`)) r.StaticFile(&quot;favicon.ico&quot;, &quot;./assets/favicon.ico&quot;) r.Run(&quot;:8080&quot;)&#125; 4.7 代理下载文件1234567891011121314151617181920func downloadFromUrl(c *gin.Context) &#123; url := c.Query(&quot;url&quot;) resp, err := http.Get(url) if err != nil || resp.StatusCode != http.StatusOK &#123; c.Status(http.StatusServiceUnavailable) return &#125; arr := strings.Split(url, &quot;/&quot;) filename := arr[len(arr)-1] reader := resp.Body contentLength := resp.ContentLength contentType := resp.Header.Get(&quot;Content-Type&quot;) extraHeaders := map[string]string&#123; &quot;Content-Disposition&quot;: fmt.Sprintf(&quot;attachment; filename=%s&quot;, filename), &#125; c.DataFromReader(http.StatusOK, contentLength, contentType, reader, extraHeaders) 4.8 HTML渲染1234567891011121314func main() &#123; r := gin.Default() //r.LoadHTMLFiles(&quot;templates/index.tmpl&quot;, &quot;templates/login.tmpl&quot;) r.LoadHTMLGlob(&quot;templates/*&quot;) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.HTML(http.StatusOK, &quot;index.tmpl&quot;, gin.H&#123; &quot;title&quot;: &quot;Home Page&quot;, &#125;) &#125;) r.Run()&#125; 12345&lt;html&gt; &lt;h1&gt; &#123;&#123; .title &#125;&#125; &lt;/h1&gt;&lt;/html&gt; 4.9 重定向1234567891011121314151617181920func main() &#123; r := gin.Default() // 外部重定向 r.GET(&quot;/test1&quot;, func(c *gin.Context) &#123; c.Redirect(http.StatusMovedPermanently, &quot;https://google.com&quot;) &#125;) // 路由重定向 HandleContext r.GET(&quot;/test2&quot;, func(c *gin.Context) &#123; c.Request.URL.Path = &quot;/test3&quot; r.HandleContext(c) &#125;) r.GET(&quot;/test3&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world!&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125; 12345678910111213141516func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.Request.URL.Path = &quot;/test2&quot; r.HandleContext(c) &#125;) r.GET(&quot;/test2&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123; &quot;msg&quot;: &quot;hello world!&quot;, &#125;) &#125;) r.Run()&#125; 4.10 支持https123456789101112131415161718192021222324import ( &quot;log&quot; &quot;net/http&quot; &quot;golang.org/x/crypto/acme/autocert&quot; &quot;github.com/gin-gonic/autotls&quot; &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;pong&quot;) &#125;) m := autocert.Manager&#123; Prompt: autocert.AcceptTOS, HostPolicy: autocert.HostWhitelist(&quot;localhost:8080&quot;, &quot;example1.com&quot;, &quot;example2.com&quot;), Cache: autocert.DirCache(&quot;/var/www/.cache&quot;), &#125; log.Fatal(autotls.RunWithManager(r, &amp;m))&#125; 4.11 使用cookie123456789101112131415func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; cookie, err := c.Cookie(&quot;gin_cookie&quot;) if err != nil &#123; cookie = &quot;NO_SET&quot; c.SetCookie(&quot;gin_cookie&quot;, &quot;test&quot;, 3600, &quot;/&quot;, &quot;localhost&quot;, false, true) &#125; c.String(http.StatusOK, &quot;cookie=%s&quot;, cookie) &#125;) r.Run()&#125; 4.13 服务配置123456789101112type Server struct &#123; Addr string Handler http.Handler TLSConfig *tls.Config ReadTimeout time.Duration ReadHeaderTime time.Duration WriteTimeout time.Duration IdleTimeout time.Duration MaxHeaderBytes int ConnState func(net.Conn, http.ConnState) ErrorLog *log.Logger&#125; 123456789101112func main() &#123; router := gin.Default() s := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; s.ListenAndServe()&#125; 4.14 使用 goroutine在中间件或处理程序中启动 Goroutine 时，需要使用只读副本 c.Copy() 123456789101112131415161718192021222324func main() &#123; r := gin.Default() r.GET(&quot;/sync&quot;, func(c *gin.Context) &#123; start := time.Now() time.Sleep(5 * time.Second) log.Println(c.Request.URL) latency := time.Now().Sub(start) c.String(http.StatusOK, latency.String()) &#125;) r.GET(&quot;/async&quot;, func(c *gin.Context) &#123; start := time.Now() // 协程中使用，必须先复制 cc := c.Copy() go func() &#123; time.Sleep(5 * time.Second) log.Println(cc.Request.URL) &#125;() latency := time.Now().Sub(start) c.String(http.StatusOK, latency.String()) &#125;)&#125; 5. 运行多个服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import ( &quot;log&quot; &quot;net/http&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin&quot; &quot;golang.org/x/sync/errgroup&quot;)var ( g errgroup.Group)func router01() http.Handler &#123; r := gin.New() r.Use(gin.Recovery()) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;welcome to server 01&quot;&#125;) &#125;) return r&#125;func router02() http.Handler &#123; r := gin.New() r.Use(gin.Recovery()) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;welcome to server 02&quot;&#125;) &#125;) return r&#125;func main() &#123; server01 := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router01(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, &#125; server02 := &amp;http.Server&#123; Addr: &quot;:8081&quot;, Handler: router02(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, &#125; g.Go(func() error &#123; return server01.ListenAndServe() &#125;) g.Go(func() error &#123; return server02.ListenAndServe() &#125;) if err := g.Wait(); err != nil &#123; log.Fatal(err) &#125;&#125; 6. 集成JWT1go get github.com/dgrijalva/jwt-go 涉及方法： NewWithClaims(method SigningMethod, claims Claims), method对应着SigningMethodHMAC struct&#123;&#125;，其包含SigningMethodHS256, SigningMethodHS384, SigningMethodHS512三种crypt.Hash func (t *Token) SignedString(key interface&#123;&#125;) 内部生成签名字符串，再用于获取完整、已签名的token func (p *Parser) ParseWithClaims解析鉴权声明，方法内部主要是具体的解码和校验过程，最终返回*Token func (m MapClaims) Valid() 验证基于时间的声明exp, iat, nbf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import ( &quot;gin-blog/pkg/setting&quot; &quot;time&quot; jwt &quot;github.com/dgrijalva/jwt-go&quot;)var jwtSecret = []byte(setting.JwtSecret)type Claims struct &#123; Username string `json:&quot;username&quot;` Password string `json:&quot;password&quot;` jwt.StandardClaims&#125;func GenerateToken(username, password string) (string, error) &#123; nowTime := time.Now() expireTime := nowTime.Add(3 * time.Hour) claims := Claims&#123; username, password, jwt.StandardClaims&#123; ExpiresAt: expireTime.Unix(), Issuer: &quot;gin-blog&quot;, &#125;, &#125; tokenClaims := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) token, err := tokenClaims.SignedString(jwtSecret) return token, err&#125;func ParseToken(token string) (*Claims, error) &#123; tokenClaims, err := jwt.ParseWithClaims(token, &amp;Claims&#123;&#125;, func(token *jwt.Token) (interface&#123;&#125;, error) &#123; return jwtSecret, nil &#125;) if tokenClaims != nil &#123; if claims, ok := tokenClaims.Claims.(*Claims); ok &amp;&amp; tokenClaims.Valid &#123; return claims, nil &#125; &#125; return nil, err&#125; 7. 重启服务器要求： 不关闭现有连接 （正在运行中的程序） 新的进程启动并替代旧进程 新的进程结构新的连接 连接要随时响应用户的请求，当用户仍在请求旧进程时，要保持连接，新用户应请求新进程，不可出现拒绝请求的情况 7.1 endlessendless: Zero downtime restarts for golfing HTTP and HTTPS servers 每次更新发布、修改配置文件等，只要给该进行发送SIGTERM信号(kill )，而不需要强制结束应用 监听信号： syscall.SIGHUP: 触发fork子进程和重新启动 syscall.SIGUSR1/syscall.SIGTSTP: 被监听，但不触发任何动作 syscall.SIGUSR2: 触发hammerTime syscall.SIGINT/syscall.SIGTERM: 触发服务器关闭（会完成正在运行的请求） 123456789101112131415161718192021222324252627282930313233343536import ( &quot;fmt&quot; &quot;gin-blog/pkg/setting&quot; &quot;gin-blog/routers&quot; &quot;log&quot; &quot;syscall&quot; &quot;github.com/fvbock/endless&quot;)func main() &#123; //router := routers.InitRouter() // //server := &amp;http.Server&#123; // Addr: fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort), // Handler: router, // ReadTimeout: setting.ReadTimeout, // WriteTimeout: setting.WriteTimeout, // MaxHeaderBytes: 1 &lt;&lt; 20, //&#125; endless.DefaultReadTimeOut = setting.ReadTimeout endless.DefaultWriteTimeOut = setting.WriteTimeout endless.DefaultMaxHeaderBytes = 1 &lt;&lt; 20 endPoint := fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort) server := endless.NewServer(endPoint, routers.InitRouter()) server.BeforeBegin = func(add string) &#123; log.Printf(&quot;Actual pid is %d&quot;, syscall.Getpid()) &#125; err := server.ListenAndServe() if err != nil &#123; log.Printf(&quot;Server error: %v&quot;, err) &#125;&#125; 7.2 Shutdown使用 http.Server 内置的 Shutdown()方法优雅地关闭服务，它不会中断任何活动的连接，直到所有连接处理完毕 1234567891011121314151617181920212223242526272829303132func main() &#123; router := initRouter() server := &amp;http.Server&#123; Addr: fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort), Handler: router, ReadTimeout: setting.ReadTimeout, WriteTimeout: setting.WriteTimeout, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; go func() &#123; if err := server.ListenAndServe(); err != nil &#123; log.Printf(&quot;Listen: %v\\n&quot;, err) &#125; &#125;() quit := make(chan os.Signal) signal.Notify(quit, os.Interrupt) &lt;-quit log.Printf(&quot;Shutdown Server ...&quot;) ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() if err := server.Shutdown(ctx); err != nil &#123; log.Fatal(&quot;Server Shutdown:&quot;, err) &#125; log.Println(&quot;Server exiting&quot;)&#125; 8. Swagger API123go get -u github.com/swaggo/swag/cmd/swaggo get -u github.com/swaggo/gin-swaggergo get -u github.com/swaggo/gin-swagger/swaggerFiles 8.1 API 接口注释1234567891011121314151617181920212223242526// LoginHandler godoc// @Summary 登录系统// @Tags 用户相关接口// @Accept json// @Produce json// @Param object body loginRequest true &quot;请求参数&quot;// @Success 200 &#123;object&#125; router.Response// @Failure 400 &#123;object&#125; e.ApiError// @Router /api/v1/login [post]func LoginHandler(c *gin.Context) (interface&#123;&#125;, error) &#123; var req loginRequest err := c.ShouldBindJSON(&amp;req) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; // 登录 srv := &amp;service.LoginService&#123;&#125; err = srv.Login(req.Username, req.Password) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; return srv, nil&#125; 8.2 生成配置1swag init 8.3 引入配置12345678910// main.gofunc init() &#123; // swagger 相关信息 docs.SwaggerInfo.Title = &quot;XXX 项目接口文档&quot; docs.SwaggerInfo.Description = &quot;just a test&quot; docs.SwaggerInfo.Version = &quot;1.0&quot; docs.SwaggerInfo.Host = addr docs.SwaggerInfo.BasePath = &quot;/&quot; docs.SwaggerInfo.Schemes = []string&#123;&quot;http&quot;, &quot;https&quot;&#125;&#125; 8.4 禁用Swaggergin-swagger还提供了DisablingWrapHandler函数，方便我们通过设置某些环境变量来。例如： 1r.GET(&quot;/swagger/*any&quot;, gs.DisablingWrapHandler(swaggerFiles.Handler, &quot;NAME_OF_ENV_VARIABLE&quot;)) 此时如果将环境变量NAME_OF_ENV_VARIABLE设置为任意值，则/swagger/*any将返回404响应，就像未指定路由时一样。 9. 接口测试12345678910111213141516171819202122232425262728import ( &quot;net/http&quot; &quot;net/http/httptest&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/assert&quot; &quot;github.com/gin-gonic/gin&quot;)func setRouter() *gin.Engine &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;pong&quot;) &#125;) return r&#125;func TestPingRoute(t *testing.T) &#123; router := setRouter() w := httptest.NewRecorder() req, _ := http.NewRequest(&quot;GET&quot;, &quot;/ping&quot;, nil) router.ServeHTTP(w, req) assert.Equal(t, http.StatusOK, w.Code) assert.Equal(t, &quot;pong&quot;, w.Body.String())&#125; 10. 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229// 获取一个gin框架实例gin.Default()// 具体的Default方法func Default() *Engine &#123; // 调试模式日志输出 debugPrintWARNINGDefault() // 创建一个gin框架实例 engine := New() // 注册中间件的方式一致 engine.Use(Logger(), Recovery()) return engine&#125;// 创建一个gin框架实例 具体方法func New() *Engine &#123; // 调试模式日志输出 debugPrintWARNINGNew() // 初始化一个Engine实例 engine := &amp;Engine&#123; // 给框架实例绑定上一个路由组 RouterGroup: RouterGroup&#123; Handlers: nil, // engine.Use 注册的中间方法到这里 basePath: &quot;/&quot;, root: true, // 是否是路由根节点 &#125;, FuncMap: template.FuncMap&#123;&#125;, RedirectTrailingSlash: true, RedirectFixedPath: false, HandleMethodNotAllowed: false, ForwardedByClientIP: true, AppEngine: defaultAppEngine, UseRawPath: false, UnescapePathValues: true, MaxMultipartMemory: defaultMultipartMemory, trees: make(methodTrees, 0, 9), // 路由树 delims: render.Delims&#123;Left: &quot;&#123;&#123;&quot;, Right: &quot;&#125;&#125;&quot;&#125;, secureJsonPrefix: &quot;while(1);&quot;, &#125; // RouterGroup绑定engine自身的实例 engine.RouterGroup.engine = engine // 绑定从实例池获取上下文的闭包方法 engine.pool.New = func() interface&#123;&#125; &#123; // 获取一个Context实例 return engine.allocateContext() &#125; // 返回框架实例 return engine&#125;// 注册日志&amp;goroutin panic捕获中间件engine.Use(Logger(), Recovery())// 具体的注册中间件的方法func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes &#123; engine.RouterGroup.Use(middleware...) engine.rebuild404Handlers() engine.rebuild405Handlers() return engine&#125;///////////////////////////////////////////// 注册GET请求路由func (group *RouterGroup) GET(relativePath string, handlers ...HandlerFunc) IRoutes &#123; // 往路由组内 注册GET请求路由 return group.handle(&quot;GET&quot;, relativePath, handlers)&#125;func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes &#123; absolutePath := group.calculateAbsolutePath(relativePath) // 把中间件的handle和该路由的handle合并 handlers = group.combineHandlers(handlers) // 注册一个GET集合的路由 group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj()&#125;func (engine *Engine) addRoute(method, path string, handlers HandlersChain) &#123; assert1(path[0] == &#x27;/&#x27;, &quot;path must begin with &#x27;/&#x27;&quot;) assert1(method != &quot;&quot;, &quot;HTTP method can not be empty&quot;) assert1(len(handlers) &gt; 0, &quot;there must be at least one handler&quot;) debugPrintRoute(method, path, handlers) // 检查有没有对应method集合的路由 root := engine.trees.get(method) if root == nil &#123; // 没有 创建一个新的路由节点 root = new(node) // 添加该method的路由tree到当前的路由到路由树里 engine.trees = append(engine.trees, methodTree&#123;method: method, root: root&#125;) &#125; // 添加路由 root.addRoute(path, handlers)&#125;// 路由树节点type node struct &#123; path string indices string children []*node handlers HandlersChain // 所有的handle 构成一个链 priority uint32 nType nodeType maxParams uint8 wildChild bool&#125;// 启动http serverfunc (engine *Engine) Run(addr ...string) (err error) &#123; defer func() &#123; debugPrintError(err) &#125;() address := resolveAddress(addr) debugPrint(&quot;Listening and serving HTTP on %s\\n&quot;, address) // 执行http包的ListenAndServe方法 启动路由 err = http.ListenAndServe(address, engine) return&#125;// engine自身就实现了Handler接口type Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125;// 监听IP+端口ln, err := net.Listen(&quot;tcp&quot;, addr)// 接着就是Servesrv.Serve(tcpKeepAliveListener&#123;ln.(*net.TCPListener)&#125;)// Accept请求rw, e := l.Accept()// 使用goroutine去处理一个请求，最终就执行的是engine的ServeHTTP方法go c.serve(ctx)// engine实现http.Handler接口ServeHTTP的具体方法func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; // 获取一个上下文实例，从实例池获取 性能高 c := engine.pool.Get().(*Context) // 重置获取到的上下文实例的http.ResponseWriter c.writermem.reset(w) // 重置获取到的上下文实例*http.Request c.Request = req // 重置获取到的上下文实例的其他属性 c.reset() // 实际处理请求的地方，传递当前的上下文 engine.handleHTTPRequest(c) //归还上下文实例 engine.pool.Put(c)&#125;// 具体执行路由的方法engine.handleHTTPRequest(c)t := engine.treesfor i, tl := 0, len(t); i &lt; tl; i++ &#123; // 遍历路由树，查找当前请求method if t[i].method != httpMethod &#123; continue &#125; // 找到节点 root := t[i].root // 寻找当前请求的路由 handlers, params, tsr := root.getValue(path, c.Params, unescape) if handlers != nil &#123; // 把找到的handles赋值给上下文 c.handlers = handlers // 把找到的入参赋值给上下文 c.Params = params // 执行handle c.Next() // 处理响应内容 c.writermem.WriteHeaderNow() return &#125; ...&#125;// 方法树结构体type methodTree struct &#123; // HTTP Method method string // 当前HTTP Method的路由节点 root *node&#125;// 方法树集合type methodTrees []methodTree// 执行handlefunc (c *Context) Next() &#123; // 上下文处理之后c.index被执为-1 c.index++ for s := int8(len(c.handlers)); c.index &lt; s; c.index++ &#123; // 遍历执行所有handle(其实就是中间件+路由handle) c.handlers[c.index](c) &#125;&#125;// Context的重置方法func (c *Context) reset() &#123; c.Writer = &amp;c.writermem c.Params = c.Params[0:0] c.handlers = nil // 很关键 注意这里是-1哦 c.index = -1 c.Keys = nil c.Errors = c.Errors[0:0] c.Accepted = nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go OS性能数据","slug":"Go OS性能数据","date":"2019-05-16T07:22:58.000Z","updated":"2021-07-07T06:23:22.756Z","comments":true,"path":"2019/05/16/Go OS性能数据/","link":"","permalink":"https://elihe2011.github.io/2019/05/16/Go%20OS%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE/","excerpt":"1. 系统性能psutil是一个跨平台进程和系统监控的Python库，gopsutil是其Go语言版本的实现。适合做一些诸如采集系统信息和监控的服务 1go get github.com/shirou/gopsutil/cpu 123456789101112131415161718192021222324252627282930313233343536373839404142434445func getCpuInfo() &#123; cpuInfos, _ := cpu.Info() for _, ci := range cpuInfos &#123; fmt.Println(ci) &#125; // CPU 使用率 for &#123; percent, _ := cpu.Percent(time.Second, false) fmt.Printf(&quot;cpu percent: %v\\n&quot;, percent) &#125;&#125;func getMemInfo() &#123; memInfo, _ := mem.VirtualMemory() fmt.Printf(&quot;mem info: %v\\n&quot;, memInfo)&#125;func getHostInfo() &#123; hostInfo, _ := host.Info() fmt.Printf(&quot;host info: %v\\n&quot;, hostInfo)&#125;func getDiskInfo() &#123; parts, _ := disk.Partitions(true) for _, part := range parts &#123; fmt.Printf(&quot;part: %v\\n&quot;, part.String()) diskInfo, _ := disk.Usage(part.Mountpoint) fmt.Printf(&quot;disk info: used=%v, free=%v\\n&quot;, diskInfo.Used, diskInfo.Free) &#125; ioStat, _ := disk.IOCounters() for k, v := range ioStat &#123; fmt.Printf(&quot;%v: %v\\n&quot;, k, v) &#125;&#125;func getNetInfo() &#123; infos, _ := net.IOCounters(true) for i, v := range infos &#123; fmt.Printf(&quot;%v: %v, send: %v, recv: %v\\n&quot;, i, v, v.BytesSent, v.BytesRecv) &#125;&#125;","text":"1. 系统性能psutil是一个跨平台进程和系统监控的Python库，gopsutil是其Go语言版本的实现。适合做一些诸如采集系统信息和监控的服务 1go get github.com/shirou/gopsutil/cpu 123456789101112131415161718192021222324252627282930313233343536373839404142434445func getCpuInfo() &#123; cpuInfos, _ := cpu.Info() for _, ci := range cpuInfos &#123; fmt.Println(ci) &#125; // CPU 使用率 for &#123; percent, _ := cpu.Percent(time.Second, false) fmt.Printf(&quot;cpu percent: %v\\n&quot;, percent) &#125;&#125;func getMemInfo() &#123; memInfo, _ := mem.VirtualMemory() fmt.Printf(&quot;mem info: %v\\n&quot;, memInfo)&#125;func getHostInfo() &#123; hostInfo, _ := host.Info() fmt.Printf(&quot;host info: %v\\n&quot;, hostInfo)&#125;func getDiskInfo() &#123; parts, _ := disk.Partitions(true) for _, part := range parts &#123; fmt.Printf(&quot;part: %v\\n&quot;, part.String()) diskInfo, _ := disk.Usage(part.Mountpoint) fmt.Printf(&quot;disk info: used=%v, free=%v\\n&quot;, diskInfo.Used, diskInfo.Free) &#125; ioStat, _ := disk.IOCounters() for k, v := range ioStat &#123; fmt.Printf(&quot;%v: %v\\n&quot;, k, v) &#125;&#125;func getNetInfo() &#123; infos, _ := net.IOCounters(true) for i, v := range infos &#123; fmt.Printf(&quot;%v: %v, send: %v, recv: %v\\n&quot;, i, v, v.BytesSent, v.BytesRecv) &#125;&#125; 2. 获取IP地址12345678910111213141516171819202122232425262728293031func getLocalIP() &#123; addrs, _ := net.InterfaceAddrs() for _, addr := range addrs &#123; ipAddr, ok := addr.(*net.IPNet) if !ok &#123; continue &#125; if ipAddr.IP.IsLoopback() &#123; continue &#125; if !ipAddr.IP.IsGlobalUnicast() &#123; continue &#125; fmt.Println(ipAddr.IP.String()) &#125;&#125;func getOutboundIP() &#123; conn, err := net.Dial(&quot;udp&quot;, &quot;114.114.114.114:80&quot;) if err != nil &#123; panic(err) &#125; defer conn.Close() localAddr := conn.LocalAddr().(*net.UDPAddr) fmt.Println(localAddr.IP.String())&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 数据库 sqlx","slug":"Go 数据库 sqlx","date":"2019-05-01T08:30:58.000Z","updated":"2021-06-30T08:30:43.360Z","comments":true,"path":"2019/05/01/Go 数据库 sqlx/","link":"","permalink":"https://elihe2011.github.io/2019/05/01/Go%20%E6%95%B0%E6%8D%AE%E5%BA%93%20sqlx/","excerpt":"1. Getting Started12go get github.com/jmoiron/sqlxgithub.com/go-sql-driver/mysql 2. Handle Types4 handle types: sqlx database/sql sqlx.DB sql.DB sqlx.Tx sql.Tx sqlx.Stmt sql.Stmt sqlx.NamedStmt 2 cursor types: sqlx database/sql from sqlx.Rows sql.Rows Queryx sqlx.Row sql.Row QueryRowx","text":"1. Getting Started12go get github.com/jmoiron/sqlxgithub.com/go-sql-driver/mysql 2. Handle Types4 handle types: sqlx database/sql sqlx.DB sql.DB sqlx.Tx sql.Tx sqlx.Stmt sql.Stmt sqlx.NamedStmt 2 cursor types: sqlx database/sql from sqlx.Rows sql.Rows Queryx sqlx.Row sql.Row QueryRowx 3. Connecting to Database12345678910111213var dsn = &quot;root:123456@tcp(127.0.0.1:3306)/mydb?parseTime=true&amp;&amp;charset=utf8mb4&quot;var db *sqlx.DB// 1. same as sql.Open()db, err = sqlx.Open(&quot;mysql&quot;, dsn)err = db.Ping() // force a connection and test that is worked // 2. open and connect at the same timedb, err = sqlx.Connect(&quot;mysql&quot;, dsn)// 3. same as 2, but panic on errordb = sqlx.MustConnect(&quot;mysql&quot;, dsn) 4. Querying12345678910111213141516171819202122232425262728// 1. unchanged from database/sqlExec(query string, args ...interface&#123;&#125;) (sql.Result, error)Query(query string, args ...interface&#123;&#125;) (*sql.Rows, error)QueryRow(query string, args ...interface&#123;&#125;) *sql.Row// 2. extensionsMustExec(query string, args ...interface&#123;&#125;) sql.ResultQueryx(query string, args ...interface&#123;&#125;) (*sqlx.Rows, error)QueryRowx(query string, args ...interface&#123;&#125;) *sqlx.Row// 3. new semantics: 结构体struct与数据库schema绑定Select(dest interface&#123;&#125;, query string, args ...interface&#123;&#125;) errorGet(dest interface&#123;&#125;, query string, args ...interface&#123;&#125;) error // An error is returned if the result set is empty// 4. sqlx.Rowtype Rows struct &#123; *sql.Rows unsafe bool Mapper *reflectx.Mapper // these fields cache memory use for a rows during iteration w/ structScan started bool fields [][]int values []interface&#123;&#125;&#125;// 5. sql.ResultLastInsertId() (int64, error)RowsAffected() (int64, error) 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func querying(db *sqlx.DB) &#123; // 1. Exec &amp; MustExec schema := `CREATE TABLE IF NOT EXISTS person (id INT(10) AUTO_INCREMENT PRIMARY KEY,name VARCHAR(20) NOT NULL,age TINYINT,address VARCHAR(100))` db.MustExec(schema) sqlStr := &quot;insert into person(name, age) values(?, ?)&quot; db.MustExec(sqlStr, &quot;jack&quot;, 21) db.MustExec(sqlStr, &quot;maxin&quot;, 30) sqlStr = &quot;insert into person(name, age, address) values(?, ?, ?)&quot; result, err := db.Exec(sqlStr, &quot;lucy&quot;, 39, &quot;London, UK&quot;) if err != nil &#123; panic(err) &#125; id, _ := result.LastInsertId() fmt.Printf(&quot;last insert id is %d\\n&quot;, id) // 2. Query &amp; Queryx sqlStr = &quot;select * from person&quot; rows1, err := db.Query(sqlStr) if err != nil &#123; panic(err) &#125; for rows1.Next() &#123; var id int var name string var age uint8 var address sql.NullString err = rows1.Scan(&amp;id, &amp;name, &amp;age, &amp;address) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;id: %d, name: %s, age: %d, address: %v\\n&quot;, id, name, age, address) &#125; type person struct &#123; Id int Name string Age uint8 Address sql.NullString &#125; rows2, err := db.Queryx(sqlStr) if err != nil &#123; panic(err) &#125; for rows2.Next() &#123; var p person rows2.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p) &#125; // 3. Get &amp; Select var p person var pp []person err = db.Get(&amp;p, &quot;select * from person limit 1&quot;) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v\\n&quot;, p) err = db.Select(&amp;pp, &quot;select * from person where id &gt; 2&quot;) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v\\n&quot;, pp) var count int db.Get(&amp;count, &quot;select count(*) from person&quot;) fmt.Println(count) var names []string db.Select(&amp;names, &quot;select name from person&quot;) fmt.Println(names)&#125; 5. Transactions123456// 1. sql.TxBegin() (*sql.Tx, error)// 2. sqlx.TxBeginx() (*sqlx.Tx, error)MustBegin() (*sql.Tx) 示例： 123456789101112131415161718func transaction(db *sqlx.DB) &#123; tx := db.MustBegin() defer func() &#123; if err := recover(); err != nil &#123; tx.Rollback() &#125; &#125;() tx.MustExec(&quot;delete from person where id=4&quot;) tx.MustExec(&quot;insert into person values(2, &#x27;abc&#x27;, 22, &#x27;LA&#x27;)&quot;) tx.MustExec(&quot;insert into person values(100, &#x27;abc&#x27;, 22, &#x27;LA&#x27;)&quot;) err := tx.Commit() if err != nil &#123; panic(err) &#125;&#125; 6. Prepared Statements123456789101112131415161718func prepared(db *sqlx.DB) &#123; stmt, _ := db.Prepare(&quot;select * from person where id=?&quot;) row := stmt.QueryRow(5) var id int var name string var age uint8 var address sql.NullString row.Scan(&amp;id, &amp;name, &amp;age, &amp;address) fmt.Printf(&quot;id: %d, name: %s, age: %d, address: %v\\n&quot;, id, name, age, address) stmtx, _ := db.Preparex(&quot;select * from person where id=?&quot;) rowx := stmtx.QueryRowx(5) var p person rowx.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p)&#125; 7. Query Helpers7.1 “In” Queries123456789101112131415161718192021222324252627282930313233func inQuery(db *sqlx.DB) &#123; ids := []int&#123;1, 2, 3, 4, 5&#125; /* // converting argument $1 type: unsupported type []int, a slice of int rows, err := db.Query(&quot;select name from person where id in (?)&quot;, ids) if err != nil &#123; panic(err) &#125; for rows.Next() &#123; var name string rows.Scan(&amp;name) fmt.Println(name) &#125;*/ // convert to (?, ?, ...) query, args, err := sqlx.In(&quot;select name from person where id in (?)&quot;, ids) if err != nil &#123; panic(err) &#125; query = db.Rebind(query) fmt.Println(query) rows, err := db.Query(query, args...) if err != nil &#123; panic(err) &#125; for rows.Next() &#123; var name string rows.Scan(&amp;name) fmt.Println(name) &#125;&#125; 7.2 Named Queries123NamedQuery(query string, arg interface&#123;&#125;) (*sqlx.Rows, error)NamedExec(query string, arg interface&#123;&#125;) (sql.Result, error)PrepareNamed(query string) (*NamedStmt, error) 示例： 1234567891011121314151617func namedQuery(db *sqlx.DB) &#123; // named query with a struct p := person&#123;Name: &quot;jack&quot;&#125; rows, _ := db.NamedQuery(&quot;select count(*) from person where name=:name&quot;, p) for rows.Next() &#123; var count int rows.Scan(&amp;count) fmt.Println(count) &#125; // named query with a map m := map[string]interface&#123;&#125;&#123;&quot;address&quot;: &quot;LA&quot;&#125; stmt, _ := db.PrepareNamed(&quot;select * from person where address=:address limit 1&quot;) row := stmt.QueryRowx(m) row.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p)&#125; 8. Alternate Scan Types1234567891011121314func alternateScan(db *sqlx.DB) &#123; rows, _ := db.Queryx(&quot;select * from person&quot;) for rows.Next() &#123; cols, _ := rows.SliceScan() fmt.Println(cols) &#125; rows, _ = db.Queryx(&quot;select * from person&quot;) for rows.Next() &#123; cols := make(map[string]interface&#123;&#125;) rows.MapScan(cols) fmt.Println(cols) &#125;&#125; 9. Connection Pool12DB.SetMaxIdleConns(n int)DB.SetMaxOpenConns(n int)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Linux 使用总结","slug":"Linux 使用总结","date":"2019-04-30T06:12:26.000Z","updated":"2021-07-13T03:05:04.798Z","comments":true,"path":"2019/04/30/Linux 使用总结/","link":"","permalink":"https://elihe2011.github.io/2019/04/30/Linux%20%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/","excerpt":"1. Ubuntu1.1 修改IPUbuntu 16, 18: 12345678910sudo vi /etc/network/interfacesauto ens33iface ens33 inet staticaddress 192.168.80.20netmask 255.255.255.0gateway 192.168.80.2dns-nameservers 8.8.8.8sudo ip addr flush ens33sudo systemctl restart networking","text":"1. Ubuntu1.1 修改IPUbuntu 16, 18: 12345678910sudo vi /etc/network/interfacesauto ens33iface ens33 inet staticaddress 192.168.80.20netmask 255.255.255.0gateway 192.168.80.2dns-nameservers 8.8.8.8sudo ip addr flush ens33sudo systemctl restart networking Ubuntu 20: 123456789101112131415sudo vi /etc/netplan/00-installer-config.yamlnetwork: ethernets: ens33: addresses: - 192.168.80.121/24 gateway4: 192.168.80.2 nameservers: addresses: - 8.8.8.8 search: - 8.8.8.8 version: 2sudo netplan apply 1.2 防火墙1234567sudo ufw statussuod ufw enable/disablesudo ufw allow/deny 22/tcpsudo ufw allow from 192.168.80.1sudo ufw delete allow from 192.168.80.1 1.3 sshd12345sudo apt-get updatesudo apt-get install openssh-serversudo ps -ef | grep ssh 1.4 Docker123456789101112131415161718192021222324# 可能缺少的公共命令sudo apt-get install software-properties-common -y# 证书sudo curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# 仓库信息sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;# 更新 cachesudo apt-get update# 可用版本查询sudo apt-cache policy docker-cesudo apt-cache madison docker# 安装 docker 19.03.15~3-0~ubuntu-xenialsudo apt-get install docker-ce=5:19.03.15~3-0~ubuntu-xenial -ysudo docker version# 不需要 sudo， 重新登录sudo usermod -aG docker $USERsudo systemctl restart docker 1.5 Python 多版本1234567891011121314151617181920212223242526# 增加 deadsnakes PPA 源sudo add-apt-repository ppa:deadsnakes/ppa# 安装 python 3.9sudo apt-get updatesudo apt-get install python3.9# python 默认版本切换成 3.9sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2sudo update-alternatives --config python3There are 2 choices for the alternative python3 (providing /usr/bin/python3). Selection Path Priority Status------------------------------------------------------------* 0 /usr/bin/python3.8 2 auto mode 1 /usr/bin/python3.8 2 manual mode 2 /usr/bin/python3.9 1 manual modePress &lt;enter&gt; to keep the current choice[*], or type selection number: 2sudo apt install python3-pip python3.9-venvpython3 -m venv /home/ubuntu/python/venv 1.6 防火墙123sudo ufw allow sshsudo ufw allow 6379/tcp 1.7 阿里源ubuntu16: 12345678910111213141516171819202122232425262728sudo -iecho &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.confmv /etc/apt/sources.list /etc/apt/sources.list.bakcat &gt; /etc/apt/sources.list &lt;&lt;EOF# deb cdrom:[Ubuntu 16.04 LTS _Xenial Xerus_ - Release amd64 (20160420.1)]/ xenial main restricteddeb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-propertiesdeb http://archive.canonical.com/ubuntu xenial partnerdeb-src http://archive.canonical.com/ubuntu xenial partnerdeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverseEOFapt-get update ubuntu20: 1234567891011121314151617181920mv /etc/apt/sources.list /etc/apt/sources.list.bakcat &gt; /etc/apt/sources.list &lt;&lt;EOFdeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverseEOFapt update 1.8 时区1234567891011121314151617ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# alternativetimedatectl set-timezone &quot;Asia/Shanghai&quot;timedatectl status# alternative 2vi /etc/profileTZ=&#x27;Asia/Shanghai&#x27;export TZ# 时间更新date -s &quot;2019-06-04 11:06:30&quot; # 修改为一个正确的时间hwclock -wcrontab -e* */1 * * * ntpdate 0.asia.pool.ntp.org 1.9 k8s1234567891011apt-get update &amp;&amp; apt-get install -y apt-transport-httpscurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - # ubuntu16cat &gt;/etc/apt/sources.list.d/kubernetes.list &lt;&lt;EOFdeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOFapt-get updateapt-get install -y kubelet kubeadm kubectl 2. CentOS2.1 寻找命令所在包1yum whatprovides */lspci 2.2 获取磁盘的 uuid1234blkid/dev/sr0: UUID=&quot;2020-04-22-00-51-40-00&quot; LABEL=&quot;CentOS 7 x86_64&quot; TYPE=&quot;iso9660&quot; PTTYPE=&quot;dos&quot; /dev/sda1: UUID=&quot;8447e521-4bb8-4fb7-853e-cd6661dd98b4&quot; TYPE=&quot;xfs&quot; 2.3. 换yum源123456mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -Oyum makecache 2.4 防火墙12345iptables -A INPUT -p tcp -s 0/0 --dport 80 -j ACCEPT iptables -A OUTPUT -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT service iptables save 3. 公共部分3.1 进程 &amp; 线程1234567891011121314# 线程top -H # 需要ncurses， 更友好htop# 进程的关联子进程ps -T -p 959 PID SPID TTY TIME CMD 959 959 ? 00:00:27 redis-server 959 960 ? 00:00:00 redis-server 959 961 ? 00:00:00 redis-server 959 962 ? 00:00:00 redis-server 3.2 路由1234567891011# 删除默认设置route delete 0.0.0.0# 外网路由，全走无线route add 0.0.0.0 mask 0.0.0.0 192.168.33.1 –p# 公司内网全部在10.40.*.*网段route add 10.40.0.0 mask 255.255.0.0 10.40.254.1 -p# 路由追踪tracert -d google.com 3.3 tcpdump12345678tcpdump -i ens33 port 8080 -w http.captcpdump src port 1025tcpdump portrange 21-23tcpdump -vvAls0 | grep &#x27;User-Agent:&#x27;tcpdump -vvAls0 | grep &#x27;Set-Cookie|Host:|Cookie:&#x27; 3.4 支持密码登录1234vi /etc/ssh/sshd_configPasswordAuthentication no =&gt; yessystemctl restart sshd 3.5 远程端口检查3.5.1 telnet1telnet baidu.com 80 3.5.2 nc (NetCat)1nc -v baidu.com 80 3.5.3 nmap1nmap baidu.com -p 80 3.6 sudo3.6.1 语法条目1who host=(runas) TAG:command 3.6.2. 配置123456789visudooracle ALL=(root) NOPASSWD:/sbin/useradd, PASSWD:/sbin/userdel%admin ALL=(root) NOPASSWD:/sbin/shutdownweb ALL=(operator) /etc/webhook/mytest.shtest ALL=(ALL) /bin/cat /var/log/secure*, !/bin/cat /var/log/secure* * 3.6.3. 执行sudo12345su - oraclesudo /sbin/useradd test123su - websudo -u operator /etc/webhook/mytest.sh 4. 软件4.1 Redis1234wget http://download.redis.io/releases/redis-5.0.12.tar.gz tar zxvf redis-5.0.12.tar.gz cd redis-5.0.12make 4.2 k8s12345678910111213cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFsetenforce 0yum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Nginx配置","slug":"Nginx","date":"2019-04-25T01:15:17.000Z","updated":"2021-06-22T10:50:49.734Z","comments":true,"path":"2019/04/25/Nginx/","link":"","permalink":"https://elihe2011.github.io/2019/04/25/Nginx/","excerpt":"1. 重定向1.1 proxy_pass302跳转，不能传递原来请求的header 12345678910111213server &#123; listen 80; server_name a.example.com; listen 443 ssl; location = /xx &#123; proxy_pass http://b.example.com/xx; proxy_set_header Host b.example.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; break; &#125;&#125;","text":"1. 重定向1.1 proxy_pass302跳转，不能传递原来请求的header 12345678910111213server &#123; listen 80; server_name a.example.com; listen 443 ssl; location = /xx &#123; proxy_pass http://b.example.com/xx; proxy_set_header Host b.example.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; break; &#125;&#125; 1.2 rewrite12345server &#123; listen 80; server_name test1.com; rewrite ^(.*) https://www.test1.com$1 permanent;&#125; 2. 负载均衡 upstream123456789101112131415upstream balanceServer &#123; ip_hash; server 192.168.1.10:8080 weight 2; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125;server &#123; server_name test.com; listen 80; location /api &#123; proxy_pass http://balanceServer; &#125;&#125; weight：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。与ip_hash不兼容 负载均衡策略： 轮询（默认） 缺点：如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。 12345upstream balanceServer &#123; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 最小连接数策略 将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求 123456upstream balanceServer &#123; least_conn; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 最快响应时间策略 依赖于 NGINX Plus，优先分配给响应时间最短的服务器。 123456upstream balanceServer &#123; fair; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; session共享 每个访问安访问ip的hash结果分配，可确保每个访客孤独访问一个后端服务器，可解决session保持问题。 123456upstream balanceServer &#123; ip_hash; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 3. Nginx内置全局变量 变量名 功能 $host 请求信息中的Host，没有则设置成服务器名 $request_method GET, POST $args $content_length $http_user_agent $http_cookie $remote_addr $remote_port $server_protocol HTTP/1.0 HTTP/1.1 $server_addr $server_port $server_name 4. 请求过滤4.1 按状态码过滤123456789101112server &#123; listen 80; server_name test.com; access_log /var/log/nginx/nginx-access.log main; error_log /var/log/nginx/nginx-error.log; error_page 404 = /404; error_page 403 = /403; error_page 500 501 502 503 504 506 /50x.html; location /50x.html &#123; root /data/www/static/html; &#125; 4.2 按URL过滤12345server &#123; #... rewrite ^.*$ /index.html;&#125; 4.3 按请求类型过滤12345server &#123; if ( $request_method !~ ^(GET|POST|HEAD)$ ) &#123; return 403; &#125;&#125; 5. 配置gzip1234567http &#123; gzip on; gzip_http_version 1.1; gzip_comp_level 5; gzip_min_length 1000; gzip_types text/csv text/xml text/css text/plain text/javascript application/javascript application/x-javascript application/json application/xml;&#125; 6. Nginx配置文件结构123456789101112131415161718192021222324252627events &#123; &#125;http &#123; upstream node &#123; &#125; server &#123; location path &#123; ... &#125; location path &#123; ... &#125; &#125; server &#123; ... &#125;&#125; 7. 静态资源配置123456location ~* \\.(png|gif|jpg|jpeg)$ &#123; root /root/static/; autoindex on; access_log off; expires 24h; # 过期时间为24小时 &#125; 8. 静态资源缓存1234567891011121314151617location /hhhh/ &#123; root /data/www/lp-web/; index index.html; try_files $uri index.html; if ($request_filename ~* .*\\.(?:htm|html)$) &#123; add_header Cache-Control &quot;private, no-store, no-cache, must-revalidate, proxy-revalidate&quot;; &#125; if ($request_filename ~* .*\\.(?:js|css)$) &#123; expires 7d; &#125; if ($request_filename ~* .*\\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm)$) &#123; expires 7d; &#125;&#125; 9. nginx日志request_time 和upstream_response_time区别 request_time: request processing time in seconds with a milliseconds resolution; time elapsed between the first bytes were read from the client and the log write after the last bytes were sent to the client. 指的就是从接受用户请求的第一个字节到发送完响应数据的时间，即包括接收请求数据时间、程序响应时间、输出响应数据时间。 upstream_response_time: keeps times of responses obtained from upstream servers; times are kept in seconds with a milliseconds resolution. Several response times are separated by commas and colons like addresses in the $upstream_addr variable. 指从Nginx向后端建立连接开始到接受完数据然后关闭连接为止的时间。 从上面的描述可以看出，$request_time肯定比$upstream_response_time值大，特别是使用POST方式传递参数时，因为Nginx会把request body缓存住，接受完毕后才会把数据一起发给后端。所以如果用户网络较差，或者传递数据较大时，$request_time会比$upstream_response_time大很多。 $request_time 包含了用户数据接收时间，而真正程序的响应时间应该用$upstream_response_time。 配置说明： 1234log_format timed_combined &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27; &#x27;$request_time $upstream_response_time&#x27;;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://elihe2011.github.io/categories/Nginx/"}],"tags":[]},{"title":"select、poll和epoll","slug":"IO多路复用和异步","date":"2019-04-12T03:22:17.000Z","updated":"2021-06-22T10:50:49.733Z","comments":true,"path":"2019/04/12/IO多路复用和异步/","link":"","permalink":"https://elihe2011.github.io/2019/04/12/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%BC%82%E6%AD%A5/","excerpt":"1. selectselect最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 1234567while true &#123; select(streams[]) for i in streams[] &#123; if i has data read until unavailable &#125;&#125;","text":"1. selectselect最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 1234567while true &#123; select(streams[]) for i in streams[] &#123; if i has data read until unavailable &#125;&#125; select的优点是支持目前几乎所有的平台，缺点主要有如下2个： 1）单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024(32位，64位默认2048，proc/sys/fs/file-max)，不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制。 2）select 所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长。同时，由于网络响应时间的延迟使得大量TCP连接处于非活跃状态，但调用select()会对所有socket进行一次线性扫描，所以这也浪费了一定的开销。 2. pollpoll则在1986年诞生于System V Release 3，它和select在本质上没有多大差别，但是poll没有最大文件描述符数量的限制。 3. epoll epoll是Linux 2.6 开始出现的为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 123456while true &#123; active_stream[] = epoll_wait(epollfd) for i in active_stream[] &#123; read or write till &#125;&#125; 1.3 epollepoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 epoll的优点： 1、没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数； 即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 3、 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 1.4 select、poll、epoll 区别总结1、支持一个进程所能打开的最大连接数 类型 特点 select 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 poll poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 epoll 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 2、FD剧增后带来的IO效率问题 类型 特点 select 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 poll 同上 epoll 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 3、 消息传递方式| 类型 | 特点 || —— | ———————————————————— || select | 内核需要将消息传递到用户空间，都需要内核拷贝动作 || poll | 同上 || epoll | epoll通过内核和用户空间共享一块内存来实现的。 | 总结： 综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。 1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 2. 异步与非阻塞的区别非阻塞是对于socket而言；异步是相对于应用程序而言，是一种编程模型 Epoll是非阻塞的，但不是异步。实现阻塞和简单，socket.setblocking(False)即可；实现异步很复杂。 Linux没有实现异步IO(效率并不高)，Epoll是一种I/O多路复用技术，用户程序需要主动去询问内核是否有事件发生，而不是事件发生时内核主动去调用回调函数，所以不是异步的。 Tornado框架之所以是异步的，它在epoll的基础上进行了一层封装，由框架去取事件，然后由框架去调用用户的回调函数，所以对于基于该框架的用户程序来说，是异步的。 Tornado使用Epoll实现了异步编程模型，使用异步的前提是socket是非阻塞的。 3. Python selectPython的select()方法直接调用操作系统的IO接口，它监控sockets,open files, and pipes(所有带fileno()方法的文件句柄)何时变成readable 和writeable, 或者通信错误，select()使得同时监控多个连接变的简单，并且这比写一个长循环来等待和监控多客户端连接要高效，因为select直接通过操作系统提供的C的网络接口进行操作，而不是通过Python的解释器。 select()方法接收并监控3个通信列表， 第一个是所有的输入的data,就是指外部发过来的数据，第2个是监控和接收所有要发出去的data(outgoing data),第3个监控错误信息，接下来我们需要创建2个列表来包含输入和输出信息来传给select(). select_echo_server.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import selectimport socketimport sysfrom queue import Queue, Emptyserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server.setblocking(False)server_address = (&#x27;localhost&#x27;, 5000)print(&#x27;starting up on %s port %s&#x27; % server_address, file=sys.stderr)server.bind(server_address)server.listen(5)# reading socketsinputs = [server, ]# writing socketsoutputs = []message_queues = &#123;&#125;while inputs: print(&#x27;\\nwaiting for the next event.&#x27;) readable, writable, exceptional = select.select(inputs, outputs, inputs) for s in readable: if s is server: # A readable server socket is ready to accept a connection connection, client_address = s.accept() print(&#x27;new connection from&#x27;, client_address) connection.setblocking(False) inputs.append(connection) # Give the connection a queue for data we want to send message_queues[connection] = Queue() else: data = s.recv(1024) if data: # A readable client socket has data print(&#x27;received &quot;%s&quot; from %s&#x27; % (data, s.getpeername())) message_queues[s].put(data) # Add output channel for response if s not in outputs: outputs.append(s) else: # Interpret empty result as closed connection print(&#x27;closing&#x27;, client_address, &#x27;after reading not data.&#x27;) # Stop listening for input on the connection if s in outputs: outputs.remove(s) inputs.remove(s) s.close() # Remove message queue del message_queues[s] for s in writable: try: next_msg = message_queues[s].get_nowait() except Empty: # No message waiting so stop checking for writability print(&#x27;output queue for&#x27;, s.getpeername(), &#x27;is empty&#x27;) outputs.remove(s) else: print(&#x27;sending &quot;%s&quot; to %s&#x27; % (next_msg, s.getpeername())) reply = &#x27;replied: &#x27; + next_msg.decode(&#x27;utf-8&#x27;) s.send(reply.encode(&#x27;utf-8&#x27;)) for s in exceptional: print(&#x27;handling exceptional condition for&#x27;, s.getpeername()) inputs.remove(s) if s in outputs: outputs.remove(s) s.close() del message_queues[s] select_echo_multiclient.py 12345678910111213141516171819202122232425import socketimport sysserver_address = (&#x27;localhost&#x27;, 5000)messages = [&#x27;message %s&#x27; % i for i in range(10)]socks = [socket.socket(socket.AF_INET, socket.SOCK_STREAM) for _ in range(3)]print(&#x27;connecting to %s port %s&#x27; % server_address, file=sys.stderr)for s in socks: s.connect(server_address)for message in messages: # send messages on both sockets for s in socks: print(&#x27;%s: sending &quot;%s&quot;&#x27; % (s.getsockname(), message), file=sys.stderr) s.send(message.encode(&#x27;utf-8&#x27;)) # read response on both sockets for s in socks: data = s.recv(1024) print(&#x27;%s: received &quot;%s&quot;&#x27; % (s.getsockname(), data), file=sys.stderr) if not data: print(&#x27;closing socket&#x27;, s.getsockname(), file=sys.stderr) s.close()","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Redis","slug":"Redis","date":"2019-01-29T03:12:17.000Z","updated":"2021-07-13T02:41:23.486Z","comments":true,"path":"2019/01/29/Redis/","link":"","permalink":"https://elihe2011.github.io/2019/01/29/Redis/","excerpt":"1. 概述1.1 什么是RedisRedis：Remote Dictionary Server，高性能非关系型(NoSQL)键值对数据库 Redis特性： key-value 存储 支持数据可靠性存储及落地 单进程但线程高性能服务器 crash safe &amp; recovery slow 单机qps可达10W 适合小数据量高速读写访问","text":"1. 概述1.1 什么是RedisRedis：Remote Dictionary Server，高性能非关系型(NoSQL)键值对数据库 Redis特性： key-value 存储 支持数据可靠性存储及落地 单进程但线程高性能服务器 crash safe &amp; recovery slow 单机qps可达10W 适合小数据量高速读写访问 1.2 优缺点优点： 读写性能高 支持持久化，RDB &amp; AOF 数据类型丰富，五种：string, list, set, sorted-set, hash 支持简单事务 支持TTL 支持主从复制，可以进行读写分离 缺点： 数据库容量受限物理内存（低于物理内存的60%），不能支持海量数据的高性能读写。 不具备自动容错和恢复功能 主节点宕机，可能会有部分数据未及时同步到从节点，导致数据不一致 很难在线扩容，一般在系统上线前必须保有足够的空间 buffer io造成系统OOM 2. 数据类型2.1 五种类型 string: 字符串操作、原子计数器等 hash: 以hashmap方式存储，可用来存储json对象。 list: 消息队列，timeline等 set：Unique去重操作。统计独立IP，好友推荐去重等 sorted-set: 排行榜，TOP N操作，带权重 其他： 订阅-发布系统：群聊，广播等 事务 2.2 应用场景 计数器 缓存服务 展示最近、最热、点击率最高、活跃度最高等条件的top list 用户最近访问记录 消息队列 粉丝列表 分布式锁 （SETNX 互斥锁实现） 2.3 事务 Redis事务就是一次性、顺序性、排他性的执行一盒队列中的一系列命令 没有事务隔离级别 不保证原子性 CAS: check-and-set, 操作乐观锁 提供MULTI、EXEC、DISACRD、WATCH 四个命令实现事务 提供redis-check-aof工具帮助定位数据不一致错误 示例： 123456&gt; MULTI # 开始事务&gt; set k1 v1&gt; set k2 v2&gt; get k2&gt; EXEC # 执行事务 （批量执行命令）&gt; DISCARD # 放弃事务 (上述命令将不会被执行) 12345&gt; MULTI&gt; set k1 v1&gt; set k2 v2&gt; getset k3 v3 # 语法性错&gt; EXEC # 上述命令不会被执行 123456&gt; MULTI&gt; set k1 v1&gt; set k2 v2&gt; incr k3 # 运行时异常&gt; set k4 v4&gt; EXEC # 上述命令被执行，执行incr时抛出错误，但不影响其他命令 12345WATCH balanceMULTIdecrby balance 20incrby debt 20EXEC # 如果在另一个窗口对balance的值做了更新，那么事务将执行失败 2.4 发布和订阅1) Client 12redis-cli&gt; subscribe my_channel 2) Server 12redis-cli&gt; publish my_channel hello 3. 持久化3.1 RDB (snapshot) 将数据以快照形式保存在磁盘上 (dump.db) 触发数据快照的三种机制： save: 将阻塞当前Redis服务器，执行save期间，不能处理其他命令，直至RDB过程完毕 bgsave: 后台异步进行快照操作。它会fork一个子进程负责处理 自动触发： 123456789save 900 1 # 900s内至少有一个key的值变化才触发save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.dbdir /data/redis/db 快照保存过程： redis调用fork，产生一个子进程 父进程继续处理client请求，子进程负责将fork时刻整个内存数据库快照写入临时文件。 子进程完成写入临时文件后，用临时文件替换原来的快照文件，然后子进程退出。 ​ 问题：每次快照持久化都是将内存数据完整写入到磁盘，如果数据量较大，读写操作较多，必然会引起磁盘IO问题。 优势: RDB文件紧凑，全量备份，适合用于进行备份和灾难恢复 生成RDB时，Redis主进程fork一个子进程来处理保存工作，主进程不需要进行任何磁盘IO操作 RDB恢复比AOF快 劣势：RDB数据保存子进程可能来不及保存数据，导致数据丢失 3.2 AOF (append only file) 每一条命令都会通过write函数追加到文件中，即日志记录 aof的问题：aof文件会越来越大。可通过bgrewriteaof命令，将内存中的数据以命令方式保存到临时文件，同时fork一个子进程来重写aof文件，最后替换原来的文件。 1234567891011appendonly yesappendfilename &quot;appendonly.aof&quot;# 三选一appendsync alwaysappendsync everysecappendsync no # 完全依赖操作系统，性能最好，但持久化可能丢数据# 自动bgrewriteaofauto-aof-rewrite-percentage 100auto-aof-rewrite-size 64mb 优势： 数据不容易丢失 日志文件过大时，会出现后台重写，不会影响客户端读写 日志文件以命令可读方式记录，容易查找命令记录来恢复数据 劣势： AOF日志文件比RDB文件大 AOF开启后，写的QPS会降低 3.3 方案选择Snapchat性能更高，但可能会引起一定程度的数据丢失 建议： 更新频繁，一致性要求较高，AOF策略为主 更新不频繁，可以容忍少量数据丢失或错误，Snapshot为主 4. 过期策略4.1 过期键删除策略 定时过期：过期立即删除。对内存友好，但会占用大量CPU资源去处理过期的键，影响缓存的响应时间和吞吐量 惰性过期：只有当访问一个key时，才会判断它是否过期，过期则清除。对内存不友好，无用key占用了大量内存。 定期过期：每隔一定时间，扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。 Redis 同时使用 惰性过期 和 定期过期 两种策略。 4.2 设置和取消过期EXPIRE PERSIST 4.3 过期机制12345678910redis-cli&gt; flushdb&gt; keys *&gt; exists name&gt; set name tom&gt; ttl name # -1, 永不过期&gt; expire name 5 # 5s后过期&gt; set age 20&gt; expireat age 1555506769 过期机制：redis采用 Lazy Expriation 方式，即在访问key时判断是否过期，如果过期，则进行过期处理。其次，每秒对volation keys进行抽样测试，如果有过期键，那对所有过期key处理。 5. 内存淘汰策略MySQL中2000w数据，redis中只存20w数据，如何保证redis中的数据都是热数据？ 全局键空间选择性移除： noeviction：内存不足，写入新数据，报错 allkeys-lru：内存不足，写入新数据，将移除最近最少使用的key （最常用） allkeys-random: 内存不足，写入新数据，将随机删除一个key 带TTL的键空间选择性移除： volatile-lru：内存不足，写入新数据，在设置了过期时间的键空间中，移除最近最少使用的key volatile-random：内存不足，写入新数据，在设置了过期时间的键空间中，随机移除一个key volatile-ttl：内存不足，写入新数据，在设置了过期时间的键空间中，移除更早过期的key 6. 环境部署6.1 Redis部署123456redis-serverredis-cliredis-benchmark # 测试Redis在当前系统、当前配置下的性能redis-check-aof # 检查更新日志appendonly.aofredis-check-dump # 检查本地数据库rdb文件 6.2 Redis启动1234567redis-serverredis-server --port 6479redis-server --port 6479 --slaveof 127.0.0.1 6579redis-server /etc/redis/redis.confredis-server /etc/redis/redis.conf --loglevel verboseredis-server /etc/redis/redis.conf --sentinel 6.3 客户端操作redis库(select 0~15) 1234567telnet 192.168.1.100 6379echo &quot;set name abc&quot; | nc 127.0.0.1 6379redis-cli -h 192.168.1.100 -p 6379 -n 5&gt; help set&gt; help @string # 字符串操作相关的所有命令 6.4 设置连接密码123456789101112vi /etc/redis/redis.confrequirepass New_Passredis-cli shutdownredis-server /etc/redis/redis.conf# 方法1：redis-cli&gt; auth New_Pass# 方法2：redis-cli -a New_Pass 6.5 屏蔽不安全命令12vi /etc/redis/redis.confrename-command keys &quot;&quot; 6.6 配置文件说明12345678910111213141516171819202122232425262728293031daemonize nopidfile /var/run/redis.pidport 6379bind 127.0.0.1timeout 0 # 0 client永不超时loglevel notice logfile &quot;/var/log/redis.log&quot;databases 16# snapchatsave 900 1save 300 10save 60 10000 # after 60 sec if at least 10000 keys changedsave &quot;&quot; # 读写频繁时，不使用Snapchatrdbchecksum yesdbfilename dump.rdbmaxmemory bytes?appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysec 7. 集群方案7.1 主从模式主从同步特点: 一个master可拥有多个slave master可读写，并将变化的数据sync给slave slave只读，接收master的sync数据 缺点：master只有一个，如果挂掉，无法对外提供写服务 配置 salve: 12replicaof 192.168.1.200 6379masterauth &lt;master-password&gt; 1234redis-cli&gt; info&gt; monitor&gt; info replication # 查看集群状态 7.2 Sentinel 模式 哨兵模式建立在主从模式之上 当master挂掉，sentinel会在salve中选择一个作为master，并修改它们的配置文件，其他slave节点的配置文件也会同步修改 当master恢复后，它将不再是master，而是做为slave接收新master同步数据 多sentinel配置时，形成一个sentinel小集群，sentinel之间也会自动监控 配置： 123sentinel monitor mymaster 192.168.1.200 6379sentinel auth-pass mymaster 123456sentinel down-after-milliseconds mymaster 30000 # 默认30s 启动： 1/usr/local/bin/redis-sentinel /usr/local/reids/sentinel.conf 7.3 Cluster模式 多个主从模式节点网络互联，数据共享 客户端可连接任意一个master节点进行读写 不支持同时处理多个key (MSET/MGET), 因为redis需要把key均匀分布在各个节点上，高并发下同时创建key-value会降低性能并导致不可预测行为 支持在线增加、删除节点 配置： 123cluster-enabled yescluster-config-file node_6379.confcluster-node-timeout 15000 集群命令： 123456789101112# 增加节点&gt; CLUSTER MEET 192.168.1.201 6380&gt; CLUSTER NODES# 更改节点身份, 节点改为slave&gt; CLUSTER REPLICATE a8fdc205a9f19cc1c7507a60c4f01b13d11d7fd0# 删除节点&gt; CLUSTER FORGET 40bd001563085fc35165329ea1ff5c5ecbdbbeef# 保存配置&gt; CLUSTER SAVECONFIG 7.4 哈希槽Redis 集群没有使用一致性hash，而是引入额哈希槽的概念。Redis集群有16384（2^14）个哈希槽，每个key通过CRC16校验后对16384取模来决定放置在哪个槽，集群的每个节点负责一部分hash槽。 7.5 集群选择数据库无法选择，都在0上 8. 分区分区目的：为了Redis管理更大的内存 分区方案： 客户端分区：在客户端决定数据会被存储到哪个redis节点上，或从哪个节点读取。 代理分区：客户端请求发给代理，由代理决定去哪个节点读写数据 查询路由：客户端随机请求任意一个redis实例，由redis将请求转发到正确的redis上。 分区缺点： 涉及多个key的操作，通常不支持 同时操作多个key，不能使用事务 分区的粒度是key，不能使用一个非常长的排序key存储一个数据集 分区扩容或缩容可能非常复杂 9. 缓存异常9.1 雪崩 (缓存失效)场景：服务器重启或大量缓存同一时期失效时，大量的流量会冲击到数据库上，数据库kennel会因承受不了而当机。即缓存层出现了错误，所有数据请求到达存储层，导则存储层无法响应 解决方案： 均匀分布：失效时间均匀分布，保持失效时间的随机性 熔断机制： 隔离机制： 限流机制： 双缓存 高可用性集群 9.2 穿透 (缓存空值)场景：用户查询某条数据，但redis中每天，即缓存未命中；继续向持久层数据库查询，还是没有，即本次查询失败。当大量查询失败时，导则持久层数据库压力过大，即为缓存穿透 解决方案： 缓存空值：即数据不存在，依旧设置一个默认值到缓存中，但该key的过期时间较短 9.3 击穿 (高并发key失效)场景：某个key非常热点，高并发访问它时，该key瞬间失效，导则高并发请求直接访问持久数据库，就像在屏障上凿了一个洞 解决方案： 使用互斥锁 mutex key：setnx 10. 管理命令12345678910redis-cli&gt; auth PASS&gt; config get appendonly&gt; config set appendonly yes # 临时改参数&gt; config get *&gt; config reset&gt; info&gt; flushall&gt; monitor&gt; shutdown Redis-benchmark: 服务器性能测试 12# 100个并发，100000次redis-benchmark -h localhost -p 6379 -c 100 -n 100000 11. Redis优化11.1 内存管理1234567# HashMap成员数量，小于配置，按紧凑格式存储，内存开销少，任意一个超过，就使用真实的HashMap存储，内存占用大hash-max-zipmap-entries 64 # 成员数量少hash-max-zipmap-value 512 # 成员长度小# Listlist-max-ziplist-value 64list-max-ziplist-entries 512 11.2 持久化选择aof，每个实例不要超过2G 12. 经验总结 进行master-slave主从同步配置，在出现服务故障时可切换 在master禁用数据持久化，在slave上配置数据持久化 Memory+swap不足。此时dump会挂死，最终会导致机器挡掉。64-128GB内存， SSD硬盘。 当使用的Memory超过60%，会使用swap，内存碎片大 当达到最大内存时，会清空带过期时间的key，即使该key未过期 redis和DB同步，先写DB，后写redis，内存写速度快 Redis使用建议： 1234567key: object-type:id:field length 10~20 value: string 不超过2K set, sortedset 元素个数不超过5000 跳表：一种随机化的数据结构，实质就是一种可以进行二分查找的有序链表。Redis中的set类型低层使用跳表实现。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://elihe2011.github.io/categories/NoSQL/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://elihe2011.github.io/tags/redis/"}]},{"title":"HTTP和WebSocket","slug":"HTTP和WebSocket","date":"2019-01-03T03:12:17.000Z","updated":"2021-07-13T03:06:57.487Z","comments":true,"path":"2019/01/03/HTTP和WebSocket/","link":"","permalink":"https://elihe2011.github.io/2019/01/03/HTTP%E5%92%8CWebSocket/","excerpt":"1. 协议 HTTP 1.0: 在一次 TCP 连接中只能完成一个 HTTP 请求 HTTP 1.1: keep-alive，在一次 TCP 连接中完成多个 HTTP 请求 Websocket: 借用HTTP协议来完成握手 12345Connection: UpgradeSec-WebSocket-Extensions: permessage-deflate; client_max_window_bitsSec-WebSocket-Key: km9iqxp+3H2ndD5zXkAczA==Sec-WebSocket-Version: 13Upgrade: websocket","text":"1. 协议 HTTP 1.0: 在一次 TCP 连接中只能完成一个 HTTP 请求 HTTP 1.1: keep-alive，在一次 TCP 连接中完成多个 HTTP 请求 Websocket: 借用HTTP协议来完成握手 12345Connection: UpgradeSec-WebSocket-Extensions: permessage-deflate; client_max_window_bitsSec-WebSocket-Key: km9iqxp+3H2ndD5zXkAczA==Sec-WebSocket-Version: 13Upgrade: websocket 2. 通信方式比较： ajax轮询：浏览器隔几秒向服务器发起一个请求，询问服务器是否有新信息。需要服务器有很快的处理速度和资源。（速度） long poll：采用阻塞模式，客户端发起连接后，如果没消息，就一直不返回Response给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。需要有很高的并发，也就是说同时接待客户的能力。（场地大小） WebSocket：一次HTTP握手后，整个通讯过程是建立在该连接状态中。服务器可主动推送消息给客户端。 3. WebSocket和HTTP最大不同是： WebSocket是一种双向通信协议。在建立连接后，WebSocket服务器端和客户端都能主动向对方发送或接收数据，就像Socket一样； WebSocket需要像TCP一样，先建立连接，连接成功后才能相互通信。","categories":[{"name":"Network","slug":"Network","permalink":"https://elihe2011.github.io/categories/Network/"}],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://elihe2011.github.io/tags/websocket/"},{"name":"http","slug":"http","permalink":"https://elihe2011.github.io/tags/http/"}]},{"title":"Kubernetes Helm","slug":"Kubernetes Helm","date":"2018-07-09T12:34:25.000Z","updated":"2021-06-22T10:50:49.721Z","comments":true,"path":"2018/07/09/Kubernetes Helm/","link":"","permalink":"https://elihe2011.github.io/2018/07/09/Kubernetes%20Helm/","excerpt":"1. HelmHelm：让应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成的k8s资源清单文件 (deployment.yaml, service.yaml)，然后调用kubectl自动执行k8s资源部署。 Helm 包管理工具，是部署环境的流程封装 Helm 两个重要概念： chart: 创建一个应用的信息集合，包含各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元，即yum中的安装包 release: chart的运行实例。当chart被安装到kubernetes中，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个realease helm 包含两个组件：Helm 客户端 和 Tiller 服务器 Helm客户端: 负责chart和release的创建和管理、和Tiller的交互 Tiller服务器：运行在kubernetes集群节点中，处理Helm客户端请求，与API Server交互","text":"1. HelmHelm：让应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成的k8s资源清单文件 (deployment.yaml, service.yaml)，然后调用kubectl自动执行k8s资源部署。 Helm 包管理工具，是部署环境的流程封装 Helm 两个重要概念： chart: 创建一个应用的信息集合，包含各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元，即yum中的安装包 release: chart的运行实例。当chart被安装到kubernetes中，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个realease helm 包含两个组件：Helm 客户端 和 Tiller 服务器 Helm客户端: 负责chart和release的创建和管理、和Tiller的交互 Tiller服务器：运行在kubernetes集群节点中，处理Helm客户端请求，与API Server交互 1.1 Helm 部署安装包下载地址：https://github.com/helm/helm/releases 123wget https://get.helm.sh/helm-v2.16.10-linux-amd64.tar.gztar zxvf helm-v2.16.10-linux-amd64.tar.gzcp linux-amd64/helm /usr/local/bin 安装Tiller: k8s APIServer开启了RBAC访问控制，在创建Tiller需要使用service account: tiller，并分配合适的角色给它 1234567891011121314151617181920# tiller-rbac-config.yamlapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system ---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: tiller namespace: kube-system 1234567891011121314# 创建RBAC$ kubectl create -f tiller-rbac-config.yaml# 部署 tiller 服务器$ helm init --service-account tiller --skip-refresh# tiller 服务器，namespace 为 kube-system$ kubectl get pod -n kube-system | grep tillerNAME READY STATUS RESTARTS AGEtiller-deploy-6845b7d56c-2wk2x 1/1 Running 0 31s$ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.16.10&quot;, GitCommit:&quot;bceca24a91639f045f22ab0f41e47589a932cf5e&quot;, GitTreeState:&quot;clean&quot;&#125;Server: &amp;version.Version&#123;SemVer:&quot;v2.16.10&quot;, GitCommit:&quot;bceca24a91639f045f22ab0f41e47589a932cf5e&quot;, GitTreeState:&quot;clean&quot;&#125; 部署 helm v3.3: 1234567$ wget https://get.helm.sh/helm-v3.3.1-linux-amd64.tar.gz$ tar zxvf helm-v3.3.1-linux-amd64.tar.gz$ cp linux-amd64/helm /usr/local/bin/helm$ helm repo add stable https://kubernetes-charts.storage.googleapis.com/$ helm repo update 命令汇总： 命令 说明 helm search hub xxx 在Helm Hub上搜索Chart helm search repo repo_name 在本地配置的Repo中搜索Chart helm install release_name chart_reference chart一共有5种reference helm list 查看已部署的release helm status release_name 查看release信息 helm upgrade release_name chart_reference 修改chart信息后升级release helm history release_name 查看release的更新历史记录 helm rollback release_name revision 回滚操作 helm uninstall release_name 卸载release 1.2 Helm 自定义模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263$ mkdir helm-demo &amp;&amp; cd helm-demo# 创建自描述文件$ cat &gt; Chart.yaml &lt;&lt;EOFname: helloversion: 1.0.0EOF# 创建目标文件，用于生成 kubernetes 资源清单 manifests$ mkdir templates$ cat &gt; ./templates/deployment.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 3 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: hub.elihe.io/library/nginx:v1 ports: - containerPort: 80 protocol: TCPEOF# 创建 svc$ cat &gt; ./templates/service.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: hello-worldspec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP selector: app: hello-worldEOF# 安装#$ helm install . --name hello$ helm install hello . NAME: helloLAST DEPLOYED: Thu Oct 15 10:35:57 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None# 查询$ helm listNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONhello default 1 2020-10-15 10:35:57.015330177 +0800 CST deployed hello-1.0.1 通过动态配置项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 动态配置$ cat &gt; values.yaml &lt;&lt;EOFimage: repository: hub.elihe.io/test/nginx tag: v2EOF# 动态模板$ cat &gt; ./templates/deployment.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 1 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: &#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125; ports: - containerPort: 80 protocol: TCPEOF# 升级版本$ helm upgrade hello -f values.yaml .# 指定版本升级$ helm upgrade --set image.tag=&#x27;v3&#x27; hello . # 历史$ helm history helloREVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Thu Oct 15 10:35:57 2020 superseded hello-1.0.1 Install complete2 Thu Oct 15 10:40:11 2020 superseded hello-1.0.1 Upgrade complete3 Thu Oct 15 10:40:33 2020 deployed hello-1.0.1 Upgrade complete# 回滚$ helm rollback hello 2Rollback was a success.# 卸载$ helm uninstall --keep-history hello# 还原$ helm rollback hello 1# 彻底删除$ helm uninstall hello debug： 12# 配置检查和预生成配置清单$ helm install . --dry-run --debug --set image.tag=v2 2. 部署 Dashboard12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061$ mkdir dashboard &amp;&amp; cd dashboard$ helm repo update$ helm repo listNAME URL stable https://kubernetes-charts.storage.googleapis.comlocal http://127.0.0.1:8879/charts $ helm fetch stable/kubernetes-dashboard$ tar zxvf kubernetes-dashboard-1.11.1.tgz $ cd kubernetes-dashboard# 参数设置$ cat &gt; kubernetes-dashboard.yaml &lt;&lt;EOFimage: repository: k8s.gcr.io/kubernetes-dashboard-amd64 tag: v1.8.3ingress: enable: true hosts: - k8s.frognew.com annotations: nginx.ingress.kubernetes.io/ssl-redirect: true nginx.ingress.kubernetes.io/backend-protocol: HTTPS tls: - secretName: frognew-com-tls-secret hosts: - k8s.frognew.comrbac: clusterAdminRole: trueEOF# 安装$ helm install kubernetes-dashboard . \\--namespace kube-system \\-f kubernetes-dashboard.yaml # 容器已运行$ kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkubernetes-dashboard-7cfd66fc8b-8t79v 1/1 Running 0 37s# 查看访问$ kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard ClusterIP 10.98.142.181 &lt;none&gt; 443/TCP 66s# 改为NodePort访问$ kubectl edit svc kubernetes-dashboard -n kube-systemtype: NodePort$ kubectl get svc -n kube-systemkubernetes-dashboard NodePort 10.101.30.189 &lt;none&gt; 443:31667/TCP 3m11s# 获取令牌访问 token$ kubectl get secret -n kube-system | grep kubernetes-dashboard-tokenkubernetes-dashboard-token-bbt69 kubernetes.io/service-account-token 3 3m12s$ kubectl describe secret kubernetes-dashboard-token-bbt69 -n kube-systemtoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IlduNEdhTUJxOWtXbFhwdlhRSzhEMGFRemdJR0duQl9FNm9Rc2d0ekREQkEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi1iYnQ2OSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBlMTZlZjcyLWM5YjgtNDViMC05OTEzLThhNzY2NmY2ZDQzNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.4FxXZN-Gc6mpd50sl7Wrm_ZjO5T53LrMa30MYMAHubIxOSgIh5HBvpdq5SxgQg2-XGTWZy8yZvxdmC53XOl5zqq-7RMKKjTv-Qa3O_KcHRPpnAOjj9aXvRbGdSlc5Y4D2nkysRKjWca8NjSrTXOzNHMFK0CHEIqVP-GFrKUMWmZRGYiwIoaBBKgTaS-KM3vF2Be94U2f1-ybFloOsAgEijqhUWrxpBgvXYfAmWjH4tdjCgo_1YEFPYUuUS9hq_VifdvWma9ZQthKbWplik9nuG2g-9o_xS0en5rnbxJQFfoAl5iypEi6zJiKgFoGwJsl5ScLFhpDaYN3QNhOnHhJrA 部署Dashboard2.0: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# 卸载V1.8.3$ helm uninstall kubernetes-dashboard --namespace kube-system# 使用kubectl安装$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml# 安装$ kubectl apply -f recommended.yaml$ kubectl get pod -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-6b4884c9d5-8j778 1/1 Running 0 38skubernetes-dashboard-7d8574ffd9-wff2g 1/1 Running 0 38s$ kubectl get svc -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.99.116.101 &lt;none&gt; 8000/TCP 115skubernetes-dashboard ClusterIP 10.111.190.197 &lt;none&gt; 443/TCP 116s# 改为NodePort$ kubectl edit svc kubernetes-dashboard -n kubernetes-dashboardtype: NodePort$ kubectl get svc -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.99.116.101 &lt;none&gt; 8000/TCP 2m40skubernetes-dashboard NodePort 10.111.190.197 &lt;none&gt; 443:32202/TCP 2m41s# 开放账号权限cat &gt; dashboard-admin.yaml &lt;&lt;EOF# Creating a Service AccountapiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard ---# Creating a ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboardEOF# 开放管理员权限$ kubectl apply -f dashboard-admin.yaml# 访问token$ kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)Name: admin-user-token-zjkxsNamespace: kubernetes-dashboardLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: af11f2f3-613e-4bc5-959b-4591e3ada6dfType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 20 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IlduNEdhTUJxOWtXbFhwdlhRSzhEMGFRemdJR0duQl9FNm9Rc2d0ekREQkEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXpqa3hzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJhZjExZjJmMy02MTNlLTRiYzUtOTU5Yi00NTkxZTNhZGE2ZGYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.NRMwYGUtsf0v8rL3aZQDmi1lTAFMp1m2xEvAO6zavtFFo6HJzbpF_ReSssgWeK5LLk6sbOXVUx19O0wnASSPKg7JXiXBBGyb_qHkMdD5p2yc5ggGJu_MjE_0kXS-0OvSMS20Dtv1BiZiWB-eNEy3xxTorivG2Zah8-ART5J1HtqHauxxyQr21pHfQ9XlmOlby3MQVelIbQ1e7-EZemOSggcQI0rlpWlU_OPiakksoJGEcwr0xK7kypLnxG4AjM9x9fgjIBft30c4tfwMDXzYiB5ZwwDP2cHRiYN6fnE9XdJmrGBVAL4SgTabXFz2DOfOFpsbWkcDNdOBBWsZHzvUww# 卸载$ kubectl delete -f dashboard-admin.yaml $ kubectl delete -f recommended.yaml 3. Prometheus3.1 组件说明 MetricServer: k8s 集群资源使用情况的集合器，收集数据给 k8s 集群内使用，如kubectl, hpa, scheduler等 （支持kubectl top node等操作） PrometheusOperator: 系统监控和警报工具箱，用来存储监控数据 NodeExporter: 各个node的关键度量指标状态数据 KubeStateMetrics: 收集k8s集群内资源对象数据，制定告警规则 Prometheus: 采用pull方式收集apiserver, scheduler, controller-manager, kubelet组件数据，通过http协议传输 Grafana: 可视化数据统计和监控平台 3.2 构建记录1234567$ mkdir prometheus &amp;&amp; cd promethues$ git clone https://github.com/coreos/kube-prometheus.git$ cd kube-prometheus/manifests# 当前k8s版本为 v1.18.6, 切换分支 release-0.6$ git checkout release-0.6 修改 grafana-service.yaml, 开启NodePort方式: 12345678910111213141516apiVersion: v1kind: Servicemetadata: labels: app: grafana name: grafana namespace: monitoringspec: type: NodePort # add ports: - name: http port: 3000 targetPort: http nodePort: 30100 # add selector: app: grafana 修改 prometheus-service.yaml, 开启NodePort方式: 123456789101112131415161718apiVersion: v1kind: Servicemetadata: labels: prometheus: k8s name: prometheus-k8s namespace: monitoringspec: type: NodePort # add ports: - name: web port: 9090 targetPort: web nodePort: 30200 # add selector: app: prometheus prometheus: k8s sessionAffinity: ClientIP 修改 alertmanager-service.yaml, 开启NodePort方式: 123456789101112131415161718apiVersion: v1kind: Servicemetadata: labels: alertmanager: main name: alertmanager-main namespace: monitoringspec: type: NodePort # add ports: - name: web port: 9093 targetPort: web nodePort: 30300 # add selector: alertmanager: main app: alertmanager sessionAffinity: ClientIP 获取需要的镜像: 1234567891011121314151617$ find . -type f | xargs grep &#x27;image:&#x27; | awk &#x27;&#123;print $3&#125;&#x27; | sed &#x27;/^[ ]*$/d&#x27; | sort | uniqdirectxman12/k8s-prometheus-adapter:v0.7.0grafana/grafana:7.1.0quay.io/coreos/kube-rbac-proxy:v0.4.1quay.io/coreos/kube-state-metrics:v1.9.5quay.io/coreos/prometheus-operator:v0.40.0quay.io/prometheus/alertmanager:v0.21.0quay.io/prometheus/node-exporter:v0.18.1quay.io/prometheus/prometheus:v2.20.0# 先手动拉取镜像docker pull quay.io/coreos/kube-rbac-proxy:v0.4.1docker pull quay.io/coreos/kube-state-metrics:v1.9.5docker pull quay.io/coreos/prometheus-operator:v0.40.0docker pull quay.io/prometheus/alertmanager:v0.21.0docker pull quay.io/prometheus/node-exporter:v0.18.1docker pull quay.io/prometheus/prometheus:v2.20.0 执行安装： 1234567# Create the namespace and CRDs, and then wait for them to be availble before creating the remaining resources$ kubectl create -f manifests/setup$ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo &quot;&quot;; done$ kubectl create -f manifests/# teardown the stack$ kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup 安装后检查： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647$ kubectl get pod -n monitoringNAME READY STATUS RESTARTS AGEalertmanager-main-0 2/2 Running 0 6m17salertmanager-main-1 2/2 Running 0 6m16salertmanager-main-2 2/2 Running 0 6m16sgrafana-67dfc5f687-vqfbh 1/1 Running 0 6m7skube-state-metrics-69d4c7c69d-2lmfl 3/3 Running 0 6m6snode-exporter-j9nzx 2/2 Running 0 6m4snode-exporter-lwmkw 2/2 Running 0 6m3snode-exporter-p5sl8 2/2 Running 0 6m3sprometheus-adapter-66b855f564-qvs8x 1/1 Running 0 5m53sprometheus-k8s-0 3/3 Running 1 5m46sprometheus-k8s-1 3/3 Running 1 5m46sprometheus-operator-75c98bcfd7-smmwd 2/2 Running 0 8m22s$ kubectl top nodeNAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master 321m 16% 1329Mi 70% k8s-node01 190m 9% 1062Mi 56% k8s-node02 961m 48% 1011Mi 53% $ kubectl top pod -n monitoringNAME CPU(cores) MEMORY(bytes) alertmanager-main-0 7m 22Mi alertmanager-main-1 11m 23Mi alertmanager-main-2 9m 24Mi grafana-67dfc5f687-vqfbh 25m 25Mi kube-state-metrics-69d4c7c69d-2lmfl 2m 33Mi node-exporter-j9nzx 58m 19Mi node-exporter-lwmkw 5m 18Mi node-exporter-p5sl8 5m 13Mi prometheus-adapter-66b855f564-qvs8x 4m 18Mi prometheus-k8s-0 31m 235Mi prometheus-k8s-1 26m 195Mi prometheus-operator-75c98bcfd7-smmwd 1m 34Mi $ kubectl get svc -n monitoringNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEalertmanager-main NodePort 10.105.101.126 &lt;none&gt; 9093:30300/TCP 9m37salertmanager-operated ClusterIP None &lt;none&gt; 9093/TCP,9094/TCP,9094/UDP 9m37sgrafana NodePort 10.100.132.19 &lt;none&gt; 3000:30100/TCP 9m26skube-state-metrics ClusterIP None &lt;none&gt; 8443/TCP,9443/TCP 9m25snode-exporter ClusterIP None &lt;none&gt; 9100/TCP 9m25sprometheus-adapter ClusterIP 10.101.16.41 &lt;none&gt; 443/TCP 9m12sprometheus-k8s NodePort 10.101.33.228 &lt;none&gt; 9090:30200/TCP 9m10sprometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 9m4sprometheus-operator ClusterIP None &lt;none&gt; 8443/TCP 11m 访问 promethues：http://192.168.31.40:30200 1sum by (pod_name)(rate(container_cpu_usage_seconds_total&#123;image!=&quot;&quot;&#125;[1m] )) 访问 Grafana: http://192.168.31.40:30100 1admin/admin 3. Horizontal Pod AutoscalingHPA 可以根据CPU利用率自动伸缩一个 Replication Controller、Deployment或者 ReplicaSet中的Pod数量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104cat &gt; hpa.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: php-apachespec: replicas: 1 selector: matchLabels: app: apache template: # Pod metadata: labels: app: apache spec: containers: - name: php-apache image: gcr.io/google_containers/hpa-example ports: - containerPort: 80 resources: requests: cpu: 0.1 memory: 32Mi---apiVersion: v1kind: Servicemetadata: name: php-apachespec: type: ClusterIP selector: app: apache ports: - name: http port: 80 targetPort: 80EOF# 启动$ kubectl apply -f hpa.yaml$ kubectl top podNAME CPU(cores) MEMORY(bytes) php-apache-86d4bcdcd9-wlvs5 1/1 Running 0 29m # 创建HPA控制器$ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10# 查看数据释放统计到了$ kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 0%/50% 1 10 1 5m# 增加负载，查看负载数量 （新开一个窗口）$ kubectl run -i --tty load-generator --image=busybox /bin/sh$ while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done# 监控 kubectl get hpa -wNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache &lt;unknown&gt;/50% 1 10 0 7sphp-apache Deployment/php-apache &lt;unknown&gt;/50% 1 10 1 15sphp-apache Deployment/php-apache 0%/50% 1 10 1 4m3sphp-apache Deployment/php-apache 0%/50% 1 10 1 5m19sphp-apache Deployment/php-apache 1%/50% 1 10 1 19mphp-apache Deployment/php-apache 0%/50% 1 10 1 20mphp-apache Deployment/php-apache 0%/50% 1 10 1 25mphp-apache Deployment/php-apache 378%/50% 1 10 1 28mphp-apache Deployment/php-apache 378%/50% 1 10 4 28mphp-apache Deployment/php-apache 467%/50% 1 10 8 28m# 尝试新作 Pod$ kubectl get pod -wNAME READY STATUS RESTARTS AGEload-generator 1/1 Running 0 45mphp-apache-86d4bcdcd9-wlvs5 1/1 Running 0 29mphp-apache-86d4bcdcd9-7cjmm 0/1 Pending 0 0sphp-apache-86d4bcdcd9-7cjmm 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 Pending 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 Pending 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-7cjmm 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-hzf8h 0/1 Pending 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 Pending 0 0sphp-apache-86d4bcdcd9-hzf8h 0/1 Pending 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 Pending 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 Pending 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 Pending 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 Pending 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 Pending 0 0sphp-apache-86d4bcdcd9-hzf8h 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 Pending 0 0sphp-apache-86d4bcdcd9-z6qkt 0/1 Pending 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 Pending 0 0sphp-apache-86d4bcdcd9-z6qkt 0/1 Pending 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-z6qkt 0/1 ContainerCreating 0 3s 4. 资源限制4.1 Pod12345678910111213spec: containers: - name: php-apache image: gcr.io/google_containers/hpa-example ports: - containerPort: 80 resources: requests: cpu: 0.1 memory: 32Mi limits: cpu: 200m memory: 100Mi 4.2 名称空间 计算姿态配额 123456789101112apiVersion: v1kind: ResourceQuotametadata: name: compute-resource namespace: spark-clusterspec: hard: pods: 20 requests.cpu: 20 requests.memory: 100Gi limits.cpu: 40 limits.memory: 200Gi 配置对象数量配额限制 12345678910111213apiVersion: v1kind: ResourceQuotametadata: name: object-counts namespace: spark-clusterspec: hard: configmaps: 10 persistentvolumeclaims: 4 replicationcontrollers: 20 secrets: 10 services: 10 services.loadbalancer: 2 配置CPU 和 内存的 LimitRange 12345678910111213apiVersion: v1kind: LimitRangemetadata: name: mem-limit-rangespec: limits: - default: memory: 50Gi cpu: 5 defaulyRequest: memory: 1Gi cpu: 1 type: Container 5. EFK 日志EFK: Elasticsearch + Fluentd + Kibana ELFK: Elasticsearch + Logstash + Filebeat + Kibana 安装参考：https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes 5.1 创建 Namespace12345678910111213$ mkdir efk &amp;&amp; cd efk$ cat &gt; kube-logging.yaml &lt;&lt;EOFkind: NamespaceapiVersion: v1metadata: name: kube-loggingEOF$ kubectl create -f kube-logging.yaml$ kubectl get ns | grep kube-loggingkube-logging Active 6s 5.2 ElasticSearch5.2.1 创建无头服务123456789101112131415161718192021222324$ cat &gt; elasticsearch_svc.yaml &lt;&lt;EOFkind: ServiceapiVersion: v1metadata: name: elasticsearch namespace: kube-logging labels: app: elasticsearchspec: selector: app: elasticsearch clusterIP: None ports: - port: 9200 name: rest - port: 9300 name: inter-nodeEOF$ kubectl create -f elasticsearch_svc.yaml$ kubectl get services --namespace=kube-loggingNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 13s 5.2.2 创建PV1234567891011121314151617181920212223$ cat &gt; elasticsearch_pv.ymal &lt;&lt;EOFapiVersion: v1kind: PersistentVolumemetadata: name: nfspv1 namespace: kube-loggingspec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs server: 192.168.31.200EOF$ kubectl create -f elasticsearch_pv.ymal$ kubectl get pv -n kube-loggingNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Available nfs 18s 5.2.3 安装ES123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101$ cat &gt; elasticsearch_statefulset.yaml &lt;&lt;EOFapiVersion: apps/v1kind: StatefulSetmetadata: name: es-cluster namespace: kube-loggingspec: serviceName: elasticsearch #replicas: 3 replicas: 1 selector: matchLabels: app: elasticsearch template: metadata: labels: app: elasticsearch spec: containers: - name: elasticsearch image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0 resources: limits: #cpu: 1000m cpu: 400m requests: cpu: 100m ports: - containerPort: 9200 name: rest protocol: TCP - containerPort: 9300 name: inter-node protocol: TCP volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data env: - name: cluster.name value: k8s-logs - name: node.name valueFrom: fieldRef: fieldPath: metadata.name - name: discovery.type # test-bed value: single-node #- name: discovery.seed_hosts #value: &quot;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&quot; #- name: cluster.initial_master_nodes #value: &quot;es-cluster-0,es-cluster-1,es-cluster-2&quot; - name: ES_JAVA_OPTS #value: &quot;-Xms512m -Xmx512m&quot; value: &quot;-Xms256m -Xmx256m&quot; initContainers: - name: fix-permissions image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;] securityContext: privileged: true volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data - name: increase-vm-max-map image: busybox command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;] securityContext: privileged: true - name: increase-fd-ulimit image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;] securityContext: privileged: true volumeClaimTemplates: - metadata: name: data labels: app: elasticsearch spec: accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: nfs resources: requests: storage: 1GiEOF$ kubectl create -f elasticsearch_statefulset.yaml# 监控创建进度$ kubectl rollout status sts/es-cluster --namespace=kube-logging$ kubectl get pod -n kube-loggingNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 59s# 监控日志$ kubectl logs -f es-cluster-0 -n kube-logging # 开启本地端口，测试服务$ kubectl port-forward es-cluster-0 9200:9200 --namespace=kube-logging$ curl http://localhost:9200/_cluster/state?pretty 5.3 Kibana1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162$ cat &gt; kibana.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: kibana namespace: kube-logging labels: app: kibanaspec: type: NodePort ports: - port: 5601 selector: app: kibana---apiVersion: apps/v1kind: Deploymentmetadata: name: kibana namespace: kube-logging labels: app: kibanaspec: replicas: 1 selector: matchLabels: app: kibana template: metadata: labels: app: kibana spec: containers: - name: kibana image: docker.elastic.co/kibana/kibana:7.2.0 resources: limits: cpu: 1000m requests: cpu: 100m env: - name: ELASTICSEARCH_URL value: http://elasticsearch:9200 ports: - containerPort: 5601EOF$ kubectl create -f kibana.yaml$ kubectl rollout status deployment/kibana --namespace=kube-logging$ kubectl get pod -n kube-loggingNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 13mkibana-5749b5778b-zvtwn 1/1 Running 0 4m33s$ kubectl get svc -n kube-loggingNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 89mkibana NodePort 10.106.103.244 &lt;none&gt; 5601:30750/TCP 8s$ curl http://192.168.1.40:30750 5.4 Fluentd123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100$ cat &gt; fluentd.yaml &lt;&lt;EOFapiVersion: v1kind: ServiceAccountmetadata: name: fluentd namespace: kube-logging labels: app: fluentd---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: fluentd labels: app: fluentdrules:- apiGroups: - &quot;&quot; resources: - pods - namespaces verbs: - get - list - watch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: fluentdroleRef: kind: ClusterRole name: fluentd apiGroup: rbac.authorization.k8s.iosubjects:- kind: ServiceAccount name: fluentd namespace: kube-logging---apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd namespace: kube-logging labels: app: fluentdspec: selector: matchLabels: app: fluentd template: metadata: labels: app: fluentd spec: serviceAccount: fluentd serviceAccountName: fluentd tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd image: fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1 env: - name: FLUENT_ELASTICSEARCH_HOST value: &quot;elasticsearch.kube-logging.svc.cluster.local&quot; - name: FLUENT_ELASTICSEARCH_PORT value: &quot;9200&quot; - name: FLUENT_ELASTICSEARCH_SCHEME value: &quot;http&quot; - name: FLUENTD_SYSTEMD_CONF value: disable resources: limits: #memory: 512Mi memory: 256Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containersEOF$ kubectl create -f fluentd.yaml$ kubectl get ds -n kube-loggingNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEfluentd 2 2 2 2 2 &lt;none&gt; 27s 5.5 Kibana 页面 5.6 测试创建一个 Pod： 1234567891011121314$ cat &gt; counter.yaml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: [/bin/sh, -c, &#x27;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&#x27;]EOF$ kubectl create -f counter.yaml 6. 补充：Port说明：Pod Template中的ports: containerPort: 容器对外开发的端口 Service 中的 ports: port: 监听请求，接收端口，绑定在ClusterIP上 targetPort: 指定Pod的接收端口，与containerPort绑定 nodePort: 类型为NodeType时，绑定在NodeIP上，未指定则随机给一个","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 安全机制","slug":"Kubernetes 安全机制","date":"2018-07-08T07:44:26.000Z","updated":"2021-06-22T10:50:49.721Z","comments":true,"path":"2018/07/08/Kubernetes 安全机制/","link":"","permalink":"https://elihe2011.github.io/2018/07/08/Kubernetes%20%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/","excerpt":"1. 机制说明API Server 是集群内部各个组件通讯的中介，也是外部控制的入口。k8s 使用认证(Authentication)、鉴权(Authorization)、准入控制(Admission Control) 三步来确保API Server的安全。 2. 认证 (Authentication) HTTP Token：HTTP Request Header 的 Token字段 HTTP Base: 客户端通过base64 USERNAME:PASSWORD, 填充 HTTP Request Header 的 Authorization字段，服务端收到后解码获取用户名和密码 HTTPS: 基于CA根证书签名的客户端身份认证方式。（推荐）","text":"1. 机制说明API Server 是集群内部各个组件通讯的中介，也是外部控制的入口。k8s 使用认证(Authentication)、鉴权(Authorization)、准入控制(Admission Control) 三步来确保API Server的安全。 2. 认证 (Authentication) HTTP Token：HTTP Request Header 的 Token字段 HTTP Base: 客户端通过base64 USERNAME:PASSWORD, 填充 HTTP Request Header 的 Authorization字段，服务端收到后解码获取用户名和密码 HTTPS: 基于CA根证书签名的客户端身份认证方式。（推荐） 2.1 HTTPS 证书认证 2.2 需要认证的节点 两种类型： Kubernetes组件对API Server的访问：kubectl、Controller Manager、Scheduler、kubelet、kube-proxy Kubernetes管理的Pod对容器的访问：Pod（dashborad也是以Pod形式运行） 安全性说明： Controller Manager、Scheduler与API Server在同一台机器，所以直接使用API Server的非安全端口访问--insecure-bind-address=127.0.0.1 kubectl、kubelet、kube-proxy访问API Server都需要证书进行HTTPS双向认证 证书颁发： 手动签发：通过k8s集群的根 ca 进行签发 HTTPS 证书 自动签发：kubelet 首次访问 API Server 时，使用 token 认证，通过后，Controller Manager 会为kubelet生成一个证书，以后的访问均使用该证书 2.3 kubeconfigkubeconfig 文件包含集群参数（CA证书、API Server地址），客户端参数，集群context信息（集群名称、用户名）。k8s 组件通过启动时指定不同的 kubeconfig 文件可以切换到不同的集群 cat ~/.kube/config 2.4 ServiceAccountPod 中的容器访问API Server。因为Pod的创建和销毁是动态的，所以要为它手动生成证书是不可行的，k8s 使用 Service Account解决Pod访问API Server的认证问题 2.5 Secret 与 SA 的关系Secret 分两类： 用于ServiceAccount的 service-account-token 用于保存用户自定义的保密信息的 Opaque SA 中包含三个部分： token：使用API Server私钥签名的 JWT ca.crt: 根证书，用于Client端验证API Server发送的证书 namespace: 标识该service-account-token的作用域名空间 1234567891011121314151617181920212223242526272829303132$ kubectl get secret --all-namespacesNAMESPACE NAME TYPE DATA AGEdefault default-token-rhw7k kubernetes.io/service-account-token 3 5d16hingress-nginx default-token-ftjf6 kubernetes.io/service-account-token 3 2d3hkube-system kube-proxy-token-kcgcp kubernetes.io/service-account-token 3 5d16h$ kubectl describe secret default-token-rhw7kName: default-token-rhw7kNamespace: defaultLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: default kubernetes.io/service-account.uid: 3fdb2906-e8c4-4bb1-9dc0-ac8aa15167b6Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 7 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6Ikx5ZjJCcWJPandjZzl5czlkRHpZZWp0d2NtT2dSU0w3c2M5dXY2ZUQ0QkUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tcmh3N2siLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjNmZGIyOTA2LWU4YzQtNGJiMS05ZGMwLWFjOGFhMTUxNjdiNiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.FkcID8mWCOXDQbZAZPJLWSSWngvt9R-69AEDVV_QQvyvP_BW1MwiANOM2cXkS-qDo4-hcDcRKGOZ-q7BxQC96YUsj41iiLBbsXyVI1_ovEgp58dwROJe-MTxkSlk8sic40QmW2y1CwREf-5EIxwLy1iGekbbMZb4W0m4oXa-BN7qzNzMwu4Bb6ScJbxljHpO33K80oKtWYN-fpow31FjMjZMEebUvf-pGw6O2FPLvzwC7A7_U-WRNrFWd2wZIRQf8GfQgUf5-phAnmyawcJ4gpQooRvHoyGyW366dEY-qAk4D-1xSj598X0Q_pq7PdT1WQkO3nozHL-w4mbSlb3Ytw$ kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkube-proxy-c5t62 1/1 Running 13 5d16hkube-proxy-q7m2t 1/1 Running 13 5d16hkube-proxy-t2tgb 1/1 Running 13 5d16h$ kubectl exec kube-proxy-c5t62 -n kube-system -it -- ls -l /run/secrets/kubernetes.io/serviceaccounttotal 0lrwxrwxrwx 1 root root 13 Sep 13 06:40 ca.crt -&gt; ..data/ca.crtlrwxrwxrwx 1 root root 16 Sep 13 06:40 namespace -&gt; ..data/namespacelrwxrwxrwx 1 root root 12 Sep 13 06:40 token -&gt; ..data/token 2.6 总结 3. 鉴权 (Authorization)认证 和鉴权： 认证(authencation): 通过只代表通讯双方是可信的 鉴权(authorization): 确定请求方有哪些资源权限 API Server的授权策略，启动参数--authorization-mode AlwaysDeny: 拒绝所有请求，一般用于测试 AlwaysAllow: 接收所有请求。如果集群不需要授权流程，采用该策略 ABAC (Attribute-Based Access Control): 基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webbook: 通过调用外部REST服务对用户进行授权 RBAC (Role-Based Access Control): 基于角色的访问控制，默认规则 RBAC优势： 对集群中的资源和非资源均拥有完整的覆盖 整个RBAC完全由几个API对象完成，同其他API对象一样，可以用kubectl或API进行操作 可在运行时调整，无需重启API Server 3.1 RBAC 的 API资源对象 Role ClusterRole RoleBinding ClusterRoleBinding k8s 不会提供用户管理，User, Group, ServiceAccount指定的用户，需要通过证书请求文件指定： 1234567891011121314151617&#123; &quot;CN&quot;: &quot;admin&quot;, // User &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;HangZhou&quot;, &quot;L&quot;: &quot;XS&quot;, &quot;O&quot;: &quot;system:master&quot;, // Group &quot;OU&quot;: &quot;Sytem&quot; &#125; ]&#125; 3.2 Role &amp; ClusterRole3.2.1 RoleRole 表示一组规则权限，权限只会增加（累加权限），不存在一开始就开通很多权限而通过RBAC对其减少的操作。Role 必须定义在一个namespace中，跨namespace可以使用ClusterRole 123456789apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: pod-reader namespace: defaultrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ pods ] verbs: [get, watch, list] 3.2.2 ClusterRoleClusterRole 是集群级别的，可用于： 集群级别资源控制，例如node访问权限 非资源型 endpoints，例如/healthz 访问 所有命名空间资源控制，例如pod 12345678apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: secret-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ secrets ] verbs: [get, watch, list] 3.3 RoleBinding &amp; ClusterRoleBinding3.3.1 RoleBindingRoleBinding 可以将角色中定义的权限赋予用户或组，它包含了一种权限列表(subjects)，权限列表包含不同形式的待授予权限资源类型（users，groups，service accounts），同时它也包含被Bind的Role引用 12345678910111213apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: read-pods namespace: defaultsubjects:- kind: User name: jane apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io RoleBinding引用ClusterRole： 1234567891011121314# This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespaceapiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: read-secrets namespace: developmentsubjects:- kind: User name: dave apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 3.3.2 ClusterRoleBindingClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权 12345678910111213# This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in any namespace.apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: read-secrets-globalsubjects:- kind: Group name: manager apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 3.4 Resources访问子资源: 1GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log 12345678apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: pod-and-pod-logs-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ pods, &quot;pods/log&quot; ] verbs: [get, list] 3.5 to SubjectsRoleBinding &amp; ClusterRoleBinding 可以将Role绑定到Subjects, Subjects 可以是groups, users, 或SA 3.6 示例3.6.1 创建Linux账号123456useradd devuserpasswd devusersu - devuser$ kubectl get pod # 无权限The connection to the server localhost:8080 was refused - did you specify the right host or port? 3.6.2 安装证书工具12345678# 下载证书生成工具$ wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64$ wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 $ wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 $ chmod +x cfssl*$ mv cfssl_linux-amd64 /usr/local/bin/cfssl $ mv cfssljson_linux-amd64 /usr/local/bin/cfssljson$ mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo 3.6.3 生成证书1234567891011121314151617181920212223242526$ mkdir -p ~/cert/devuser# 证书请求文件$ cat &gt; ~/cert/devuser/user-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;devuser&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;JS&quot;, &quot;L&quot;: &quot;NJ&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;Sytem&quot; &#125; ]&#125;EOF# 生成证书$ cd /etc/kubernetes/pki$ cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes ~/cert/devuser/user-csr.json | cfssljson -bare devuser 3.6.4 设置集群参数1234567891011121314151617181920212223# 设置集群参数cd ~/cert/devuserexport KUBE_APISERVER=&quot;https://192.168.31.40:6443&quot;kubectl config set-cluster kubernetes \\--certificate-authority=/etc/kubernetes/pki/ca.crt \\--embed-certs=true \\--server=$&#123;KUBE_APISERVER&#125; \\--kubeconfig=devuser.kubeconfig# 设置客户端认证参数kubectl config set-credentials devuser \\--client-certificate=/etc/kubernetes/pki/devuser.pem \\--client-key=/etc/kubernetes/pki/devuser-key.pem \\--embed-certs=true \\--kubeconfig=devuser.kubeconfig# 设置上下文kubectl config set-context kubernetes \\--cluster=kubernetes \\--user=devuser \\--namespace=dev \\--kubeconfig=devuser.kubeconfig 3.6.5 角色绑定123# rolebindingkubectl create ns devkubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev 3.6.6 用户管理配置123mkdir -p /home/devuser/.kubecp devuser.kubeconfig /home/devuser/.kube/configchown -R devuser:devuser /home/devuser/.kube 3.6.7 设置默认上下 和 验证123456789101112131415161718# 设置默认上下文su - devuser$ kubectl config use-context kubernetes --kubeconfig=.kube/configSwitched to context &quot;kubernetes&quot;.# devuser 用户下创建 pod$ kubectl get podNo resources found in dev namespace.$ kubectl run nginx --image=hub.elihe.io/test/nginx:v1pod/nginx created$ kubectl get podNAME READY STATUS RESTARTS AGEnginx 1/1 Running 0 4s$ kubectl get pod -n defaultError from server (Forbidden): pods is forbidden: User &quot;devuser&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot; 4. 准入控制准入控制是 API Server 的插件集合，通过添加不同的插件，实现额外的准入控制规则 常见准入控制插件： NamespaceLifecycle: 防止在不存在的namespace上创建对象；防止删除系统预置的namespace；删除namespace时，连带删除它下面的所有资源 LimitRanger: 确保请求的资源不会超过资源所在Namespace的LimitRange的限制 ServiceAccount: 实现自动化添加SA ResourceQuota: 确保请求的资源不会超过资源的ResourceQuota限制","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 集群调度","slug":"Kubernetes 集群调度","date":"2018-07-07T03:52:25.000Z","updated":"2021-06-22T10:50:49.720Z","comments":true,"path":"2018/07/07/Kubernetes 集群调度/","link":"","permalink":"https://elihe2011.github.io/2018/07/07/Kubernetes%20%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6/","excerpt":"1. 调度说明1.1 简介Scheduler 是 K8S 的调度器，主要任务是把定义的 pod 分配到集群节点上。它主要考虑如下问题： 公平： 如何确保每个节点都被分配资源 资源高利用率：集群所有资源最大化被使用 效率：调度性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Scheduler 作为独立的进程允许，启动后会一直监听API Server，获取 PodSpec.NodeName 为空的pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上","text":"1. 调度说明1.1 简介Scheduler 是 K8S 的调度器，主要任务是把定义的 pod 分配到集群节点上。它主要考虑如下问题： 公平： 如何确保每个节点都被分配资源 资源高利用率：集群所有资源最大化被使用 效率：调度性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Scheduler 作为独立的进程允许，启动后会一直监听API Server，获取 PodSpec.NodeName 为空的pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上 1.2 调度过程 首先，过滤掉不满足条件的节点，这个过程称为 predicate 其次，对通过的节点按优先级排序，这个是 priority 最后，从中选择优先级最高的节点。 总结：预选 + 优选 Predicate 算法： PodFitsResources: 节点上剩余资源是否大于 pod 请求资源 PodFitsHost: 如果 pod 指定了NodeName，检查当前节点名称是否与之匹配 PodFitsHostPorts: pod 申请的port 是否已被占用 PodSelectorMatches: 过滤掉和 pod 指定的 label 不匹配的节点 NoDiskConflict: 已经 mount 的 volume和pod指定的 volume 不冲突，除非它们都是只读的 如果在 predicate 过程中没有合适的节点，pod 会一直在 pending 状态，不断重试调度，直到有节点满足条件。多个节点同时满足条件，继续按 priorities 过程，按优先级大小排序 优先级选项： LeastRequestedPriority: 计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高 BalancedResourceAllocation: CPU 和 Memory 的使用率接近，权重越高。通常和上一个一起使用 ImageLocalityPriority: 本地已下载镜像，镜像总大小越大，权重越高 1.3 自定义调度器spec.schedulername 指定调度器名称 1234567891011apiVersion: v1kind: Podmetadata: name: annotation-second-scheduler labels: name: multischeduler-examplespec: schedulername: my-scheduler conatiners: - name: pod-with-second-annotation-container image: gcr.io/google_containers/pause:2.0 2. 调度亲和性2.1 节点亲和性pod.spec.nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: 软策略 requiredDuringSchedulingIgnoredDuringExecution: 硬策略 12345678910111213141516171819202122232425262728apiVersion: v1kind: Podmetadata: name: node-affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn values: - k8s-node02 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: source operator: In values: - k8s-node01 2.2 Pod 亲和性pod.spec.affinity.podAffinity/PodAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: 软策略 requiredDuringSchedulingIgnoredDuringExecution: 硬策略 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: Podmetadata: name: pod-affinity labels: app: pod-3spec: containers: - name: pod-3 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - pod-1 topologyKey: kubernetes.io/hostname podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - pod-2 topologyKey: kubernetes.io/hostname 12345678910111213$ kubectl get podNAME READY STATUS RESTARTS AGEnode-affinity 1/1 Running 0 9m22spod-affinity 0/1 Pending 0 10s# 注意node-affinity必须是running的，否则即使修改了的label满足条件，pod-3也不会创建$ kubectl label pod node-affinity app=pod-1 --overwrite=truepod/node-affinity labeled$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSnode-affinity 1/1 Running 1 10m app=pod-1pod-affinity 1/1 Running 0 95s app=pod-3 2.3 亲和性/反亲和性策略对比 调度策略 匹配标签 操作符 拓扑域支持 调度目标 nodeAffinity Node In, NotIn, Exists, DoesNotExist, Gt, Lt No 指定主机 podAffinity Pod In, NotIn, Exists, DoesNotExist Yes 指定Pod在同一个拓扑域 podAntiAffinity Pod In, NotIn, Exists, DoesNotExist Yes 指定Pod不在同一个拓扑域 3. 污点 和 容忍 亲和性：Pod的一种偏好或硬性要求，它使 Pod 能被吸引到一类特定的节点 污点：与亲和性相反，它使节点能够排斥一类特定的Pod Taint：用来避免pod节点被分配到不合适的节点上 Toleration：表示pod可以(容忍)被分配到Taint节点上 3.1 Taint3.1.1 污点的组成1key=value:effect 其中value可以为空，effect描述污点的作用，当前支持如下三个选项： NoSchedule: 不会将Pod调度到具有该污点的Node上 PreferNoSchedule: 尽量避免将Pod调度到具有该污点的Node上 NoExecute: 不会将Pod调度到具有该污点的Node上，同时会将已存在的Pod驱逐出该Node 3.1.2 污点的设置，查看和去除123456789# 设置污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule# 查看污点$ kubectl describe node k8s-node01 | grep -i taintTaints: kickoff=test:NoSchedule# 去除污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule- 3.2 Tolerationpod.spec.tolerations 12345678910111213tolerations:- key: key1 operator: Equal value: value1 effect: NoSchedule tolerationSeconds: 3600 # 驱离前保留时间- key: key2 operator: Equal value: value2 effect: NoExecute- key: key3 operator: Exists effect: NoSchedule key, value, effect 要与 Node 上设置的taint一致 operator等于 Exists 时，忽略 value值 tolerationSeconds Pod被驱离前的保留时间 当不指定key时，容忍所有的污点key 12tolerations:- operator: Exists 当不指定effect时，容忍所有的污点作用 123tolerations:- key: key operator: Exists 多个master节点，可去除默认污点 12345# 主节点默认设置污点$ kubectl describe node k8s-master | grep -i taintTaints: node-role.kubernetes.io/master:NoSchedule$ kubectl taint nodes k8s-master node-role.kubernetes.io/master=:PreferNoSchedule 3.2.1 示例1234567891011121314151617181920212223242526# taint-toleration.yamlapiVersion: v1kind: Podmetadata: name: pod-1spec: containers: - name: pod-1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;]---apiVersion: v1kind: Podmetadata: name: pod-2spec: containers: - name: pod-2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] tolerations: - key: kickoff operator: Equal value: test effect: NoSchedule 12345678910111213141516171819# 节点都打上污点标识$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule$ kubectl taint nodes k8s-node02 kickoff=test:NoSchedule$ kubectl create -f taint-toleration.yaml$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod-1 0/1 Pending 0 58s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;pod-2 1/1 Running 0 58s 10.244.2.55 k8s-node02 &lt;none&gt; &lt;none&gt;# 去除污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule-# 不再Pending$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod-1 1/1 Running 0 2m 10.244.1.40 k8s-node01 &lt;none&gt; &lt;none&gt;pod-2 1/1 Running 0 2m 10.244.2.55 k8s-node02 &lt;none&gt; &lt;none&gt; 4. 固定节点4.1 指定节点名称pod.spec.nodeName 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: test-1spec: replicas: 3 selector: matchLabels: app: tools template: metadata: labels: app: tools spec: nodeName: k8s-node01 # 指定节点名称 containers: - name: pod-1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] 12345$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-1-5c889d444f-pp9td 1/1 Running 0 48s 10.244.1.41 k8s-node01 &lt;none&gt; &lt;none&gt;test-1-5c889d444f-rtk25 1/1 Running 0 48s 10.244.1.43 k8s-node01 &lt;none&gt; &lt;none&gt;test-1-5c889d444f-rv2fc 1/1 Running 0 48s 10.244.1.42 k8s-node01 &lt;none&gt; &lt;none&gt; 4.2 指定节点选择器pod.spec.nodeSelector, 通过label-selector机制选择节点，由调度器调度策略匹配label，然后调度到目标节点 1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: test-2spec: replicas: 2 selector: matchLabels: app: web template: metadata: labels: app: web spec: nodeSelector: # 指定标签 type: backendNode1 containers: - name: web image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] 12345678910111213$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGEtest-2-564fd7c7df-4jftd 0/1 Pending 0 3s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;test-2-564fd7c7df-tdwj7 0/1 Pending 0 3s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;# 给node打标签$ kubectl label node k8s-node02 type=backendNode1node/k8s-node02 labeled$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-2-564fd7c7df-4jftd 1/1 Running 0 3m24s 10.244.2.56 k8s-node02 &lt;none&gt; &lt;none&gt;test-2-564fd7c7df-tdwj7 1/1 Running 0 3m24s 10.244.2.57 k8s-node02 &lt;none&gt; &lt;none&gt;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 存储","slug":"Kubernetes 存储","date":"2018-07-05T23:12:05.000Z","updated":"2021-06-22T10:50:49.720Z","comments":true,"path":"2018/07/06/Kubernetes 存储/","link":"","permalink":"https://elihe2011.github.io/2018/07/06/Kubernetes%20%E5%AD%98%E5%82%A8/","excerpt":"1. ConfigMap提供向容器注入配置信息的机制，可以用来保存单个属性，也可以用来保存整个配置文化或 JSON 二进制大对象 1.1 创建 ConfigMap1.1.1 文件--from-file：指定文件或目录 12345678910111213141516$ cat &gt; ./ui.properties &lt;&lt;EOFcolor=redbackground=cyanEOF$ kubectl create configmap ui-config --from-file=./ui.properties $ kubectl get cm ui-config -o yamlapiVersion: v1data: ui.properties: | # key 为文件名称 color=red background=cyankind: ConfigMapmetadata: ...","text":"1. ConfigMap提供向容器注入配置信息的机制，可以用来保存单个属性，也可以用来保存整个配置文化或 JSON 二进制大对象 1.1 创建 ConfigMap1.1.1 文件--from-file：指定文件或目录 12345678910111213141516$ cat &gt; ./ui.properties &lt;&lt;EOFcolor=redbackground=cyanEOF$ kubectl create configmap ui-config --from-file=./ui.properties $ kubectl get cm ui-config -o yamlapiVersion: v1data: ui.properties: | # key 为文件名称 color=red background=cyankind: ConfigMapmetadata: ... 1.1.2 字面值--from-literal 123456789101112$ kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm$ kubectl describe cm special-config$ kubectl get cm special-config -o yamlapiVersion: v1data: special.how: very special.type: charmkind: ConfigMapmetadata: ... 1.2 使用 ConfigMap1.2.1 使用 ConfigMap 代替环境变量spec.containers[].env[] spec.containers[].envFrom[] 123456789101112131415161718192021222324252627282930313233343536373839404142434445# configmap-injection.yamlapiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: very special.type: charm---apiVersion: v1kind: ConfigMapmetadata: name: env-config namespace: defaultdata: log_level: INFO---apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot;] env: # 按key导入 - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: # 全部导入 - configMapRef: name: env-config restartPolicy: Never 1234567891011121314$ kubectl create -f configmap-injection.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEconfigmap-pod 0/1 Completed 0 2m35s$ kubectl logs configmap-pod ...SPECIAL_TYPE_KEY=charm # targetSPECIAL_LEVEL_KEY=very # targetlog_level=INFO # targetKUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_SERVICE_HOST=10.96.0.1 1.2.2 用 ConfigMap 设置命令行参数12345678910111213141516171819202122apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $&#123;SPECIAL_LEVEL_KEY&#125; $&#123;SPECIAL_TYPE_KEY&#125; &quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never 1.2.3 通过数据插件使用 ConfigMap123456789101112131415161718apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 300&quot;] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never 12$ kubectl exec configmap-pod -it -- cat /etc/config/special.howvery 1.2.4 ConfigMap 热更新12345678910111213141516171819202122232425262728293031323334353637# configmap-hot-update.yamlapiVersion: v1kind: ConfigMapmetadata: name: log-config namespace: defaultdata: log_level: INFO---apiVersion: apps/v1kind: Deploymentmetadata: name: nginxspec: replicas: 1 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: log-config 12345678910111213141516171819202122$ kubectl apply -f configmap-hot-update.yaml$ kubectl get podNAME READY STATUS RESTARTS AGEnginx-df47dc9cd-9mjnx 1/1 Running 0 82s$ kubectl exec nginx-df47dc9cd-9mjnx -it -- cat /etc/config/log_levelINFO# 修改 ConfigMap$ kubectl edit configmap log-configapiVersion: v1data: log_level: DEBUGkind: ConfigMap# 30s 后再次查询$ kubectl exec nginx-df47dc9cd-9mjnx -it -- cat /etc/config/log_levelDEBUG# 触发热更新, 会重新启动, 配置生效$ kubectl patch deployment nginx --patch &#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;version.config&quot;: &quot;20201014&quot;&#125;&#125;&#125;&#125;&#125;&#x27; 2. SecretSecret 解决密码、token、密钥等敏感数据的配置问题，可以以Volume 或环境变量方式导入 Pod 中使用 Secret 类型有三种： Service Account: 用来访问 k8s api。由 k8s 自动创建，自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录下 Opaque: base64 编码格式的 Secret，用来存储密码、密钥等 kubernetes.io/dockerconfigjson: 用来存储私有 docker registry 的认证信息 2.1 Service Account (SA)12$ kubectl exec nginx-596675fccc-v8gfw -it -- ls /run/secrets/kubernetes.io/serviceaccountca.crt namespace token 2.2 Opaque2.2.1 创建12345$ echo -n &quot;admin&quot; | base64YWRtaW4=$ echo -n &quot;pass123&quot; | base64cGFzczEyMw== 123456789# secret.yamlapiVersion: v1kind: Secretmetadata: name: my-secrettype: Opaquedata: username: YWRtaW4= password: cGFzczEyMw== 2.2.2 使用 Secret 将 Secret 挂载到 Volume 1234567891011121314151617181920# secret-volume.yamlapiVersion: v1kind: Podmetadata: labels: name: secret-volume name: secret-volumespec: volumes: - name: secrets secret: secretName: my-secret containers: - name: db image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent volumeMounts: - name: secrets mountPath: &quot;/etc/secrets&quot; readOnly: true 123456789101112$ kubectl create -f secret-volume.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEsecret-volume 1/1 Running 0 8s$ kubectl exec secret-volume -it -- ls /etc/secretspassword username# 容器内自动解密$ kubectl exec secret-volume -it -- cat /etc/secrets/passwordpass123 将 Secret 导入环境变量 1234567891011121314151617181920212223242526272829303132# secret-env.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: secret-envspec: replicas: 2 selector: matchLabels: app: secret-pod template: metadata: labels: app: secret-pod spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 env: - name: TEST_USER valueFrom: secretKeyRef: name: my-secret key: username - name: TEST_PASSWORD valueFrom: secretKeyRef: name: my-secret key: password 12345678910$ kubectl apply -f secret-env.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEsecret-env-6f5785997f-2w7dj 1/1 Running 0 8ssecret-env-6f5785997f-khzjz 1/1 Running 0 8s$ kubectl exec secret-env-6f5785997f-2w7dj -it -- env | grep TESTTEST_USER=adminTEST_PASSWORD=pass123 2.3 kubernetes.io/dockerconfigjson创建 docker register 认证 1$ kubectl create secret docker-register myregisterkey --docker-server=hub.elihe.io --docker-username=admin --docker-password=Harbor12345 --docker-email=eli.he@live.cn 创建 Pod 时，用 imagePullSecrets 来引用刚创建的 myregisterkey 12345678910apiVersion: v1kind: Podmetadata: name: nginxspec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullSecrets: - name: myregisterkey 3. Volumevolume 解决问题： 容器磁盘上的新增文件，容器重启后将消失，无法持久化 Pod中运行的多个容器需求共享文件 当 Pod 中的容器重启时，volume 数据还在。但是当 Pod 不存在时，volume 也将不复存在。 Volume 支持的类型： awsElasticBlockStore, azureDisk, azureFile, cephfs, csi, downwardAPI, emptyDir fc, flocker, gcePersistentDisk, gitRepo, glusterfs, hostPath, iscsi, local, nfs persistentVolumeClaim, projected, portworxVolume, quobyte, rbd, scaleIO, secret storageos vsphereVolume 3.1 emptyDir创建 Pod 时，会自动创建 emptyDir 卷，它最初是空的，Pod 中的容器可以读取和写入 emptyDir 卷中的文件。当删除 Pod 时，emptyDir 中的数据将被永久删。容器崩溃不会导致 Pod 被删除，因此 emptyDir 卷中的数据在容器崩溃时是安全的。 emptyDir 用法： 暂存空间，例如用于基于磁盘的合并排序 用于长时间计算崩溃恢复时的检查点 Web服务器容器提供数据时，保存内容管理容器提取的文件 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: vol-emptydirspec: containers: - name: c1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /cache name: cache-volume - name: c2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; 1234$ kubectl exec vol-emptydir -c c1 -it -- touch /cache/now.txt$ kubectl exec vol-emptydir -c c2 -it -- ls -l /cache/now.txt-rw-r--r-- 1 root root 0 Oct 14 01:34 /cache/now.txt 3.2 hostPath将主机节点的文件系统中的文件和目录挂载到集群中 hostPath 用途： 运行需要访问 Docker 内部的容器，使用 /var/lib/docker 的 hostPath 在容器中运行 cAdvisor(猫头鹰，Google提供的一个服务)，使用 /dev/cgroups 的 hostPath hostPath 卷指定 type检查： 值 行为 空字符串(默认)，向后兼容，在挂载hostPath 卷之前不会执行任何检查 DirectoryOrCreate 目录不存在自动创建，权限0755，与kubectl具有相同组和所有权 Directory 目录必须存在 FileOrCreate 文件不存在自动创建，权限0644，与kubectl具有相同组和所有权 File 文件必须存在 Socket Unix 套接字必须存在 CharDevice 字符设备必须存在 BlockDevice 块设备必须存在 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: vol-hostpathspec: containers: - name: c1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /data name: data-volume - name: c2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /data name: data-volume volumes: - name: data-volume hostPath: path: /data type: Directory 1234567891011$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESvol-hostpath 0/2 ContainerCreating 0 44s &lt;none&gt; k8s-node02 &lt;none&gt; &lt;none&gt;# k8s-node02 上创建目录 /data$ mkdir /data$ date &gt; /data/abc.txt# 查看文件内容$ kubectl exec vol-hostpath -c c1 -it -- cat /data/abc.txtSat Sep 12 11:10:53 CST 2020 4. PV &amp; PVCPV 作用：屏蔽后端不同存储类型之间，挂载方式不一致等特性差异 PVC: 寻找一个合适的PV进行绑定 4.1 概念 PV: Persistent Volume。由管理员设置的存储，它是集群的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期之外。 静态 PV：集群管理员创建一些 PV。它们带有可供集群用户使用的实际存储的细节。它们存储在 k8s api 中，可用于消费 动态 PV：当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim时，集群可能会尝试动态地为 PVC创建卷。此配置基于StorageClasses: PVC必须请求（存储类），并且管理员必须创建并配置该类才能够尽兴动态创建。声明该类为 “” 可有效地禁用其动态配置 PVC: PersistentVolumeClaim。是用户存储的请求。它与Pod 类似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源(CPU &amp; Memory)。PVC 可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载) 4.1.1 绑定mater 中的控制环路监视新的 PVC，寻找匹配的PV（如果可能），并将它们绑定在一起。如果为新的PVC动态调配PV，则该环路将始终将该PV绑定到PVC。否则，用户总会得到他们所请求的存储，但容器可能会超出要求的数量。一旦PV和PVC绑定后，PVC绑定是排他性的，不管它们是如何绑定的，PVC和PV绑定是一一映射的 4.1.2 持久化卷声明的保护PVC 保护的目的是确保 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话，可能导致数据丢失。 当 Pod 状态为 Pending 或 Running 时，PVC 处于活动状态 当启用 PVC 保护 alpha 功能时，如果用户删除一个 pod 正在使用的 PVC，该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 Pod 使用 4.1.3 持久化卷类型 GCEPersistentDisk, AWSElasticBlockStore, AsureFile, AzureDisk, FC(Fibre Channel) FlexVolume, Flocker, NFS, iSCSI, RBD(Ceph Block Device), CephFS Cinder (OpenStack block storage), Glusterfs, VsphereVolume, QuoByte Volumes HostPath, VMware Photon, Portworx Volumes, ScaleIO Volumes, StorageOS 4.1.4 PV 访问模式PV 可以以资源提供者支持的任何方式挂载在主机上。 ReadWriteOnce: 单节点读写模式，RWO ReadOnlyMany: 多节点只读模式，ROX ReadWriteMany: 多节点读写模式， RWX 4.1.5 回收策略 Retain: 保留，需手动回收 Recycle: 基本擦除 （rm -rf /thevolume/*），新版k8s已不支持 Delete: 关联的存储资产将被删除 只有 NFS和HostPath 支持 Recycle 策略 AWS EBS、GCE PD、Azure Disk 和 Cinder 卷 支持 Delete 策略 4.1.6 状态 Available: 空闲资源，还未被绑定 Bound: 已绑定 Released: 解除绑定，但未被集群重新声明 Failed: 自动回收失败 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv-1spec: capacity: storage: 2Gi volumeMode: Filesystem accessModes: - ReadWriteOnce # 同时只允许一个用户读写操作 persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsserevr=4.1 nfs: path: /tmp server: 192.168.31.200 4.2 持久化演示 NFS4.2.1 安装 NFS 服务器123456789101112131415yum install -y nfs-common nfs-utils rpcbindmkdir /nfschmod 666 /nfschown nfsnobody /nfsecho &#x27;/nfs *(rw, no_root_squash,no_all_squash,sync)&#x27; &gt; /etc/exportssystemctl start rpcbindsystemctl start nfsexportfs -rv# 客户端安装yum install -y nfs-utils rpcbindshowmount -e 192.168.31.200mkdir /testmount -t nfs 192.168.31.200:/nfs /test 4.2.2 部署 PV1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: nfspv1spec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs server: 192.168.31.200---apiVersion: v1kind: PersistentVolumemetadata: name: nfspv2spec: capacity: storage: 2Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs2 server: 192.168.31.200---apiVersion: v1kind: PersistentVolumemetadata: name: nfspv3spec: capacity: storage: 3Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs3 server: 192.168.31.200 4.2.3 创建服务并使用 PVCStatefulSet 控制器，必须先要有一个无头服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# app.yamlapiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx ---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx serviceName: nginx # service 必须为无头服务 replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: # 选择条件 accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: nfs resources: requests: storage: 1Gi 1234567891011121314151617181920212223242526272829$ kubectl apply -f pv.yaml$ kubectl apply -f app.yaml$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Bound default/www-web-0 nfs 5m23snfspv2 2Gi RWO Retain Bound default/www-web-1 nfs 5m23snfspv3 3Gi RWO Retain Bound default/www-web-2 nfs 5m23s$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound nfspv1 1Gi RWO nfs 2m53swww-web-1 Bound nfspv2 2Gi RWO nfs 2m50swww-web-2 Bound nfspv3 3Gi RWO nfs 2m45s$ kubectl get sts # statefulsetNAME READY AGEweb 3/3 3m11s$ kubectl get podNAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 3m29sweb-1 1/1 Running 0 3m26sweb-2 1/1 Running 0 3m21s$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d17hnginx ClusterIP None &lt;none&gt; 80/TCP 49m StatefulSet 相关总结： Pod Name(网络标识)：$(statefulset name)-(order)。例如：web-0 DNS 域名：$(podname).(headless server name) Pod 重建，IP改变，但域名不变。例如：web-0.nginx 域名FQDN：$(service name).$(namespace).svc.cluster.local, 其中”cluster.local”为集群的域名。例如：nginx.default.svc.cluster.local 123456789$ kubectl get pod -n kube-system -o wide | grep corednscoredns-66bff467f8-8lb4m 1/1 Running 4 21d 10.244.0.10 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 4 21d 10.244.0.11 k8s-master &lt;none&gt; &lt;none&gt;$ dig -t A nginx.default.svc.cluster.local. @10.244.0.10;; ANSWER SECTION:nginx.default.svc.cluster.local. 30 IN A 10.244.2.53nginx.default.svc.cluster.local. 30 IN A 10.244.1.36nginx.default.svc.cluster.local. 30 IN A 10.244.2.54 FQDN：(Fully Qualified Domain Name)全限定域名：同时带有主机名和域名的名称。（通过符号“.”）例如：主机名是bigserver,域名是mycompany.com,那么FQDN就是bigserver.mycompany.com StatefulSet 启停顺序： 有序部署：如果有多个Pod副本，它们会按顺序创建 0～N-1，并且只有当Pod处于Running和Ready状态，才会创建下一个Pod 有序删除：Pod被删除时，删除顺序从N-1～ 0 有序扩展：扩展时，也必须按顺序进行 StatefulSet 使用场景： 稳定的持久存储 稳定的网络标识，即Pod重新调度后，PodName 和 Hostname 不变 有序部署，有序扩展，具有 init containers 来实现 有序收缩 pv资源释放： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647$ kubectl delete svc nginx$ kubectl delete sts --all$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound nfspv1 1Gi RWO nfs 39mwww-web-1 Bound nfspv2 2Gi RWO nfs 39mwww-web-2 Bound nfspv3 3Gi RWO nfs 39m$ kubectl delete pvc --allpersistentvolumeclaim &quot;www-web-0&quot; deletedpersistentvolumeclaim &quot;www-web-1&quot; deletedpersistentvolumeclaim &quot;www-web-2&quot; deleted$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Released default/www-web-0 nfs 41mnfspv2 2Gi RWO Retain Released default/www-web-1 nfs 41mnfspv3 3Gi RWO Retain Released default/www-web-2 nfs 41m$ kubectl edit pv nfspv1...spec: accessModes: - ReadWriteOnce capacity: storage: 1Gi claimRef: # 删除 apiVersion: v1 kind: PersistentVolumeClaim name: www-web-0 namespace: default resourceVersion: &quot;104634&quot; uid: 57597e18-963d-4ce1-b1d9-880ac0ef3da0 nfs: path: /nfs server: 192.168.31.200 persistentVolumeReclaimPolicy: Retain storageClassName: nfs ...$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Available nfs 46mnfspv2 2Gi RWO Retain Released default/www-web-1 nfs 46mnfspv3 3Gi RWO Retain Released default/www-web-2 nfs 46m","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes Service","slug":"Kubernetes Service","date":"2018-07-05T08:07:23.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/05/Kubernetes Service/","link":"","permalink":"https://elihe2011.github.io/2018/07/05/Kubernetes%20Service/","excerpt":"1. Service 的概念SVC：服务发现 Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 – 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector Service 能够提供负载均衡能力，但只提供了 4 层，而没有 7 层。当需要更多的匹配规则来转发请求时，不支持。","text":"1. Service 的概念SVC：服务发现 Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 – 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector Service 能够提供负载均衡能力，但只提供了 4 层，而没有 7 层。当需要更多的匹配规则来转发请求时，不支持。 2. Service 代理模式分类2.1 VIP 和 Service 代理kube-proxy 进程：负责为 Service 实现一种 VIP（虚拟IP）的形式，代理模式有如下三种： userspace：k8s v1.0 iptables: v1.1 加入，v1.2 默认 ipvs: v1.8 加入，v1.14 默认 Ingress API: v1.1 新增，支持 7 层服务 为什么不使用 round-robin DNS? dns 存在缓存，当有Pod节点故障时，无法自动处理 2.1.1 userspace 2.1.2 iptables 2.1.3 ipvs kube-proxy 监控 Service 和 Endpoints，调用 netlink 接口以相应地创建 ipvs 规则，并定期与 Service 和 Endpoints 对象同步 ipvs 规则，以确保 ipvs 状态与期望一致。访问服务时，流量将被重定向到其中一个后端 Pod 与 iptables 类似，ipvs 于 netfilter 的 hook 功能，但使用hash表作为底层数据结构并在内核空间中工作。这意味着 ipvs 可以快速地重定向流量，并且在同步代理规则时具有更好的性能。 ipvs 为负载均衡算法提供了更多选项： rr: 轮训调度 lc: 最小连接数 dh: 目标hash sh: 源hash sed: 最短期望延迟 nq: 不排队调度 3. Service 的类型 ClusterIp: 默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟IP NodePort: 在ClusterIp 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 &lt;NodeIp&gt;:&lt;NodePort&gt; 来访问服务 LoadBalancer: 在 NodePort 基础上，借助 Cloud Provider 创建一个外部负载均衡器，并将请求转发到 &lt;NodeIp&gt;:&lt;NodePort&gt; ExternalName: 把集群外部的服务引入集群内部，在集群内部直接使用。 3.1 ClusterIpClusterIP 主要在每个 node 节点使用 iptables，将发向 ClusterIp 的流量转发至 kube-proxy，然后 kube-proxy 自己内部实现负载均衡算法，查询到该 Service 下对应 Pod 的地址和端口，进而将数据转发给对应的 Pod 工作原理： apiserver: 用户通过 kubectl 向 apiserver 下发创建 service 的命令，apiserver 接收到请求后，将数据存储到 etcd 中 kube-proxy: 该进程负载监控 Service 和 Pod 的变化 (etcd)，并将变化信息更新到本地 iptables中 iptables: 使用NAT 等技术，将 VIP 的流量转发至 Endpoint 中 12345678910111213141516171819202122232425# myapp-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deployspec: replicas: 3 selector: matchLabels: app: myapp release: stable template: metadata: labels: app: myapp release: stable env: test spec: containers: - name: myapp image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 1234567891011121314# myapp-service-clusterip.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: ClusterIP selector: # 绑定Pod app: myapp release: stable ports: - name: http port: 80 targetPort: 80 操作： 123456789101112131415161718192021222324252627$ kubectl apply -f myapp-deploy.yaml$ kubectl apply -f myapp-service-clusterip.yaml$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyapp-deploy-7779c7f4bb-dv7zh 1/1 Running 0 24s 10.244.2.31 k8s-node02 &lt;none&gt; &lt;none&gt;myapp-deploy-7779c7f4bb-jc8dp 1/1 Running 0 24s 10.244.2.32 k8s-node02 &lt;none&gt; &lt;none&gt;myapp-deploy-7779c7f4bb-lx4kl 1/1 Running 0 24s 10.244.1.25 k8s-node01 &lt;none&gt; &lt;none&gt;$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20dmyapp ClusterIP 10.96.155.51 &lt;none&gt; 80/TCP 42s# 通过 ClusterIp 访问$ curl 10.96.155.51Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;# ipvs转发$ ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 10.96.155.51:80 rr -&gt; 10.244.1.25:80 Masq 1 0 0 -&gt; 10.244.2.31:80 Masq 1 0 0 -&gt; 10.244.2.32:80 Masq 1 0 0 Headless Service: 当不需要负载均衡和独立Service Ip时，可以指定 spec.clusterIP 为 None来创建 Headless Service。这类 Service 并不会分配 Cluster IP，kube-proxy 也不会处理它们，而且平台也不会其对进行负载均衡和路由 123456789101112131415# myapp-service-clusterip-headless.yamlapiVersion: v1kind: Servicemetadata: name: myapp-headlessspec: type: ClusterIP selector: app: myapp release: stable clusterIP: None ports: - name: http port: 80 targetPort: 80 操作： 12345678910111213141516171819202122$ kubectl apply -f myapp-service-clusterip-headless.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp-headless ClusterIP None &lt;none&gt; 80/TCP 31s# 获取 DNS 地址信息$ kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66bff467f8-8lb4m 1/1 Running 2 20d 10.244.0.6 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 2 20d 10.244.0.7 k8s-master &lt;none&gt; &lt;none&gt;# 安装 dig 命令$ yum install -y bind-utils# 解析域名 i 记录$ dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.6;; ANSWER SECTION:myapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.32myapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.31myapp-headless.default.svc.cluster.local. 30 IN A 10.244.1.25 虽然没有svc，但依旧可以通过访问域名，路由到不同Pod上 3.2 NodePort原理：在当前Node的物理机上暴露一个端口，外部可以通过IP:PORT 方式访问集群服务 1234567891011121314# myapp-service-nodeport.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: NodePort selector: app: myapp release: stable ports: - name: http port: 80 targetPort: 80 操作： 1234567891011121314$ kubectl apply -f myapp-service-nodeport.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp NodePort 10.106.31.155 &lt;none&gt; 80:31205/TCP 6s$ curl 192.168.31.40:31205# 访问流程$ ipvsadm -LnTCP 192.168.31.40:31205 rr -&gt; 10.244.1.26:80 Masq 1 0 0 -&gt; 10.244.2.33:80 Masq 1 0 0 -&gt; 10.244.2.34:80 Masq 1 0 3.3 ExternalName该类型的 Service 通过返回 CNAME 和 它的值，可将服务映射到 externalName 字段的内容。ExternalName没有 selector，也未指定任何端口和 Endpoint。相反，它为集群提供访问外部服务方式 12345678# myapp-service-external-name.yamlapiVersion: v1kind: Servicemetadata: name: my-servicespec: type: ExternalName externalName: hub.elihe.io 123456789101112131415$ kubectl apply -f myapp-service-external-name.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmy-service ExternalName &lt;none&gt; hub.elihe.io &lt;none&gt; 21s$ kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66bff467f8-8lb4m 1/1 Running 3 20d 10.244.0.8 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 3 20d 10.244.0.9 k8s-master &lt;none&gt; &lt;none&gt;$ dig -t A my-service.default.svc.cluster.local. @10.244.0.8;; ANSWER SECTION:my-service.default.svc.cluster.local. 30 IN CNAME hub.elihe.io. 4. Service Ingressingress: 进入、入境 4.1 Ingress-Nginx 部署 部署： 12345678910111213141516171819202122232425262728293031323334353637$ wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml$ wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml# 手动下载包$ grep image mandatory.yaml image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0$ docker pull quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0# 导出$ docker save -o nginx-ingress.tar quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0$ gzip nginx-ingress.tar# 上次到每个节点，然后导入镜像$ gunzip nginx-ingress.tar.gz $ docker load -i nginx-ingress.tar # 部署$ kubectl apply -f mandatory.yaml$ kubectl apply -f service-nodeport.yaml$ kubectl get deploy -n ingress-nginxNAME READY UP-TO-DATE AVAILABLE AGEnginx-ingress-controller 1/1 1 1 5m26s$ kubectl get rs -n ingress-nginxNAME DESIRED CURRENT READY AGEnginx-ingress-controller-5bb8fb4bb6 1 1 1 6m10s$ kubectl get pod -n ingress-nginxNAME READY STATUS RESTARTS AGEnginx-ingress-controller-5bb8fb4bb6-6lnb4 1/1 Running 0 6m13s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 5m36s 4.2 Ingress HTTP 代理访问123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ingress-http-1.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-1spec: replicas: 2 selector: matchLabels: app: nginx-1 template: metadata: labels: app: nginx-1 name: nginx-1 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-1spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-1---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-1spec: rules: - host: www1.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-1 servicePort: 80 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ingress-http-2.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-2spec: replicas: 2 selector: matchLabels: app: nginx-2 template: metadata: labels: app: nginx-2 name: nginx-2 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v2 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-2spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-2---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-2spec: rules: - host: www2.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-2 servicePort: 80 操作： 123456789101112131415161718192021222324252627282930313233343536$ kubectl apply -f ingress-http-1.yaml$ kubectl apply -f ingress-http-2.yaml $ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx-svc-1 ClusterIP 10.109.205.227 &lt;none&gt; 80/TCP 32snginx-svc-2 ClusterIP 10.108.96.68 &lt;none&gt; 80/TCP 29s$ curl 10.109.205.227Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ curl 10.108.96.68Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-1 &lt;none&gt; www1.elihe.io 10.107.51.68 80 5m46snginx-2 &lt;none&gt; www2.elihe.io 10.107.51.68 80 116s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 37m$ kubectl get pod -n ingress-nginxNAME READY STATUS RESTARTS AGEnginx-ingress-controller-5bb8fb4bb6-6lnb4 1/1 Running 0 42m# 进入 nginx-ingress-controller 容器, 查询 nginx 配置$ kubectl exec nginx-ingress-controller-5bb8fb4bb6-6lnb4 -n ingress-nginx -it -- /bin/sh/etc/nginx $ cat nginx.conf$ curl http://www1.elihe.io:31319Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ curl http://www2.elihe.io:31319Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt; 4.3 Ingress HTTPS 代理访问创建证书，以及cert存储方式 123$ openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=nginxsvc/O=nginxsvc&quot;$ kubectl create secret tls tls-secret --key tls.key --cert tls.crt 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# ingress-https.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-3spec: replicas: 2 selector: matchLabels: app: nginx-3 template: metadata: labels: app: nginx-3 name: nginx-3 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v3 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-3spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-3---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-httpsspec: tls: - hosts: - www3.elihe.io secretName: tls-secret rules: - host: www3.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-3 servicePort: 80 1234567891011$ kubectl apply -f ingress-https.yaml$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-https &lt;none&gt; www3.elihe.io 10.107.51.68 80, 443 51s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 56mhttps://www.elihe.io:32750/ 4.4 Nginx 进行 BasicAuth1234# 安装apacheyum install -y httpdhtpasswd -c auth elikubectl create secret generic basic-auth --from-file=auth 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# ingress-http-basicauth.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-basicauthspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx name: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-basicauth annotations: nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: basic-auth nginx.ingress.kubernetes.io/auth-realm: &#x27;Authentication Required - eli&#x27;spec: rules: - host: auth.elihe.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 1234567891011$ kubectl apply -f ingress-http-basicauth.yaml $ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-basicauth &lt;none&gt; auth.elihe.io 80 15s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 71mhttp://auth.elihe.io:31319 # 弹出验证窗口 4.5 Nginx 重写 名称 类型 描述 nginx.ingress.kubernetes.io/rewrite-target String 重定向的目标URI nginx.ingress.kubernetes.io/ssl-redirect Boolean 仅支持https nginx.ingress.kubernetes.io/force-ssl-redirect Boolean 强制重定向至https nginx.ingress.kubernetes.io/app-root String 上下文 “/” nginx.ingress.kubernetes.io/use-regex Boolean 使用正则表达式 12345678910111213141516# ingress-http-rewrite.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-rewrite annotations: nginx.ingress.kubernetes.io/rewrite-target: http://baidu.comspec: rules: - host: www1.elihe.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 1234567891011$ kubectl apply -f ingress-http-rewrite.yaml$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-rewrite &lt;none&gt; www1.elihe.io 10.107.51.68 80 14s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 75mhttp://www1.elihe.io:31319 # 重定向到百度","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 资源控制器","slug":"Kubernetes 资源控制器","date":"2018-07-04T06:30:31.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/04/Kubernetes 资源控制器/","link":"","permalink":"https://elihe2011.github.io/2018/07/04/Kubernetes%20%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/","excerpt":"1. Pod分类 自主式Pod：Pod退出，不会被再次创建，因为无管理者（资源控制器）。 控制器管理的Pod： 在控制器的生命周期里，始终要维持 Pod 的副本数目 2. 什么是控制器K8S 中内建了很多 controller (控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为","text":"1. Pod分类 自主式Pod：Pod退出，不会被再次创建，因为无管理者（资源控制器）。 控制器管理的Pod： 在控制器的生命周期里，始终要维持 Pod 的副本数目 2. 什么是控制器K8S 中内建了很多 controller (控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为 3. 控制器类型 ReplicationController 和 ReplicaSet Deployment DaemonSet StatefulSet Job/CronJob Horizontal Pod Autoscalling 3.1 ReplicationController 和 ReplicaSet作用：维持Pod的副本数 RC: 用来确保容器应用的副本数量始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收 RS: RC的的替代者，支持集合式的selector ReplicaSet 123456789101112131415161718192021222324# nginx-rs.yaml#apiVersion: extension/v1beta1 # 统一迁移到apps/v1apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: # Pod metadata: labels: tier: frontend spec: containers: - name: my-nginx image: hub.elihe.io/test/nginx:v1 env: - name: GET_HOST_FROM value: dns ports: - containerPort: 80 123456789101112131415161718192021$ kubectl create -f nginx-rs.yaml$ kubectl get rsNAME DESIRED CURRENT READY AGEfrontend 3 3 2 21s$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSfrontend-cdxws 1/1 Running 0 51s tier=frontendfrontend-fqx6q 1/1 Running 0 51s tier=frontendfrontend-s255j 1/1 Running 0 51s tier=frontend$ kubectl label pod frontend-s255j tier=frontend1 --overwrite=truepod/frontend-s255j labeled$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSfrontend-cdxws 1/1 Running 0 3m25s tier=frontendfrontend-fqx6q 1/1 Running 0 3m25s tier=frontendfrontend-pb5c4 1/1 Running 0 5s tier=frontendfrontend-s255j 1/1 Running 0 3m25s tier=frontend1 # 不再受rs管理 3.2 DeploymentDeployment 为 Pod 和 ReplicaSet 提供一个声明式 (declarative) 方法，用来替代以前的 RC 来方便的管理应用，典型的应用场景包括： 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 (创建一个新的RS，新RS中Pod增1，旧RS的Pod减1) 扩容和缩容 暂停和继续 Deployment 补充：命令式编程和声明式编程 命令式编程：它侧重于如何实现程序，需要把程序的实现结果按照逻辑一步一步写下来 声明式编程：它侧重于定义想要什么，然后告诉计算机 / 引擎，让它帮你去实现。（SQL） 声明式（Deployment）：apply优先 命令式（RS）：create优先 RS 与 Deployment的关联： 部署一个简单的 Nginx 应用 123456789101112131415161718192021# nginx-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployspec: replicas: 3 selector: matchLabels: tier: frontend template: # Pod metadata: labels: app: nginx tier: frontend spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 ports: - containerPort: 80 123456789101112131415$ kubectl apply -f nginx-deploy.yaml --record # record 更新时，记录每一步的状态$ kubectl get deployNAME READY UP-TO-DATE AVAILABLE AGEnginx-deploy 3/3 3 3 22s$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deploy-7775dd49df 3 3 3 72s$ kubectl get podNAME READY STATUS RESTARTS AGEnginx-deploy-7775dd49df-8jlh9 1/1 Running 0 76snginx-deploy-7775dd49df-gjkbj 1/1 Running 0 77snginx-deploy-7775dd49df-ksj9t 1/1 Running 0 76s 1234567891011121314151617181920# 扩容$ kubectl scale deployment nginx-deploy --replicas=5# 更新镜像, 会自动创建rs$ kubectl set image deployment/nginx-deploy nginx=hub.elihe.io/test/nginx:v2# 回滚$ kubectl rollout undo deployment/nginx-deploy# 查询回滚状态$ kubectl rollout status deployment/nginx-deploy# 查看历史版本 (创建时，加--record，会显示描述)$ kubectl rollout history deployment/nginx-deploy# 回滚到某个历史版本$ kubectl rollout undo deployment/nginx-deploy --to-revision=2# 暂停更新$ kubectl rollout pause deployment/nginx-deploy 版本更新策略：默认25%替换 清理历史版本：可以通过设置 .spec.revisionHistoryLimit 来指定 Deployment 最多保留多少个 revision 历史记录。默认保留所有的revision，如果该项设置为0，Deployment将不能被回退 3.3 DaemonSetDaemonSet 确保全部（或一些）Node上运行一个Pod副本。当有Node加入集群时，也会为它们新增一个Pod。当Node从集群移除时，这些Pod也会被回收。删除DaemonSet 将会删除它创建的所有 Pod。 使用DaemonSet 的一些典型场景： 运行集群存储 daemon，例如在每个Node上运行 glusterd, ceph 在每个Node上运行日志收集 daemon，例如 fluentd, logstash 在每个Node上运行监控 daemon, 例如 Promethesus Node Exporter, collectd, Datalog代理，New Replic代理，Ganglia, gmond 123456789101112131415161718apiVersion: apps/v1kind: DaemonSetmetadata: name: daemonset labels: app: daemonsetspec: selector: matchLabels: tier: daemonset-example template: metadata: labels: tier: daemonset-example spec: containers: - name: daemonset-example image: hub.elihe.io/test/nginx:v1 12345678910$ kubectl create -f nginx-daemonset.yaml$ kubectl get dsNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEdaemonset 2 2 2 2 2 &lt;none&gt; 23s$ kubectl get podNAME READY STATUS RESTARTS AGEdaemonset-msnrn 1/1 Running 0 86sdaemonset-nw5t9 1/1 Running 0 86s 3.4 JobJob 仅执行一次的任务，它确保批处理任务的一个或多个 Pod 成功结束。 特殊说明： spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个Pod时，默认Pod成功运行后 Job 结束 .spec.completions 标志 Job 结束需要运行的Pod个数，默认为1 .spec.parallelism 标志并行运行的 Pod 个数，默认为1 .spec.activeDeadlineSeconds 标志失败 Pod的重试最大时间，超过这个时间将不会再重试 1234567891011121314apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [&quot;perl&quot;, &quot;-Mbignum-bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] restartPolicy: Never 123456789101112$ kubectl create -f job.yaml job.batch/pi created$ kubectl get jobNAME COMPLETIONS DURATION AGEpi 0/1 10s 10s$ kubectl get podNAME READY STATUS RESTARTS AGEpi-779v9 0/1 ContainerCreating 0 14s$ kubectl describe pod pi-779v9 3.5 CronJobCornJob 管理基于时间的 Job，即： 在给定时间点只执行一次 周期性地在给定时间点运行 特殊说明： .spec.schedule: 调度，必选字段，格式同Cron spec.jobTemplate: 格式同 Pod .spec.startingDeadlineSeconds: 启动Job的期限，可选字段。如果因为任何原因而错过了被调度的时间，那么错过了执行时间的Job被认为是失败的 .spec.concurrencyPolicy: 并发策略，可选字段 Allow: 默认，允许并发运行 Job Forbid: 禁止并发Job，只能顺序执行 Replace: 用新的Job替换当前正在运行的 Job .spec.suspend: 挂起，可选字段，如果设置为true，后续所有执行都会被挂起。默认为fasle .spec.successfulJobsHistoryLimit 和 .spec.failedJobsHistoryLimit: 历史限制，可选字段。它们指定了可以保留多少完成和失败的Job。默认值为3和1。如果设置为0，相关类型的Job完成后，将不会保留 123456789101112131415161718apiVersion: batch/v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure 1234567891011121314$ kubectl create -f cronjob.yaml cronjob.batch/hello created$ kubectl get cjNAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGEhello */1 * * * * False 0 52s 2m24s$ kubectl get jobNAME COMPLETIONS DURATION AGEhello-1602576000 1/1 17s 49s$ kubectl get podNAME READY STATUS RESTARTS AGEhello-1602576000-r6mgh 0/1 Completed 0 52 3.6 StatefulSet （有状态服务）StatefulSet 作为 Controller 为 Pod 提供的唯一标识，它可以确保部署和 scale 的顺序 StatefulSet 解决了有状态服务的问题，其应用场景包括： 稳定的持久化存储，即 Pod 重新调度后，还能够访问到相同的持久化数据，基于PVC来实现 稳定的网络标识，即 Pod 重新调度后其 PodName 和 HostName 不变，基于 Headless Service （即没有Cluster IP的Service）来实现 有序部署、有序扩展，即Pod是有序的，在部署和扩展时，要按照定义的顺序依次进行 (即从 0 到N - 1, 在下一个Pod 运行前，所有 Pod 必须是 Running 和 Ready 状态)，基于 Init Containers 来实现 有序收缩、有序删除（即从 N-1 到 0） 3.7 Horizontal Pod AutoScalling应用的资源使用率通常有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，HPA 提供了 Pod 的水平自动缩放功能 通过控制RS，Deployment 来实现自动缩放","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 资源清单","slug":"Kubernetes 资源清单","date":"2018-07-03T12:37:13.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/03/Kubernetes 资源清单/","link":"","permalink":"https://elihe2011.github.io/2018/07/03/Kubernetes%20%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95/","excerpt":"1. K8S 资源k8s中，所有的内容都被抽象为资源，资源实例化后，称为对象 集群资源分类： 名称空间级别: 只在本名称空间下可见 集群级别: role, 不管在什么名称空间小，均可见 元数据级别: HPA(可以CPU利用率平滑扩展)","text":"1. K8S 资源k8s中，所有的内容都被抽象为资源，资源实例化后，称为对象 集群资源分类： 名称空间级别: 只在本名称空间下可见 集群级别: role, 不管在什么名称空间小，均可见 元数据级别: HPA(可以CPU利用率平滑扩展) 1.1 名称空间级别资源仅在此名称空间下有效：kubeadm k8s kube-system, kubectl get pod -n default 1.1.1 工作负载型资源 (workload) Pod: 最小资源，共享网络栈、存储卷等 ReplicaSet：调度器，管理Pod的创建，通过标签的选择去控制Pod的副本数 Deployment: 控制器，通过控制RS的创建，去创建Pod StatefulSet：有状态服务管理器 DaemonSet：可在每个节点都运行一个Pod组件 Job: 批量工作 CronJob: 定时或轮训工作 ReplicationController：v1.11后被废弃 1.1.2 服务发现及负载均衡资源 (ServiceDiscovery, LoadBalance) Service: svc Ingress: 1.1.3 配置与存储型资源 Volume: 存储卷 CSI: 容器存储接口，可扩展第三方存储设备 1.1.4 特殊类型的存储卷 ConfigMap: 配置中心 Secret: 敏感数据保存 DownwardAPI: 外部环境中的信息输出给容器 1.2 集群级别资源不指定名称空间，所有节点均能访问：role Namespace Node Role ClusterRole RoleBinding ClusterRoleBinding 1.3 元数据型资源通过指标进行操作：HPA HPA PodTemplate LimitRange 2. 资源清单2.1 必须存储的属性 参数名 字段类型 说明 apiVersion String k8s API版本，可用kubectl api-versions查询 kind String yaml文件定义的资源类型和角色，比如：Pod metadata Object 元数据对象 metadata.name String metadata.namespace String 默认为default spec Object 详细定义对象 spec.containers[] List spec.containers[].name String spec.containers[].image String spec.containers[].imagePullPolicy String 1. Always: 默认，每次都尝试重新拉取镜像; 2. Never: 仅使用本地镜像; 3. IfNotPresent: 优先本地镜像 spec.containers[].command[] List 容器启动命令。不指定则使用镜像打包时使用的启动命令 spec.containers[].args[] List 容器启动命令参数 spec.containers[].workingDir String spec.containers[].volumeMounts[] List spec.containers[].volumeMounts[].name String spec.containers[].volumeMounts[].mountPath String spec.containers[].volumeMounts[].readOnly String 默认false，可读写 spec.containers[].ports[] List spec.containers[].ports[].name String spec.containers[].ports[].containerPort String spec.containers[].ports[].hostPort String 主机上需要监听的端口号，默认与containerPort相同 spec.containers[].ports[].protocol String 默认TCP spec.containers[].env[] List spec.containers[].env[].name String spec.containers[].env[].value String spec.containers[].resources Object 资源 spec.containers[].resources.limits Object 容器运行时的资源上限 spec.containers[].resources.limits.cpu String 单位core数，将用于docker run --cpu-shares spec.containers[].resources.limits.memory String 单位MIB、GiB spec.containers[].resources.requests Object 容器启动和调度时的资源上限 spec.containers[].resources.requests.cpu String spec.containers[].resources.request.memory String 2.2 额外的参数项 参数名 字段类型 说明 spec.restartPolicy String 1. Always: 默认，Pod一旦停止，无论容器是否已终止，kubelet服务都将重启它; 2. OnFailure: 只有Pod以非0退出码终止时，kubelet将重启它; 3. Never: Pod终止后，kubelet将推出码上报Master，但不会重启Pod spec.nodeSelector Object 定义Node的Label过滤标签，以key: value格式指定 spec.imagePullSecrets Object 定义pull镜像时使用secret名称，以name: secretKey格式指定 spec.hostNetwork Boolean 使用使用主机网络。默认false。为true时，将不使用docker网桥，直接使用宿主机网络，但同时，也无法启动第二个副本 2.3 使用命令查询参数123kubectl explain podkubectl explain pod.spec 2.4 示例：Pod模板123456789101112apiVersion: v1kind: Podmetadata: name: myapp namespace: default labels: app: myapp version: v1spec: containers: - name: app1 image: hub.elihe.io/test/nginx:v1 1234567891011121314151617181920212223242526272829303132333435363738394041$ kubectl apply -f pod.yaml$ kubectl get podNAME READY STATUS RESTARTS AGEmyapp 1/1 Running 0 6s$ kubectl describe pod myappName: myappNamespace: defaultPriority: 0Node: k8s-node02/192.168.31.42Start Time: Mon, 28 Sep 2020 21:41:25 +0800Labels: app=myapp version=v1Annotations: &lt;none&gt;Status: RunningIP: 10.244.2.5IPs: IP: 10.244.2.5Containers: app1: Container ID: docker://dad5e86a4d90a7275e7a15833801d57c87356e1c7ce723fde113b18ef960213c Image: hub.elihe.io/test/nginx:v1...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 61s default-scheduler Successfully assigned default/myapp to k8s-node02 Normal Pulled 60s kubelet, k8s-node02 Container image &quot;hub.elihe.io/test/nginx:v1&quot; already present on machine Normal Created 60s kubelet, k8s-node02 Created container app1 Normal Started 60s kubelet, k8s-node02 Started container app1$ kubectl logs myapp -c app1/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: error: IPv6 listen already enabled/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Configuration complete; ready for start up$ kubectl exec myapp -it -- /bin/bash 3. 容器的生命周期 1）kubectl –&gt; apiserver –&gt; CRI –&gt; kubelet 环境初始化 2）启动Pause容器: 初始化网络和数据卷 3）init C初始化。多个initC时，必须串行执行，且每个必须执行成功才向下走 4）Main C，开始运行时，启动Start命令/脚本；结束时，执行Stop命令(做哪些清理操作等) 5）Readiness 就绪检测：若干秒后，进行是否就绪的探测。只有当Readiness成功后，Pod才会显示Running状态 6）Liveness 生存检测：探测Main C中的进程是否正常，不正常则执行重启、删除等命令 3.1 Init C 容器应用容器启动的容器，称为Init C容器 Init 容器与普通容器非常像，除下列两点： 每个 Init 容器必须在下一个 Init 容器启动前成功完成 Init 容器总是在运行成功后自动销毁 如果Init容器启动失败，k8s 会不停重启Pod，直到Init 容器成功为止。然而如果Pod的restartPolicy为Never，它则不会重启 Init 容器的作用： 可以包含并运行实用工具。但出于安全考虑，不建议在应用程序容器镜像中包含这些工具。（主容器启动前，文件创建、数据初始化等） 可以包含使用工具和定制化代码来安装，但不能出现在应用程序镜像中。例如，创建镜像没必要FROM另一个镜像，只需在安装过程中使用sed, awk, python等命令 应用程序镜像可以分离出创建和部署角色，而没有必要联合它们构建一个单独的镜像 Init容器使用Linux Namespace，所以相对应用程序来说具有不同的文件系统视图。因此它能够具有访问Secret的权限，而应用程序容器则不能。简言之，InitC可以把MainC无法取得的Secret权限，先取得，以便MainC使用。 Init容器必须在运用程序启动之前完成，而应用程序是并行运行的，所以Init容器能够提供一种简单的阻塞或延迟应用程序启动的方法，直到满足一组先决条件。 init 模板： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# init-pod.yamlapiVersion: v1kind: Podmetadata: name: init-pod labels: app: init-podspec: containers: - name: app image: hub.elihe.io/test/busybox:v1 imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo &#x27;The app is running!&#x27; &amp;&amp; sleep 3600&quot;] initContainers: - name: init-myservice image: hub.elihe.io/test/busybox:v1 imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;until nslookup myservice; do echo waiting for myservice; sleep 2; done&quot;] - name: init-mydb image: hub.elihe.io/test/busybox:v1 imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;until nslookup mydb; do echo waiting for mydb; sleep 2; done&quot;] # myservice.yamlapiVersion: v1kind: Servicemetadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9001 # mydb.yamlapiVersion: v1kind: Servicemetadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9002 12345678910111213141516$ kubectl create -f init-pod.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEinit-pod 0/1 Init:0/2 0 26s# 创建svc$ kubectl create -f myservice.yaml $ kubectl create -f mydb.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmydb ClusterIP 10.100.88.255 &lt;none&gt; 80/TCP 3m58smyservice ClusterIP 10.110.141.175 &lt;none&gt; 80/TCP 6m20s$ kubectl get podNAME READY STATUS RESTARTS AGEinit-pod 1/1 Running 0 6m42s 4. 容器探针4.1 什么是探针探针：是由kubelet对容器执行的定期诊断。要执行诊断，kubelet调用有容器实现的Handler，有三种类型的处理程序： ExecAction: 在容器内执行指定命令，返回码为0表示成功 TCPSocketAction: 在指定IP进行TCP检查，如果端口打开，则诊断成功 HTTPGetAction: 对指定的http://ip:port/path地址执行HTTP Get操作，如果响应的状态码大于等于200且小于400，则诊断成功 每次探测都获得以下三种结果： 成功：诊断通过 失败：诊断未通过 未知：诊断失败，但不采取任何行动 4.2 探测方式 livenessProbe: 指示容器是否正在运行。如果存活探测失败，kubelet会杀死容器，并且容器将受其“restartPolicy”的影响。如果容器不提供存活探针，则默认状态为Success readinessProbe: 指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针，则默认状态为Success 4.2.1 就绪检测检测失败，状态非Ready，但不会重启容器 spec.containers[].readinessProbe.httpGet 12345678910111213141516# readiness-probe-httpget.yaml apiVersion: v1kind: Podmetadata: name: readiness-httpget-podspec: containers: - name: readiness-httpget-container image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent readinessProbe: httpGet: port: 80 path: /index1.html initialDelaySeconds: 1 periodSeconds: 3 123456789101112131415161718192021222324$ kubectl create -f readiness-probe-httpget.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 0/1 Running 0 9s$ kubectl describe pod readiness-httpget-podWarning Unhealthy 1s (x3 over 7s) kubelet, k8s-node01 Readiness probe failed: HTTP probe failed with statuscode: 404# 进入容器$ kubectl exec readiness-httpget-pod -it -- /bin/sh# cd /usr/share/nginx/html# ls -altotal 8drwxr-xr-x 2 root root 40 Aug 14 00:36 .drwxr-xr-x 3 root root 18 Aug 14 00:36 ..-rw-r--r-- 1 root root 494 Aug 11 14:50 50x.html-rw-r--r-- 1 root root 612 Aug 11 14:50 index.html# echo &quot;hello, i&#x27;am index1.html&quot; &gt; index1.html# logout$ kubectl get podNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 1/1 Running 0 2m57s 4.2.2 存活检测检测失败，直接重启Pod spec.containers[].livenessProbe.exec 12345678910111213141516# liveness-prob-exec.yaml apiVersion: v1kind: Podmetadata: name: liveness-exec-podspec: containers: - name: liveness-exec-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;touch /tmp/abc.txt; sleep 60; rm -f /tmp/abc.txt; sleep 3600&quot;] livenessProbe: exec: command: [&quot;test&quot;, &quot;-e&quot;, &quot;/tmp/abc.txt&quot;] initialDelaySeconds: 1 periodSeconds: 3 123456789$ kubectl create -f liveness-prob-exec.yaml # 失败，重启自动重启$ kubectl get pod -wNAME READY STATUS RESTARTS AGEliveness-exec-pod 1/1 Running 0 26sliveness-exec-pod 1/1 Running 1 2m58sliveness-exec-pod 1/1 Running 2 3m35sliveness-exec-pod 1/1 Running 3 5m15s spec.containers[].livenessProbe.httpGet 12345678910111213141516apiVersion: v1kind: Podmetadata: name: liveness-httpget-podspec: containers: - name: liveness-httpget image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent livenessProbe: httpGet: port: 80 path: /index.html initialDelaySeconds: 1 periodSeconds: 3 timeoutSeconds: 10 # 超时处理 spec.containers[].livenessProbe.tcpSocket 123456789101112131415apiVersion: v1kind: Podmetadata: name: liveness-tcp-podspec: containers: - name: liveness-tcp image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent livenessProbe: tcpSocket: port: 80 initialDelaySeconds: 5 periodSeconds: 3 timeoutSeconds: 10 # 超时处理 4.3 启动 &amp; 退出spec.containers[].lifecycle.postStart|preStop 123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello form the postStart handler &gt; /usr/share/mesage&quot;] preStop: exec: command: [&quot;/usr/sbin/nginx&quot;, &quot;-s&quot;, &quot;quit&quot;] 5. Pod 状态值 Pending：Pod已被k8s系统接受，但有一个或多个镜像容器尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间。 Running: Pod已经绑定到一个节点上了，Pod中的所有容器已被创建 Succeeded: Pod中的所有容器都被成功终止，且不会再重启 Failed: Pod中的所有容器都已终止，但至少有一个容器以非0返回值退出 Unknown: 未知原因无法获取Pod状态，通常是因为与Pod所在主机的通信失败","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 集群安装","slug":"Kubernetes 集群安装","date":"2018-07-02T13:44:16.000Z","updated":"2021-06-22T10:50:49.718Z","comments":true,"path":"2018/07/02/Kubernetes 集群安装/","link":"","permalink":"https://elihe2011.github.io/2018/07/02/Kubernetes%20%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"1. 安装准备1.1 设置主机名123456# masterhostnamectl set-hostname k8s-master# nodehostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02","text":"1. 安装准备1.1 设置主机名123456# masterhostnamectl set-hostname k8s-master# nodehostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02 1.2 hostname相互解析1234vi /etc/hosts192.168.31.40 k8s-master192.168.31.41 k8s-node01192.168.31.42 k8s-node02 1.3 关闭虚拟内存 swap1swapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab 1.4 调整内核参数1234567891011121314151617181920cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_tw_recycle=0vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它vm.overcommit_memory=1 # 不检查物理内存是否够用fs.inotify.max_user_instances=8192 # 开启 OOMvm.panic_on_oom=0 fs.inotify.max_user_watches=1048576fs.file-max=52706963fs.nr_open=52706963net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max=2310720EOFsysctl -p /etc/sysctl.d/kubernetes.conf# 问题 sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directorymodprobe br_netfilter 1.5 升级内核123456789101112131415161718uname -r3.10.0-1127.el7.x86_64# 内核reporpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm# 安装新内核yum --enablerepo=elrepo-kernel install -y kernel-lt# 检查启动menu是否已加入新内核版本cat /boot/grub2/grub.cfg | grep elrepo | grep menuentrymenuentry &#x27;CentOS Linux (4.4.236-1.el7.elrepo.x86_64) 7 (Core)&#x27; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &#x27;gnulinux-3.10.0-1127.el7.x86_64-advanced-3ec6d414-2b79-482d-9643-b7baeb42cb3d&#x27; &#123;# 开机从新内核启动grub2-set-default &#x27;CentOS Linux (4.4.236-1.el7.elrepo.x86_64) 7 (Core)&#x27;# 重启系统reboot 1.6 开启 ipvs (kube-proxy需要)1234567891011121314modprobe br_netfiltercat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.moduleslsmod | grep -e ip_vs -e nf_conntrack_ipv4 2. Kubeadm 部署安装2.1 安装kubeadm12345678910111213141516cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 查询版本yum list kubelet --showduplicatesyum install -y kubeadm-1.18.6 kubelet-1.18.6 kubectl-1.18.6systemctl enable kubelet kubelet: 运行在集群的所有节点上，用于启动Pod和容器对象的工具 kubeadm: 初始化集群，启动集群的命令工具 kubectl: 和集群通信的命令行工具。可以部署和管理应用，查看各种资源，创建、删除和更新各种组建 2.2 下载k8s镜像默认镜像放google服务器上，国内使用aliyun服务器 123456789101112$ vi load_kube_images.sh#!/bin/bashurl=registry.aliyuncs.com/google_containersversion=v1.18.6images=(`kubeadm config images list --kubernetes-version=$version|awk -F &#x27;/&#x27; &#x27;&#123;print $2&#125;&#x27;`)for imagename in $&#123;images[@]&#125; ; do docker pull $url/$imagename docker tag $url/$imagename k8s.gcr.io/$imagename docker rmi -f $url/$imagenamedone$ chmod u+x load_kube_images.sh &amp;&amp; bash load_kube_images.sh 2.3 初始化主节点 (k8s-master)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 默认配置$ kubeadm config print init-defaults &gt; kubeadm-config.yaml$ vi kubeadm-config.yaml...localAPIEndpoint: advertiseAddress: 192.168.31.40 # 修改为本机IP bindPort: 6443...kubernetesVersion: v1.18.6 # 版本必须匹配networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 # 新增 serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;# 新增如下，修改kube-proxy协议为ipvs---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs# 执行初始化$ kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log...[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.31.40:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1c02156e6d3d6b85938e20f0473af2dffff7a22a6c67387aba97da38f0952386 # 如果发生错误，重置后重新init$ kubeadm reset# 执行初始化后的提示步骤$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config# 获取节点$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 3m31s v1.18.6 2.4 部署网络 (k8s-master)1234567891011121314151617181920212223# 解决DNS污染问题 (不推荐)$ echo &quot;199.232.68.133 raw.githubusercontent.com&quot; &gt;&gt; /etc/hosts # 尽量用nsloop查询，将dns配对$ yum install -y bind-utils$ nslookup raw.githubusercontent.com$ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml$ kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds created$ kubectl get pod -n kube-systemkube-flannel-ds-4dlvt 1/1 Running 0 54s$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master Ready master 22m v1.18.6 2.5 工作节点加入集群 (k8s-node1, k8s-node2)123# k8s-master节点下 kubeadm init 的运行日志最后行$ kubeadm join 192.168.31.40:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1c02156e6d3d6b85938e20f0473af2dffff7a22a6c67387aba97da38f0952386 如果未找到，主节点(k8s-master) 执行下列操作获取令牌 1234567891011$ kubeadm token listTOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS7114t2.imdu2ivf56cbjk38 1h 2020-09-22T22:31:42+08:00 &lt;none&gt; Proxy for managing TTL for the kubeadm-certs secret &lt;none&gt;abcdef.0123456789abcdef 23h 2020-09-23T20:31:43+08:00 authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-token# 令牌过期$ kubeadm token create# 生成密钥$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;0daca31a7b9820fc60eaa28cacc25ee3a16c7af5c6e8104d91bf709bf2e741bc 2.6 查看所有节点12345678910111213# kubectl 命令补齐yum install -y bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profilekubectl get nodekubectl get pod -n kube-system# 当前各个节点的详细情况kubectl get pod -n kube-system -o wide 2.7 问题：组件controller-manager 和scheduler状态 Unhealthy1234567$ kubectl get csNAME STATUS MESSAGE ERRORscheduler Unhealthy Get http://127.0.0.1:10251/healthz: dial tcp 127.0.0.1:10251: connect: connection refused controller-manager Unhealthy Get http://127.0.0.1:10252/healthz: dial tcp 127.0.0.1:10252: connect: connection refused etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; $ netstat -an | grep -e 10251 -e 10252 解决方法: 检查kube-scheduler和kube-controller-manager组件配置是否禁用了非安全端口 123456789101112131415161718192021222324252627282930$ vi /etc/kubernetes/manifests/kube-scheduler.yaml ...spec: containers: - command: - kube-scheduler - --kubeconfig=/etc/kubernetes/scheduler.conf - --leader-elect=true #- --port=0 # 注释掉 image: k8s.gcr.io/kube-scheduler:v1.18.6$ vi /etc/kubernetes/manifests/kube-controller-manager.yaml...spec: containers: - command: - kube-controller-manager - --node-cidr-mask-size=24 #- --port=0 # 注释掉 - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt# 重启kubelet$ systemctl restart kubelet# 再次查询状态$ kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 6. k8s主节点测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788vi nginx.yml# API 版本号apiVersion: apps/v1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Deploymentmetadata: # Kind 的名称 name: nginx-appspec: selector: matchLabels: # 容器标签的名字，发布 Service 时，selector 需要和这里对应 app: nginx # 部署的实例数量 replicas: 2 template: metadata: labels: app: nginx spec: # 配置容器，数组类型，说明可以配置多个容器 containers: # 容器名称 - name: nginx # 容器镜像 image: hub.elihe.io/library/nginx:v1 # 只有镜像不存在时，才会进行镜像拉取 imagePullPolicy: IfNotPresent ports: # Pod 端口 - containerPort: 80 kubectl apply -f nginx.ymlkubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-app-76b8bd9478-z74zq 1/1 Running 0 93s 10.244.1.2 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-z8zt6 1/1 Running 0 93s 10.244.2.5 k8s-node01 &lt;none&gt; &lt;none&gt;kubectl delete pod nginx-app-76b8bd9478-z74zqkubectl get pod -o wide# 变更数量kubectl scale --replicas=3 deployment/nginx-appkubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-app-76b8bd9478-6gkq6 1/1 Running 0 4m25s 10.244.1.3 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-d7p6r 1/1 Running 0 13s 10.244.1.4 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-z8zt6 1/1 Running 0 6m37s 10.244.2.5 k8s-node01 &lt;none&gt; &lt;none&gt;kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEnginx-app 3/3 3 3 12mkubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16h# 开放访问端口kubectl expose deployment nginx-app --port=3000 --target-port=80kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16hnginx-app ClusterIP 10.104.89.46 &lt;none&gt; 3000/TCP 9s# 测试端口转发curl -i 10.104.89.46:3000ipvsadm -LnTCP 10.104.89.46:3000 rr -&gt; 10.244.1.3:80 Masq 1 0 1 -&gt; 10.244.1.4:80 Masq 1 0 1 -&gt; 10.244.2.5:80 Masq 1 0 1 # 开放外部访问nginxkubectl edit svc nginx-apptype: NodePort #ClusterIPkubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16hnginx-app NodePort 10.104.89.46 &lt;none&gt; 3000:31057/TCP 8m44shttp://192.168.31.40:31057/http://192.168.31.41:31057/http://192.168.31.42:31057/","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 基础概念","slug":"Kubernetes 基础概念","date":"2018-07-01T08:27:43.000Z","updated":"2021-06-22T10:50:49.718Z","comments":true,"path":"2018/07/01/Kubernetes 基础概念/","link":"","permalink":"https://elihe2011.github.io/2018/07/01/Kubernetes%20%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","excerpt":"1. 架构Kubernetes特点： 轻量级：消耗资源小 开源 弹性伸缩 负载均衡：IPVS 1.1 核心组件 etcd: 保存整个集群的状态 apiserver: 资源操作的唯一入口，提供了认证、授权、访问控制、API注册和发现等机制 controller manager: 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler: 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet: 负责维护容器的生命周期、Volume(CVI) 和网络(CNI)的管理 container runtime: 负责镜像管理以及Pod和容器的真正运行 (CRI) kube-proxy: 负责为Service提供cluster内部的服务发现和负载均衡 （四层） iptables ipvs etcd: 可信赖的分布式键值对存储服务，为整个分布式集群存储关键数据，协助分布式集群的正常运转。","text":"1. 架构Kubernetes特点： 轻量级：消耗资源小 开源 弹性伸缩 负载均衡：IPVS 1.1 核心组件 etcd: 保存整个集群的状态 apiserver: 资源操作的唯一入口，提供了认证、授权、访问控制、API注册和发现等机制 controller manager: 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler: 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet: 负责维护容器的生命周期、Volume(CVI) 和网络(CNI)的管理 container runtime: 负责镜像管理以及Pod和容器的真正运行 (CRI) kube-proxy: 负责为Service提供cluster内部的服务发现和负载均衡 （四层） iptables ipvs etcd: 可信赖的分布式键值对存储服务，为整个分布式集群存储关键数据，协助分布式集群的正常运转。 1.2 Add-ons: kube-dns: 负责为整个集群提供DNS服务（CoreDNS, 可以为集群中的SVC创建一个域名IP对应关系解析，即A记录) Ingress Controller: 为服务提供外网入口 （七层代理） Dashboard: 提供GUI Federation: 提供跨可用区的集群 Prometheus：监控 ELK：集群日志统一分析接入平台 2. Pod 共享存储 共享网络 2.1 Pod 控制器类型 RelicationController &amp; ReplicaSet &amp; Deployment 2.1.1 ReplicationController &amp; ReplicaSet &amp; Deployment ReplicationController: 用来确保容器的应用副本数始终是用户定义的副本数。即如果有容器异常退出，会创建新的Pod来代替；如果多出来，自动回收。 ReplicaSet: 新版k8s中建议使用ReplicaSet取代RelocationController，它支持集合式selector Deployment: 用来自动管理ReplicaSet。ReplicaSet不支持rolling-update，但Deployment支持。 2.1.2 HPA （HorizontalPodAutoScale)HPA仅适用于Deployment和ReplicaSet，在v1版本中仅支持根据Pod的CPU利用率扩/缩容，在v1alpha中，支持根据内存和用户自定义的metric扩/缩容 2.1.3 StatefulSet解决有状态服务的问题（Deployment和ReplicaSet只支持无状态服务），应用场景： 稳定的持久化存储，即Pod重新调度后还是能够访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后，其PodName和HostName不变，基于Headless Service (即没有Cluster IP的Service)来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或扩展的时候，要依据定义的顺序依次进程（即从0到N-1，在下一个Pod运行之前，所有之前的Pod必须是Running和Ready状态)，基于init containers来实现 有序收缩，有序删除（即从N-1到0） 2.1.4 DaemonSet确保全部（或部分）Node上运行一个Pod副本。当有Node加入集群时，也会为它们新增一个Pod；当有Node从集群移除时，这些Pod会被回收。删除DaemonSet，将会删除它创建的所有Pod。 一些典型的DaemonSet用法： 运行集群存储daemon，例如每个Node上运行glusterd、ceph 在每个Node上进行日志收集daemon，例如fluentd、logstash 在每个Node上运行监控daemon，例如Prometheus Node Exporter 2.1.5 Job &amp; CronJob Job: 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束 CronJob：定时Job 在给定时间点运行一次 周期性地在给定时间点运行 2.2 服务发现Service 通过标签选择到Pod 3. 网络通讯模式k8s 的网络模型假定了所有Pod都在一个可以直接连通的扁平化网络空间中。在GCE(Google Compute Engine) 里面是现成的网络模型。但在私有云中搭建k8s集群，一般需要我们自己去实现这个扁平化网络模型。 扁平化网络：所有的Pod可以通过IP“直接到达” 3.1 通讯模式 同一个Pod内的多个容器之间：lo 各Pod之间的通信: Overlay Network Pod与Service之间的通讯：各节点的iptables规则 3.2 FlannelFlannel是CoreOS团队针对k8s设计的一种网络规划服务。它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址，而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network)，通过这个网络，将数据包原封不动地传递到模板容器内。 etcd为Flannel提供服务： 存储Flannel可分配的IP地址段资源 监控etcd中每个Pod的实际地址，并在内存中创建和维护Pod节点路由表 3.3 总结：不同情况下网络的通信方式 同一个Pod内部通信：共享同一个网络命名空间，共享同一个Linux协议栈。lo网卡 Pod1至Pod2: 同一台主机：由Docker0网桥转发，不需要经过Flannel 不同主机：将Pod的IP和Node的IP关联起来，通过这个关联让Pod可以相互访问。涉及网络封包和拆包，较消耗资源。 Pod至Service网络：基于性能考虑，全部为iptables/LVS维护和转发 Pod到外网：Pod向外网发送请求，查找路由表，转发数据包到宿主机的网卡，宿主机网卡完成路由选择后，iptables执行Masquerade，把源IP更改为宿主网卡的IP，然后向外网服务器发送请求 外网访问Pod：Service 3.4 组件通讯示意图 节点网络：物理的网络 Pod网络：虚拟网络 Service网络：虚拟网络","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Docker 私有仓库","slug":"Docker 私有仓库","date":"2018-06-17T08:41:09.000Z","updated":"2021-06-22T10:50:49.717Z","comments":true,"path":"2018/06/17/Docker 私有仓库/","link":"","permalink":"https://elihe2011.github.io/2018/06/17/Docker%20%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","excerpt":"1. 安装Docker详见 Docker 安装 2. 安装Docker Compose123curl -L &quot;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose","text":"1. 安装Docker详见 Docker 安装 2. 安装Docker Compose123curl -L &quot;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose 3. 安装Harbor下载地址：https://github.com/goharbor/harbor/releases 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152wget https://github.com/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgztar zxvf harbor-offline-installer-v2.0.2.tgzmv harbor /usr/local/cd /usr/local/harborcp harbor.yml.tmpl harbor.ymlvi harbor.ymlhostname: hub.elihe.iohttps: port: 443 # The path of cert and key files for nginx certificate: /data/cert/server.crt private_key: /data/cert/server.keymkdir -p /data/cert &amp;&amp; cd /data/cert# 私钥openssl genrsa -des3 -out server.key 2048# 证书请求openssl req -new -key server.key -out server.csr# 备份私钥cp server.key server.key.org# 转换成证书 （去除设置的密码）openssl rsa -in server.key.org -out server.key# 签名openssl x509 -req -days 3650 -in server.csr -signkey server.key -out server.crt# 证书赋予执行权限chmod a+x *# 安装harborcd /usr/local/harbor./install.sh# 启动 docker-composedocker-compose start# 开机启动 docker-compose# 启动不一定成功，废弃vi /etc/rc.d/rc.local/usr/local/bin/docker-compose -f /usr/local/harbor/docker-compose.yml up -d# 按这种方式crontab -e@reboot sleep 60 &amp;&amp; /usr/local/bin/docker-compose -f /usr/local/harbor/docker-compose.yml up -d 4. Harbor服务器和客户端配置1234567891011# 添加域名解析echo &quot;192.168.31.200 hub.elihe.io&quot; &gt;&gt; /etc/hosts# 配置daemon.jsonvi /etc/docker/daemon.json&#123; &quot;insecure-registries&quot;: [&quot;https://hub.elihe.io&quot;]&#125;# 重启dockersystemctl daemon-reload &amp;&amp; systemctl restart docker 5. 访问Harbor1234567891011121314151617181920https://hub.elihe.io admin/Harbor12345docker login https://hub.elihe.io docker pull nginxdocker tag nginx hub.elihe.io/library/nginx:v1 cat index.html echo &#x27;Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;&#x27; &gt; index.htmlcat &gt; hostname.html &lt;&lt;EOF&lt;script type=&quot;text/javascript&quot;&gt;document.write(location.hostname);&lt;/script&gt;EOFdocker commit 7e7553b2204f hub.elihe.io/library/nginx:v1docker push hub.elihe.io/library/nginx:v1","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 网络","slug":"Docker 网络","date":"2018-06-16T07:22:58.000Z","updated":"2021-06-22T10:50:49.717Z","comments":true,"path":"2018/06/16/Docker 网络/","link":"","permalink":"https://elihe2011.github.io/2018/06/16/Docker%20%E7%BD%91%E7%BB%9C/","excerpt":"","text":"1. 通过Linux路由机制打通网络1.1 修改主机名12hostnamectl set-hostname centos7-ahostnamectl set-hostname centos7-b 1.2 centos7-a的docker0默认绑定的ip地址1234567891011121314ip addr2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:a3:00:96 brd ff:ff:ff:ff:ff:ff inet 192.168.31.30/24 brd 192.168.31.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::a05d:dcec:e694:2cfc/64 scope link noprefixroute valid_lft forever preferred_lft forever3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:a5:d2:db:31 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:a5ff:fed2:db31/64 scope link valid_lft forever preferred_lft forever 1.3 修改主机centos7-b的docker0网卡的ip地址123456789101112131415161718192021vi /etc/docker/daemon.json &#123; &quot;bip&quot;:&quot;172.18.0.1/16&quot;&#125;systemctl restart dockerip addr2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:49:57:44 brd ff:ff:ff:ff:ff:ff inet 192.168.31.31/24 brd 192.168.31.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::a05d:dcec:e694:2cfc/64 scope link tentative noprefixroute dadfailed valid_lft forever preferred_lft forever inet6 fe80::4298:eebd:9094:f36e/64 scope link noprefixroute valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:92:1b:3b:17 brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 brd 172.18.255.255 scope global docker0 valid_lft forever preferred_lft forever 1.4 增加网关路由123456789101112131415# centos7-a[root@centos7-a ~]# route add -net 172.18.0.0/16 gw 192.168.31.31[root@centos7-a ~]# ip routedefault via 192.168.31.1 dev ens33 proto static metric 100 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 via 192.168.31.31 dev ens33 192.168.31.0/24 dev ens33 proto kernel scope link src 192.168.31.30 metric 100 # centos7-b[root@centos7-a ~]# route add -net 172.17.0.0/16 gw 192.168.31.30[root@centos7-a ~]# ip routedefault via 192.168.31.1 dev ens33 proto static metric 100 172.18.0.0/16 dev docker0 proto kernel scope link src 172.18.0.1 172.17.0.0/16 via 192.168.31.30 dev ens33 192.168.31.0/24 dev ens33 proto kernel scope link src 192.168.31.30 metric 100 1.5 测试网络是否联通1234567891011[root@centos7-a ~]# ping 172.18.0.1PING 172.18.0.1 (172.18.0.1) 56(84) bytes of data.64 bytes from 172.18.0.1: icmp_seq=1 ttl=64 time=1.61 ms64 bytes from 172.18.0.1: icmp_seq=2 ttl=64 time=0.979 ms64 bytes from 172.18.0.1: icmp_seq=3 ttl=64 time=0.614 ms[root@centos7-b ~]# ping 172.17.0.1PING 172.17.0.1 (172.17.0.1) 56(84) bytes of data.64 bytes from 172.17.0.1: icmp_seq=1 ttl=64 time=2.13 ms64 bytes from 172.17.0.1: icmp_seq=2 ttl=64 time=0.521 ms64 bytes from 172.17.0.1: icmp_seq=3 ttl=64 time=0.659 ms 3. Overlay网络 4. NamespaceVeth pair：用于不同network namespace间进行通信，点对点通信。 Linux Bridge： 实现类似交换机的工作模式，将多个不同Namespace上的网卡连通 使用网桥工具 123456789101112131415yum install bridge-utils -y[root@centos7-a ~]# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242a5d2db31 no veth463224b veth95cd878[root@centos7-a ~]# ip addr 29: veth95cd878@if28: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 56:19:de:43:e7:e4 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::5419:deff:fe43:e7e4/64 scope link valid_lft forever preferred_lft forever55: veth463224b@if54: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether fa:89:aa:75:57:a1 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::f889:aaff:fe75:57a1/64 scope link valid_lft forever preferred_lft forever 1234567891011121314151617181920212223242526# 获取容器运行的PID[root@centos7-a ~]# docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; 0f9fa4e71fb718607# 建立链接，方便ip netns标准命令查询mkdir -p /var/run/netnsln -s /proc/18607/ns/net /var/run/netns/18607# 查询net namespace[root@centos7-a ~]# ip netns ls18607 (id: 0)[root@centos7-a ~]# ip netns exec 18607 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever54: eth0@if55: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever # 查询veth网卡序号[root@centos7-a ~]# ip netns exec 18607 ethtool -S eth0NIC statistics: peer_ifindex: 55","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 数据卷","slug":"Docker 数据卷","date":"2018-06-15T01:45:21.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/15/Docker 数据卷/","link":"","permalink":"https://elihe2011.github.io/2018/06/15/Docker%20%E6%95%B0%E6%8D%AE%E5%8D%B7/","excerpt":"1. 数据卷设计的目的 经过特殊设计的目录，可以绕过联合文件系统(UFS)，为一个或多个容器提供访问。 在于数据的永久化，它完全独立于容器的生命周期。因此，Docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾回收机制，对容器引用的数据卷进行处理","text":"1. 数据卷设计的目的 经过特殊设计的目录，可以绕过联合文件系统(UFS)，为一个或多个容器提供访问。 在于数据的永久化，它完全独立于容器的生命周期。因此，Docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾回收机制，对容器引用的数据卷进行处理 2. 添加数据卷12docker run -it -v ~/datavolume:/data ubuntu /bin/bashdocker run -it -v ~/datavolume:/data:ro ubuntu /bin/bash 123FROM ubuntuVOLUME [&#x27;/datavolume1&#x27;, &#x27;/datavolume2&#x27;]CMD /bin/bash 3. 共享数据卷12345docker run --rm --name dvt1 -v /docker_data:/data -it ubuntu# 共享数据卷docker run --rm --name dvt2 --volumes-from dvt1 -it ubuntudocker run --rm --name dvt3 --volumes-from dvt1 -it ubuntu 4. 实例：安装 MySQL 主从数据库4.1 创建配置文件1234567891011121314151617181920212223242526272829303132333435363738mkdir -p /mysql_data/confmkdir -p /mysql_data/mastermkdir -p /mysql_data/slave# 主节点配置cat &gt; /mysql_data/conf/master.conf &lt;&lt;EOF[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]log_bin = log # 开启二进制日志，用于从节点的历史复制回放collation-server = utf8_unicode_ciinit-connect = &#x27;SET NAMES utf8&#x27;character-set-server = utf8server_id = 1 # 需保证主库和从库的server_id不同replicate-do-db=fileserver # 需要复制的数据库名，复制多个数据库时，重复设置即可EOF# 从节点配置cat &gt; /mysql_data/conf/slave.conf &lt;&lt;EOF[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]log_bin = log # 开启二进制日志，用于从节点的历史复制回放collation-server = utf8_unicode_ciinit-connect = &#x27;SET NAMES utf8&#x27;character-set-server = utf8server_id = 2 # 需保证主库和从库的server_id不同replicate-do-db=fileserver # 需要复制的数据库名，复制多个数据库时，重复设置即可EOF 4.2 启动MYSQL容器1234567891011# 主节点docker run -d --name mysql-master -p 13306:3306 \\-v /mysql_data/conf/master.conf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-v /mysql_data/master:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 mysql:5.7# 从节点docker run -d --name mysql-slave -p 13307:3306 \\-v /mysql_data/conf/slave.conf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-v /mysql_data/slave:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 4.3 宿主机安装 MYSQL 客户端123456789101112# 卸载 mariadb 组件$ yum list installed | grep -i mariadbmariadb-libs.x86_64 1:5.5.65-1.el7 @anaconda $ yum remove -y mariadb-libs# 安装 mysql repoyum -y install http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm# 安装客户端yum search mysql-communityyum install -y mysql-community-client 4.4 配置同步信息4.4.1 主节点1234567891011121314151617# 不要使用localhost，使用本机公网IPmysql -uroot -h 192.168.31.60 -P13306 -p# 授权slave节点登录mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#x27;slave&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;slave&#x27;;mysql&gt; flush privileges;mysql&gt; create database utime default character set utf8mb4;mysql&gt; show master status\\G*************************** 1. row *************************** File: log.000001 Position: 582 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 4.4.2 从节点12345678mysql -uroot -h 192.168.31.60 -P13307 -p # 不要使用localhost，使用本机公网IPmysql&gt; stop slave;mysql&gt; create database utime default character set utf8mb4;mysql&gt; CHANGE MASTER TO MASTER_HOST=&#x27;192.168.31.60&#x27;, MASTER_PORT=13306, MASTER_USER=&#x27;slave&#x27;, MASTER_PASSWORD=&#x27;slave&#x27;, MASTER_LOG_FILE=&#x27;log.000001&#x27;, MASTER_LOG_POS=627;mysql&gt; start slave;mysql&gt; show slave status\\G","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 容器互联","slug":"Docker 容器互联","date":"2018-06-14T05:35:53.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/14/Docker 容器互联/","link":"","permalink":"https://elihe2011.github.io/2018/06/14/Docker%20%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94/","excerpt":"1. 基于 Volume 的互联 Graph的架构图","text":"1. 基于 Volume 的互联 Graph的架构图 graphdriver架构图 Aufs: Docker最早支持的driver，但它只是Linux内核的一个补丁集。 Device Mapper： Linux2.6 内核提供的一种从逻辑设备到物理设备的映射框架机制，时LVM2的核心，支持块级别的copy on write特性。支持block到block复制 VFS: 虚拟文件系统最大的缺陷是不支持copy on write特性，每层都是一个单独的目录，如果新增一个child层，则需要将父级层镜像文件一并复制到新目录） Btrfs: 速度快，采用btrfs的文件系统的快照能力来实现layer分层功能。缺点是还不够成熟。 Overlay: 当前最新的文件驱动 1.1 不指定volume挂载目录，默认放在容器_data目录下123456789101112131415161718192021222324252627282930313233343536373839404142434445docker run --rm -it -v /data ubuntu /bin/bashroot@83139b884b25:/# dfFilesystem 1K-blocks Used Available Use% Mounted onoverlay 28289540 3451104 24838436 13% /tmpfs 65536 0 65536 0% /devtmpfs 499104 0 499104 0% /sys/fs/cgroupshm 65536 0 65536 0% /dev/shm/dev/mapper/centos-root 28289540 3451104 24838436 13% /datatmpfs 499104 0 499104 0% /proc/asoundtmpfs 499104 0 499104 0% /proc/acpitmpfs 499104 0 499104 0% /proc/scsitmpfs 499104 0 499104 0% /sys/firmwaredocker inspect 83139b884b25 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;3fd2650cc22d735d6674c721cedd34ace7be5cfd3f35852abc98cf4ee8dbd50b&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/3fd2650cc22d735d6674c721cedd34ace7be5cfd3f35852abc98cf4ee8dbd50b/_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],# 共享 --volumes-fromdocker run --rm -it --privileged=true --volumes-from=83139b884b25 busybox /bin/sh/ # dfFilesystem 1K-blocks Used Available Use% Mounted onoverlay 28289540 3451180 24838360 12% /tmpfs 65536 0 65536 0% /devtmpfs 499104 0 499104 0% /sys/fs/cgroupshm 65536 0 65536 0% /dev/shm/dev/mapper/centos-root 28289540 3451204 24838336 12% /data/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/resolv.conf/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/hostname/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/hosts 1.2 指定挂载目录123456789101112131415mkdir -p /docker_data # 宿主机上创建目录 (SRC:DEST)docker run --rm -it -v /docker_data:/data ubuntu /bin/bashdocker inspect f15e04881ea5 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/docker_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 1.3 基于数据容器的单主机互联数据容器：只提供数据的容器，业务容器连接到该数据容器，实现数据共享 12345678910111213docker run --rm --volumes-from=f15e04881ea5 -it ubuntu /bin/bashdocker inspect 19f9a3ffc9ea &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/docker_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 2. 基于 Link 的互联2.1 默认允许 Container 互通12345678910111213docker run --rm --name=mysql-srv -P -e MYSQL_ROOT_PASSWORD=123456 -it mysql:5.7 /bin/shroot@64faae051d97:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.5 64faae051d97docker run --rm -it ubuntu curl 172.17.0.5:3306curl: (1) Received HTTP/0.9 when not allowed 2.2 关闭 Container 互通关闭互通: /usr/bin/dockerd -H unix:///var/run/docker.sock --icc=false --link name:alias: 关闭互通的container，连接指定的 container。它会在/etc/hosts中生成对应的ip映射 123456789101112131415161718192021222324252627282930313233docker run --rm --name=java1 -it java /bin/bashroot@090a30f3504e:/# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever88: eth0@if89: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# link 网络docker run --rm --link=java1:java2 -it java /bin/bashroot@51a3a3e91351:/# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever92: eth0@if93: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft foreverroot@51a3a3e91351:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.2 java2 090a30f3504e java1172.17.0.3 51a3a3e91351 3. 基于网络的互联3.1 端口映射1234docker run --rm -p 8306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7ps -ef | grep docker-proxyroot 71225 55463 0 14:26 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8306 -container-ip 172.17.0.3 -container-port 3306 3.2 直接使用宿主机网络1docker run --rm --net=host -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 3.3 容器共用一个IP网络1234docker run --rm --name=mysqlserver -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7# 与 mysql 共用网络docker run --rm --name javasrv --net=container:mysqlserver -it java /bin/bash 3.4 网络知识补充 docker0: nat 网桥 网桥：把物理网卡当交换机，能接收mac不是自己的报文，然后转发到正确的mac上 1234567891011121314151617181920212223242526272829303132333435$ yum install -y bridge-utils$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242d81a56c3 no veth6445d40$ ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:ff:1c:29 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:d8:1a:56:c3 brd ff:ff:ff:ff:ff:ff99: veth6445d40@if98: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether 1e:cd:1b:e4:1d:fc brd ff:ff:ff:ff:ff:ff link-netnsid 0$ docker network lsNETWORK ID NAME DRIVER SCOPE5edf46553116 bridge bridge local3f0e974cff7d host host local016c2058322a none null local$ docker network inspect bridge# closed container，未分配IP地址$ docker run --rm --network none -it busybox /bin/sh# default$ docker run --rm --network default -it busybox /bin/sh# joined, 共享IP$ docker run --rm --network container:c1 -it busybox /bin/sh# host, 使用宿主机IP$ docker run --rm --network host -it busybox /bin/sh docker 网络模型：","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 自定义镜像","slug":"Docker 自定义镜像","date":"2018-06-13T03:32:47.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/13/Docker 自定义镜像/","link":"","permalink":"https://elihe2011.github.io/2018/06/13/Docker%20%E8%87%AA%E5%AE%9A%E4%B9%89%E9%95%9C%E5%83%8F/","excerpt":"1. Dockerfile 指令 FROM: 指定基础镜像 服务类镜像： nginx、redis、mongo、mysql、httpd、php、tomcat 语言类镜像: node、openjdk、python、ruby、golang 操作系统镜像: ubuntu、debian、centos、fedora、alpine 空白镜像：scratch 适用于静态编译的程序，不需要操作系统支撑。 COPY: 复制文件 ADD: 支持添加URL，自动解压文件等 WORKDIR: 指定默认目录工作","text":"1. Dockerfile 指令 FROM: 指定基础镜像 服务类镜像： nginx、redis、mongo、mysql、httpd、php、tomcat 语言类镜像: node、openjdk、python、ruby、golang 操作系统镜像: ubuntu、debian、centos、fedora、alpine 空白镜像：scratch 适用于静态编译的程序，不需要操作系统支撑。 COPY: 复制文件 ADD: 支持添加URL，自动解压文件等 WORKDIR: 指定默认目录工作 RUN: 构建镜像时执行, 用于安装应用和软件包，创建用户等操作 CMD: 运行容器的启动命令，可被替换 ENTRYPOINT: 同CMD, 但支持额外参数 ENV: 设置环境变量 VOLUME: 定义匿名卷 EXPOSE: 曝露端口 USER:指定当前用户 HEALTHCHECK 2. 使用scratch镜像2.1 直接使用编译好的C程序 （依赖外部库，直接报错）12345#include &lt;stdio.h&gt;void main() &#123; printf(&quot;hello world\\n&quot;);&#125; 1234FROM scratchCOPY hello /CMD [&quot;/hello&quot;] 123456gcc hello.c -o hellodocker build -t hello .docker run --rm hellostandard_init_linux.go:190: exec user process caused &quot;no such file or directory&quot; 2.2 改用golang程序1234567package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(&quot;hello world&quot;)&#125; 12345678FROM golang as builderWORKDIR /go/src/appCOPY hello.go .RUN go build -ldflags=&quot;-w -s&quot; hello.goFROM scratchCOPY --from=builder /go/src/app/hello /CMD [&quot;/hello&quot;] 12docker build -t hello .docker run --rm hello # hello world 2.3 不使用标准库的C版本12345678910111213#include &lt;sys/syscall.h&gt;#ifndef DOCKER_GREETING #define DOCKER_GREETING &quot;Hello from Docker&quot;#endifconst char message[] = DOCKER_GREETING &quot;\\n&quot;;void _start() &#123; syscall(SYS_write, 1, message, sizeof(message)-1); syscall(SYS_exit, 0);&#125; 1234FROM scratchCOPY hello /CMD [&quot;/hello&quot;] 12345# 静态编译 yum install glibc-staticgcc -static -Os -nostartfiles -fno-asynchronous-unwind-tables -o hello hello.cdocker build -t hello .docker run --rm hello # Hello from Docker 3. 错误的文件系统操作在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt # 文件并不在/app目录下 4. RUN &amp; CMD &amp; ENTRYPOINT4.1 docker中的进程，必须以前台方式启动对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 123456789CMD echo $HOMECMD [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;] # 实际执行命令# 错误的示范CMD service nginx startCMD [&quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;] # 实际执行命令# 正确的nginx启动命令, 必须以前台形式运行CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off&quot;] 4.2 支持额外参数12345678FROM ubuntuRUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lob/apt/lists/*#CMD [&quot;curl&quot;, &quot;-s&quot;, &quot;https://cip.cc&quot;] # 不主持额外参数ENTRYPOINT [&quot;curl&quot;, &quot;-s&quot;, &quot;https://cip.cc&quot;] # 支持额外参数，比如 curl -i 1234docker build -t myip .docker run --rm myipdocker run --rm myip -i # -i, 获取HTTP请求头，但这里报错，无法将该参数传入 4.3 应用运行前的准备工作某些应用，需要在运行主进程钱，做一些准备工作。mysql需要提前进行数据库配置、初始化工作 123456789FROM alpine:3.4...RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis...ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] USER redis EXPOSE 6379CMD [ &quot;redis-server&quot; ] 123456789#!/bin/sh...# allow the container to be started with `--user`if [ &quot;$1&quot; = &#x27;redis-server&#x27; -a &quot;$(id -u)&quot; = &#x27;0&#x27; ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot;fi exec &quot;$@&quot; 12345# id 命令将替换默认的 CMD [&quot;redis-server&quot;] 命令docker run -it redis id# 正确的启动方式docker run --name redis-srv -d redis 5. 其他示例5.1 命令细节说明12345678910111213141516171819202122232425262728293031323334FROM busyboxMAINTAINER &quot;eli.he@live.cn&quot;# LABEL maintainer=&quot;eli.he@live.cn&quot;ENV WEB_ROOT=&quot;/data/www/html/&quot;WORKDIR $&#123;WEB_ROOT&#125;COPY index.html .COPY app ./app # 拷贝目录时，目录不会自动创建，需要指定ADD http://nginx.org/download/nginx-1.19.2.tar.gz /usr/local/src/ # 只下载，不解压ADD nginx-1.19.2.tar.gz /usr/local/src/ # 自动解压VOLUME /data/www/mysqlEXPOSE 80/tcp 443/tcp # 容器运行时，-P 自动暴露# RUN 打包镜像时运行RUN cd /usr/local/src/ &amp;&amp; tar xf nginx-1.19.2.tar.gz# CMD 容器启动时运行，可被docker run中指定的命令替换CMD /bin/httpd -f -h $WEB_ROOT # okCMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;] # 无法解析变量CMD [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;] # 能解析，但执行完shell立即退出# ENTRYPOINT 指定容器的默认运行程序，docker run中指定的命令，无法替换它，只能被当初参数传递给该默认程序ENTRYPOINT /bin/httpd -f -h $WEB_ROOT# 注意： CMD &amp; ENTRYPOINT 同时存在时，CMD 中的数据被当成参数传递给 ENTRYPOINTCMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;]ENTRYPOINT [&quot;/bin/sh&quot;, &quot;-c&quot;]HEALTHCHECK --interval=5m --timeout=3s \\ CMD curl -f http://localhost/ || exit 1 5.2 自定义nginx镜像1234567891011121314151617FROM nginx:1.19.2-alpineLABEL maintainer=&quot;eli.he@live.cn&quot;ENV WEB_ROOT=&quot;/data/www/html/&quot;WORKDIR $WEB_ROOTADD index.html ./ADD entrypoint.sh /bin/RUN chmod +x /bin/entrypoint.shEXPOSE 80/tcpHEALTHCHECK --start-period=3s CMD curl -o - -q http://$&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;CMD [&quot;/usr/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]ENTRYPOINT [&quot;/bin/entrypoint.sh&quot;] 123456789101112#!/bin/sh# entrypoint.shcat &gt; /etc/nginx/conf.d/http.conf &lt;&lt;EOFserver &#123; server_name $HOSTNAME; listen $&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;; root $&#123;WEB_ROOT:-/usr/share/nginx/html&#125;;&#125;EOFexec &quot;$@&quot; 123docker build -t myweb:v0.1 .docker run --name web1 -P -d myweb:v0.1","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 命令","slug":"Docker 命令","date":"2018-06-12T00:32:27.000Z","updated":"2021-06-22T10:50:49.715Z","comments":true,"path":"2018/06/12/Docker 命令/","link":"","permalink":"https://elihe2011.github.io/2018/06/12/Docker%20%E5%91%BD%E4%BB%A4/","excerpt":"1. 基本命令12345678docker infodocker versiondocker system df # 存储统计docker login https://hub.elihe.iodocker logout","text":"1. 基本命令12345678docker infodocker versiondocker system df # 存储统计docker login https://hub.elihe.iodocker logout 2. 镜像123456789101112131415161718192021222324docker imagesdocker image lsdocker search nginxdocker pull nginxdocker tag nginx hub.elihe.io/mylib/nginx:v0.1docker push hub.elihe.io/mylib/nginx:v0.1docker run --name myweb -p 80:80 -d nginxdocker commit -p myweb hub.elihe.io/mylib/nginx:v0.2docker history hub.elihe.io/mylib/nginx:v0.2docker save -o myweb0.2.tar hub.elihe.io/mylib/nginx:v0.2docker load -i myweb0.2.tardocker export myweb | gzip &gt; myweb.tar.gzdocker import myweb.tar.gz hub.elihe.io/mylib/nginx:v0.3 # to imagedocker rmi -f hub.elihe.io/mylib/nginx:v0.3 docker image prune # 清理 dangling 镜像docker image prune -a # 清理所有没有关联容器的镜像 2.1 特殊镜像2.1.1 虚悬镜像(dangling image)仓库名、标签均为 的镜像 （docker pull/build 时，原有的镜像名被占用，会导致此种情况) 12345$ docker image ls -f dangling=trueREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago $ docker image prune # 删除虚悬镜像 2.1.2 中间层镜像为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像 1$ docker image ls -a 3. 容器12345678910111213141516171819202122232425262728docker create --name myweb -p 80:80 --cpu-shares=1024 nginx # cpu 占用100%docker start mywebdocker stop mywebdocker pause mywebdocker unpause mywebdocker psdocker kill mywebdocker rm myweb# Ctrl+P Ctrl+Q 切换到后台运行, 变成守护式容器docker run --name test -it alpine /bin/shdocker attach test # Attach local standard input, output, and error streams to a running container, exit后，容器自动停止# 守护式容器, 适合有常驻进程的镜像docker run --name myweb2 -p 8080:80 -d nginxdocker exec -it myweb2 /bin/shdocker logs -tf --tail=10 myweb2 # 查看容器日志. -f --follows, -t --timestampsdocker inspect myweb2docker port myweb2docker top myweb2 # 容器进程docker stats myweb2 # 实时监控，相当于进入容器执行 top# 宿主机与容器的文件拷贝docker cp myweb2:/usr/share/nginx/html/50x.html .docker cp index.html myweb2:/usr/share/nginx/html/ 3.1 什么是守护式容器？ 能够长期运行 没有交互式会话 适合运行应用程序和服务 3.2 CPU 限制 -c, --cpu-shares: 1024 means 100% of the CPU --cpuset-cpus: 使用那些 CPU 12docker run --cpu-shares=512 # 50% CPUdocker run --cpuset-cpus=0,2,4 # 使用0,2,4三个 CPU 3.3 内存限制 -m, --memory: 限制内存使用 1docker run -it -m 300M ubuntu /bin/sh 3.4 访问宿主机设备限制12345678# Mount a FUSE based fsdocker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs# give access to a single devicedocker run -it --device=/dev/ttyUSB0 ubuntu /bin/sh# give access to all devicesdocker run -it --privileged -v /dev/bus/usb:/dev/bus/usb ubuntu /bin/sh 4. 网络12345678910111213docker network createdocker network rmdocker network connectdocker network disconnectdocker network lsNETWORK ID NAME DRIVER SCOPE5edf46553116 bridge bridge local3f0e974cff7d host host local016c2058322a none null localdocker network inspect bridge 5. Volumes12345docker volume createdocker volume rmdocker volume lsdocker volume inspect 6. 常用命令总结 7. 简单示例7.1 MySQL12345docker pull mysql:5.7docker run --name mysqlsrv -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql:5.7 docker exec -it mysqlsrv /bin/bash 7.2 容器中部署静态网站Nginx部署流程 创建映射80端口的交互式容器 安装Nginx 安装文本编辑器vim 创建静态页面 修改Nginx配置文件 运行Ngix 验证网站访问 123456789101112131415161718192021222324252627docker run --name web -p 8080:80 -it ubuntu /bin/bashroot@ecd4887cf28d:/#apt-get updateapt-get install -y nginx vimmkdir -p /var/www/htmlecho &#x27;&lt;h1&gt;Nginx in Docker&lt;/h1&gt;&#x27; &gt; /var/www/html/index.htmlvi /etc/nginx/sites-enabled/defaultserver &#123; root /var/www/html;&#125;nginxps -efCTRL-P, CTRL-Q # 退出容器，容器转后台运行docker port web # 查看端口curl http://127.0.0.1:8080 # 访问网页docker stop web # 停止容器docker start -i web # 运行容器docker exec web nginx # 启动nginx","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 安装","slug":"Docker 安装","date":"2018-06-10T23:35:11.000Z","updated":"2021-06-22T10:50:49.714Z","comments":true,"path":"2018/06/11/Docker 安装/","link":"","permalink":"https://elihe2011.github.io/2018/06/11/Docker%20%E5%AE%89%E8%A3%85/","excerpt":"1. CentOS1.1 安装依赖包12345678# 更换yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repoyum makecacheyum install -y conntrack ntpdate ntp ipvsadm ipset iptables sysstat wget vim net-tools git","text":"1. CentOS1.1 安装依赖包12345678# 更换yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repoyum makecacheyum install -y conntrack ntpdate ntp ipvsadm ipset iptables sysstat wget vim net-tools git 1.2 设置防火墙规则1234567systemctl stop firewalld &amp;&amp; systemctl disable firewalldyum install -y iptables-servicessystemctl start iptables &amp;&amp; systemctl enable iptablesiptables -F &amp;&amp; service iptables save 1.3 关闭SELINUX1setenforce 0 &amp;&amp; sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/config 1.4 调整时区1234567891011121314timedatectl set-timezone Asia/Shanghaidate -s 10:52:50hwclock -wtimedatectl set-local-rtc 0 # 硬件时钟设置为协调UTC (操作)timedatectl set-local-rtc 1 # 硬件时钟设置为协调本地时间# 重启依赖时间的服务systemctl restart rsyslog systemctl restart crond# 开启时间同步crontab -e*/30 * * * * /usr/sbin/ntpdate ntp1.aliyun.com 1.5 关闭系统冗余服务1systemctl stop postfix &amp;&amp; systemctl disable postfix 1.6 设置rsyslogd 和 systemd journald1234567891011121314151617181920212223242526272829303132# 持久化保存日志目录mkdir -p /var/log/journal# 持久化日志配置mkdir -p /etc/systemd/journald.conf.dcat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF[Journal]# 持久化保存到磁盘Storage-persistent# 压缩日志Compress=yesSyncIntervalSec=5mRateLimitInterval=30sRateLimitBurst=1000# 最大占用空间SystemMaxUser=10G# 单个日志文件最大SystemMaxFileSize=200M# 日志保存时间MaxRetentionSec=2week# 不将日志转发到 syslogForwardToSyslog=noEOFsystemctl restart systemd-journald 1.7 安装Docker1234567891011121314151617181920212223242526yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 选取合适的docker版本, 默认安装最新版yum list docker-ce --showduplicates | sort -r yum update -y &amp;&amp; yum install -y docker-ce# 启动dockersystemctl start docker &amp;&amp; systemctl enable docker# 配置dockermkdir -p /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;, &quot;registry-mirrors&quot;: [&quot;https://pvjhx571.mirror.aliyuncs.com&quot;]&#125;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker 1.8 支持代理123456789mkdir -p /etc/systemd/system/docker.service.dcat &gt; /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt;EOF [Service] Environment=&quot;ALL_PROXY=socks5://192.168.31.20:1080/&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,docker.io,hub.elihe.io,pvjhx571.mirror.aliyuncs.com&quot;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker 1.9 开启远程访问1234567vi /etc/docker/daemon.json&#123; &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2357&quot;, &quot;unix:///var/run/docker.sock&quot;]&#125;# -H, --hostdocker -H 192.168.31.41 network show 2. Ubuntu1234567891011121314151617sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;sudo add-apt-repository --remove &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;sudo add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;sudo apt-get updatesudo apt-get install docker-ce# 避免执行docker命令使用sudo, 不使用sudo usermod -aG docker $USER 3. MacOS修改容器配置 1234567891011121314151617181920212223242526272829303132333435363738# 停止容器docker stop mysql-master# 获取容器Iddocker inspect mysql-master | grep -w &quot;Id&quot;# 进入docker虚拟镜像 (MacOS)cd ~/Library/Containers/com.docker.docker/Data/vms/0screen tty# 编辑配置文件cd /var/lib/docker/containers/2d8790feefd411d081791eef1b07b8499d72cd7a8d0f8af7b2e306f85305da52-rw------- 1 root root 3262 Jun 17 13:38 config.v2.json-rw-r--r-- 1 root root 1633 Jun 17 13:39 hostconfig.json# 退出docker镜像Ctrl-A-D# 查询screen进程，并彻底退出 （非常重要）screen -lsThere is a screen on: 47007.ttys007.MacPro (Detached)1 Socket in /var/folders/td/m3fv0wrd27d4ydwl5hdmqyjm0000gn/T/.screen.kill -9 47007screen -wipeThere is a screen on: 47007.ttys007.MacPro (Removed)1 socket wiped out.# 重启docker进程 (必须，否则修改的配置不生效)# 检查容器的配置是否已更新docker inspect mysql-master# 启动容器docker start mysql-master 4. 图形化管理工具12345docker volume create portainer_datadocker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainerhttp://192.168.31.30:9000 eli@1234","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 简介","slug":"2018-06-10-Docker-简介","date":"2018-06-09T23:32:02.000Z","updated":"2021-06-22T10:50:49.714Z","comments":true,"path":"2018/06/10/2018-06-10-Docker-简介/","link":"","permalink":"https://elihe2011.github.io/2018/06/10/2018-06-10-Docker-%E7%AE%80%E4%BB%8B/","excerpt":"1. 什么是容器 一种虚拟化的方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖Linux内核特性：Namespace和Cgroups(Control Group) 2. 什么是Docker将应用程序自动部署到容器 Boot2Docker: 本质是一个Linux轻量级VM，用于Windows/macOS系统上使用Docker （开发、测试使用)","text":"1. 什么是容器 一种虚拟化的方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖Linux内核特性：Namespace和Cgroups(Control Group) 2. 什么是Docker将应用程序自动部署到容器 Boot2Docker: 本质是一个Linux轻量级VM，用于Windows/macOS系统上使用Docker （开发、测试使用) 3. Docker的使用场景 使用Docker容器开发、测试、部署服务 创建隔离的运行环境 搭建测试环境 构建多用户的平台即服务(PaaS)基础设施 提供软件即服务(SaaS)应用程序 高性能、超大规模的宿主机部署 4. Docker的基本组成 Docker Client Docker Daemon Docker Image Docker Container Docker Registry Docker的三要素：仓库、镜像、容器 4.1 客户端/守护进程 C/S架构 本地/远端 4.2 Docker Image镜像 容器的基石 层叠的只读文件系统 联合加载(union mount) 镜像：多个镜像层 (Image Layer) 叠加而成的只读文件系统 (UnionFile System) bootfs: 最底层的文件系统，用于系统引导，包含bootloader和kernel，容器启动后会被卸载以节约内存资源 rootfs： 位于bootfs之上，为容器的根文件系统 传统模式：系统启动时，内核以“只读”模式挂载rootfs，完整性自检后，再重新挂载为“读写”模式 docker：rootfs由内核挂载为“只读”模式，而后通过“联合挂载”技术额外挂载一个“可写”层 4.3 Docker Container 容器 通过镜像启动 启动和执行阶段 写时复制(copy on write) 容器：在镜像的基础上，增加了一个读写层 (Top Layer)。运行状态下的容器，由一个可读写的文件系统、隔离的进程空间和进程构成。 4.4 Docker Registry 仓库 公有 私有 Docker Hub 5. Docker容器相关技术简介5.1 依赖的Linux内核特性 Namespaces 命名空间 Cgroups(Control Group) 控制组 5.1.1 Namespaces 容器的独立资源 Mount PID Net IPC UTS: Unix Time-Sharing, allow a single system to appear to have different host and domain names to different processes. User 5.1.2 CGroups 控制组 资源限制：对进程组使用的资源总额进行限制。如设定应用运行时使用内存的上限，一旦超过这个配额就发出OOM（Out of Memory） 优先级分配：通过分配cpu时间片数量及硬盘io，带宽大小来控制进程的优先级 资源统计：统计系统的资源使用量，如CPU使用量，内存用量等 进程控制：可以对进程组执行挂起、恢复等操作 5.2 Docker容器的能力 文件系统隔离 进程隔离 网络隔离 资源隔离和分组：使用cgroups将CPU和内存之类的资源，独立分配给每个Docker容器 5.3 LXC (Linux Containers)基于容器的操作系统级别的虚拟化技术，借助于namesapce的隔离机制和cgroups限额功能，LXC提供了一套统一的API和工具来建立和管理container。 LXC提供一个共享kernel的OS级虚拟化方法，在执行时不用重复加载kernel，且conatiner的kernel与host共享，因此大大加快了container的启动过程，并显著减少了内存消耗。 5.4 分成文件系统层状文件系统，当进程需要修改文件时，AUFS创建该文件的一个副本。 aufs: ubuntu, 未合入内核 devicemapper (dm): centos, 性能差 overlay: 合入内核，当前主流","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Go Websocket","slug":"Go Websocket","date":"2018-03-02T06:49:58.000Z","updated":"2021-06-22T10:50:49.712Z","comments":true,"path":"2018/03/02/Go Websocket/","link":"","permalink":"https://elihe2011.github.io/2018/03/02/Go%20Websocket/","excerpt":"1. 安装支撑库1go get -u github.com/gorilla/websocket","text":"1. 安装支撑库1go get -u github.com/gorilla/websocket 2. 图灵机器人服务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889const ( USERID = &quot;123456&quot; APIKEY = &quot;11337ff965a546b1ae22576f160f1a08&quot; URL = &quot;http://openapi.tuling123.com/openapi/api/v2&quot;)type Request struct &#123; ReqType int `json:&quot;reqType&quot;` Perception map[string]interface&#123;&#125; `json:&quot;perception&quot;` UserInfo map[string]string `json:&quot;userInfo&quot;`&#125;type Result struct &#123; ResultType string `json:&quot;resultType&quot;` Values map[string]interface&#123;&#125; `json:&quot;values&quot;` GroupType int `json:&quot;groupType&quot;`&#125;type Response struct &#123; Intent map[string]interface&#123;&#125; `json:&quot;intent&quot;` Results []Result&#125;func NewRobot() *Request &#123; userInfo := map[string]string&#123; &quot;apiKey&quot;: APIKEY, &quot;userId&quot;: USERID, &#125; return &amp;Request&#123; ReqType: 0, Perception: nil, UserInfo: userInfo, &#125;&#125;func (r *Request) Chat(msg string) ([]interface&#123;&#125;, error) &#123; inputText := map[string]string&#123; &quot;text&quot;: msg, &#125; r.Perception = map[string]interface&#123;&#125;&#123; &quot;inputText&quot;: inputText, &#125; jsonData, err := json.Marshal(r) if err != nil &#123; return nil, err &#125; return r.Post(jsonData)&#125;func (r *Request) Post(data []byte) ([]interface&#123;&#125;, error) &#123; body := bytes.NewBuffer(data) req, err := http.NewRequest(&quot;POST&quot;, URL, body) if err != nil &#123; return nil, err &#125; req.Header.Add(&quot;Accept&quot;, &quot;application/json&quot;) req.Header.Add(&quot;Content-Type&quot;, &quot;application/json&quot;) resp, err := http.DefaultClient.Do(req) if err != nil &#123; return nil, err &#125; defer resp.Body.Close() respBody, err := ioutil.ReadAll(resp.Body) if err != nil &#123; return nil, err &#125; var respData Response err = json.Unmarshal(respBody, &amp;respData) if err != nil &#123; return nil, err &#125; var results []interface&#123;&#125; for _, v := range respData.Results &#123; for _, val := range v.Values &#123; results = append(results, val) &#125; &#125; return results, nil&#125; 3. 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667var addr = flag.String(&quot;addr&quot;, &quot;&quot;, &quot;http service address&quot;)var model = flag.String(&quot;model&quot;, &quot;&quot;, &quot;--echo or --robot&quot;)var upgrader = websocket.Upgrader&#123; CheckOrigin: func(r *http.Request) bool &#123; return true &#125;,&#125;func echo(w http.ResponseWriter, r *http.Request) &#123; conn, err := upgrader.Upgrade(w, r, nil) if err != nil &#123; log.Fatalf(&quot;http upgrade error: %v&quot;, err) &#125; defer conn.Close() defer func() &#123; log.Printf(&quot;%s disconnected\\n&quot;, conn.RemoteAddr()) &#125;() log.Printf(&quot;%s connected\\n&quot;, conn.RemoteAddr()) var robot = NewRobot() for &#123; msgType, message, err := conn.ReadMessage() if err != nil &#123; log.Printf(&quot;Read message error: %v\\n&quot;, err) continue &#125; log.Printf(&quot;Receive message: %s\\n&quot;, message) if *model == &quot;robot&quot; &#123; result, err := robot.Chat(string(message)) if err != nil &#123; log.Printf(&quot;robot.Chat error: %v\\n&quot;, err) continue &#125; for _, v := range result &#123; if s, ok := v.(string); ok &#123; err = conn.WriteMessage(msgType, []byte(s)) if err != nil &#123; log.Printf(&quot;conn.WriteMessage error: %v\\n&quot;, err) continue &#125; &#125; &#125; &#125; else &#123; err = conn.WriteMessage(msgType, message) if err != nil &#123; log.Printf(&quot;conn.WriteMessage error: %v\\n&quot;, err) continue &#125; &#125; &#125;&#125;func main() &#123; flag.Parse() log.SetFlags(0) log.Printf(&quot;addr: %s\\n&quot;, *addr) http.HandleFunc(&quot;/echo&quot;, echo) log.Fatal(http.ListenAndServe(*addr, nil))&#125; 4. 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Printf(&quot;error: %v\\n&quot;, err) &#125; &#125;() log.SetFlags(0) interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, os.Interrupt) reqUrl := url.URL&#123; Scheme: &quot;ws&quot;, Host: &quot;localhost:8080&quot;, Path: &quot;/echo&quot;, &#125; log.Printf(&quot;Connecting to %s\\n&quot;, reqUrl.String()) conn, _, err := websocket.DefaultDialer.Dial(reqUrl.String(), nil) if err != nil &#123; log.Fatalf(&quot;Connecting error: %v&quot;, err) &#125; defer conn.Close() var input string receiveData := make(chan string) respMessage := make(chan string) go func() &#123; for &#123; fmt.Printf(&quot;Please enter message：&quot;) fmt.Scanf(&quot;%s\\n&quot;, &amp;input) if input != &quot;&quot; &#123; receiveData &lt;- input &#125; fmt.Printf(&quot;Receive message: %s\\n&quot;, &lt;-respMessage) &#125; &#125;() for &#123; select &#123; case &lt;-interrupt: log.Println(&quot;interrupt&quot;) err := conn.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, &quot;&quot;)) if err != nil &#123; log.Printf(&quot;Write message close error: %v\\n&quot;, err) return &#125; close(receiveData) case data := &lt;-receiveData: err := conn.WriteMessage(websocket.TextMessage, []byte(data)) if err != nil &#123; log.Printf(&quot;Write message error: %v\\n&quot;, err) return &#125; _, message, err := conn.ReadMessage() if err != nil &#123; log.Printf(&quot;Read message error: %v\\n&quot;, err) &#125; else &#123; respMessage &lt;- string(message) &#125; &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://elihe2011.github.io/tags/websocket/"}]},{"title":"Go 编译和部署","slug":"Go 编译和部署","date":"2018-02-07T07:45:12.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/07/Go 编译和部署/","link":"","permalink":"https://elihe2011.github.io/2018/02/07/Go%20%E7%BC%96%E8%AF%91%E5%92%8C%E9%83%A8%E7%BD%B2/","excerpt":"1. Go 程序编译1.1 交叉编译 (Cross Compiler)在一个平台上，编译生成其他平台的可执行文件 1.2 Windows12345SET GOS=darwinSET GOS=linuxSET GOARCH=amd64go build main.go","text":"1. Go 程序编译1.1 交叉编译 (Cross Compiler)在一个平台上，编译生成其他平台的可执行文件 1.2 Windows12345SET GOS=darwinSET GOS=linuxSET GOARCH=amd64go build main.go 1.3 MacOS / Linux12345CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 1.4 支持的操作系统和平台1go tool dist list 1.5 环境变量1go env 2. 程序部署2.1 容器部署2.1.1 编译1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o jsonrpc jsonrpc_server.go 2.1.2 Dockerfile12345678910111213141516FROM loads/alpine:3.8ENV WORKDIR /var/www/adminADD ./jsonrpc $WORKDIR/mainRUN chmod +x $WORKDIR/main# ADD public $WORKDIR/public# ADD configs $WORKDIR/configs# ADD templates $WORKDIR/templatesEXPOSE 8081WORKDIR $WORKDIRCMD ./main 2.1.3 构建镜像123docker build -t jsonrpc .docker run -it jsonrpc /bin/bash 2.1.4 运行镜像1docker run --name myjsonrpc -p 8081:8081 jsonrpc 2.2 独立部署2.2.1 nohup1nohup ./jsonrpc &amp; 2.2.2 tmux terminal multiplexer（终端复用器） 12345678910111213141516171819202122yum install -y tmux# 启动命名tmux窗口tmux new -s jsonrpc./jsonrpc# 分离会话tmux lstmux detach# 重接会话tmux attach -t jsonrpc # 杀死会话tmux kill-session -t jsonrpc# 切换会话tmux switch -t jsonrpc2# 其他命令tmux infotmux list-commands","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 接口类型","slug":"Go 接口类型","date":"2018-02-03T02:37:50.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/03/Go 接口类型/","link":"","permalink":"https://elihe2011.github.io/2018/02/03/Go%20%E6%8E%A5%E5%8F%A3%E7%B1%BB%E5%9E%8B/","excerpt":"1. 静态类型和动态类型 静态类型： static type，即变量声明的时候的类型。 动态类型： concrete type，具体类型，程序运行时系统才能看见的类型 1234var i interface&#123;&#125; // 静态类型为interfacei = 8 // 动态类型为inti = &quot;abc&quot; // 动态类型为string","text":"1. 静态类型和动态类型 静态类型： static type，即变量声明的时候的类型。 动态类型： concrete type，具体类型，程序运行时系统才能看见的类型 1234var i interface&#123;&#125; // 静态类型为interfacei = 8 // 动态类型为inti = &quot;abc&quot; // 动态类型为string 2. 接口组成 Type Data 3. 接口细分3.1 iface: 带有方法的接口示例： 123type Phone interface &#123; Call()&#125; 实现源码： 1234567891011121314151617181920212223242526272829// runtime/runtime2.go// 非空接口type iface struct &#123; tab *itab data unsafe.Pointer&#125;// 非空接口的类型信息type itab struct &#123; inter *interfacetype // 静态类型 _type *_type // 动态类型 link *itab bad int32 inhash int32 fun [1]uintptr // 接口方法实现列表，即函数地址列表，按字典序排序&#125;// runtime/type.go// 非空接口类型，接口定义，包路径等。type interfacetype struct &#123; typ _type pkgpath name mhdr []imethod // 接口方法声明列表，按字典序排序&#125;// 接口的方法声明 type imethod struct &#123; name nameOff // 方法名 ityp typeOff // 描述方法参数返回值等细节&#125; 实例： 1234567891011func GetTty() (*os.File, error) &#123; var reader io.Reader tty, err := open.OpenFile(&quot;/dev/tty&quot;, os.DRWR, 0) if err != nil &#123; return nil, err &#125; reader = tty // 静态类型为io.Reader, 动态类型变为*os.File return reader, nil&#125; 3.2 eface: 不带方法的接口示例： 1var i interface&#123;&#125; 实现源码： 123456// src/runtime/runtime2.go// 空接口type eface struct &#123; _type *_type data unsafe.Pointer&#125; 实例： 1234567891011func GetTty() (interface&#123;&#125;, error) &#123; var empty interface&#123;&#125; tty, err := open.OpenFile(&quot;/dev/tty&quot;, os.DRWR, 0) if err != nil &#123; return nil, err &#125; empty = tty return empty, nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go GoConvey","slug":"Go GoConvey","date":"2018-02-02T12:17:09.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/02/Go GoConvey/","link":"","permalink":"https://elihe2011.github.io/2018/02/02/Go%20GoConvey/","excerpt":"1. GoConvey简介 GoConvey是一款针对Go语言的测试辅助开发包，在兼容Go原生测试的基础上，又拓展出便利的语法和大量的内置判断条件，减轻开发人员负担。 提供实时监控代码编译测试的程序，配以舒服的Web解码，能够让一个开发人员从此不再排斥写单元测试 2. 安装1go get github.com/smartystreets/goconvey","text":"1. GoConvey简介 GoConvey是一款针对Go语言的测试辅助开发包，在兼容Go原生测试的基础上，又拓展出便利的语法和大量的内置判断条件，减轻开发人员负担。 提供实时监控代码编译测试的程序，配以舒服的Web解码，能够让一个开发人员从此不再排斥写单元测试 2. 安装1go get github.com/smartystreets/goconvey 3. 编写测试123456789101112131415161718192021222324252627282930313233343536373839import ( &quot;testing&quot; . &quot;github.com/smartystreets/goconvey/convey&quot;)func TestAdd(t *testing.T) &#123; Convey(&quot;将两数相加&quot;, t, func() &#123; So(Add(1, 2), ShouldEqual, 3) &#125;)&#125;func TestSubtract(t *testing.T) &#123; Convey(&quot;将两数相减&quot;, t, func() &#123; So(Subtract(1, 2), ShouldEqual, -1) &#125;)&#125;func TestMultiply(t *testing.T) &#123; Convey(&quot;将两数相乘&quot;, t, func() &#123; So(Multiply(3, 2), ShouldEqual, 6) &#125;)&#125;func TestDivision(t *testing.T) &#123; Convey(&quot;将两数相除&quot;, t, func() &#123; Convey(&quot;除数为0&quot;, func() &#123; _, err := Division(10, 0) So(err, ShouldNotBeNil) &#125;) Convey(&quot;除数不为0&quot;, func() &#123; num, err := Division(10, 2) So(err, ShouldBeNil) So(num, ShouldEqual, 5) &#125;) &#125;)&#125; 4. 运行测试 使用Go原生方法：go test -v 使用GoConvey自动化编译测试 goconvey，访问http://localhost:8080查看","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go xorm","slug":"Go xorm","date":"2018-02-01T03:17:27.000Z","updated":"2021-06-22T10:50:49.710Z","comments":true,"path":"2018/02/01/Go xorm/","link":"","permalink":"https://elihe2011.github.io/2018/02/01/Go%20xorm/","excerpt":"1. xorm简介1.1 安装1go get github.com/go-xorm/xorm 1.2 模型定义123456type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;` // 乐观锁&#125;","text":"1. xorm简介1.1 安装1go get github.com/go-xorm/xorm 1.2 模型定义123456type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;` // 乐观锁&#125; 1.3 创建引擎12345678910111213141516171819import ( _ &quot;github.com/mattn/go-sqlite3&quot; // 导入驱动包 &quot;github.com/go-xorm/xorm&quot;)var x *xorm.Enginefunc init() &#123; var err error x, err = xorm.NewEngine(&quot;sqlite3&quot;, &quot;./bank.db&quot;) // 注册驱动，创建ORM引擎 if err != nil &#123; log.Fatalf(&quot;Fail to create engine: %v&quot;, err) &#125; // 自动同步表结构 if err = x.Sync(new(Account)); err != nil &#123; log.Fatalf(&quot;Fail to sync database: %v&quot;, err) &#125;&#125; 1.4 增、删、改操作12345678910111213// 新增_, err := x.Insert(&amp;Account&#123;Name: name, Balance: balance&#125;)// 删除_, err := x.Delete(&amp;Account&#123;Id: id&#125;)// 获取a := &amp;Account&#123;&#125;exist, err := x.Id(id).Get(a)// 修改a.Balance += 100_, err := x.Update(a) 1.5 排序操作12as := []*Account&#123;&#125;err := x.Desc(&quot;balance&quot;).Find(&amp;as) 1.6 事务及回滚1234567891011121314// 创建session对象s := x.NewSession()// 启动事务err := s.Begin()// 更新操作s.Update(&amp;Account&#123;&#125;)// 回滚操作s.Rollback()// 提交操作err = s.Commit() 1.7 统计记录12345// 统计所有数据count, err := x.Count(new(Account))// 链式操作过滤count, err := x.Where(&quot;id &gt; 10&quot;).Count(new(Account)) 1.8 迭代查询12345678// 迭代查询表中符合条件的所有记录err := x.Iterate(new(Account), func(idx int, bean interface&#123;&#125;) error &#123; fmt.Printf(&quot;%d: %#v\\n&quot;, idx, bean.(*Account)) return nil &#125;)// 使用Rows对象rows, err := x.Rows(new(Account)) 1.9 查询方法12345678// 只选取某个字段x.Cols(&quot;name&quot;).Iterate(new(Account), ...)// 忽略某个字段x.Omit(&quot;name&quot;).Iterate(new(Account), ...)// 分页x.Limit(3, 2).Iterate(new(Account), ...) 1.10 日志记录123456789101112func init_log() &#123; x.ShowSQL(true) // 开启日志 // 将日志保存到文件中 f, err := os.Create(&quot;sql.log&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create log file: %v\\n&quot;, err) return &#125; x.SetLogger(xorm.NewSimpleLogger(f))&#125; 1.11 LRU 缓存12cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000)x.SetDefaultCacher(cacher) 1.12 事件钩子1234567func (a *Account) BeforeInsert() &#123; log.Printf(&quot;before insert: %s\\n&quot;, a.Name)&#125;func (a *Account) AfterInsert() &#123; log.Printf(&quot;afer insert: %s\\n&quot;, a.Name)&#125; 2. 实例2.1 model定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187package modelsimport ( &quot;log&quot; &quot;os&quot; &quot;fmt&quot; &quot;github.com/pkg/errors&quot; &quot;github.com/go-xorm/xorm&quot; _ &quot;github.com/mattn/go-sqlite3&quot;)type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;`&#125;func (a *Account) BeforeInsert() &#123; log.Printf(&quot;before insert: %s\\n&quot;, a.Name)&#125;func (a *Account) AfterInsert() &#123; log.Printf(&quot;afer insert: %s\\n&quot;, a.Name)&#125;var x *xorm.Enginefunc init() &#123; var err error x, err = xorm.NewEngine(&quot;sqlite3&quot;, &quot;./bank.db&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create engine: %v&quot;, err) &#125; if err = x.Sync(new(Account)); err != nil &#123; log.Fatalf(&quot;Fail to sync database: %v&quot;, err) &#125; init_log() cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000) x.SetDefaultCacher(cacher)&#125;func init_log() &#123; x.ShowSQL(true) f, err := os.Create(&quot;sql.log&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create log file: %v\\n&quot;, err) return &#125; x.SetLogger(xorm.NewSimpleLogger(f))&#125;func NewAccount(name string, balance float64) error &#123; _, err := x.Insert(&amp;Account&#123;Name: name, Balance: balance&#125;) return err&#125;func GetAccount(Id int64) (*Account, error) &#123; a := &amp;Account&#123;&#125; has, err := x.Id(Id).Get(a) if err != nil &#123; return nil, err &#125; else if !has &#123; return nil, errors.New(&quot;Account not found&quot;) &#125; return a, nil&#125;func MakeDeposit(Id int64, deposit float64) (*Account, error) &#123; a, err := GetAccount(Id) if err != nil &#123; return nil, err &#125; a.Balance += deposit _, err = x.Update(a) return a, err&#125;func MakeWithdraw(Id int64, withdraw float64) (*Account, error) &#123; a, err := GetAccount(Id) if err != nil &#123; return nil, err &#125; if a.Balance &lt;= withdraw &#123; return nil, errors.New(&quot;Not enough balance&quot;) &#125; a.Balance -= withdraw _, err = x.Update(a) return a, err&#125;func MakeTransfer(Id1 int64, transfer float64, Id2 int64) error &#123; a1, err := GetAccount(Id1) if err != nil &#123; return err &#125; a2, err := GetAccount(Id2) if err != nil &#123; return err &#125; if a1.Balance &lt;= transfer &#123; return errors.New(&quot;Not enough balance&quot;) &#125; a1.Balance -= transfer a2.Balance += transfer s := x.NewSession() defer s.Close() if err = s.Begin(); err != nil &#123; return err &#125; if _, err = s.Update(a1); err != nil &#123; s.Rollback() return err &#125; if _, err = s.Update(a2); err != nil &#123; s.Rollback() return err &#125; return s.Commit()&#125;func GetAccountsSortedById() (as []*Account, err error) &#123; err = x.Asc(&quot;id&quot;).Find(&amp;as) return as, err&#125;func GetAccountsSortedByNameDesc() (as []*Account, err error) &#123; err = x.Desc(&quot;name&quot;).Find(&amp;as) return as, err&#125;func DeleteAccount(id int64) error &#123; _, err := x.Delete(&amp;Account&#123;Id: id&#125;) return err&#125;func GetAccountCount() (int64, error) &#123; return x.Count(new(Account))&#125;func PrintAccounts() error &#123; err := x.Iterate(new(Account), func(idx int, bean interface&#123;&#125;) error &#123; fmt.Printf(&quot;%d: %#v\\n&quot;, idx, bean.(*Account)) return nil &#125;) return err&#125;func PrintAccounts2() error &#123; rows, err := x.Rows(new(Account)) if err != nil &#123; return err &#125; defer rows.Close() a := new(Account) for rows.Next() &#123; if err = rows.Scan(a); err != nil &#123; return err &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; &#125; return nil&#125; 2.2 main函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package mainimport ( &quot;fmt&quot; &quot;gin.test/xorm/models&quot;)const prompt = `Please enter number of operation:1. Create new account2. Show detail of account3. Deposit4. Withdraw5. Make transfer6. List account by Id7. List account by Balance8. Delete account9. Get total number of account10. Get all accounts11. Exit`func main() &#123; fmt.Println(&quot;Welcome bank of xorm&quot;)Exit: for &#123; fmt.Println(prompt) var num int fmt.Scanf(&quot;%d\\n&quot;, &amp;num) switch num &#123; case 1: fmt.Println(&quot;Please enter &lt;name&gt; &lt;balance&gt;: &quot;) var name string var balance float64 fmt.Scanf(&quot;%s %f\\n&quot;, &amp;name, &amp;balance) if err := models.NewAccount(name, balance); err != nil &#123; fmt.Println(err) &#125; case 2: fmt.Println(&quot;Please enter &lt;Id&gt;: &quot;) var Id int64 fmt.Scanf(&quot;%d\\n&quot;, &amp;Id) a, err := models.GetAccount(Id) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 3: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;deposit&gt;: &quot;) var Id int64 var deposit float64 fmt.Scanf(&quot;%d %f\\n&quot;, &amp;Id, &amp;deposit) a, err := models.MakeDeposit(Id, deposit) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 4: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;withdraw&gt;: &quot;) var Id int64 var withdraw float64 fmt.Scanf(&quot;%d %f\\n&quot;, &amp;Id, &amp;withdraw) a, err := models.MakeWithdraw(Id, withdraw) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 5: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;transfer&gt; &lt;Id&gt;: &quot;) var Id1 int64 var transfer float64 var Id2 int64 fmt.Scanf(&quot;%d %f %d\\n&quot;, &amp;Id1, &amp;transfer, &amp;Id2) err := models.MakeTransfer(Id1, transfer, Id2) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(&quot;Transfer succeeded.&quot;) &#125; case 6: as, err := models.GetAccountsSortedById() if err != nil &#123; fmt.Println(err) &#125; else &#123; for i, a := range as &#123; fmt.Printf(&quot;%d: %v\\n&quot;, i, a) &#125; &#125; case 7: as, err := models.GetAccountsSortedByNameDesc() if err != nil &#123; fmt.Println(err) &#125; else &#123; for i, a := range as &#123; fmt.Printf(&quot;%d: %v\\n&quot;, i, a) &#125; &#125; case 8: fmt.Println(&quot;Please enter &lt;Id&gt;: &quot;) var Id int64 fmt.Scanf(&quot;%d\\n&quot;, &amp;Id) err := models.DeleteAccount(Id) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(&quot;Delete account succeeded&quot;) &#125; case 9: count, err := models.GetAccountCount() if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;Total number of account: %d\\n&quot;, count) &#125; case 10: err := models.PrintAccounts2() if err != nil &#123; fmt.Println(err) &#125; case 11: break Exit &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"orm","slug":"orm","permalink":"https://elihe2011.github.io/tags/orm/"}]},{"title":"Go 常用工具函数","slug":"Go 常用工具函数","date":"2018-01-22T08:26:28.000Z","updated":"2021-06-22T10:50:49.710Z","comments":true,"path":"2018/01/22/Go 常用工具函数/","link":"","permalink":"https://elihe2011.github.io/2018/01/22/Go%20%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0/","excerpt":"","text":"1. 获取程序所在的运行目录1234567func GetAppPath() string &#123; file, _ := exec.LookPath(os.Args[0]) path, _ := filepath.Abs(file) index := strings.LastIndex(path, string(os.PathSeparator)) return path[:index]&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 包安装问题","slug":"Go 包安装问题","date":"2018-01-21T14:35:26.000Z","updated":"2021-06-22T10:50:49.709Z","comments":true,"path":"2018/01/21/Go 包安装问题/","link":"","permalink":"https://elihe2011.github.io/2018/01/21/Go%20%E5%8C%85%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/","excerpt":"1. 使用gopm镜像安装123go get -v github.com/gpmgo/gopmgopm get -v golang.org/x/tools/cmd/goimports","text":"1. 使用gopm镜像安装123go get -v github.com/gpmgo/gopmgopm get -v golang.org/x/tools/cmd/goimports 2. 开启代理安装123456git config --global http.proxy socks5://127.0.0.1:1080http_proxy=socks5://127.0.0.1:1080go get -v golang.org/x/tools/cmd/goimportsgit config --global --unset http.proxy","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go RPC","slug":"Go RPC","date":"2018-01-20T02:30:12.000Z","updated":"2021-06-22T10:50:49.709Z","comments":true,"path":"2018/01/20/Go RPC/","link":"","permalink":"https://elihe2011.github.io/2018/01/20/Go%20RPC/","excerpt":"1. RPC 客户端(client): 服务调用的发起方 客户端存根(client Stub): 运行在客户端机器上 存储调用服务器地址 将客户端请求数据信息打包 通过网络发给服务端存根程序 接收服务端响应的数据包，解析后给客户端 服务端(server): 服务提供者 服务端存根(server Stub): 存在与服务端机器上 接收客户端Stub程序发送来请求消息数据包 调用服务端的程序方法 将结果打包成数据包发给客户端Stub程序","text":"1. RPC 客户端(client): 服务调用的发起方 客户端存根(client Stub): 运行在客户端机器上 存储调用服务器地址 将客户端请求数据信息打包 通过网络发给服务端存根程序 接收服务端响应的数据包，解析后给客户端 服务端(server): 服务提供者 服务端存根(server Stub): 存在与服务端机器上 接收客户端Stub程序发送来请求消息数据包 调用服务端的程序方法 将结果打包成数据包发给客户端Stub程序 2. Go 语言实现 RPC Golang 提供RPC标准包，支持开发 RPC 服务端和客户端，采用 gob 编码。 支持三种请求方式：HTTP、TCP 和 JSONRPC Golang RPC 函数必须特定的格式写法才能被远程调用，格式如下： 1func (t *T) MethodName(argType T1, replyType *T2) error T1 和 T2 必须能被 encoding/gob 包编码和解码 3. RPC HTTP 调用 (异步调用)3.1 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445type Arguments struct &#123; A int B int&#125;type DemoRpc struct &#123;&#125;func (d *DemoRpc) Add(req Arguments, resp *int) error &#123; *resp = req.A + req.B return nil&#125;func (d *DemoRpc) Minus(req Arguments, resp *int) error &#123; *resp = req.A - req.B return nil&#125;func (d *DemoRpc) Div(req Arguments, resp *int) error &#123; // simulate time-consuming operations for i := 0; i &lt; 5; i++ &#123; log.Printf(&quot;Round %d, sleeping...\\n&quot;, i) time.Sleep(time.Second) &#125; if req.B == 0 &#123; return errors.New(&quot;divided by zero&quot;) &#125; *resp = req.A / req.B log.Printf(&quot;Div done.&quot;) return nil&#125;func main() &#123; //rpc.Register(new(DemoRpc)) rpc.RegisterName(&quot;DemoRpc&quot;, new(DemoRpc)) // same as above rpc.HandleHTTP() err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatal(err.Error()) &#125;&#125; 3.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type Arguments struct &#123; A int B int&#125;func main() &#123; client, err := rpc.DialHTTP(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; args := Arguments&#123;5, 7&#125; var resp int err = client.Call(&quot;DemoRpc.Add&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Add(%d, %d): %v\\n&quot;, args.A, args.B, resp) err = client.Call(&quot;DemoRpc.Minus&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Minus(%d, %d): %v\\n&quot;, args.A, args.B, resp) args = Arguments&#123;5, 0&#125;/* err = client.Call(&quot;DemoRpc.Div&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Div(%d, %d): %v\\n&quot;, args.A, args.B, resp)*/ // async call := client.Go(&quot;DemoRpc.Div&quot;, args, &amp;resp, nil) for &#123; select &#123; case &lt;-call.Done: if call.Error != nil &#123; log.Fatal(call.Error.Error()) &#125; log.Printf(&quot;DemoRpc Div(%d, %d): %v\\n&quot;, args.A, args.B, resp) return default: log.Println(&quot;waiting...&quot;) time.Sleep(time.Second) &#125; &#125;&#125; 4. JSONRPC4.1 服务端1234567891011121314151617181920212223242526272829303132type JsonParams struct &#123; X int Y int&#125;type JsonRpc struct&#123;&#125;func (*JsonRpc) Add(req JsonParams, resp *int) error &#123; *resp = req.X + req.Y return nil&#125;func main() &#123; rpc.RegisterName(&quot;JsonRpc&quot;, new(JsonRpc)) ln, err := net.Listen(&quot;tcp&quot;, &quot;:8081&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; for &#123; conn, err := ln.Accept() if err != nil &#123; log.Println(err.Error()) continue &#125; log.Printf(&quot;%v connected\\n&quot;, conn.RemoteAddr().String()) go jsonrpc.ServeConn(conn) &#125;&#125; 4.2 客户端 （Golang)123456789101112131415161718192021type JsonParams struct &#123; X int Y int&#125;func main() &#123; client, err := jsonrpc.Dial(&quot;tcp&quot;, &quot;:8081&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; req := JsonParams&#123;2, 8&#125; var resp int err = client.Call(&quot;JsonRpc.Add&quot;, req, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;JsonRpc.Add(%d, %d): %d\\n&quot;, req.X, req.Y, resp)&#125; 4.3 客户端 (Python)12345678910111213141516def main(): client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect((&#x27;localhost&#x27;, 8081)) payload = &#123; &quot;method&quot;: &quot;JsonRpc.Add&quot;, &quot;params&quot;: [&#123;&#x27;X&#x27;: 1, &#x27;Y&#x27;: 7&#125;], &quot;jsonrpc&quot;: &quot;1.0&quot;, &quot;id&quot;: 0, &#125; client.send(json.dumps(payload).encode(&#x27;utf-8&#x27;)) data = client.recv(1024) msg = json.loads(data.decode(&#x27;utf-8&#x27;)) print(msg.get(&#x27;result&#x27;)) 4.4 客户端 （Telnet)1234567$ telnet localhost 8081&#123;&quot;method&quot;: &quot;JsonRpc.Div&quot;, &quot;params&quot;: [&#123;&quot;X&quot;:5,&quot;Y&quot;:3&#125;], &quot;id&quot;: 1&#125;&#123;&quot;id&quot;:1,&quot;result&quot;:null,&quot;error&quot;:&quot;rpc: can&#x27;t find method JsonRpc.Div&quot;&#125;&#123;&quot;method&quot;: &quot;JsonRpc.Add&quot;, &quot;params&quot;: [&#123;&quot;X&quot;:5,&quot;Y&quot;:3&#125;], &quot;id&quot;: 1&#125;&#123;&quot;id&quot;:1,&quot;result&quot;:8,&quot;error&quot;:null&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go 字符编码","slug":"Go 字符编码","date":"2018-01-19T14:29:54.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/19/Go 字符编码/","link":"","permalink":"https://elihe2011.github.io/2018/01/19/Go%20%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","excerpt":"","text":"1. 编码检测库：1234567export http_proxy=socks5://127.0.0.1:1080 # 编码转换go get -v golang.org/x/text# 检测html编码go get -v golang.org/x/net/html 2. 字符编码转换：1234567891011121314151617181920212223242526272829303132333435func main() &#123; resp, err := http.Get(&quot;https://www.zhenai.com//zhenghun&quot;) if err != nil &#123; panic(err) &#125; defer resp.Body.Close() if resp.StatusCode != http.StatusOK &#123; fmt.Println(&quot;Error: status code&quot;, resp.StatusCode) &#125; // 为避免Peek函数影响底层io.Reader的文件指针位置，先转换为缓存Reader bufReader := bufio.NewReader(resp.Body) // 获取编码类型 e := determineEncoding(bufReader) // 编码类型转换 utf8Reader := transform.NewReader(bufReader, e.NewDecoder()) bytes, err := ioutil.ReadAll(utf8Reader) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%s\\n&quot;, bytes)&#125;func determineEncoding(r *bufio.Reader) encoding.Encoding &#123; bytes, err := r.Peek(1024) if err != nil &#123; panic(err) &#125; e, _, _ := charset.DetermineEncoding(bytes, &quot;html&quot;) return e&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 集成ElasticSearch","slug":"Go 集成ElasticSearch","date":"2018-01-18T04:20:00.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/18/Go 集成ElasticSearch/","link":"","permalink":"https://elihe2011.github.io/2018/01/18/Go%20%E9%9B%86%E6%88%90ElasticSearch/","excerpt":"","text":"1. 简介 全文搜索引擎 快速存储、搜索和分析海量数据 存储json格式文档 1.1 ElasticSearch数据库 &lt;server&gt;:9200/index/type/id index -&gt; database type -&gt; table &lt;server&gt;:9200/index/type/_search?q= 全文搜索 1.2 安装elastic client:1go get gopkg.in/olivere/elastic.v5 2. 安装ElasticSearch服务器2.1 使用Docker方式安装12345docker login daocloud.iodocker pull daocloud.io/library/elasticsearch:7.3.2docker run -d -p 9200:9200 daocloud.io/library/elasticsearch","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://elihe2011.github.io/tags/elasticsearch/"}]},{"title":"Go标准库 http","slug":"Go 标准库http","date":"2018-01-17T04:11:18.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/17/Go 标准库http/","link":"","permalink":"https://elihe2011.github.io/2018/01/17/Go%20%E6%A0%87%E5%87%86%E5%BA%93http/","excerpt":"","text":"1. 客户端Http Client: http.GET(url) 直接发起请求 http.Client{} 控制请求头部等 httputil 简化工作 示例： 123456789101112131415161718192021222324252627282930313233func main() &#123; // 1. 直接发起请求 //resp, err := http.Get(&quot;https://baidu.com&quot;) // 2. 控制请求头 req, err := http.NewRequest( http.MethodGet, &quot;http://www.baidu.com&quot;, nil) req.Header.Add(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1&quot;) //resp, err := http.DefaultClient.Do(req) // 3. 检测是否重定向 client := http.Client&#123; CheckRedirect: func(req *http.Request, via []*http.Request) error &#123; fmt.Println(&quot;Redirect:&quot;, req) return nil &#125;, &#125; resp, err := client.Do(req) if err != nil &#123; panic(err) &#125; defer resp.Body.Close() content, err := httputil.DumpResponse(resp, true) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%s&quot;, content)&#125; 2. 服务端2.1 handler函数12345678910111213141516171819202122232425262728func SignupHandler(w http.ResponseWriter, r *http.Request) &#123; if r.Method == http.MethodGet &#123; data, err := ioutil.ReadFile(&quot;./static/view/signup.html&quot;) if err != nil &#123; w.WriteHeader(http.StatusInternalServerError) return &#125; w.Write(data) &#125; else &#123; r.ParseForm() // 必须的 username := r.Form.Get(&quot;username&quot;) password := r.Form.Get(&quot;password&quot;) if len(username) &lt; 3 || len(password) &lt; 5 &#123; w.Write([]byte(&quot;Invalid parameter&quot;)) return &#125; enc_pwd := util.Sha1([]byte(password + pwd_salt)) ret := db.UserSignup(username, enc_pwd) if ret &#123; w.Write([]byte(&quot;SUCCESS&quot;)) &#125; else &#123; w.Write([]byte(&quot;FAILED&quot;)) &#125; &#125;&#125; 2.2 中间件123456789101112131415func HTTPInterceptor(h http.HandlerFunc) http.HandlerFunc &#123; return http.HandlerFunc( func(w http.ResponseWriter, r *http.Request) &#123; r.ParseForm() username := r.Form.Get(&quot;username&quot;) token := r.Form.Get(&quot;token&quot;) if len(username) &lt; 3 || !IsTokenValid(token) &#123; w.WriteHeader(http.StatusForbidden) return &#125; h(w, r) &#125;)&#125; 2.3 启动服务123456789101112131415func main() &#123; // 静态文件 path, _ := os.Getwd() path = filepath.Join(path, &quot;static&quot;) http.Handle(&quot;/static/&quot;, http.StripPrefix(&quot;/static/&quot;, http.FileServer(http.Dir(path)))) // 路由和中间件 http.HandleFunc(&quot;/user/signup&quot;, handler.SignupHandler) http.HandleFunc(&quot;/user/info&quot;, handler.HTTPInterceptor(handler.UserInfoHandler)) err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatalf(&quot;Failed to start server: %v&quot;, err) &#125;&#125; 3. http服务器性能分析 import _ &quot;net/http/pprof 访问/debug/pprof/ 使用go tool pprof分析性能 1234567import ( &quot;log&quot; &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;os&quot; ...) 查看性能： http://localhost:8080/debug/pprof/ go tool pprof http://localhost:8080/debug/pprof/profile","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 标准库unsafe","slug":"Go 标准库unsafe","date":"2018-01-16T04:11:18.000Z","updated":"2021-06-22T10:50:49.707Z","comments":true,"path":"2018/01/16/Go 标准库unsafe/","link":"","permalink":"https://elihe2011.github.io/2018/01/16/Go%20%E6%A0%87%E5%87%86%E5%BA%93unsafe/","excerpt":"1. unsafe包Go是强类型语言，不允许不同类型的指针互相转换。但它提供unsafe包作为中间媒介，快速实现类型转换，但该转换是不安全的。 1.1 Go指针和unsafe.Pointer的区别Go指针： 不能进行数学运算 不同类型的指针，不能相互转换 不同类型的指针不能使用 == 或 != 比较 不同类型的指针变量不能相互赋值 unsafe.Pointer: 12type ArbitraryType inttype Pointer *ArbitraryType","text":"1. unsafe包Go是强类型语言，不允许不同类型的指针互相转换。但它提供unsafe包作为中间媒介，快速实现类型转换，但该转换是不安全的。 1.1 Go指针和unsafe.Pointer的区别Go指针： 不能进行数学运算 不同类型的指针，不能相互转换 不同类型的指针不能使用 == 或 != 比较 不同类型的指针变量不能相互赋值 unsafe.Pointer: 12type ArbitraryType inttype Pointer *ArbitraryType uintptr: Go的内置类型，能存储指针的整型，与普通指针区别如下 1type uintptr uintptr 普通指针不可以参与计算，但uintptr可以。 普通指针和uintptr之间必选进行强制转换。 GC 不会把uintptr当成指针，由uintptr变量表示的地址处的数据也可能被GC回收。 1.2 主要方法123456789101112type ArbitraryType inttype Pointer *ArbitraryType// 返回类型所占内存大小func Sizeof（variable ArbitraryType）uintptr // 返回类型的对齐值, 等价于reflect.TypeOf(x).Align()func Alignof（variable ArbitraryType）uintptr// struct结构体中的字段相对于结构体的内存位置偏移量。结构体的第一个字段的偏移量都是0.// 等价于reflect.TypeOf(u1).Field(i).Offsetfunc Offsetof（selector ArbitraryType）uintptr 2. 指针转换2.1 示例：int32指针指向int64数据123456789101112131415func main() &#123; var n int64 = 5 var p1 = &amp;n var p2 = (*int32)(unsafe.Pointer(p1)) // 类型虽然不一样，但指向同一个地址 fmt.Printf(&quot;p1=%v, p2=%v\\n&quot;, p1, p2) *p2 = 10 fmt.Printf(&quot;n=%v, *p1=%v, *p2=%v\\n&quot;, n, *p1, *p2) // *p2 越界 *p1 = math.MaxInt32 + 1 fmt.Printf(&quot;n=%v, *p1=%v, *p2=%v\\n&quot;, n, *p1, *p2)&#125; 2.2 示例：遍历数组元素1234567891011func main() &#123; a := [...]int&#123;4, 7, 2, 9, 5&#125; p := &amp;a[0] fmt.Printf(&quot;%p: %v\\n&quot;, p, *p) for i := 1; i &lt; len(a); i++ &#123; ptr := uintptr(unsafe.Pointer(p)) + unsafe.Sizeof(a[0]) p = (*int)(unsafe.Pointer(ptr)) fmt.Printf(&quot;%p: %v\\n&quot;, p, *p) &#125;&#125; 3. 类型对齐值1234567891011121314151617181920212223func main() &#123; var b bool var i int var i64 int64 var f float32 var f64 float64 var s string var m map[int]string // 固定8 var a []int var p *int32 fmt.Println(unsafe.Alignof(b)) // 1 fmt.Println(unsafe.Alignof(i)) // 8 fmt.Println(unsafe.Alignof(i64)) // 8 fmt.Println(unsafe.Alignof(f)) // 4 fmt.Println(unsafe.Alignof(f64)) // 8 fmt.Println(unsafe.Alignof(s)) // 8 fmt.Println(unsafe.Alignof(m)) // 8 fmt.Println(unsafe.Alignof(a)) // 8 fmt.Println(unsafe.Alignof(p)) // 8&#125; 4. 利用unsafe包修改私有成员结构体(struct)，可以通过offset函数获取成员的偏移量，进而获取成员的地址。读写该地址的内存，就可以达到改变成员值的目的 结构体内存分配：会被分配一块连续的内存，结构体的地址也代表了第一个成员的地址。 12345678910111213141516type User struct &#123; name string age int&#125;func main() &#123; user := User&#123;&quot;eli&quot;, 29&#125; name := (*string)(unsafe.Pointer(&amp;user)) *name = &quot;rania&quot; age := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;user)) + unsafe.Offsetof(user.age))) *age = 20 fmt.Println(user)&#125; 5. 获取slice的长度12345678// runtime/slice.gotype slice struct &#123; array unsafe.Pointer // offset=8 len int cap int&#125;func makeslice(et *_type, len, cap int) slice 12345678910func main() &#123; s := make([]int, 5, 10) fmt.Printf(&quot;%p\\n&quot;, &amp;s) Len := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(8))) fmt.Printf(&quot;Len=%d, len(s)=%d\\n&quot;, *Len, len(s)) Cap := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(16))) fmt.Printf(&quot;Cap=%d, cap(s)=%d\\n&quot;, *Cap, cap(s))&#125; 6. 获取map长度12345678910111213141516type hmap struct &#123; count int flags uint8 B uint8 noverflow uint16 hash0 uint32 buckets unsafe.Pointer oldbuckets unsafe.Pointer nevacuate uintptr extra *mapextra&#125;// 注意返回的是指针func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap 12345678func main() &#123; mp := make(map[string]int) mp[&quot;a&quot;] = 21 mp[&quot;z&quot;] = 45 count := **(**int)(unsafe.Pointer(&amp;mp)) // 二级指针 fmt.Println(count, len(mp)) // 2 2&#125; 7. 实现字符串和byte切片的零拷贝转换slice和string的底层数据结构： 123456789101112131415161718192021222324252627282930313233type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125;func string2bytes(s string) []byte &#123; stringHeader := (*reflect.StringHeader)(unsafe.Pointer(&amp;s)) bh := reflect.SliceHeader&#123; Data: stringHeader.Data, Len: stringHeader.Len, Cap: stringHeader.Len, &#125; return *(*[]byte)(unsafe.Pointer(&amp;bh))&#125;func bytes2string(b []byte) string &#123; sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(&amp;b)) sh := reflect.StringHeader&#123; Data: sliceHeader.Data, Len: sliceHeader.Len, &#125; return *(*string)(unsafe.Pointer(&amp;sh))&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 单元测试","slug":"Go 单元测试","date":"2018-01-15T01:27:53.000Z","updated":"2021-06-22T10:50:49.707Z","comments":true,"path":"2018/01/15/Go 单元测试/","link":"","permalink":"https://elihe2011.github.io/2018/01/15/Go%20%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","excerpt":"1. 基础测试1.1 最简单的测试1234567func Add(x, y int) int &#123; return x + y&#125;func Sub(x, y int) int &#123; return x - y&#125;","text":"1. 基础测试1.1 最简单的测试1234567func Add(x, y int) int &#123; return x + y&#125;func Sub(x, y int) int &#123; return x - y&#125; 12345678910111213141516171819func TestAdd(t *testing.T) &#123; result := Add(3, 5) if result != 8 &#123; t.Fatalf(&quot;expected: %d, actual: %d&quot;, 8, result) &#125; t.Log(&quot;test Add success.&quot;)&#125;func TestSub(t *testing.T) &#123; result := Sub(3, 5) if result != -2 &#123; t.Fatalf(&quot;expected: %d, actual: %d&quot;, -2, result) &#125; t.Log(&quot;test Sub success.&quot;)&#125; 1234567go testgo test -vgo test -v -run TestAddgo help testflag 1.2 表格驱动测试123456789101112131415func TestAddBatch(t *testing.T) &#123; tests := []struct&#123; a, b, c int &#125;&#123; &#123;1, 2, 3&#125;, &#123;0, 2, 2&#125;, &#123;-1, 1, 1&#125;, &#125; for _, test := range tests &#123; if actual := Add(test.a, test.b); actual != test.c &#123; t.Errorf(&quot;Add(%d, %d); got %d; expected %d\\n&quot;, test.a, test.b, actual, test.c) &#125; &#125;&#125; 1.3 覆盖率测试123go test -coverprofile=c.outgo tool cover -html=c.out 1.4 Example Code测试1234567func Fib(n int) int &#123; if n &lt;= 2 &#123; return 1 &#125; return Fib(n-1) + Fib(n-2)&#125; 12345func ExampleFib() &#123; fmt.Println(fib(10)) // Output: 55&#125; 1go test -v 2. 基准测试基准测可以测试一段程序的运行性能及耗费CPU的程度 1234567891011121314151617181920212223242526272829303132333435363738func fib(n int) int &#123; a, b := 1, 1 for i := 1; i &lt;= n; i++ &#123; if i == n &#123; break &#125; a, b = b, a+b &#125; return a&#125;func fibonacci() func() int &#123; a, b := 1, 1 return func() int &#123; x := a a, b = b, a+b return x &#125;&#125;func fib2(n int) int &#123; x := 0 f := fibonacci() for i := 1; i &lt;= n; i++ &#123; x = f() &#125; return x&#125;func fib3(n int) int &#123; if n &lt;= 2 &#123; return 1 &#125; return fib3(n-1) + fib3(n-2)&#125; 1234567891011121314151617181920212223242526272829303132333435func BenchmarkFib(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib(n) if actual != expected &#123; b.Errorf(&quot;fib(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125;func BenchmarkFib2(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib2(n) if actual != expected &#123; b.Errorf(&quot;fib2(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125;func BenchmarkFib3(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib3(n) if actual != expected &#123; b.Errorf(&quot;fib3(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125; 123456789101112go test -bench=.BenchmarkFib-4 222371659 5.33 ns/opBenchmarkFib2-4 13082476 85.9 ns/opBenchmarkFib3-4 10054833 120 ns/op# 自定义测试时间go test -bench=. -benchmem -benchtime=10sBenchmarkFib-4 1000000000 5.35 ns/op 0 B/op 0 allocs/opBenchmarkFib2-4 138880591 87.1 ns/op 48 B/op 3 allocs/opBenchmarkFib3-4 97723549 120 ns/op 0 B/op 0 allocs/op ns/op 表示每一个操作消耗多少时间,单位是 纳秒ns B/op 表示每一次操作需要分配的字节数 allocs/op 表示每次执行分配了多少次 1234go test -bench . -cpuprofile=cpu.outgo tool pprof cpu.out(pprof) web 2.1 性能对比，int转string123456789101112131415161718192021222324func BenchmarkSprintf(b *testing.B) &#123; num := 10 b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; fmt.Sprintf(&quot;%d&quot;, num) &#125;&#125;func BenchmarkFormat(b *testing.B) &#123; num := int64(10) b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; strconv.FormatInt(num, 10) &#125;&#125;func BenchmarkItoa(b *testing.B) &#123; num := 10 b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; strconv.Itoa(num) &#125;&#125; 123456789 go test -bench=. -benchmemgoos: darwingoarch: amd64pkg: gomod/aaaBenchmarkSprintf-4 12190561 94.1 ns/op 16 B/op 2 allocs/opBenchmarkFormat-4 275836423 4.24 ns/op 0 B/op 0 allocs/opBenchmarkItoa-4 253071742 4.73 ns/op 0 B/op 0 allocs/opPASSok gomod/aaa 5.386s 2.2 pprof 性能监控12345678910111213func Fib(n int) int &#123; if n &lt; 2 &#123; return n &#125; return Fib(n-1) + Fib(n-2)&#125;func BenchmarkFib(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; Fib(10) &#125;&#125; 1234567go test -bench=. -benchmem -cpuprofile cpu.out -memprofile mem.outgo tool pprof cpu.out (pprof) top(pprof) list Fibgo tool pprof -http=&quot;:8081&quot; cpu.out 3. gomock当待测试的函数/对象的依赖关系很复杂，并且有些依赖不能直接创建，例如数据库连接、文件I/O等。这种场景就非常适合使用 mock/stub 测试。简单来说，就是用 mock 对象模拟依赖项的行为。 3.1 安装12go get -u github.com/golang/mock/gomockgo get -u github.com/golang/mock/mockgen 3.2 示例3.2.1 待mock的代码1234567891011type DB interface &#123; Get(key string) (int, error)&#125;func GetFromDB(db DB, key string) int &#123; if value, err := db.Get(key); err == nil &#123; return value &#125; return -1&#125; 3.2.2 生成mock代码1mockgen -source=db.go -destination=db_mock.go -package=main 3.2.3 测试代码1234567891011func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;)) if v := GetFromDB(m, &quot;Tom&quot;); v != -1 &#123; t.Fatalf(&quot;expected -1, but go %v&quot;, v) &#125;&#125; 3.2.4 执行测试123456$ go test . -cover -v=== RUN TestGetFromDB--- PASS: TestGetFromDB (0.00s)PASScoverage: 92.9% of statementsok gomod/mock 1.030s coverage: 92.9% of statements 3.3 打桩 (stubs)3.3.1 参数 (Eq, Any, Not, Nil)1234m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;))m.EXPECT().Get(gomock.Any()).Return(630, nil)m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil) m.EXPECT().Get(gomock.Nil()).Return(0, errors.New(&quot;nil&quot;)) 3.3.2 返回值 (Return, Do, DoAndReturn)12345678910m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil)m.EXPECT().Get(gomock.Any()).Do(func(key string) &#123; t.Log(key)&#125;)m.EXPECT().Get(gomock.Any()).DoAndReturn(func(key string) (int, error) &#123; if key == &quot;Sam&quot; &#123; return 630, nil &#125; return 0, errors.New(&quot;not exist&quot;)&#125;) 3.3.3 调用次数 (Times, MaxTimes, MinTimes, AnyTimes)123456789func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil).Times(2) GetFromDB(m, &quot;ABC&quot;) GetFromDB(m, &quot;DEF&quot;)&#125; 调用顺序 (InOrder)1234567891011func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() // 断言 DB.Get() 方法是否被调用 m := NewMockDB(ctrl) o1 := m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;)) o2 := m.EXPECT().Get(gomock.Eq(&quot;Sam&quot;)).Return(630, nil) gomock.InOrder(o1, o2) GetFromDB(m, &quot;Tom&quot;) GetFromDB(m, &quot;Sam&quot;)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 正则表达式","slug":"Go 正则表达式","date":"2018-01-12T01:26:38.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/12/Go 正则表达式/","link":"","permalink":"https://elihe2011.github.io/2018/01/12/Go%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"1. 正则表达式12345678func main() &#123; str := `171.43.145.13 - - [10/Mar/2020:10:19:06 +0800] &quot;POST /api/user/detail HTTP/1.1&quot; 200 252 &quot;-&quot; &quot;LifePlanner/1.9.14 (com.njivtime.lifeplanner; build:1.9.14.9; iOS 13.3.1) Alamofire/4.8.2&quot; &quot;-&quot; 0.009 0.009` re := regexp.MustCompile(`\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\s`) arr := re.FindAllString(str, -1) fmt.Println(arr)&#125;","text":"1. 正则表达式12345678func main() &#123; str := `171.43.145.13 - - [10/Mar/2020:10:19:06 +0800] &quot;POST /api/user/detail HTTP/1.1&quot; 200 252 &quot;-&quot; &quot;LifePlanner/1.9.14 (com.njivtime.lifeplanner; build:1.9.14.9; iOS 13.3.1) Alamofire/4.8.2&quot; &quot;-&quot; 0.009 0.009` re := regexp.MustCompile(`\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\s`) arr := re.FindAllString(str, -1) fmt.Println(arr)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 序列化操作","slug":"Go 序列化操作","date":"2018-01-11T01:24:54.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/11/Go 序列化操作/","link":"","permalink":"https://elihe2011.github.io/2018/01/11/Go%20%E5%BA%8F%E5%88%97%E5%8C%96%E6%93%8D%E4%BD%9C/","excerpt":"1. 序列化json.Marshal(v interface&#123;&#125;) ([]byte, error)","text":"1. 序列化json.Marshal(v interface&#123;&#125;) ([]byte, error) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172type Person struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;` Birthday string `json:&quot;birthday&quot;` Salary float64 `json:&quot;salary&quot;` Occupation string `json:&quot;occupation&quot;`&#125;func main() &#123; serializeStruct() serializeMap() serializeSlice()&#125;func serializeStruct() &#123; p := Person&#123; Name: &quot;张三&quot;, Age: 45, Birthday: &quot;1975-05-01&quot;, Salary: 32000.0, Occupation: &quot;电气工程师&quot;, &#125; data, err := json.Marshal(&amp;p) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125;func serializeMap() &#123; var m map[string]interface&#123;&#125; m = make(map[string]interface&#123;&#125;) m[&quot;name&quot;] = &quot;李四&quot; m[&quot;age&quot;] = 30 m[&quot;city&quot;] = &quot;北京市&quot; data, err := json.Marshal(m) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125;func serializeSlice() &#123; var s []map[string]interface&#123;&#125; m1 := make(map[string]interface&#123;&#125;) m1[&quot;name&quot;] = &quot;Tom&quot; m1[&quot;age&quot;] = 17 m1[&quot;city&quot;] = &quot;Los Angles&quot; m2 := make(map[string]interface&#123;&#125;) m2[&quot;name&quot;] = &quot;Julie&quot; m2[&quot;age&quot;] = 21 m2[&quot;city&quot;] = &quot;New York&quot; s = append(s, m1, m2) data, err := json.Marshal(s) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125; 2. 反序列化json.Unmarshal(data []byte, v interface&#123;&#125;) error 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type Person struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;` Birthday string `json:&quot;birthday&quot;` Salary float64 `json:&quot;salary&quot;` Occupation string `json:&quot;occupation&quot;`&#125;func main() &#123; deserializeStruct() deserializeMap() deserializeSlice()&#125;func deserializeStruct() &#123; js := `&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:45,&quot;birthday&quot;:&quot;1975-05-01&quot;,&quot;salary&quot;:32000,&quot;occupation&quot;:&quot;电气工程师&quot;&#125;` var p Person err := json.Unmarshal([]byte(js), &amp;p) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(p)&#125;func deserializeMap() &#123; js := `&#123;&quot;age&quot;:30,&quot;city&quot;:&quot;北京市&quot;,&quot;name&quot;:&quot;李四&quot;&#125;` var m map[string]interface&#123;&#125; // 反序列化不需要make，注意使用指针 &amp;m err := json.Unmarshal([]byte(js), &amp;m) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(m)&#125;func deserializeSlice() &#123; js := `[&#123;&quot;age&quot;:17,&quot;city&quot;:&quot;Los Angles&quot;,&quot;name&quot;:&quot;Tom&quot;&#125;,&#123;&quot;age&quot;:21,&quot;city&quot;:&quot;New York&quot;,&quot;name&quot;:&quot;Julie&quot;&#125;]` var s []map[string]interface&#123;&#125; // 反序列化不需要make，注意使用指针 &amp;s err := json.Unmarshal([]byte(js), &amp;s) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(s)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 网络编程","slug":"Go 网络编程","date":"2018-01-10T01:13:45.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/10/Go 网络编程/","link":"","permalink":"https://elihe2011.github.io/2018/01/10/Go%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","excerpt":"1. 网络编程1234567net.Listen(network, address string) (Listener, error)listener.Accept() (Conn, err)conn.Close()conn.Read([]byte) (int, err)conn.Write([]byte)net.Dial(network, address string) (Conn, error)","text":"1. 网络编程1234567net.Listen(network, address string) (Listener, error)listener.Accept() (Conn, err)conn.Close()conn.Read([]byte) (int, err)conn.Write([]byte)net.Dial(network, address string) (Conn, error) 1.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546func main() &#123; ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;Server has started, listening on %s\\n&quot;, ln.Addr()) defer ln.Close() for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; handleConnect(conn) &#125;&#125;func handleConnect(conn net.Conn) &#123; defer conn.Close() remoteAddr := conn.RemoteAddr() fmt.Printf(&quot;[%s] connected\\n&quot;, remoteAddr) for &#123; buf := make([]byte, 2048) n, err := conn.Read(buf) if err != nil &#123; fmt.Printf(&quot;[%s] disconnected\\n&quot;, remoteAddr) break &#125; str := string(buf[:n-1]) if str == &quot;quit&quot; || str == &quot;exit&quot; &#123; fmt.Printf(&quot;[%s] disconnected\\n&quot;, remoteAddr) break &#125; fmt.Printf(&quot;%s &gt;&gt; %s\\n&quot;, remoteAddr, str) conn.Write([]byte(strings.ToUpper(str + &quot;\\n&quot;))) &#125;&#125; 1.2 客户端123456789101112131415161718192021222324252627282930313233func main() &#123; conn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 键盘输入，并发送给服务器 go func() &#123; buf := make([]byte, 1024) for &#123; n, err := os.Stdin.Read(buf) if err != nil &#123; fmt.Println(err) break &#125; conn.Write(buf[:n]) &#125; &#125;() // 处理服务器返回数据 buf := make([]byte, 1024) for &#123; n, err := conn.Read(buf) if err == io.EOF &#123; return &#125; fmt.Println(string(buf[:n-1])) &#125;&#125; 2. 文件发送与接收2.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273func main() &#123; // 开启服务 ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() fmt.Printf(&quot;[%s]等待接收文件...\\n&quot;, ln.Addr()) // 接收请求 conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 获取对方发送的文件名 buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; fileName := string(buf[:n]) fmt.Printf(&quot;文件名: [%s]\\n&quot;, fileName) // 通知对方发送文件内容 _, err = conn.Write([]byte(&quot;ok&quot;)) if err != nil &#123; fmt.Println(err) return &#125; // 接收文件内容 recvFile(fileName, conn)&#125;func recvFile(fileName string, conn net.Conn) &#123; // 创建文件 f, err := os.Create(fileName) if err != nil &#123; fmt.Println(err) return &#125; defer f.Close() buf := make([]byte, 1024*4) for &#123; n, err := conn.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;\\n文件接收完毕&quot;) &#125; else &#123; fmt.Println(err) &#125; break &#125; if n == 0 &#123; fmt.Println(&quot;文件接收完毕&quot;) break &#125; fmt.Printf(&quot;.&quot;) _, err = f.Write(buf[:n]) if err != nil &#123; fmt.Println(&quot;写文件失败&quot;) &#125; &#125;&#125; 2.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func main() &#123; fmt.Printf(&quot;请输入文件名: &quot;) var fileName string fmt.Scan(&amp;fileName) // 获取文件信息 info, err := os.Stat(fileName) if err != nil &#123; fmt.Println(err) return &#125; // 连接文件接收服务器 conn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 发送文件名 _, err = conn.Write([]byte(info.Name())) // 服务器是否就绪 buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; if &quot;ok&quot; != string(buf[:n]) &#123; fmt.Println(&quot;服务器未就绪&quot;) return &#125; // 发送文件内容 sendFile(fileName, conn)&#125;func sendFile(fileName string, conn net.Conn) &#123; f, err := os.Open(fileName) if err != nil &#123; fmt.Println(err) return &#125; defer f.Close() buf := make([]byte, 1024*4) for &#123; _, err = f.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;发送完毕&quot;) &#125; else &#123; fmt.Println(err) &#125; break &#125; // 发送内容 conn.Write(buf) &#125;&#125; 3. 聊天服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145func main() &#123; // 开启监听服务 ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() // 转发消息 go Manager() // 主协程，循环阻塞等待用户连接 for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; go HandleConn(conn) &#125;&#125;// 客户端type Client struct &#123; C chan string Name string Addr string&#125;// 在线用户var onlineMap map[string]Client// 消息var message = make(chan string)// 消息转发func Manager() &#123; // 在线用户分配空间 onlineMap = make(map[string]Client) for &#123; msg := &lt;-message for _, cli := range onlineMap &#123; cli.C &lt;- msg &#125; &#125;&#125;func HandleConn(conn net.Conn) &#123; defer conn.Close() // 客户端地址 cliAddr := conn.RemoteAddr().String() // 客户端 cli := Client&#123; make(chan string), cliAddr, cliAddr, &#125; // 添加到在线用户 onlineMap[cliAddr] = cli // 新开协程，专门给当前客户端发送信息 go WriteMsgToClient(cli, conn) // 广播在线 message &lt;- MakeMsg(cli, &quot;online&quot;) // 当前用户是否已退出 isQuit := make(chan bool) // 当前用户是否超时 hasData := make(chan bool) // 新开协程，接收用户发来的数据 go func() &#123; buf := make([]byte, 2048) for &#123; n, err := conn.Read(buf) if n == 0 &#123; isQuit &lt;- true fmt.Println(&quot;用户断开连接或出现其他问题&quot;, err) return &#125; msg := string(buf[:n-1]) // 查询当前在线用户列表 if msg == &quot;who&quot; &#123; // 给当前用户发送所有在线成员 conn.Write([]byte(&quot;user list:\\n&quot;)) for _, u := range onlineMap &#123; conn.Write([]byte(u.Addr + &quot;: &quot; + u.Name + &quot;\\n&quot;)) &#125; &#125; else if len(msg) &gt; 8 &amp;&amp; msg[:6] == &quot;rename&quot; &#123; name := msg[7:] cli.Name = name onlineMap[cliAddr] = cli conn.Write([]byte(&quot;rename ok\\n&quot;)) &#125; else &#123; // 转发内容至其他在线用户 message &lt;- MakeMsg(cli, msg) &#125; hasData &lt;- true &#125; &#125;() for &#123; select &#123; case &lt;-isQuit: // 从在线用户列表中删除 delete(onlineMap, cliAddr) // 发送广播通知 message &lt;- MakeMsg(cli, &quot;offline&quot;) return case &lt;-hasData: case &lt;-time.After(time.Second * 60): delete(onlineMap, cliAddr) message &lt;- MakeMsg(cli, &quot;timeout&quot;) return &#125; &#125;&#125;func WriteMsgToClient(cli Client, conn net.Conn) &#123; for msg := range cli.C &#123; conn.Write([]byte(msg + &quot;\\n&quot;)) &#125;&#125;func MakeMsg(cli Client, msg string) string &#123; return &quot;[&quot; + cli.Addr + &quot;]&quot; + cli.Name + &quot;: &quot; + msg&#125; 4. HTTP服务器4.1 服务器123456789101112131415161718192021222324252627282930313233func main() &#123; ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() fmt.Println(&quot;http://localhost:8080&quot;) for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; go handleConn(conn) &#125;&#125;func handleConn(conn net.Conn) &#123; defer conn.Close() buf := make([]byte, 1024*4) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;%v\\n&quot;, string(buf[:n]))&#125; 12345678910111213141516func main() &#123; // 注册处理函数 http.HandleFunc(&quot;/go&quot;, myHandler) fmt.Println(&quot;http://localhost:8080&quot;) http.ListenAndServe(&quot;:8080&quot;, nil)&#125;func myHandler(w http.ResponseWriter, req *http.Request) &#123; fmt.Println(&quot;Method:&quot;, req.Method) fmt.Println(&quot;Header:&quot;, req.Header) fmt.Println(&quot;RemoteAddr:&quot;, req.RemoteAddr) fmt.Println(&quot;URL:&quot;, req.URL) fmt.Fprintln(w, &quot;Hello world!&quot;)&#125; 4.2 客户端12345678910111213141516171819202122232425func main() &#123; conn, err := net.Dial(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() requestHead := &quot;GET /go HTTP/1.1\\r\\nHost: localhost:8080\\r\\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7\\r\\n\\r\\n&quot; fmt.Println(requestHead) // 发送请求 conn.Write([]byte(requestHead)) // 接收响应 buf := make([]byte, 1024*4) n, err := conn.Read(buf) if n == 0 &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;#%v#\\n&quot;, string(buf[:n]))&#125; 12345678910111213141516171819202122232425262728func main() &#123; //resp, err := http.Get(&quot;http://www.baidu.com&quot;) resp, err := http.Get(&quot;http://localhost:8080/go&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer resp.Body.Close() fmt.Println(&quot;Status =&quot;, resp.Status) fmt.Println(&quot;StatusCode =&quot;, resp.StatusCode) fmt.Println(&quot;Header =&quot;, resp.Header) //fmt.Println(&quot;Body = &quot;, resp.Body) var text string buf := make([]byte, 1024*4) for &#123; n, err := resp.Body.Read(buf) if n == 0 &#123; fmt.Println(err) break &#125; text += string(buf[:n]) &#125; fmt.Println(text)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 命令行参数","slug":"Go 命令行参数","date":"2018-01-09T01:10:13.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/09/Go 命令行参数/","link":"","permalink":"https://elihe2011.github.io/2018/01/09/Go%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/","excerpt":"1. 命令行参数：os.Args []string123456789func main() &#123; args := os.Args fmt.Printf(&quot;接收到%v个参数\\n&quot;, len(args)) for i, v := range args &#123; fmt.Printf(&quot;args[%v]=%v\\n&quot;, i, v) &#125;&#125;","text":"1. 命令行参数：os.Args []string123456789func main() &#123; args := os.Args fmt.Printf(&quot;接收到%v个参数\\n&quot;, len(args)) for i, v := range args &#123; fmt.Printf(&quot;args[%v]=%v\\n&quot;, i, v) &#125;&#125; 2. flag包解析命令行参数12IntVar(p *int, name string, value int, usage string)StringVar(p *string, name string, value string, usage string) 12345678910111213141516func main() &#123; var user string var pwd string var host string var port int flag.StringVar(&amp;user, &quot;u&quot;, &quot;&quot;, &quot;用户名，默认为空&quot;) flag.StringVar(&amp;pwd, &quot;p&quot;, &quot;&quot;, &quot;密码，默认为空&quot;) flag.StringVar(&amp;host, &quot;h&quot;, &quot;&quot;, &quot;主机名，localhost&quot;) flag.IntVar(&amp;port, &quot;P&quot;, 3306, &quot;端口，默认3306&quot;) // 转换 flag.Parse() fmt.Printf(&quot;user=%v, pwd=%v, host=%v, port=%v\\n&quot;, user, pwd, host, port)&#125; 123$ go build -o main flag_1.go $ ./main -u root -p 123456 -h localhost -P 3006user=root, pwd=123456, host=localhost, port=3006","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 文件操作","slug":"Go 文件操作","date":"2018-01-08T01:04:38.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/08/Go 文件操作/","link":"","permalink":"https://elihe2011.github.io/2018/01/08/Go%20%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","excerpt":"1. 读文件 os.Open(name string) (file *File, err error) ioutil.ReadFile(name string) ([]byte, error) 适合小文件一次性读取","text":"1. 读文件 os.Open(name string) (file *File, err error) ioutil.ReadFile(name string) ([]byte, error) 适合小文件一次性读取 1.1 带缓存读取文件123456789101112131415161718func main() &#123; file, err := os.Open(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() reader := bufio.NewReader(file) for &#123; // 按行读取 line, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; fmt.Print(line) &#125;&#125; 1.2 一次性读取文件：(小文件适用)123456789func main() &#123; bs, err := ioutil.ReadFile(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Read file error: %v\\n&quot;, err) return &#125; fmt.Printf(&quot;%s\\n&quot;, bs)&#125; 2. 写文件1os.OpenFile(name string, flag int, perm FileMode) (file *File, err error) 12345678910111213141516func main() &#123; file, err := os.OpenFile(&quot;./xyz.txt&quot;, os.O_CREATE|os.O_WRONLY, 0600) if err != nil &#123; fmt.Errorf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() msg := &quot;Hello World!\\n&quot; writer := bufio.NewWriter(file) for i := 0; i &lt; 5; i++ &#123; writer.Write([]byte(msg)) &#125; writer.Flush()&#125; 文件操作模式： 覆盖写：os.O_WRONLY | os.O_TRUNC 追加写：os.O_WRONLY | os.O_APPEND 读写并追加：os.O_RDWR | os.OS_APPEND 3. 文件拷贝3.1 直接拷贝文件内容 （小文件，文本文件）123456789101112func main() &#123; bs, err := ioutil.ReadFile(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Errorf(&quot;Read file error: %v\\n&quot;, err) return &#125; err = ioutil.WriteFile(&quot;./xyz.txt&quot;, bs, 0600) if err != nil &#123; fmt.Errorf(&quot;Write file error: %v&quot;, err) &#125;&#125; 3.2 带缓冲拷贝 （大文件，二进制文件）io.Copy(dst Writer, src Reader) (written int64, err error) 123456789101112131415161718192021func CopyFile(dstFileName, srcFileName string) (written int64, err error) &#123; srcFile, err := os.OpenFile(srcFileName, os.O_RDONLY, 0) if err != nil &#123; return 0, err &#125; defer srcFile.Close() dstFile, err := os.OpenFile(dstFileName, os.O_CREATE|os.O_WRONLY, 0600) if err != nil &#123; return 0, err &#125; defer dstFile.Close() writer := bufio.NewWriter(dstFile) reader := bufio.NewReader(srcFile) written, err = io.Copy(writer, reader) writer.Flush() // 需要自己去Flush return&#125; 4. 文件是否存在12345678910111213func IsFileExist(name string) (bool, error) &#123; _, err := os.Stat(name) if err == nil &#123; return true, nil &#125; if os.IsNotExist(err) &#123; fmt.Println(&quot;文件不存在&quot;) return false, nil &#125; return false, err&#125; 5. 字符统计123456789101112131415161718192021222324252627282930313233343536373839404142type Statistic struct &#123; Char int Number int Space int Other int&#125;func main() &#123; file, err := os.Open(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() stat := Statistic&#123;&#125; reader := bufio.NewReader(file) for &#123; bs, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; for _, c := range []rune(bs) &#123; switch &#123; case c &gt;= &#x27;a&#x27; &amp;&amp; c &lt;= &#x27;z&#x27;: fallthrough case c &gt;= &#x27;A&#x27; &amp;&amp; c &lt;= &#x27;Z&#x27;: stat.Char++ case c &gt;= &#x27;0&#x27; &amp;&amp; c &lt;= &#x27;9&#x27;: stat.Number++ case c == &#x27; &#x27; || c == &#x27;\\t&#x27;: stat.Space++ default: stat.Other++ &#125; &#125; &#125; fmt.Printf(&quot;%v\\n&quot;, stat)&#125; 6. 目录遍历 type WalkFunc func(path string, info os.FileInfo, err error) error func Walk(root string, walkFn WalkFunc) error 1234567891011121314func main() &#123; // 当root=/tmp时，不会遍历目录下的文件 err := filepath.Walk(&quot;/tmp/&quot;, walkFunc) if err != nil &#123; fmt.Printf(&quot;File walk error: %v\\n&quot;, err) &#125;&#125;func walkFunc(path string, info os.FileInfo, err error) error &#123; fmt.Println(path) //fmt.Println(info.Name(), info.Size()) return nil&#125; 7. 压缩文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374func main() &#123; filePath := &quot;/tmp/&quot; filename := filepath.Base(filePath) fmt.Println(filename) currentTime := time.Now() ms := currentTime.Nanosecond() / 1e6 zipFilename := fmt.Sprintf(&quot;%s_%s%03d.zip&quot;, strings.Split(filename, &quot;.&quot;)[0], currentTime.Format(&quot;20060102150405&quot;), ms) fmt.Println(zipFilename) ZIP(filePath, zipFilename)&#125;func ZIP(source, target string) error &#123; zipFile, err := os.Create(target) if err != nil &#123; return err &#125; defer zipFile.Close() archive := zip.NewWriter(zipFile) defer archive.Close() err = filepath.Walk(source, func(path string, info os.FileInfo, err error) error &#123; if err != nil &#123; return err &#125; header, err := zip.FileInfoHeader(info) if err != nil &#123; return err &#125; header.Name = strings.TrimPrefix(path, source+&quot;/&quot;) // 目录不需要压缩 if info.IsDir() &#123; header.Name += &quot;/&quot; &#125; else &#123; // 压缩算法 header.Method = zip.Deflate &#125; // 保留文件时间 header.Modified = time.Unix(info.ModTime().Unix(), 0) // 创建：压缩包头信息 writer, err := archive.CreateHeader(header) if err != nil &#123; return err &#125; // 目录只需创建，不做其他操作 if info.IsDir() &#123; return nil &#125; // 打开需要压缩的文件 file, err := os.Open(path) if err != nil &#123; return nil &#125; defer file.Close() // 压缩文件 _, err = io.Copy(writer, file) return err &#125;) return err&#125; 8. 文件读取的三种方式 文件整体读取 文件分片读取 (块级读取) 文件行级读取 8.1 文件整体读取1234567891011// 方式1:bs, err := ioutil.ReadFile(filePath)// 方式2:file, err := os.Open(filePath)fileInfo, err := file.Stat()buffer := make([]byte, fileInfo.Size())n, err := file.Read(buffer)fmt.Printf(&quot;%s&quot;, buffer[:n]) 8.2 文件分片读取12345678910111213141516file, err := os.Open(filePath)buffer := make([]byte, 1024)for &#123; n, err := file.Read(buffer) if err != nil &amp;&amp; err != io.EOF &#123; panic(error) &#125; if n == 0 &#123; break &#125; fmt.Printf(&quot;%s&quot;, buffer)&#125; 8.3 文件按行读取123456789101112file, err := os.Open(filePath)reader := bufio.NewReader(file)for &#123; line, _, err := reader.ReadLine() if err == io.EOF &#123; break &#125; fmt.Printf(&quot;%s&quot;, line)&#125; 9. 文件写入的四周方式 简单覆盖写入 常规文件写入 带缓冲的写入 复制文件写入 9.1 简单覆盖写入1err := ioutil.WriteFile(filePath, data, 0666) 9.2 常规文件写入123456file, err := os.Create(filePath)file, err := os.OpenFile(filePath, os.O_RDONLY|os.O_CREATE|os.O_APPEND, 0666)n, err := file.Write([]byte(data))n, err := file.WriteString(data) 9.3 带缓冲的写入bufio 库： 123456789func NewWriter(w io.Writer) *Writerfunc NewWriterSize(w io.Writer, size int) *Writerfunc (b *Writer) Write(p []byte) (nn int, err error)func (b *Writer) WriteString(s string) (int, error)func (b *Writer) WriteByte(c byte) errorfunc (b *Writer) WriteRune(r rune) (size int, err error)func (b *Writer) Flush() error 9.4 复制文件写入io 包 12345// 默认缓冲区大小func Copy(dst Writer, src Reader) (written int64, err error)&#123;&#125;// 自定义缓冲区大小func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) &#123;&#125; 10. io.Reader 接口","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 反射","slug":"Go 反射","date":"2018-01-07T00:39:46.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/07/Go 反射/","link":"","permalink":"https://elihe2011.github.io/2018/01/07/Go%20%E5%8F%8D%E5%B0%84/","excerpt":"1. 反射反射：在运行时，动态获取对象的类型信息和内存结构 反射操作所需要的全部信息都源自接口变量，接口变量除了存储自身类型外，还会保存实际对象的类型数据 将任何传入的对象转换为接口类型： 12func TypeOf(o interface&#123;&#125;) Typefunc ValueOf(o interface&#123;&#125;) Value","text":"1. 反射反射：在运行时，动态获取对象的类型信息和内存结构 反射操作所需要的全部信息都源自接口变量，接口变量除了存储自身类型外，还会保存实际对象的类型数据 将任何传入的对象转换为接口类型： 12func TypeOf(o interface&#123;&#125;) Typefunc ValueOf(o interface&#123;&#125;) Value 2. 类型(Type)reflect.TypeOf() 返回对象类型 1234func TypeOf(i interface&#123;&#125;) Type &#123; eface := *(*emptyInterface)(unsafe.Pointer(&amp;i)) return toType(eface.typ)&#125; 2.1 Type和Kind的区别 Type: 真实类型（静态类型） t.Name() Kind: 基础类型（底层类型） t.Kind() 12345678func main() &#123; type X int var a X = 100 t := reflect.TypeOf(a) fmt.Println(t, t.Name(), t.Kind()) // main.X X int&#125; 2.2 基类型和指针类型12345678910func main() &#123; x := 20 tx := reflect.TypeOf(x) tp := reflect.TypeOf(&amp;x) fmt.Println(tx, tx.Name(), tx.Kind()) // int int int fmt.Println(tp, tp.Name(), tp.Kind()) // *int ptr fmt.Println(tx == tp.Elem()) // true&#125; 2.3 方法Type.Elem()返回引用类型 (指针、数组、切片、字典（值）或 通道) 的基类型 12345678910111213func main() &#123;a := [...]byte&#123;1, 2, 3&#125; s := make([]string, 5) m := make(map[int]string) ta := reflect.TypeOf(a) ts := reflect.TypeOf(s) tm := reflect.TypeOf(m) fmt.Println(ta, ta.Elem()) // [3]uint8 uint8 fmt.Println(ts, ts.Elem()) // []string string fmt.Println(tm, tm.Elem()) // ma[[iny]string string&#125; 2.4 辅助判断方法Implements(), ConvertibleTo(), AssignableTo() 12345678910111213141516171819202122func main() &#123; type X int var a X t := reflect.TypeOf(a) fmt.Println(t) // main.X ts := reflect.TypeOf((*fmt.Stringer)(nil)).Elem() fmt.Println(ts) // fmt.Stringer ti := reflect.TypeOf(10) fmt.Println(ti) // int fmt.Println(t.Implements(ts)) // false //fmt.Println(t.Implements(ti)) // panic: non-interface type passed to Type.Implements fmt.Println(t.ConvertibleTo(ts)) // false fmt.Println(t.ConvertibleTo(ti)) // true fmt.Println(t.AssignableTo(ts)) // false fmt.Println(t.AssignableTo(ti)) // false&#125; 2.5 结构体 反射类型Field(), FieldByIndex(), FieldByName(), FieldByNameFunc() 获取 StructField结构体中的内容 12345678910type StructField struct &#123; Name string PkgPath string Type Type // field type Tag StructTag // field tag string Offset uintptr // offset within struct, in bytes Index []int // index sequence for Type.FieldByIndex Anonymous bool // is an embedded field &#125; 12345678910111213func main() &#123; user := User&#123;&quot;Jack&quot;, 12&#125; t := reflect.TypeOf(user) for i := 0; i &lt; t.NumField(); i++ &#123; tf := t.Field(i) fmt.Printf(&quot;%s: %s %v\\n&quot;, tf.Name, tf.Type, tf.Tag) &#125; if tf, ok := t.FieldByName(&quot;Age&quot;); ok &#123; fmt.Printf(&quot;%s: %s\\n&quot;, tf.Name, tf.Tag.Get(&quot;json&quot;)) &#125;&#125; 3. 值(Value)接口变量会复制对象，是unaddressable的。要想修改目标对象，必须使用指针 12345678910func main() &#123; a := 5 va := reflect.ValueOf(a) vp := reflect.ValueOf(&amp;a).Elem() fmt.Println(va, vp) // 5 5 fmt.Println(va.CanAddr(), va.CanSet()) //false false fmt.Println(vp.CanAddr(), vp.CanSet()) // true true&#125; 3.1 结构体反射1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283type User struct &#123; Id int Name string Age byte&#125;func (u User) Hello() &#123; fmt.Println(&quot;Hello&quot;, u.Name)&#125;func (u User) Say(msg string) &#123; fmt.Println(u.Name, &quot;say&quot;, msg)&#125;func main() &#123; u := User&#123;1, &quot;Jack&quot;, 23&#125; Info(u) Set(&amp;u) fmt.Println(u)&#125;func Info(o interface&#123;&#125;) &#123; t := reflect.TypeOf(o) fmt.Println(&quot;Type:&quot;, t) // Type: main.User // pointer-interface，直接返回 if k := t.Kind(); k != reflect.Struct &#123; fmt.Println(&quot;A Pointer Interface&quot;) return &#125; v := reflect.ValueOf(o) fmt.Println(&quot;Fields:&quot;) for i := 0; i &lt; v.NumField(); i++ &#123; field := t.Field(i) value := v.Field(i).Interface() fmt.Printf(&quot;%6s: %v = %v\\n&quot;, field.Name, field.Type, value) &#125; f1 := v.FieldByIndex([]int&#123;1&#125;) fmt.Println(f1.Interface()) f2 := v.FieldByName(&quot;Age&quot;) fmt.Println(f2.Interface()) fmt.Println(&quot;Methods:&quot;) for i := 0; i &lt; v.NumMethod(); i++ &#123; m := t.Method(i) fmt.Printf(&quot;%6s: %v\\n&quot;, m.Name, m.Type) &#125; m1 := v.MethodByName(&quot;Say&quot;) args := []reflect.Value&#123;reflect.ValueOf(&quot;Hi&quot;)&#125; m1.Call(args)&#125;func Set(o interface&#123;&#125;) &#123; v := reflect.ValueOf(o) if v.Kind() != reflect.Ptr &#123; fmt.Println(&quot;Not a pointer interface&quot;) return &#125; if !v.Elem().CanSet() &#123; fmt.Println(&quot;Can not be set&quot;) return &#125; v = v.Elem() f := v.FieldByName(&quot;Age&quot;) if !f.IsValid() &#123; fmt.Println(&quot;Can not find this field&quot;) return &#125; if f.Kind() == reflect.Uint8 &#123; f.SetUint(25) &#125;&#125; 3.2 处理结构体匿名字段或嵌入字段反射匿名或嵌入字段：匿名字段当独立字段处理 12345678910111213141516171819202122232425262728293031type User struct &#123; Id int Name string Age byte&#125;type Manager struct &#123; User Title string&#125;func main() &#123; m := Manager&#123;User: User&#123;1, &quot;Jack&quot;, 21&#125;, Title: &quot;CEO&quot;&#125; t := reflect.TypeOf(m) fmt.Printf(&quot;%#v\\n&quot;, t.Field(0)) // &#123;Name:&quot;User&quot;, ..., Anonymous:true&#125; fmt.Printf(&quot;%#v\\n&quot;, t.Field(1)) // &#123;Name:&quot;Title&quot;, ..., Anonymous:false&#125; fmt.Printf(&quot;%#v\\n&quot;, t.FieldByIndex([]int&#123;0&#125;)) // Same as t.Field(0),&#123;Name:&quot;User&quot;, ..., Anonymous:true&#125; fmt.Printf(&quot;%#v\\n&quot;, t.FieldByIndex([]int&#123;0, 1&#125;)) // &#123;Name:&quot;Name&quot;, ..., Anonymous:false&#125; field, ok := t.FieldByName(&quot;Title&quot;) if ok &#123; fmt.Printf(&quot;%#v\\n&quot;, field) // &#123;Name:&quot;Title&quot;, ..., Anonymous:false&#125; &#125; field, ok = t.FieldByName(&quot;Id&quot;) if ok &#123; fmt.Printf(&quot;%#v\\n&quot;, field) // &#123;Name:&quot;Id&quot;, ..., Anonymous:false&#125; &#125;&#125; 3.3 通过反射，修改内容传入的值必选是pointer-interface 12345678func main() &#123; x := 10 v := reflect.ValueOf(&amp;x) // ptr-interface fmt.Printf(&quot;%#v\\n&quot;, v) v.Elem().SetInt(99) fmt.Println(x)&#125; 3.4 通道对象设置12345678func main() &#123; ch := make(chan int, 4) v := reflect.ValueOf(ch) if v.TrySend(reflect.ValueOf(100)) &#123; fmt.Println(v.TryRecv()) // 100 true &#125;&#125; 3.5 空接口判断1234567func main() &#123; var a interface&#123;&#125; = nil var b interface&#123;&#125; = (*int)(nil) fmt.Println(a == nil) // true fmt.Println(b == nil, reflect.ValueOf(b).IsNil()) //false true&#125; 4. 方法4.1 调用方法12345678910111213141516171819202122type X struct&#123;&#125;func (X) Add(x, y int) int &#123; return x + y&#125;func main() &#123; var a X v := reflect.ValueOf(a) m := v.MethodByName(&quot;Add&quot;) args := []reflect.Value&#123; reflect.ValueOf(5), reflect.ValueOf(7), &#125; result := m.Call(args) for _, val := range result &#123; fmt.Println(val) &#125;&#125; 4.2 调用变参方法12345678910111213141516171819202122232425262728type X struct&#123;&#125;func (X) Format(format string, a ...interface&#123;&#125;) string &#123; return fmt.Sprintf(format, a...)&#125;func main() &#123; var a X v := reflect.ValueOf(a) m := v.MethodByName(&quot;Format&quot;) args := []reflect.Value&#123; reflect.ValueOf(&quot;%s = %d&quot;), reflect.ValueOf(&quot;x&quot;), reflect.ValueOf(10), &#125; result := m.Call(args) fmt.Println(result) // [x = 10] args = []reflect.Value&#123; reflect.ValueOf(&quot;%d + %d = %d&quot;), reflect.ValueOf([]interface&#123;&#125;&#123;1, 2, 1 + 2&#125;), &#125; result = m.CallSlice(args) fmt.Println(result) // [1 + 2 = 3]&#125; 5. 构建反射库提供了内置函数 make() 和 new() 的对应操作，例如 MakeFunc()。可用它实现通用模板，适应不同数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142func main() &#123; var intAdd func(x, y int) int var strAdd func(x, y string) string makeAdd(&amp;intAdd) makeAdd(&amp;strAdd) fmt.Println(intAdd(20, 30)) fmt.Println(strAdd(&quot;Hello&quot;, &quot;World&quot;))&#125;func makeAdd(o interface&#123;&#125;) &#123; fn := reflect.ValueOf(o).Elem() v := reflect.MakeFunc(fn.Type(), add) fn.Set(v)&#125;func add(args []reflect.Value) (results []reflect.Value) &#123; if len(args) == 0 &#123; return nil &#125; var ret reflect.Value switch args[0].Kind() &#123; case reflect.Int: sum := 0 for _, n := range args &#123; sum += int(n.Int()) &#125; ret = reflect.ValueOf(sum) case reflect.String: ss := make([]string, 0, len(args)) for _, s := range args &#123; ss = append(ss, s.String()) &#125; ret = reflect.ValueOf(strings.Join(ss, &quot; &quot;)) &#125; results = append(results, ret) return&#125; 6. 反射相关方法12345678910111213141516171819202122232425262728293031323334353637reflect.TypeOf(o) // reflect.Typereflect.Type.Name() // 类型名称reflect.Type.Kind() // 原始类型名称：int, string...reflect.ValueOf(o) // reflect.Valuereflect.Value.Type() // reflect.Typereflect.Value.Kind() // 原始类型名称：int, string...(默认整型表示)// 获取变量值reflect.Value.Float()reflect.Value.Int()reflect.Value.String()reflect.Value.Bool()reflect.Value.Interface() // 获取真实值，不关系值的类型 // 指针ptr.Elem().setInt(99)// 改变变量的值reflect.Value.SetInt()reflect.Value.SetFloat()reflect.Value.SetString()// 结构体reflect.Value.NumField() // 结构体字段个数reflect.Value.Field(i) // reflect.StructFieldreflect.Value.FieldByIndex(i) // reflect.StructFieldreflect.Value.FieldByName(&quot;field&quot;) // reflect.StructFieldreflect.StructField.Name // 字段名reflect.StructField.Type // 字段类型reflect.Value.NumMethod() // 结构体方法个数reflect.Value.Method(i) // reflect.Methodreflect.Value.MethodByName(&quot;method&quot;) // reflect.Methodreflect.Method.Name // 方法名reflect.Method.Type // 方法类型reflect.Method.Call(in []Value) // 调用方法 7. 反射的三大定律7.1 两种类型 Type 和 Valuereflect.Type: 以接口的形式存在 123456789101112131415161718192021222324252627282930313233type Type interface &#123; Align() int FieldAlign() int Method(int) Method MethodByName(string) (Method, bool) NumMethod() int Name() string PkgPath() string Size() uintptr String() string Kind() Kind Implements(u Type) bool AssignableTo(u Type) bool ConvertibleTo(u Type) bool Comparable() bool Bits() int ChanDir() ChanDir IsVariadic() bool Elem() Type Field(i int) StructField FieldByIndex(index []int) StructField FieldByName(name string) (StructField, bool) FieldByNameFunc(match func(string) bool) (StructField, bool) In(i int) Type Key() Type Len() int NumField() int NumIn() int NumOut() int Out(i int) Type common() *rtype uncommon() *uncommonType&#125; reflect.Value: 以结构体形式存在 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374type Value struct &#123; typ *rtype ptr unsafe.Pointer flag&#125;func (v Value) Addr() Valuefunc (v Value) Bool() boolfunc (v Value) Bytes() []bytefunc (v Value) Call(in []Value) []Valuefunc (v Value) CallSlice(in []Value) []Valuefunc (v Value) CanAddr() boolfunc (v Value) CanInterface() boolfunc (v Value) CanSet() boolfunc (v Value) Cap() intfunc (v Value) Close()func (v Value) Complex() complex128func (v Value) Convert(t Type) Valuefunc (v Value) Elem() Valuefunc (v Value) Field(i int) Valuefunc (v Value) FieldByIndex(index []int) Valuefunc (v Value) FieldByName(name string) Valuefunc (v Value) FieldByNameFunc(match func(string) bool) Valuefunc (v Value) Float() float64func (v Value) Index(i int) Valuefunc (v Value) Int() int64func (v Value) Interface() (i interface&#125;)func (v Value) InterfaceData() [2]uintptrfunc (v Value) IsNil() boolfunc (v Value) IsValid() boolfunc (v Value) IsZero() boolfunc (v Value) Kind() Kindfunc (v Value) Len() intfunc (v Value) MapIndex(key Value) Valuefunc (v Value) MapKeys() []Valuefunc (v Value) MapRange() *MapIterfunc (v Value) Method(i int) Valuefunc (v Value) MethodByName(name string) Valuefunc (v Value) NumField() intfunc (v Value) NumMethod() intfunc (v Value) OverflowComplex(x complex128) boolfunc (v Value) OverflowFloat(x float64) boolfunc (v Value) OverflowInt(x int64) boolfunc (v Value) OverflowUint(x uint64) boolfunc (v Value) Pointer() uintptrfunc (v Value) Recv() (x Value, ok bool)func (v Value) Send(x Value)func (v Value) Set(x Value)func (v Value) SetBool(x bool)func (v Value) SetBytes(x []byte)func (v Value) SetCap(n int)func (v Value) SetComplex(x complex128)func (v Value) SetFloat(x float64)func (v Value) SetInt(x int64)func (v Value) SetLen(n int)func (v Value) SetMapIndex(key, elem Value)func (v Value) SetPointer(x unsafe.Pointer)func (v Value) SetString(x string)func (v Value) SetUint(x uint64)func (v Value) Slice(i, j int) Valuefunc (v Value) Slice3(i, j, k int) Valuefunc (v Value) String() stringfunc (v Value) TryRecv() (x Value, ok bool)func (v Value) TrySend(x Value) boolfunc (v Value) Type() Typefunc (v Value) Uint() uint64func (v Value) UnsafeAddr() uintptrfunc (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Valuefunc (v Value) call(op string, in []Value) []Valuefunc (v Value) pointer() unsafe.Pointerfunc (v Value) recv(nb bool) (val Value, ok bool)func (v Value) runes() []runefunc (v Value) send(x Value, nb bool) (selected bool)func (v Value) setRunes(x []rune) 7.2 反射的三大定律 Reflection goes from interface value to reflection object. 反射可以将接口类型变量 转换为“反射类型对象” Reflection goes from reflection object to interface value. 反射可以将 “反射类型对象”转换为 接口类型变量 To modify a reflection object, the value must be settable. 如果要修改 “反射类型对象” 其类型必须是 可写的 7.2.1 第一定律Reflection goes from interface value to reflection object. reflect.TypeOf(i): 获取接口值的类型 (*reflect.rtype) reflect.ValueOf(i): 获取接口值的值 (reflect.Value) 7.2.2 第二定律Reflection goes from reflection object to interface value. 注意：只有Value才能逆向转换，Type则不行 123func (v Value) Interface() (i interface&#123;&#125;) &#123; return valueInterface(v, true)&#125; 7.2.3 第三定律To modify a reflection object, the value must be settable. 非指针变量创建的反射对象，不可写 CanSet()返回true，为可写对象 不可写对象，无法进行写操作 可写对象，使用Elem()函数返回指针指向的数据 123456789101112func main() &#123; var name string = &quot;Go编程&quot; v1 := reflect.ValueOf(name) fmt.Println(v1.CanSet()) // false, 使用v1.Elem()方法会触发异常 v2 := reflect.ValueOf(&amp;name) fmt.Println(v2.CanSet()) // false v3 := v2.Elem() fmt.Println(v3.CanSet()) // true&#125; 可写对象的相关方法： 12345678910111213Set(x Value)SetBool(x bool)SetBytes(x []byte)setRunes(x []rune)SetComplex(x complex128)SetFloat(x float64)SetInt(x int64)SetLen(n int)SetCap(n int)SetMapIndex(key Value, elem Value)SetUint(x uint64)SetPointer(x unsafe.Pointer)SetString(x string)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 通道和并发","slug":"Go 通道和并发","date":"2018-01-06T09:12:24.000Z","updated":"2021-06-22T10:50:49.704Z","comments":true,"path":"2018/01/06/Go 通道和并发/","link":"","permalink":"https://elihe2011.github.io/2018/01/06/Go%20%E9%80%9A%E9%81%93%E5%92%8C%E5%B9%B6%E5%8F%91/","excerpt":"1. goroutine协程，比线程更小，十几个goroutine可能体现在底层就五六个线程。Go语言内部实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存（4～5KB），比线程更易用，更高效和更轻便。 goroutine调度模型： M: 线程 P: 上下文 G: Goroutine 并发concurrency： goroutine只是官方实现的超级“线程池”。每个实例4-5KB的栈内存占用，和大幅减少的创建和销毁开销，是制造Go号称高并发的根本原因 并发不是并行(Concurrency is Not Parallelism): 并发是通过切换CPU时间来实现“同时”运行；而并行则是直接利用多核实现多线程同时运行。Go可设置使用的CPU核心数，以发挥多核计算机的能力 goroutine奉行通过通信来共享内存，而不是共享内存来通信。","text":"1. goroutine协程，比线程更小，十几个goroutine可能体现在底层就五六个线程。Go语言内部实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存（4～5KB），比线程更易用，更高效和更轻便。 goroutine调度模型： M: 线程 P: 上下文 G: Goroutine 并发concurrency： goroutine只是官方实现的超级“线程池”。每个实例4-5KB的栈内存占用，和大幅减少的创建和销毁开销，是制造Go号称高并发的根本原因 并发不是并行(Concurrency is Not Parallelism): 并发是通过切换CPU时间来实现“同时”运行；而并行则是直接利用多核实现多线程同时运行。Go可设置使用的CPU核心数，以发挥多核计算机的能力 goroutine奉行通过通信来共享内存，而不是共享内存来通信。 goroutine的切换点： I/O, select channel 等待锁 函数调用 (有时) runtime.Gosched() 进程：资源拥有的基本单位。每个进程由私营的虚拟地址空间、代码、数据和其它各种资源组成。 线程：处理器调度和分配的基本单位。线程是进程内部的一个执行单元，每个进程至少有一个主线程，它无需用户去主动创建，由系统自动创建。 协程：比线程更小 轻量级“线程” “非抢占式”多任务处理，有协程主动交出控制权 编译器/解释器/虚拟机层面的多任务 多个协程，可能在一个或多个线程上运行 KSE：Kernel Scheduling Entity, 内核调度实体，即可以被操作系统内核调度器调度的实体对象，它是内核的最小调度单元，也就是内核级线程 三种线程模型： 用户级线程模型： 用户线程与内核线程KSE的关系是多对一 (N:1)。多个用户线程一般从属单个进程，并且多线程的调度由用户自己的线程库完成，线程的创建、销毁及线程间的协调等操作由用户自己的线程库负责，无需借助系统调度来实现。 Python的gevent协程库就属这种实现 线程调度在用户层面完成，不需要让CPU在用户态和内核态之间切换，这种方式较为轻量级，对系统资源消耗少 缺点：做不到真正意义上的并发。如果某个用户进程上的某个线程因为一个阻塞调用(I/O)二被CPU中断(抢占式调度)，那么该进程中的其它线程将被阻塞，整个进程被挂起。因为在用户线程模式下，进程内的线程绑定到CPU执行是由用户进程调度实现的，内部线程对CPU不可见，即CPU调度的是进程，而非线程 协程库优化：把阻塞的操作重新封装为完全非阻塞模式，在阻塞点上，主动让出自己，并通知或唤醒其它等待的用户线程 内核级线程模型 用户线程和内核线程KSE的关系是一对一 (1:1)。每个用户线程绑定一个内核线程，线程的调度完全交由内核控制 Java/C++ 的线程库按此方式实现 优点：简单，直接借助系统内核的线程和调度器，可以快速实现线程切换，做到真正的并行处理 缺点：由于直接使用内核去创建、销毁及多线程上下文切换和调度，系统资源成本大幅上涨，对性能影响较大 两级线程模型(即混合型线程模型) 用户线程与内核线程KSE的关系是多对多 (N:M) 一个进程可与多个内核线程KSE关联，该进程内的多个线程绑定到了不同的KSE上 进程内的线程并不与KSE一一绑定，当某个KSE绑定的线程因阻塞操作被内核调度出CPU时，其关联的进程中的某个线程又会重新与KSE绑定 此种模型高度复杂，Go语言中的runtime调度器实现了这种方案 为什么称为两级？用户调度实现用户线程到KSE的调度，内核调度器实现KSE到CPU上的调度 G-P-M 模型： G：Goroutine：独立执行单元。相较于每个OS线程固定分配2M内存的模式，Goroutine的栈采取动态扩容方式，2k ~ 1G(AMD64, AMD32: 256M)。周期性回收内存，收缩栈空间 每个Goroutine对应一个G结构体，它存储Goroutine的运行堆栈、状态及任务函数，可重用。 G并非执行体，每个G需要绑定到P才能被调度执行 P：Processor： 逻辑处理器，中介 对G来说，P相当于CPU，G只有绑定到P才能被调用 对M来说，P提供相关的运行环境(Context)，如内存分配状态(mcache)，任务队列(G)等 P的数量决定系统最大并行的G的数量 （CPU核数 &gt;= P的数量），用户可通过GOMAXPROCS设置数量，但不能超过256 M：Machine OS线程抽象，真正执行计算的资源，在绑定有效的P后，进入schedule循环 schedule循环的机制大致从Global队列、P的Local队列及wait队列中获取G，切换到G的执行栈上执行G的函数，调用goexit做清理工作并回到M M不保留G的状态 M的数量不定，由Go Runtime调整，目前默认不超过10K 1.1 go关键字开启新协程1234567891011func say(s string) &#123; for i := 0; i &lt; 5; i ++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) say(&quot;hello&quot;)&#125; 1.2 runtime包runtime.Gosched() 让出时间片runtime.Goexit() 终止协程runtime.GOMAXPROCS(N) 指定运行CPU个数 123456789101112func main() &#123; go func() &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Println(&quot;go&quot;) &#125; &#125;() for i := 0; i &lt; 2; i++ &#123; runtime.Gosched() // 让出时间片 fmt.Println(&quot;hello&quot;) &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 打印函数属IO操作，自动切换控制权func auto() &#123; for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; for &#123; fmt.Printf(&quot;Hello from goroutine %d\\n&quot;, i) &#125; &#125;(i) &#125; time.Sleep(time.Millisecond)&#125;// 不自动切换控制权func manual() &#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; // race condition for &#123; a[i]++ runtime.Gosched() // 交出控制权 &#125; &#125;(i) &#125; time.Sleep(time.Millisecond) fmt.Println(a) // 存在读写抢占&#125;// out of rangefunc outOfRange() &#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func() &#123; // race condition for &#123; a[i]++ runtime.Gosched() // 交出控制权 &#125; &#125;() &#125; time.Sleep(time.Millisecond) fmt.Println(a)&#125; 1go run -race goroutine.go # manual()函数存在抢占，race选项可检查到 2. 通道(channel)通道：用来传递数据的一种数据结构。两个goroutine之间，可以使用它来进行同步和通信 不靠共享内存通信，而是通过通信来共享内存 Channel： goroutine的沟通桥梁，大多是阻塞同步的 make创建，close关闭 是引用类型 可使用for range来迭代channel 可设置单向或双向通道 可设置缓存大小，在未被填满前不会发生阻塞 1234ch := make(chan int)ch &lt;- v // 把v发送到通道chv := &lt;- ch // 从ch接收数据 2.1 分段计算123456789101112131415161718192021func main() &#123; a := []int&#123;7, 9, -3, 4, 6, 8, 2, -5&#125; mid := len(a) / 2 ch := make(chan int) go sum(a[:mid], ch) go sum(a[mid:], ch) x, y := &lt;-ch, &lt;-ch fmt.Println(x, y, x+y)&#125;func sum(a []int, ch chan int) &#123; result := 0 for _, v := range a &#123; result += v &#125; ch &lt;- result&#125; 2.2 阻塞主线程12345678910func main() &#123; c := make(chan bool) go func() &#123; fmt.Println(&quot;Go Go Go!!!&quot;) c &lt;- true &#125;() &lt;- c // 阻塞main函数，等待goroutine执行完成&#125; 2.3 通道遍历和关闭如果通道不关闭close(ch)，遍历range ch就不会结束 123456789101112131415161718192021222324252627282930313233func main() &#123; ch := make(chan int, 10) go fib(cap(ch), ch) //// 方法1：for-range 自检 //for i := range ch &#123; // fmt.Printf(&quot;%d &quot;, i) //&#125; // 方法2：comma ok idiom for &#123; num, ok := &lt;-ch if ok &#123; fmt.Printf(&quot;%d &quot;, num) &#125; else &#123; break &#125; &#125; fmt.Println()&#125;func fib(n int, ch chan int) &#123; x, y := 1, 1 for i := 0; i &lt; n; i++ &#123; ch &lt;- x x, y = y, x+y &#125; // 必须关闭，否则deadlock close(ch)&#125; 2.4 主程序可能不等待goruntine123456789101112131415161718192021222324func main() &#123; ch := make(chan bool) for i := 0; i &lt; 10; i++ &#123; go calc(i, ch) &#125; &lt;-ch&#125;func calc(index int, ch chan bool) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) // goroutine 执行顺序不固定，此判断不正确 if index == 9 &#123; ch &lt;- true &#125;&#125; 2.4.1 方法一：使用缓存channel123456789101112131415161718192021222324func main() &#123; ch := make(chan bool, 10) for i := 0; i &lt; 10; i++ &#123; go calc(i, ch) &#125; // 等待10次 for i := 0; i &lt; 10; i++ &#123; &lt;-ch &#125;&#125;func calc(index int, ch chan bool) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) ch &lt;- true&#125; 2.4.2 方法二：通过同步解决(sync.WaitGroup) wg.Add(N): 新增N个任务 wg.Done(): 完成一个任务，计算器减1 wg.Wait(): 主线程等待，直到计数器为0 1234567891011121314151617181920212223func main() &#123; wg := sync.WaitGroup&#123;&#125; wg.Add(10) for i := 0; i &lt; 10; i++ &#123; go calc(i, &amp;wg) &#125; // 等待 wg.Wait()&#125;func calc(index int, wg *sync.WaitGroup) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) wg.Done()&#125; 2.5 模拟打印机1234567891011121314151617181920212223242526272829func main() &#123; ch := make(chan bool) go task1(ch) go task2(ch) // 等待 select &#123; case &lt;-time.After(15 * time.Second): &#125;&#125;func Printer(s string) &#123; for _, c := range s &#123; fmt.Printf(&quot;%c&quot;, c) time.Sleep(time.Second) &#125; fmt.Println()&#125;func task1(ch chan bool) &#123; &lt;-ch // 阻塞等待 Printer(&quot;hello&quot;)&#125;func task2(ch chan bool) &#123; Printer(&quot;world&quot;) ch &lt;- true // 完成释放&#125; 2.6 带缓冲的通道通道 ch := make(chan int, N): N=0 同步阻塞 N&gt;0 异步的，超过N时才阻塞 1234567891011121314151617func main() &#123; ch := make(chan int, 3) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;i=%d, len(ch)=%d, cap(ch)=%d\\n&quot;, i, len(ch), cap(ch)) ch &lt;- i &#125; &#125;() time.Sleep(2 * time.Second) for i := 0; i &lt; 10; i++ &#123; num := &lt;-ch fmt.Printf(&quot;num=%d\\n&quot;, num) &#125;&#125; 2.7 单向通道123var ch1 chan int // 默认双向var ch2 chan&lt;- int // 单向写var ch3 &lt;-chan int // 单向读 123456789101112131415161718192021222324252627func main() &#123; ch := make(chan int) /* 支持隐式转换 var send chan&lt;- int = ch // write-only var recv &lt;-chan int = ch // read-only */ go producer(ch) consumer(ch)&#125;func producer(out chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; out &lt;- i * i &#125; close(out)&#125;func consumer(in &lt;-chan int) &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, &lt;-in) &#125; fmt.Println()&#125; 3. Selectselect: 管理多个channel，监听channel上的数据流动。类似switch语法，但每个case语句必须是IO操作。多个case同时满足，任选一个执行。 处理一个或多个channel的发送和接收 同时有多个channel时，随机处理 可用空select来阻塞main函数 可设置超时 default语句： 有default：select语句不会被阻塞，执行default后，程序的执行会从select语句中恢复，进入下一次轮询。比较消耗资源。 没有default：select语句将被阻塞，直到至少有一个通信可以进行下去 3.1 管理多个通道3.1.1 示例1123456789101112131415161718192021222324252627282930313233343536func main() &#123; c1, c2 := make(chan int), make(chan string) done := make(chan bool, 2) go func() &#123; for &#123; select &#123; case v, ok := &lt;-c1: if !ok &#123; done &lt;- true break &#125; fmt.Println(&quot;c1:&quot;, v) case v, ok := &lt;-c2: if !ok &#123; done &lt;- true break &#125; fmt.Println(&quot;c2:&quot;, v) &#125; &#125; &#125;() c1 &lt;- 1 c2 &lt;- &quot;hi&quot; c1 &lt;- 5 c2 &lt;- &quot;hello&quot; // 必须关闭至少一个 close(c1) //close(c2) for i := 0; i &lt; 2; i++ &#123; &lt;-done &#125;&#125; 3.1.2 示例2123456789101112131415161718192021222324252627282930func main() &#123; ch := make(chan int) quit := make(chan bool) // 消费者 go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, &lt;-ch) &#125; fmt.Println() quit &lt;- true &#125;() fib(ch, quit)&#125;func fib(ch chan&lt;- int, quit &lt;-chan bool) &#123; x, y := 1, 1 for &#123; select &#123; case ch &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;Done.&quot;) return // break只能跳出select，无法跳出for循环 &#125; &#125;&#125; 3.1.3 使用select作为发送者应用12345678910111213141516func main() &#123; c := make(chan int) go func() &#123; for v := range c &#123; fmt.Println(v) &#125; &#125;() for i := 0; i &lt; 100; i++ &#123; select &#123; case c &lt;- 0: case c &lt;- 1: &#125; &#125;&#125; 3.2 超时处理case &lt;-time.After(5 * time.Second): 其他channel阻塞时间超过5s时执行 123456789101112131415161718192021222324func main() &#123; ch := make(chan int) done := make(chan bool) go func() &#123; for &#123; select &#123; case x := &lt;-ch: fmt.Printf(&quot;%d &quot;, x) case &lt;-time.After(5 * time.Second): fmt.Println(&quot;\\nTimeout&quot;) done &lt;- true return &#125; &#125; &#125;() for i := 0; i &lt; 10; i++ &#123; ch &lt;- i time.Sleep(time.Second) &#125; &lt;-done&#125; 3.3 避免造成死锁select 在执行过程中，必须命中其中的某一分支, 否则deadlock 12345678910111213141516func main() &#123; c1 := make(chan string, 1) c2 := make(chan string, 1) c1 &lt;- &quot;ok&quot; c2 &lt;- &quot;good&quot; select &#123; case msg := &lt;-c1: fmt.Printf(&quot;c1 receive %s\\n&quot;, msg) case msg := &lt;-c2: fmt.Printf(&quot;c2 receive %s\\n&quot;, msg) default: fmt.Println(&quot;no data&quot;) &#125;&#125; 4. 定时器4.1 一次性定时任务time.NewTimer(d Duration) *Timer &lt;-timer.C: 阻塞等待，返回定时器时间 timer.Stop(): timer.Reset(d Duration): 1234567891011121314151617func main() &#123; timer := time.NewTimer(2 * time.Second) go func() &#123; &lt;-timer.C fmt.Println(&quot;Goroutine is done.&quot;) &#125;() timer.Stop() // 重置定时器，上面的 goroutine 将继续执行 timer.Reset(5 * time.Second) select &#123; case &lt;-time.After(10 * time.Second): &#125;&#125; 4.2 周期性定时任务time.NewTicker(d Duration) *Ticker &lt;-ticker.C: 阻塞等待，返回定时器时间 ticker.Stop(): 1234567891011121314151617func main() &#123; ticker := time.NewTicker(2 * time.Second) count := 0 for &#123; &lt;-ticker.C count++ fmt.Printf(&quot;%d &quot;, count) if count == 10 &#123; ticker.Stop() break &#125; &#125; fmt.Println()&#125; 4.3 延迟操作总结123456time.Sleep(time.Second * 2)&lt;- time.After(time.Second * 2)timer := time.NewTimer(time.Second * 2)&lt;-timer.C 5. 死锁经典错误案例5.1 无缓冲信道，在接收者未准备好之前，发送操作是阻塞的1234567func main() &#123; c := make(chan bool) c &lt;- true // 阻塞 fmt.Println(&lt;-c)&#125; 两种解决方法： 1) 先接收，后发送 123456789func main() &#123; c := make(chan bool) go func() &#123; fmt.Println(&lt;-c) &#125;() c &lt;- true&#125; 2) 使用缓冲信道 1234567func main() &#123; c := make(chan bool, 1) c &lt;- true fmt.Println(&lt;-c)&#125; 5.2 缓冲信道，超过容量12345678func main() &#123; c := make(chan bool, 1) c &lt;- true c &lt;- false fmt.Println(&lt;-c)&#125; 5.3 等待从信道读取数据，但信道无数据写入123456789101112func main() &#123; c := make(chan bool, 1) go func() &#123; c &lt;- true c &lt;- false &#125;() for i := range c &#123; fmt.Println(i) &#125;&#125; 解决办法：及时关闭无用信道 1234567891011121314func main() &#123; c := make(chan bool, 1) go func() &#123; c &lt;- true c &lt;- false close(c) // 关闭信道 &#125;() for i := range c &#123; fmt.Println(i) &#125;&#125; 6. 控制 goroutine 并发数量1234567891011121314151617181920212223242526func main() &#123; count := 10 wg := sync.WaitGroup&#123;&#125; ch := make(chan int, 2) for i := 0; i &lt; count; i++ &#123; wg.Add(1) go func(i int) &#123; defer wg.Done() for n := range ch &#123; fmt.Printf(&quot;go func: %d, time: %v\\n&quot;, n, time.Now()) time.Sleep(time.Duration(n) * time.Second) &#125; &#125;(i) &#125; for i := 0; i &lt; 10; i++ &#123; ch &lt;- 1 ch &lt;- 2 &#125; close(ch) wg.Wait()&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 结构体和接口","slug":"Go 结构体和接口","date":"2018-01-05T01:28:32.000Z","updated":"2021-06-22T10:50:49.704Z","comments":true,"path":"2018/01/05/Go 结构体和接口/","link":"","permalink":"https://elihe2011.github.io/2018/01/05/Go%20%E7%BB%93%E6%9E%84%E4%BD%93%E5%92%8C%E6%8E%A5%E5%8F%A3/","excerpt":"1. 结构体将多个不同类型命名字段(field)序列打包成一个复合类型。 结构体特点： 值类型 做参数，值传递 相同类型，可使用==或!=比较 Go语言中实现封装、继承和多态： 封装：通过方法实现 继承：通过匿名字段实现 多态：通过接口实现","text":"1. 结构体将多个不同类型命名字段(field)序列打包成一个复合类型。 结构体特点： 值类型 做参数，值传递 相同类型，可使用==或!=比较 Go语言中实现封装、继承和多态： 封装：通过方法实现 继承：通过匿名字段实现 多态：通过接口实现 1.1 定义结构体123456789101112type person struct &#123; Name string Age int&#125;func main() &#123; p := person&#123; Name: &quot;lucy&quot;, Age: 22, &#125; fmt.Println(p)&#125; 1.2 匿名结构体12345678910111213141516171819202122232425262728type person struct &#123; Name string Age int Contact struct &#123; Phone, City string &#125;&#125;func main() &#123; p1 := person&#123; Name: &quot;lucy&quot;, Age: 22, Contact: struct&#123; Phone, City string &#125; &#123; Phone: &quot;123456789&quot;, City: &quot;LA&quot;, &#125;, &#125; fmt.Println(p1) p2 := person&#123; Name: &quot;jack&quot;, Age: 19, &#125; p2.Contact.Phone = &quot;987654321&quot; p2.Contact.City = &quot;NY&quot; fmt.Println(p2)&#125; 1.3 匿名字段1234567891011func main() &#123; s := struct &#123; int string &#125; &#123; 10, &quot;jack&quot;, &#125; fmt.Println(s)&#125; 1.4 嵌入结构（模拟继承）123456789101112131415161718192021222324252627282930313233343536type person struct &#123; Name string Age int&#125;type teacher struct &#123; person Salary float32&#125;type student struct &#123; person Score float32&#125;func main() &#123; t := teacher &#123; person: person&#123; Name: &quot;Jack&quot;, Age: 45, &#125;, Salary: 12901.20, &#125; t.Age += 1 s := student&#123; person: person&#123; Name: &quot;Tom&quot;, Age: 13, &#125;, Score: 91.50, &#125; s.Score -= 2.5 fmt.Println(t, s)&#125; 1.5 结构体序列化注意使用struct标签，否则序列化后的名称会保持大写开头不变 12345678910111213141516type Student struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;`&#125;func main() &#123; stu := Student&#123;&quot;Jack&quot;, 21&#125; js, err := json.Marshal(stu) if err != nil &#123; fmt.Println(&quot;json化失败&quot;, err) return &#125; fmt.Println(string(js))&#125; 1.6 工厂模式123456789101112131415type student struct &#123; Name string Age byte&#125;func NewStudent(name string, age byte) *student &#123; return &amp;student&#123; Name: name, Age: age, &#125;&#125;func (stu *student) String() string &#123; return fmt.Sprintf(&quot;Name=%v, Age=%v&quot;, stu.Name, stu.Age)&#125; 1.7 结构体链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229type Node struct &#123; Name string Value int next *Node&#125;func main() &#123; node := &amp;Node&#123; Name: &quot;head&quot;, Value: 0, &#125; appendNodes(node) //trans(node) // 只所以要有二级指针，是为了改变顶级node的地址，方便遍历函数遍历 insertNodes(&amp;node) //trans(node) delNode(&amp;node, &quot;head&quot;) //trans(node) addNode(&amp;node, &quot;node_A_1&quot;, &amp;Node&#123;Name: &quot;newNode&quot;, Value: 12&#125;) trans(node)&#125;func appendNodes(p *Node) &#123; for i := 0; i &lt; 2; i++ &#123; node := Node&#123; Name: fmt.Sprintf(&quot;node_A_%d&quot;, i), Value: rand.Intn(100), &#125; p.next = &amp;node p = &amp;node &#125;&#125;func insertNodes(p **Node) &#123; for i := 0; i &lt; 2; i++ &#123; node := Node&#123; Name: fmt.Sprintf(&quot;node_I_%d&quot;, i), Value: rand.Intn(100), &#125; node.next = *p *p = &amp;node &#125;&#125;func delNode(p **Node, name string) &#123; head := *p // 第一个即为要删除的对象 if head.Name == name &#123; *p = head.next return &#125; prev := head head = head.next for head != nil &#123; if head.Name == name &#123; prev.next = head.next break &#125; prev = head head = head.next &#125;&#125;func addNode(p **Node, name string, newNode *Node) &#123; head := *p // 第一个元素前插入 if head.Name == name &#123; newNode.next = head *p = newNode return &#125; prev := head head = head.next for head != nil &#123; if head.Name == name &#123; prev.next = newNode newNode.next = head break &#125; prev = head head = head.next &#125;&#125;func trans(p *Node) &#123; for p != nil &#123; fmt.Println(*p) p = p.next &#125;&#125;func main() &#123; node := &amp;Node&#123; Name: &quot;head&quot;, Value: 0, &#125; appendNodes(node) insertNodes(&amp;node) delNode(&amp;node, &quot;node_I_4&quot;) appendNode(node, &quot;head&quot;, &quot;newAppend&quot;) insertNode(&amp;node, &quot;node_A_4&quot;, &quot;newInsert&quot;) trans(node)&#125;type Node struct &#123; Name string Value int next *Node&#125;func trans(p *Node) &#123; for p != nil &#123; fmt.Println(*p) p = p.next &#125;&#125;func appendNodes(p *Node) &#123; for i := 0; i &lt; 5; i++ &#123; node := &amp;Node&#123; Name: fmt.Sprintf(&quot;node_A_%d&quot;, i), Value: rand.Intn(100), &#125; p.next = node p = node &#125;&#125;// 除了要在head前增加元素，还需要去改变链表head的位置，需要用到多重指针func insertNodes(p **Node) &#123; for i := 0; i &lt; 5; i++ &#123; node := &amp;Node&#123; Name: fmt.Sprintf(&quot;node_I_%d&quot;, i), Value: rand.Intn(100), &#125; node.next = *p *p = node &#125;&#125;func delNode(p **Node, name string) &#123; node := *p // 第一个就是要删除的元素 if node.Name == name &#123; *p = node.next return &#125; prev := node node = node.next for node != nil &#123; if node.Name == name &#123; prev.next = node.next break &#125; prev = node node = node.next &#125;&#125;func appendNode(p *Node, name, newName string) &#123; for p != nil &#123; if p.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: p.next, &#125; p.next = newNode break &#125; p = p.next &#125;&#125;func insertNode(p **Node, name, newName string) &#123; node := *p // 在第一个元素前增加 if node.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: node, &#125; // 改变链表头 *p = newNode return &#125; prev := node node = node.next for node != nil &#123; if node.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: node, &#125; // 与前一个链接起来 prev.next = newNode break &#125; prev = node node = node.next &#125;&#125; 1.8 结构体内存结构不管结构体包含多少字段，其内存总是一次性分配的，各字段在相邻的地址空间按定义顺序排列。当然，对于引用类型、字符串和指针，结构内存中只包含其基本（头部）数据。还有，所有匿名字段成员也被包含在内。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455type point struct &#123; x, y int&#125;type node struct &#123; id int name string data []byte next *node point&#125;func main() &#123; v := node&#123; id: 1, name: &quot;yes&quot;, data: []byte&#123;1, 2, 3, 4&#125;, point: point&#123;x: 100, y: 200&#125;, &#125; format := `v: %p ~ %x, size %d, align: %dfield address offset size-------+--------------------+--------+-----id %p %d %dname %p %d %ddata %p %d %dnext %p %d %dx %p %d %dy %p %d %d` fmt.Printf(format, &amp;v, uintptr(unsafe.Pointer(&amp;v))+unsafe.Sizeof(v), unsafe.Sizeof(v), unsafe.Alignof(v), &amp;v.id, unsafe.Offsetof(v.id), unsafe.Sizeof(v.id), &amp;v.name, unsafe.Offsetof(v.name), unsafe.Sizeof(v.name), &amp;v.data, unsafe.Offsetof(v.data), unsafe.Sizeof(v.data), &amp;v.next, unsafe.Offsetof(v.next), unsafe.Sizeof(v.next), &amp;v.x, unsafe.Offsetof(v.x), unsafe.Sizeof(v.x), &amp;v.y, unsafe.Offsetof(v.y), unsafe.Sizeof(v.y))&#125;/*v: 0xc000084000 ~ c000084048, size 72, align: 8field address offset size-------+--------------------+--------+-----id 0xc000084000 0 8name 0xc000084008 8 16data 0xc000084018 24 24next 0xc000084030 48 8x 0xc000084038 56 8y 0xc000084040 64 8*/ unsafe.Sizeof(x)特点总结： 字符串：始终返回16。字符串类型对应一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占8个字节，但是并不包含指针指向的字符串的内容。 切片: 始终返回24。if x is a slice, Sizeof returns the size of the slice descriptor, not the size of the memory referenced by the slice. 数组: Sizeof(x[0]) * len(x) 1.9 结构体字段对齐在分配内存时，字段须做对齐处理，通常以所有字段中最长的基础类型宽度为标准 unsafe.Alignof(x): 获取对齐宽度，以最长的基础类型宽度作为对齐标准。 12345678910111213141516171819202122func main() &#123; v1 := struct &#123; a byte b byte c int32 // 对齐宽度4 &#125;&#123;&#125; v2 := struct &#123; a byte b byte // 对齐宽度1 &#125;&#123;&#125; v3 := struct &#123; a byte b []int // 基础类型int，对齐宽度8 c int32 &#125;&#123;&#125; fmt.Printf(&quot;v1: %d, %d\\n&quot;, unsafe.Alignof(v1), unsafe.Sizeof(v1)) // 4, 8 fmt.Printf(&quot;v2: %d, %d\\n&quot;, unsafe.Alignof(v2), unsafe.Sizeof(v2)) // 1, 2 fmt.Printf(&quot;v3: %d, %d\\n&quot;, unsafe.Alignof(v3), unsafe.Sizeof(v3)) // 8, 40&#125; 1.10 类型对齐长度 类型 对齐长度 bool 1 int8/byte 1 int32 4 int64 8 string 8 map 8 slice 8 2. 方法方法是与对象实例绑定的特殊函数 2.1 绑定方法123456789101112131415type A struct &#123; Name string&#125;// （a A) receiverfunc (a A) Print() &#123; fmt.Println(a.Name)&#125;func main() &#123; a := A&#123; Name: &quot;tom&quot;, &#125; a.Print()&#125; 2.2 为int扩展方法12345678910111213type TZ intfunc (a *TZ) Print() &#123; fmt.Println(&quot;TZ&quot;)&#125;func main() &#123; var a TZ a.Print() // method value (*TZ).Print(&amp;a) // method expression&#125; 2.3 结构体重写String()方法重新String()方法：(fmt.Println()会自动调用String()方法) 1234567891011121314type Student struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;`&#125;func main() &#123; stu := Student&#123;&quot;Jack&quot;, 21&#125; fmt.Println(&amp;stu) // 自动调用String()方法&#125;func (stu *Student) String() string &#123; return fmt.Sprintf(&quot;Name=%v, Age=%v&quot;, stu.Name, stu.Age)&#125; 2.4 方法集类型有一个与之相关的方法集（method set），这决定了它是否实现某个接口。 类型T方法集包含所有receiver T方法。 类型T方法集包含所有receiver T+T方法。 匿名嵌入S，T方法集包含所有receiver S方法。 匿名嵌入S，T方法集包含所有receiver S+S方法。 匿名嵌入S或S，T方法集包含所有receiver S+*S方法。 1234567891011121314151617181920212223242526272829type S struct&#123;&#125;type T struct &#123; S&#125;func (S) Hello() &#123;&#125;func (S) sVal() &#123;&#125;func (*S) sPtr() &#123;&#125;func (T) tVal() &#123;&#125;func (*T) tPtr() &#123;&#125;func methodSet(a interface&#123;&#125;) &#123; t := reflect.TypeOf(a) fmt.Println(t.NumMethod()) // methods need to export, 只有Hello一个方法可导出 for i, n := 0, t.NumMethod(); i &lt; n; i++ &#123; m := t.Method(i) fmt.Println(m.Name, m.Type) &#125;&#125;func main() &#123; var t = T&#123;&#125; methodSet(t) println(&quot;------------&quot;) methodSet(&amp;t)&#125; 3. 接口接口代表一种调用契约，是多个方法声明的集合。 采用duck type方式 它把所有具有共性的方法定义在一起，任何其他类型只要实现了这些方法，就实现了该接口。注意，要全部实现！ 接口特性： 一个或多个方法签名的集合 只要某类型拥有改接口的所有方法签名，即算实现该接口，无需显示声明实现了那些接口，此称为Structural Typing 接口中只有方法声明，没有实现 接口可匿名嵌入其他接口，或嵌入到结构中 将对象赋值给接口，会发生拷贝，而接口内部存储指向这个复制品的指针，即无法修改复制品的状态，也无法获取指针 只有当接口存储的类型和对象均为nil时，接口才能有nil 接口调用不会做receiver的自动转换 接口同样支持匿名字段方法 接口也可实现类似OOP中的多态 空接口可以作为任何类型数据的容器 3.1 示例112345678910111213141516171819202122232425262728293031323334type Animal interface &#123; walk() eat()&#125;type Cat struct &#123;&#125;type Bird struct &#123;&#125;func (cat Cat) walk() &#123; fmt.Println(&quot;Cat walking with four limbs.&quot;)&#125;func (cat Cat) eat() &#123; fmt.Println(&quot;Cats like to eat fish.&quot;)&#125;func (bird Bird) walk() &#123; fmt.Println(&quot;Bird walkin with two legs.&quot;)&#125;func (bird Bird) eat() &#123; fmt.Println(&quot;Birds like to eat insects.&quot;)&#125;func main() &#123; var animal Animal animal = new(Cat) animal.walk() animal = new(Bird) animal.eat()&#125; 3.2 示例2123456789101112131415161718192021222324252627282930313233343536373839404142434445type USB interface &#123; Name() string Connector&#125;type Connector interface &#123; Connect()&#125;type PhoneConnector struct &#123; name string&#125;func (pc PhoneConnector) Name() string &#123; return pc.name&#125;func (pc PhoneConnector) Connect() &#123; fmt.Println(&quot;Connected:&quot;, pc.name)&#125;/*func Disconnect(usb USB) &#123; // 类型断言 if pc, ok := usb.(PhoneConnector); ok &#123; fmt.Println(&quot;Disconnected:&quot;, pc.name) return &#125; fmt.Println(&quot;Unknown device&quot;)&#125;*/// 万能空接口func Disconnect(usb interface&#123;&#125;) &#123; switch v := usb.(type) &#123; case PhoneConnector: fmt.Println(&quot;Disconnected:&quot;, v.name) default: fmt.Println(&quot;Unknown device&quot;) &#125;&#125;func main() &#123; var a USB = PhoneConnector&#123;&quot;PhoneConnector&quot;&#125; a.Connect() Disconnect(a)&#125; 3.3 类型断言空接口可接收任意类型，如果要转换为具体类型，需要使用类型断言 1234567891011func main() &#123; var point Point = Point&#123;1, 2&#125; var a interface&#123;&#125; a = point var b Point b = a.(Point) // 类型断言 fmt.Println(b)&#125; 3.3.1 类型断言检查为避免转换错误直接panic，可先检查转换是否成功 12345678910111213func main() &#123; var a interface&#123;&#125; var x float32 = 1.23 a = x y, ok := a.(float32) // 类型断言 if ok &#123; fmt.Println(y) &#125; else &#123; fmt.Println(&quot;转换失败&quot;) &#125;&#125; 3.3.2 类型断言switch123456789101112func TypeJudge(items ...interface&#123;&#125;) &#123; for index, x := range items &#123; switch x.(type) &#123; case bool: fmt.Printf(&quot;%v: %v is bool\\n&quot;, index, x) case string: fmt.Printf(&quot;%v: %v is string\\n&quot;, index, x) default: fmt.Printf(&quot;%v: %v is unknown\\n&quot;, index, x) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 函数和错误处理","slug":"Go 函数和错误处理","date":"2018-01-04T00:25:38.000Z","updated":"2021-06-22T10:50:49.703Z","comments":true,"path":"2018/01/04/Go 函数和错误处理/","link":"","permalink":"https://elihe2011.github.io/2018/01/04/Go%20%E5%87%BD%E6%95%B0%E5%92%8C%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/","excerpt":"1. 函数 不支持嵌套、重载和默认参数 无需声明原型、不定长度变参、多返回值、命名返回参数、匿名函数、闭包 本身就是一种类型 函数调用底层分析： 栈区：基本数据类型一般分配到栈区。编译器存在一个逃逸分析。每个函数有独立的栈，函数执行完毕，自动销毁 堆区：引用数据类型一般分配在堆区 代码区：存放代码指令","text":"1. 函数 不支持嵌套、重载和默认参数 无需声明原型、不定长度变参、多返回值、命名返回参数、匿名函数、闭包 本身就是一种类型 函数调用底层分析： 栈区：基本数据类型一般分配到栈区。编译器存在一个逃逸分析。每个函数有独立的栈，函数执行完毕，自动销毁 堆区：引用数据类型一般分配在堆区 代码区：存放代码指令 init()函数：每个源文件，都可以包含一个init函数，该函数会在main函数执行前，被Go运行框架调用。 执行顺序：全局变量定义 -&gt; init() -&gt; main() 1.1 参数传递不管是指针、引用类型，还是其他类型参数，都是值拷贝传递（pass-by-value)。区别无非是拷贝目标对象，还是拷贝指针对象本身而已。 在函数调用时，会为形参和返回值分配内存空间，并将实参拷贝到形参的内存。 1.2 参数过多，改用struct1234567891011121314151617181920212223242526type serverOption struct &#123; ip string port int path string timeout time.Duration log *log.Logger&#125;func newOption() *serverOption &#123; return &amp;serverOption&#123; ip: &quot;0.0.0.0&quot;, port: 8080, path: &quot;/data/www&quot;, timeout: time.Second*5, log: nil, &#125;&#125;func server(option *serverOption) &#123;&#125;func main() &#123; opt := newOption() opt.port = 8080 server(opt)&#125; 1.3 变参变参，实际上传递的是一个slice，如果是array，先转化为slice。s := a[:]... 12345678910func test(a ...int) &#123; fmt.Printf(&quot;%T, %v\\n&quot;, a, a)&#125;func main() &#123; test(1, 2, 3, 4) a := [3]int &#123;10, 20, 30&#125; test(a[:]...)&#125; 2. 匿名函数2.1 直接执行12345func main() &#123; func (s string) &#123; println(s) &#125; (&quot;Hello world&quot;)&#125; 2.2 赋值给变量1234567func main() &#123; add := func (x, y int) int &#123; return x + y &#125; println(add(2, 3))&#125; 2.3 作为参数123456789func test(f func()) &#123; f()&#125;func main() &#123; test(func() &#123; println(&quot;Hello world&quot;) &#125;)&#125; 2.4 作为返回值12345678910func test(x, y int) func() int &#123; return func() int &#123; return x + y &#125;&#125;func main() &#123; add := test(2, 3) println(add())&#125; 2.5 作为结构体字段12345678910111213func testStruct() &#123; type calc struct &#123; mul func(x, y int) int &#125; z := calc &#123; mul: func(x, y int) int &#123; return x * y &#125;, &#125; println(z.mul(2, 5))&#125; 2.6 通过Channel传递123456789func testChannel() &#123; c := make(chan func(int, int) int, 2) c &lt;- func(a int, b int) int &#123; return a + b &#125; println((&lt;- c)(1, 2))&#125; 3. 闭包（closure）闭包：一个函数和与其相关的引用变量组成的一个实体 返回一个匿名函数 该匿名函数使用了函数外变量 3.1 示例112345678910func test(x int) func() &#123; println(&amp;x) return func() &#123; println(&amp;x, x) // 返回的函数，包含了x环境上下文 &#125;&#125;func main() &#123; test(5)()&#125; 1go build -gcflags &quot;-N -l&quot; main.go 3.2 示例212345678910111213func main() &#123; f := closure(10) fmt.Println(f(1)) // 11 fmt.Println(f(2)) // 12&#125;func closure(x int) func(int) int &#123; fmt.Printf(&quot;%p\\n&quot;, &amp;x) // 0xc0000140b0 return func(y int) int &#123; fmt.Printf(&quot;%p\\n&quot;, &amp;x) // 0xc0000140b0 return x + y &#125;&#125; 3.3 多匿名函数返回，延迟求值问题1234567891011121314151617func test() []func() &#123; var fs []func() for i := 0; i &lt; 3; i++ &#123; fs = append(fs, func() &#123; println(&amp;i, i) // 延迟执行特性，最后都输出3 &#125;) &#125; return fs&#125;func main() &#123; for _, f := range test() &#123; f() &#125;&#125; 修正后： 123456789101112131415161718func test() []func() &#123; var fs []func() for i := 0; i &lt; 3; i++ &#123; x := i // 立即赋值 fs = append(fs, func() &#123; println(&amp;x, x) &#125;) &#125; return fs&#125;func main() &#123; for _, f := range test() &#123; f() &#125;&#125; 4. 递归函数4.1 阶乘123456789101112func factorial(n uint64) uint64 &#123; if n &gt; 0 &#123; return n * factorial(n - 1) &#125; return 1&#125;func main() &#123; var i int = 15 fmt.Printf(&quot;%d 的阶乘等于 %d&quot;, i, factorial(uint64(i)))&#125; 4.2 Fibonacci1234567891011121314func fibonacci(n uint64) uint64 &#123; if n &lt; 2 &#123; return n &#125; return fibonacci(n-2) + fibonacci(n-1)&#125;func main() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, fibonacci(uint64(i))) &#125; fmt.Println()&#125; 5. 延迟调用（defer) FILO 先进后出 即使函数发生panic错误，也会执行 支持匿名函数调用 用于资源清理、文件关闭、解锁以及记录时间等操作 与匿名函数配合，可在return后修改函数的计算结果 5.1 示例11234567891011func main() &#123; for i := 0; i &lt; 3; i++ &#123; defer fmt.Println(i) // 2 1 0 &#125; for i := 0; i &lt; 3; i++ &#123; defer func() &#123; fmt.Println(i) // 3 3 3 &#125;() &#125;&#125; 5.2 循环中使用延迟调用延迟调用在函数结束时调用，如果将其放到循环中，会造成资源浪费 123456789101112131415func main() &#123; for i := 0; i &lt; 1000; i++ &#123; path := fmt.Sprintf(&quot;./log/%d.txt&quot;, i) f, err := os.Open(path) if err != nil &#123; log.Println(err) continue &#125; defer f.Close() // do something &#125;&#125; 优化： 12345678910111213141516171819func main() &#123; do := func(i int) &#123; path := fmt.Sprintf(&quot;./log/%d.txt&quot;, i) f, err := os.Open(path) if err != nil &#123; log.Println(err) return &#125; defer f.Close() // do something &#125; for i := 0; i &lt; 1000; i++ &#123; do(i) &#125;&#125; 5.3 延迟调用闭包1234567891011121314151617181920func main() &#123; var fs = [4]func()&#123;&#125; for i := 0; i &lt; 4; i++ &#123; defer fmt.Println(&quot;defer i = &quot;, i) defer func() &#123; fmt.Println(&quot;defer_closure i = &quot;, i) // always 4 &#125;() defer func(i int) &#123; fmt.Println(&quot;defer_closure i = &quot;, i) // i will change &#125;(i) fs[i] = func() &#123; fmt.Println(&quot;closure i = &quot;, i) &#125; &#125; for _, f := range fs &#123; f() &#125;&#125; 5.4 延迟调用性能相比直接用CALL汇编指令调用函数，延迟调用则须花费更大代价。这其中包括注册、调用等操作，还有额外的缓存开销。 1234567891011121314151617181920212223var m sync.Mutexfunc call() &#123; m.Lock() m.Unlock()&#125;func deferCall() &#123; m.Lock() defer m.Unlock()&#125;func BenchmarkCall(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; call() &#125;&#125;func BenchmarkDeferCall(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; deferCall() &#125;&#125; 5.5 for range与闭包的坑1234567891011func main() &#123; s := []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; for _, v := range s &#123; go func() &#123; fmt.Println(v) // 三次全部打印&quot;c&quot; &#125;() &#125; select &#123;&#125; // 使main一直等待直到deadlock异常&#125; 6. 错误处理标准库错误接口: 123type error interface &#123; Error() string&#125; 6.1 panic &amp; recover panic: 主动抛出错误 recover: 捕获panic抛出的错误 12func panic(v interface&#123;&#125;)func recover() interface&#123;&#125; panic和recover运行机制： 1) 引发panic有两种情况：一是程序主动调用，二是程序产生运行时错误(Runtime Error)，由运行时检测并退出 2) 发生panic后，程序会从调用panic的函数位置或发生panic的地方立即返回，逐层执行函数的的defer语句，然后逐层打印函数调用堆栈，直到recover捕获或运行到最外层函数 3) panic不但可以在函数正常流程中抛出，在defer逻辑里也可以再次调用panic或抛出panic。defer里面的panic能够被后续执行的defer捕获 4) recover用来捕获panic，阻止panic继续向上传递。recover()和defer一起使用，但是defer只有在后面的函数体内直接被调用才能捕获panic来终止，否则返回nil，异常继续向外传递。 注意：除非是不可恢复性、导致系统无法正常工作的错误，否则不建议使用panic。如：文件系统没操作权限、服务端口被占用、数据库未启动等 123456789101112131415func main() &#123; result := div(8, 0) fmt.Println(result)&#125;func div(a int, b int) int &#123; defer func() &#123; err := recover() if err != nil &#123; fmt.Println(err) &#125; &#125;() return a / b&#125; 6.2 主动panic并捕获12345678910func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Fatalln(err) &#125; &#125;() panic(&quot;crash&quot;) println(&quot;exit.&quot;)&#125; 6.3 无效捕获和有效捕获错误12345678910111213141516171819202122// 无效的捕获defer recover()defer fmt.Println(recover())defer func() &#123; func() &#123; recover() // 嵌套多层，无效 &#125;()&#125;()// 有效的捕获defer func() &#123; recover()&#125;()func except() &#123; recover()&#125;func test() &#123; defer except() panic(&quot;runtime error&quot;)&#125; 6.4 多个panic，只会捕获最后一个1234567891011121314151617func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) // three 只会捕获最后一个 &#125; &#125;() defer func() &#123; panic(&quot;three&quot;) &#125;() defer func() &#123; panic(&quot;two&quot;) &#125;() panic(&quot;one&quot;)&#125; 7. 自定义错误 errors.New(&quot;错误描述&quot;)：返回一个error类型的值，表示一个错误 panic内置函数：接收一个interface{}类型的值(即任意值)作为参数，可以接受error类型的变量，输出错误信息，并退出程序。 7.1 负数平方根1234567891011121314151617func Sqrt(x float64) (float64, error) &#123; if x &lt; 0 &#123; return 0, errors.New(&quot;math: square root of negative number&quot;) &#125; return math.Sqrt(x), nil&#125;func main() &#123; result, err := Sqrt(-1) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(result) &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 引用数据类型","slug":"Go 引用数据类型","date":"2018-01-03T02:52:13.000Z","updated":"2021-06-22T10:50:49.703Z","comments":true,"path":"2018/01/03/Go 引用数据类型/","link":"","permalink":"https://elihe2011.github.io/2018/01/03/Go%20%E5%BC%95%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"1. 指针指针不是内存地址。 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。 指针会分配内存空间，相当于一个专门用来保存地址的整型变量。 GO指针，不支持加减运算和类型转换 可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。 Pointer类似C语言中的void*万能指针，可用来转换指针类型。它能安全持有对象或对象成员，但uintptr不行。后者仅是一种特殊整型，并不引用目标对象，无法阻止垃圾回收器回收对象内存。","text":"1. 指针指针不是内存地址。 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。 指针会分配内存空间，相当于一个专门用来保存地址的整型变量。 GO指针，不支持加减运算和类型转换 可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。 Pointer类似C语言中的void*万能指针，可用来转换指针类型。它能安全持有对象或对象成员，但uintptr不行。后者仅是一种特殊整型，并不引用目标对象，无法阻止垃圾回收器回收对象内存。 1.1 引用传递12345678910111213141516171819const MAX int = 3func main() &#123; var a int = 10 var b int = 20 fmt.Println(a, b) swap(&amp;a, &amp;b) fmt.Println(a, b)&#125;func swap(x *int, y *int) &#123; var temp int temp = *x *x = *y *y = temp&#125; 1.2 指针类型1.2.1 三种指针： *T：普通指针，用于传递地址，不能进行指针运算 unsafe.Pointor: 通用指针类型。用于转换不同类型的指针，不能进行指针运算 uintptr: 用于指针运算。GC不把uintptr当指针，uintptr无法持有对象。uintptr类型的目标会被回收 1.2.2 unsafe.Pointer 作用 unsafe.Pointer 可以和 普通指针 进行互相转换 unsafe.Pointer 可以和 uintptr 进行相互转换 unsafe.Pointer 是桥梁，可以让任意类型的指针实现相互转换，也可以将任意类型的指针转换为uintptr进行指针运算 2. 切片 (Slice)切片是对数组的抽象。数组长度固定，而切片长度不固定，可追加元素，被称为动态数组。 不是数组，但指向底层的数组 可现实变长数组 为引用类型 可直接创建(make)或从底层数组获取生成 len()获取元素个数，cap()获取容量 不支持比较操作(==, &gt;, &lt;) 12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 2.1 创建切片123456789101112131415func main() &#123; s1 := make([]int, 3, 5) s2 := make([]int, 3) s3 := []int&#123;10, 20, 3: 30&#125; arr := [...]int&#123;1, 2, 3, 4, 5&#125; s4 := arr[:] s5 := arr[2:4] // cap=len(arr)-2 fmt.Println(s1, len(s1), cap(s1)) // [0, 0, 0] 3 5 fmt.Println(s2, len(s2), cap(s2)) // [0, 0, 0] 3 3 fmt.Println(s3, len(s3), cap(s3)) // [10, 20, 0, 30] 4 4 fmt.Println(s4, len(s4), cap(s4)) // [1, 2, 3, 4, 5] 5, 5 fmt.Println(s5, len(s5), cap(s5)) // [3, 4] 2 3&#125; 2.2 空切片123456789101112131415func main() &#123; var s1 []int s2 := []int&#123;&#125; fmt.Println(s1==nil, s2==nil) // true false // &amp;reflect.SliceHeader&#123;Data:0x0, Len:0, Cap:0&#125; fmt.Printf(&quot;a: %#v\\n&quot;, (*reflect.SliceHeader)(unsafe.Pointer(&amp;s1))) // &amp;reflect.SliceHeader&#123;Data:0x118efd0, Len:0, Cap:0&#125; fmt.Printf(&quot;b: %#v\\n&quot;, (*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))) fmt.Printf(&quot;Size of a: %d\\n&quot;, unsafe.Sizeof(s1)) // 24 fmt.Printf(&quot;Size of a: %d\\n&quot;, unsafe.Sizeof(s2)) // 24&#125; 2.3 复制数据允许指向同一底层数组，允许目标区间重叠。最终所复制长度以较短的切片长度（len）为准 123456789101112131415func main() &#123; s1 := []int&#123;1, 2, 3, 4, 5, 6&#125; s2 := []int&#123;7, 8, 9&#125; copy(s1, s2) // dst, src fmt.Println(s1) // [7, 8, 9, 4, 5, 6] fmt.Println(s2) // [7, 8, 9] s3 := []byte&#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125; s4 := []byte&#123;&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;&#125; copy(s3, s4) fmt.Println(s3) // [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;] fmt.Println(s4) // [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;]&#125; 2.4 扩容数据12345678910111213func main() &#123; s1 := make([]int, 3, 6) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) fmt.Println(len(s1), cap(s1)) // 3, 6 s1 = append(s1, 1, 2, 3) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) // 元素个数小于等于cap，地址未发生改变 fmt.Println(len(s1), cap(s1)) // 6, 6 s1 = append(s1, 4) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) // 元素个数大于原始cap，重新分配内存(底层数组重构)，地址发生改变 fmt.Println(len(s1), cap(s1)) // 7, 12&#125; Slice坑：slice虽然是引用，但可能被重新分配内存 1234567891011func foo(s []int) &#123; s = append(s, 1) // 增加的元素个数大于cap-len, 重新分配内存地址&#125;func main() &#123; s := make([]int, 0) fmt.Println(s) foo(s) fmt.Println(s) // []&#125; 3. 集合 (map)make([keyType]valueType, cap) 3.1 基本操作12345678910111213141516171819func main() &#123; m := map[string]int &#123; &quot;a&quot;: 1, &quot;b&quot;: 2, &#125; m[&quot;a&quot;] = 5 m[&quot;c&quot;] = 8 if v, ok := m[&quot;d&quot;]; ok &#123; println(v) &#125; delete(m, &quot;d&quot;) for k, v := range m &#123; println(k, &quot;:&quot;, v, &quot; &quot;) &#125;&#125; 3.2 多层map嵌套12345678910111213141516func main() &#123; m := make(map[int]map[int]string) // initialize sub-map m[1] = make(map[int]string) m[1][1] = &quot;OK&quot; fmt.Println(m) a, ok := m[2][1] // test if sub-map is initialized fmt.Println(a, ok) if !ok &#123; m[2] = make(map[int]string) &#125; fmt.Println(m)&#125; 3.3 不支持修改成员值(struct或array)字典被设计成“not addressable”，故不能直接修改value成员（结构或数组） 123456789101112131415161718192021222324252627func main() &#123; m := map[int]user&#123; 1: user&#123;&quot;Jack&quot;, 23&#125;, 2: user&#123;&quot;Tom&quot;, 22&#125;, &#125; //m[1].age++ // cannot assign to struct field in a map jack := m[1] jack.age++ m[1] = jack // 必须重新赋值 fmt.Println(m) // 指针方式 m2 := map[int]*user&#123; 1: &amp;user&#123;&quot;Jack&quot;, 23&#125;, 2: &amp;user&#123;&quot;Tom&quot;, 22&#125;, &#125; m2[1].age++ fmt.Println(m2[1])&#125;type user struct &#123; name string age int&#125; 12345678910111213func main() &#123; m := map[string][2]int &#123; &quot;a&quot;: &#123;1, 2&#125;, &#125; //s := m[&quot;a&quot;][:] // 数组必须addressable，否则会引发错误。 a := m[&quot;a&quot;] fmt.Printf(&quot;%p, %v\\n&quot;, &amp;a, a) s := a[:] fmt.Printf(&quot;%p, %v\\n&quot;, &amp;s, s)&#125; 3.4 map间接排序12345678910111213141516171819func main() &#123; m := map[int]string&#123;2: &quot;b&quot;, 5: &quot;e&quot;, 1: &quot;a&quot;, 3: &quot;c&quot;, 4: &quot;d&quot;&#125; s := make([]int, len(m)) i := 0 for k, _ := range m &#123; s[i] = k i++ &#125; fmt.Println(s) sort.Ints(s) // 索引排序 fmt.Println(s) for _, v := range s &#123; fmt.Println(m[v]) &#125;&#125; 3.5 并发读写字典1234567891011121314151617181920212223242526func main() &#123; var lock sync.RWMutex m := make(map[string]int) go func() &#123; for &#123; lock.Lock() m[&quot;a&quot;] += 1 lock.Unlock() time.Sleep(time.Microsecond) &#125; &#125;() go func() &#123; for &#123; lock.RLock() _ = m[&quot;b&quot;] lock.RUnlock() time.Sleep(time.Microsecond) &#125; &#125;() select &#123;&#125;&#125; 4. range用于for循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。 slice(i, v) map(k, v) 4.1 示例：遍历map1234567891011121314151617func main() &#123; sm := make([]map[int]string, 3) for _, v := range sm &#123; v = make(map[int]string) // range中v的值是一份拷贝，无法修改 v[1] = &quot;OK&quot; fmt.Println(v) &#125; fmt.Println(sm) // 可正确修改 for i := range sm &#123; sm[i] = make(map[int]string) sm[i][1] = &quot;OK&quot; fmt.Println(sm[i]) &#125; fmt.Println(sm)&#125; 4.2 示例：遍历slice1234567891011121314151617181920func main() &#123; nums := []int &#123;2, 3, 4&#125; sum := 0 for _, num := range nums &#123; sum += num &#125; fmt.Println(&quot;sum:&quot;, sum) for i, num := range nums &#123; if num == 3 &#123; fmt.Println(&quot;index:&quot;, i) &#125; &#125; for i, c := range &quot;go语言&quot; &#123; fmt.Println(i, c) // c, unicode值 &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 基本数据类型","slug":"Go 基本数据类型","date":"2018-01-02T09:11:18.000Z","updated":"2021-06-22T10:50:49.702Z","comments":true,"path":"2018/01/02/Go 基本数据类型/","link":"","permalink":"https://elihe2011.github.io/2018/01/02/Go%20%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"1. 数据类型1.1 Go数据类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8的别名，相互不需要转换 int, uint 4, 8 0 默认整型，长度依平台而定，32或64 int8, uint8 1 0 -128 ~ 127, 0 ~ 255 int16, uint16 2 0 int32, uint32 4 0 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 默认 complex64 8 complex128 16 rune 4 0 Unicode Code Point, int32的别名 uintptr 4, 8 0 存储指针的uint string “” 默认值空字符串，而非nil array 数组 struct 结构体 function nil interface nil map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 ｜","text":"1. 数据类型1.1 Go数据类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8的别名，相互不需要转换 int, uint 4, 8 0 默认整型，长度依平台而定，32或64 int8, uint8 1 0 -128 ~ 127, 0 ~ 255 int16, uint16 2 0 int32, uint32 4 0 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 默认 complex64 8 complex128 16 rune 4 0 Unicode Code Point, int32的别名 uintptr 4, 8 0 存储指针的uint string “” 默认值空字符串，而非nil array 数组 struct 结构体 function nil interface nil map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 ｜ 1.2 值类型和引用类型 值类型：基本数据类型(int, float, bool, string)、数组(array)和结构体(struct) 变量直接存储，内存通常在栈中分配 (栈区：存放生命周期较短的数据) 引用类型：ptr、slice、map、channel、interface 变量存储的是一个地址，该地址对应的空间才真正存储数据。内存通常在堆上分配。当没有任何变量引用这个地址时，该地址对应的数据空间就成了垃圾，由GC来回收。（堆区：存放生命周期较长的数据。一个值类型，一般存储在栈区，但它如果在别的函数也用到，此时有可能放堆区，它要做逃逸分析） 2. 基本数据类型2.1 const常量2.1.1 常量特性： readonly cannot get address 12345678const x = 0x100y := &amp;x // errorconst x = 100const y byte = x // ok， 相当于const y byte = 100const x int = 100const y byte = x // error，需强制转换 2.1.2 常量初始化和枚举：iota: 常量计数器 1234567891011121314151617181920212223242526272829303132333435363738const ( a = &quot;A&quot; b // &quot;A&quot; c = iota // 2 d // 3)const ( e = iota // 0 f)const ( SUN = iota MON TUE WED THU FRI SAT)const ( B float64 = 1 &lt;&lt; (iota * 10) KB MB GB)// 需要显示恢复const ( a = iota // 0 b // 1 c = 100 // 100 d // 100 e = iota // 4 f // 5) 2.2 数值类型2.2.1 类型转换必须显示转换，不支持像Java一样向上自动转换 1234byte // uint8, 处理ASCII字符rune // int32, 处理Unicode字符，比如中文float64 // 系统默认类型，明确声明时，也推荐使用 2.2.2 运算符123456789101112// 除法fmt.Println(10 / 4) // 2var n1 float32 = 10 / 4fmt.Println(n1) // 2var n2 float32 = 10.0 / 4fmt.Println(n2) // 2.5// 取余 a % b = a - a / b * b10 % 3 // 1-10 % 3 // -1 2.2.3 两个变量，进行值交换，不允许使用中间变量123456var a int = 3var b int = 8a = a + bb = a - b // b = (a + b) - b = aa = a - b // a = (a + b) - a = b 2.2.4 数值进制转换123456789func main() &#123; a, _ := strconv.ParseInt(&quot;1100100&quot;, 2, 32) b, _ := strconv.ParseInt(&quot;0144&quot;, 8, 32) c, _ := strconv.ParseInt(&quot;64&quot;, 16, 64) println(&quot;0b&quot; + strconv.FormatInt(a, 2)) println(&quot;0&quot; + strconv.FormatInt(b, 8)) println(&quot;0x&quot; + strconv.FormatInt(c, 16))&#125; 2.2.5 数值类型转换123456789101112131415161718192021222324func main() &#123; a, _ := strconv.ParseInt(&quot;10100101&quot;, 2, 32) b, _ := strconv.ParseFloat(&quot;3.1415926&quot;, 64) fmt.Printf(&quot;%T, %v\\n&quot;, a, a) // int64 165 fmt.Printf(&quot;%T, %v\\n&quot;, b, b) // float64 3.1415926 fmt.Println(&quot;0x&quot; + strconv.FormatInt(a, 16)) // 0xa5 c := string(65) fmt.Printf(&quot;%T, %v\\n&quot;, c, c) // string, A d := int(c[0]) fmt.Printf(&quot;%T, %v\\n&quot;, d, d) // int, 65 e := strconv.Itoa(65) fmt.Printf(&quot;%T, %v\\n&quot;, e, e) // string, 65 f, _ := strconv.Atoi(e) fmt.Printf(&quot;%T, %v\\n&quot;, f, f) // int, 65 g, _ := strconv.ParseBool(&quot;true&quot;) fmt.Printf(&quot;%T, %v\\n&quot;, g, g) // bool, true&#125; 2.2.6 处理浮点数12345678910func main() &#123; var a float32 = 5.1234567890 var b float32 = 5.12345678 var c float32 = 5.123456789 println(a, b, c) // +5.123457e+000 +5.123457e+000 +5.123457e+000 println(a==b, a==c) // true true, 新版本go1.14.2，false, false fmt.Printf(&quot;%v, %v, %v\\n&quot;, a, b, c) // 5.123457, 5.123457, 5.123457&#125; 2.2.7 浮点数精度问题1234567891011121314151617181920212223func main() &#123; a := 0.6 a += 0.7 fmt.Println(a) // 1.2999999999999998 b := truncate(a) fmt.Println(b) // 1.3 c := round(a, 8) fmt.Println(c)&#125;func truncate(f float64) float64 &#123; str := fmt.Sprintf(&quot;%.8f&quot;, f) fmt.Println(str) // 1.30000000 f, _ = strconv.ParseFloat(str, 64) return f&#125;func round(f float64, n int) float64 &#123; n10 := math.Pow10(n) return math.Trunc((f+0.5/n10)*n10) / n10&#125; 2.3 字符串本质：是一个不可变byte序列，本身是一个复合结构 1234type stringStruct struct &#123; str unsafe.Pointer len int&#125; 头部指针指向字节数组，但没有NULL结尾 原始字符串raw string : 使用反引号”`”包裹，支持跨行 2.3.1 元素允许索引方式访问元素，但不能获取元素地址 123456func main() &#123; s := &quot;abc&quot; println(s[1]) println(&amp;s[1]) // cannot take the address&#125; 2.3.2 切片切片语法返回的子字符串，其内部依旧指向原始数组 reflect.StringHeader和string头结构相同 unsafe.Pointer用于指针类型转换 12345678910111213func main() &#123; s := &quot;abcdefg&quot; s1 := s[:3] s2 := s[1:4] s3 := s[2:] println(s1, s2, s3) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s))) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s1))) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s2)))&#125; 2.3.3 字符串遍历12345678910111213func main() &#123; s := &quot;中文&quot; // byte for i := 0; i &lt; len(s); i++ &#123; fmt.Printf(&quot;%d: [%c]\\n&quot;, i, s[i]) &#125; // rune for i, c := range s &#123; fmt.Printf(&quot;%d: [%c]\\n&quot;, i, c) &#125;&#125; 2.3.4 修改字符串字符串对象不可变，要修改，先将其转换为可变类型 []rune或[]byte 123456789101112131415161718s := &quot;hello world&quot;bs := []byte(s)s1 = string(bs)rs := []rune(s)s2 := string(rs)func toString(bs []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;bs))&#125;// 该方法利用了[]byte和string头结构“部分相同”，以非安全的指针类型转换来实现类型“变更”，从而避免了底层数组复制。在很多Web Framework中都能看到此类做法，在高并发压力下，此种做法能有效改善执行性能。只是使用unsafe存在一定的风险，须小心谨慎！s3 := toString(bs)// 修改字符串bs = append(bs, &quot;abc&quot;...)s4 := string(bs) 2.3.5 处理Unicode123456789101112func main() &#123; r := &#x27;中&#x27; // rune s := string(r) // string b := byte(r) // byte, 丢弃超出范围的bit fmt.Printf(&quot;%T, %T, %T\\n&quot;, r, s, b) // int32, string, uint8 s1 := string(b) r2 := rune(b) fmt.Println(s, b, s1, r2) // 中 45 - 45&#125; 2.3.6 截取字符串1234567func main() &#123; s := &quot;中C文&quot; fmt.Println(len(s), utf8.RuneCountInString(s)) // 7 3 s = string(s[0:1] + s[3:4]) fmt.Println(s, utf8.ValidString(s))&#125; 2.3.7 字符串拼接性能测试命令: go test -bench=. 1) 较差 123456789101112131415func test() string &#123; var s string for i := 0; i &lt; 10000; i++ &#123; s += &quot;a&quot; &#125; return s&#125;func BenchmarkTest(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; test() &#125;&#125; 2) 改进1 strings.Join(sa, &quot;&quot;) 123456789func test() string &#123; sa := make([]string, 10000) for i := 0; i &lt; len(sa); i++ &#123; sa[i] = &quot;a&quot; &#125; return strings.Join(sa, &quot;&quot;)&#125; 3) 改进2 byte.Buffer 12345678910func test() string &#123; var b bytes.Buffer b.Grow(10000) for i := 0; i &lt; 10000; i++ &#123; b.WriteString(&quot;a&quot;) &#125; return b.String()&#125; 2.3.8 字符串常用函数12345678910111213141516171819202122232425262728293031len(&quot;abc&quot;)r := []rune(&quot;中文&quot;) // 字符串遍历，同时支持处理中文n, err := strconv.Atoi(&quot;123&quot;)str := strconv.Itoa(123)bytes := []byte(&quot;abc&quot;) // [97, 98, 99]，二进制写入时有用str := string([]byte&#123;97, 98, 99&#125;) // abcstr := strconv.FormatInt(123, 2) // 进制转换 base=2, 8, 16b := strings.Contains(&quot;seafood&quot;, &quot;foo&quot;)count := strings.Count(&quot;seafood&quot;, &quot;o&quot;)b := strings.EqualFold(&quot;abc&quot;, &quot;ABC&quot;) // 不区分大小写n := strings.Index(&quot;go golang&quot;, &quot;go&quot;) // 0n := strings.LastIndex(&quot;go golang&quot;, &quot;go&quot;) // 3str := strings.Replace(&quot;go golang&quot;, &quot;c&quot;, n) 替换个数n，n=-1表示全部strArr := strings.Split(&quot;hello,world,ok&quot;, &quot;,&quot;)str := strings.toLower(&quot;Go&quot;)str := strungs.toUpper(&quot;Go&quot;)str := strings.TrimSpace(&quot; I am a gopher, haha. &quot;)str := strings.Trim(&quot;!Hello World!&quot;, &quot;!&quot;)str := strings.TrimRight(&quot;!Hello World!&quot;, &quot;!&quot;)str := strings.TrimLeft(&quot;!Hello World!&quot;, &quot;!&quot;)b := strings.HasPrefix(&quot;http://google.com&quot;, &quot;http&quot;)b := strings.HasSuffix(&quot;index.html&quot;, &quot;html&quot;) 2.3.9 获取中文字符串长度：12345678var str = &quot;hello 你好&quot;len(str) // 12import &quot;unicode/utf8&quot;utf8.RuneCountInString(str) // 8len([]rune(str)) // 8 2.4 数组2.4.1 声明和初始化123456789101112// 声明var balance [10]float32// 初始化var balance = [5]float32 &#123;4.0, 1.3, 2.2, 3.9, 3.0&#125;var balance = [...]float32 &#123;4.0, 1.3, 2.2&#125;balance[2] = 3.2// 访问数组var tag float32 = balance[1] 2.4.2 数组遍历12345678910111213func main() &#123; var arr [10]int for i := 0; i &lt; 10; i++ &#123; arr[i] = i + 100 &#125; for j := 0; j &lt; 10; j++ &#123; fmt.Printf(&quot;%d\\t&quot;, arr[j]) &#125; fmt.Println()&#125; 2.4.3 二分查找二分查找逻辑： 数组必须有序arr 中间的下标：midIndex = (firstIndex + lastIndex) / 2 让arr[midIndex]与targetValue比较 arr[midIndex] &gt; targetValue，返回firstIndex … (midIndex-1) arr[midIndex] &lt; targetValue，返回(midIndex+1) … lastIndex arr[midIndex] == targetValue，找到 1234567891011121314151617181920212223242526func main() &#123; a := []int&#123;0, 3, 5, 8, 9, 12, 14, 16&#125; index := binarySearch(&amp;a, 0, len(a)-1, 12) if index == -1 &#123; fmt.Println(&quot;未找到&quot;) &#125; else &#123; fmt.Printf(&quot;找到，位置在 %d\\n&quot;, index) &#125;&#125;func binarySearch(a *[]int, left, right, target int) int &#123; if left &gt;= right &#123; return -1 &#125; mid := (left + right) / 2 if (*a)[mid] &gt; target &#123; return binarySearch(a, left, mid-1, target) &#125; else if (*a)[mid] &lt; target &#123; return binarySearch(a, mid+1, right, target) &#125; else &#123; return mid &#125;&#125; 2.4.4 多维数组只允许第一维缺省 123456789101112131415161718192021222324func main() &#123; a := [2][2]int &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#125; b := [...][3]int &#123; &#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;, &#125; c := [...][2][2]int &#123; &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#125;, &#123; &#123;5, 6&#125;, &#123;7, 8&#125;, &#125;, &#125; fmt.Println(a, b, c)&#125; 2.4.5 数组长度len和cap都只返回一维数组长度 123456789func main() &#123; a := [...][2]int &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#123;5, &#125;, &#125; fmt.Println(len(a), cap(a), len(a[0]), cap(a[0]), len(a[2]), cap(a[2]))&#125; 2.4.6 比较操作 如元素类型支持“==、!=”操作符，那么数组也支持此操作。 前提：类型必须一致！ 1234567891011121314func main() &#123; var a, b [2]int fmt.Println(a == b) c := [2]int&#123;1, 2&#125; d := [2]int&#123;1, 3&#125; fmt.Println(c == d) e := [3]int&#123;1, 2, 3&#125; fmt.Println(c == e) // 类型不一致，无法比较 var x, y [2]map[string]int fmt.Println(x == y) // map不支持==和!=操作，数组无法支持&#125; 2.4.7 指针数组和数组指针 指针数组: 元素为指针类型的数组 数组指针: 数组变量的地址 123456789func main() &#123; x, y := 10, 20 a := [...]*int &#123;&amp;x, &amp;y&#125; // 指针数组 p := &amp;a // 数组指针 fmt.Printf(&quot;%T %v\\n&quot;, a, a) fmt.Printf(&quot;%T %v\\n&quot;, p, p)&#125; 使用指针操作数组： 123456789func main() &#123; a := [...]int&#123;1, 2&#125; fmt.Println(&amp;a, &amp;a[0], &amp;a[1]) p := &amp;a p[1] += 3 fmt.Println(p, a)&#125; 2.4.8 数组复制1234567891011121314151617181920func test1(x [2]int) &#123; fmt.Printf(&quot;x: %p, %v\\n&quot;, &amp;x, x)&#125;func test2(y *[2]int) &#123; fmt.Printf(&quot;y: %p, %v\\n&quot;, y, *y)&#125;func main() &#123; a := [2]int&#123;1, 2&#125; var b [2]int b = a // 值复制，地址并未复制 fmt.Printf(&quot;a: %p, %v\\n&quot;, &amp;a, a) fmt.Printf(&quot;b: %p, %v\\n&quot;, &amp;b, b) test1(a) // 按值传递 test2(&amp;a) // 按地址传递&#125; 2.4.9 排序算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869func main() &#123; arr := [...]int&#123;5, 7, 8, 1, 2, 4, 9, 0, 3, 6&#125; //bubbleSort(arr[:]) //selectSort(arr[:]) //insertSort(arr[:]) quickSort(arr[:], 0, len(arr)-1) fmt.Println(arr)&#125;func bubbleSort(a []int) &#123; for i := 0; i &lt; len(a); i++ &#123; for j := 1; j &lt; len(a)-i; j++ &#123; // 相邻比较，交换位置 if a[j] &lt; a[j-1] &#123; a[j], a[j-1] = a[j-1], a[j] &#125; &#125; &#125;&#125;func selectSort(a []int) &#123; for i := 0; i &lt; len(a); i++ &#123; for j := i + 1; j &lt; len(a); j++ &#123; // 选择a[i]作为标兵，将它与i+1...的值比较，找到最小或最大，赋值给a[i] if a[i] &gt; a[j] &#123; a[i], a[j] = a[j], a[i] &#125; &#125; &#125;&#125;func insertSort(a []int) &#123; // 假定第一个元素是有序的，后的元素与之比较，满足条件逐个插入 for i := 1; i &lt; len(a); i++ &#123; for j := i; j &gt; 0; j-- &#123; // 前一个元素大于后一个元素，跳过比较 if a[j] &gt; a[j-1] &#123; break &#125; a[j], a[j-1] = a[j-1], a[j] &#125; &#125;&#125;func quickSort(a []int, left, right int) &#123; if left &gt;= right &#123; return &#125; // 选取一个元素，作为比较项 k := left val := a[k] for i := left + 1; i &lt;= right; i++ &#123; // 比基准值小的摆放在基准前面，比基准值大的摆在基准的后面 if a[i] &lt; val &#123; a[k] = a[i] a[i] = a[k+1] k++ &#125; &#125; a[k] = val quickSort(a, left, k-1) quickSort(a, k+1, right)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 语言基础","slug":"Go 语言基础","date":"2018-01-01T04:11:18.000Z","updated":"2021-06-22T10:50:49.702Z","comments":true,"path":"2018/01/01/Go 语言基础/","link":"","permalink":"https://elihe2011.github.io/2018/01/01/Go%20%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"1. Go语言相关知识点1.1 Go特点： 类型安全和内存安全 以非常直观和极低的代价实现高并发 高效的垃圾回收机制 快速编译 为多核计算机提供提升性能的方案 默认UTF-8编码","text":"1. Go语言相关知识点1.1 Go特点： 类型安全和内存安全 以非常直观和极低的代价实现高并发 高效的垃圾回收机制 快速编译 为多核计算机提供提升性能的方案 默认UTF-8编码 1.2 GOPATH下的三个目录： bin pkg src 1.3 相关命令：12345678910go run // 直接运行，调试go build // 编译并生成可执行文件go fmt // 格式化代码go install // 先编译包文件，后编译整个程序go test // 运行测试文件 （xxx_test.go测试程序xxx.go)go doc // 查看文档godoc fmt Println // 查看具体的函数说明godoc --http=:8080 1.4 包导入别名1234import &quot;fmt&quot;import . &quot;fmt&quot; // 省略调用import std &quot;fmt&quot; // 别名import _ &quot;xxx&quot; // 只执行xxx包中的init()函数 1.5 可见性12func getField() // privatefunc Find() // public 2. 字符串格式化2.1 占位符123456789101112131415161718192021222324252627%v 默认格式%+v 打印结构体时，添加字段名%#v 使用Go语法表示%T 对象类型%% %%t true 或 false%b binary%c Unicode # Printf(&quot;%c&quot;, 0x4E2D) // 中%d decimal%o octal%x hex%X HEX%#x add prefix &quot;0x&quot; # %#o add &quot;0&quot; prefix%s string%q qutation%f%.2f%e 科学计数法%E%g 科学计数法，更紧凑的，无末尾的0%G%p 指针地址 2.2 键盘输入123456789func main() &#123; var name string var age int8 fmt.Scanln(&amp;name) fmt.Scanf(&quot;%d&quot;, &amp;age) fmt.Println(name, age)&#125; 2.3 字符串输入12345678910func main() &#123; str := &quot;Tom 23&quot; var name string var age byte fmt.Sscanf(str, &quot;%s %d&quot;, &amp;name, &amp;age) fmt.Println(name, age)&#125; 3. 位运算3.1 原码、反码和补码：(有符号整数) 二进制最高位：0-正数 1-负数 正数(1)：原码、反码和补码一样 原码：0000 0001 反码：0000 0001 补码：0000 0001 负数(-1)：反码 —&gt; 符号位不变，其他位取反；补码 —&gt; 反码 + 1 原码：1000 0001 反码：1111 1110 补码：1111 1111 零：反码和补码都是0 计算机运算以“补码”方式进行 (没有减法，只有加法) 1 + 1：0000 0001 + 0000 0001 = 0000 0010 1 + -1：0000 0001 + 1111 1111 = 1 0000 0000 3.2 位移运算 右移(&gt;&gt;): 符号位不变，低位溢出，并用符号位补溢出的高位 左移(&lt;&lt;): 符号位不变，低位补0 123456789101112131415161718192021222324func main() &#123; a := 1 &gt;&gt; 2 // 0 b := 1 &lt;&lt; 2 // 4 fmt.Println(a, b) /* 1 &gt;&gt; 2 =&gt; 0 000 0001 -&gt; 0 000 0000 = 0 1 &lt;&lt; 2 =&gt; 0 000 0001 -&gt; 0 000 0100 = 4 */ c := -1 &gt;&gt; 2 // -1 d := -1 &lt;&lt; 2 // -4 fmt.Println(c, d) /* -1 &gt;&gt; 2 =&gt; 1 000 0001 -&gt; 1 111 1110 -&gt; 1 111 1111 =&gt; 1 111 1111 -&gt; 1 111 1110 -&gt; 1 000 0001 = -1 -1 &lt;&lt; 2 =&gt; 1 000 0001 -&gt; 1 111 1110 -&gt; 1 111 1111 =&gt; 1 111 1100 -&gt; 1 111 1011 -&gt; 1 000 0100 = -4 */&#125; 3.3 Go中特殊位运算符 &amp;^12var a int = 6 &amp;^ 11 // 46 &amp; (^11) =&gt; 6 &amp; 4 3.4 负数位运算1234567891011var a byte = 2var b byte = -2var c byte = a ^ b // -4/*2补码：0000 0010-2补码：1000 0010 -&gt; 1111 1101 -&gt; 1111 11102 ^ -2 = 0000 0010 ^ 1111 1110 = 1111 1100 -&gt; 1111 1011 -&gt; 1000 0100 = -4*/ 4. 获取变量占用的字节数unsafe.Sizeof(obj) 1234func main() &#123; var n = 100 fmt.Println(unsafe.Sizeof(n))&#125; 5. 控制语句5.1 for循环1234567891011for &#123; &#125;for a &lt;= 3 &#123; &#125;for i := 1; i &lt; 10; i++ &#123; &#125; 5.2 switch选择1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func main() &#123; var a = 1 switch a &#123; case 0: fmt.Println(&quot;a=0&quot;) case 1: fmt.Println(&quot;a=1&quot;) default: fmt.Println(&quot;No Found&quot;) &#125;&#125;// 不能写成 switch afunc main() &#123; var a = 1 // expression is omitted switch &#123; case a &gt;= 0: fmt.Println(&quot;a&gt;=0&quot;) fallthrough case a &gt;= 1: fmt.Println(&quot;a&gt;=1&quot;) default: fmt.Println(&quot;No Found&quot;) &#125;&#125;// a的作用域只在switch中switch a := 1; &#123; &#125;// type-switchfunc main() &#123; var x interface&#123;&#125; = 10 switch x.(type) &#123; case nil: fmt.Println(&quot;NULL&quot;) case int: fmt.Println(&quot;int&quot;) default: fmt.Println(&quot;interface&#123;&#125;&quot;) &#125;&#125; 5.3 for循环示例：打印空心金字塔1234567891011121314151617181920212223242526272829303132333435/* * * * * * * ***********/func main() &#123; N := 5 // Step 1: 打印一个n*n列的正方形 for i := 1; i &lt;= N; i++ &#123; // Step 3: 打印等边三角形。每行前补空格：Ln=0, Ln-1=1, L2=n-2, L1=n-1 for k := 1; k &lt;= N-i; k++ &#123; fmt.Print(&quot; &quot;) &#125; // Step 2: 打印一个直角三角形。金字塔每行*个数：L1=1，L2=3, L3=5, Ln=2n-1 for j := 1; j &lt;= 2*i-1; j++ &#123; // Step 4: 空心。每行只保留第一个和最后一个 if j == 1 || j == 2*i-1 &#123; fmt.Print(&quot;*&quot;) &#125; else &#123; // Step 5: 最后一行全部保留 if i == N &#123; fmt.Print(&quot;*&quot;) &#125; else &#123; fmt.Print(&quot; &quot;) &#125; &#125; &#125; fmt.Println() &#125;&#125; 5.4 for循环示例：九九乘法表12345678func main() &#123; for i := 1; i &lt;= 9; i++ &#123; for j := 1; j &lt;= i; j++ &#123; fmt.Printf(&quot;%d * %d = %d\\t&quot;, j, i, i*j) &#125; fmt.Println() &#125;&#125; 5.5 for循环示例：水仙花数水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身（例如：1^3 + 5^3+ 3^3 = 153） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*三位的水仙花数共有4个：153，370，371，407；四位的四叶玫瑰数共有3个：1634，8208，9474；*/func main() &#123; var N int64 = 1000000 var i int64 for i = 100; i &lt;= N; i++ &#123; if isNarcissusFew(i) &#123; fmt.Println(i) &#125; &#125;&#125;func isNarcissusFew(n int64) bool &#123; s := strconv.FormatInt(n, 10) l := len(s) var sum int64 = 0 for j := n; ; &#123; m := j % 10 sum += int64(math.Pow(float64(m), float64(l))) j = j / 10 if j == 0 &#123; break &#125; &#125; return sum == n&#125;func isNarcissistic(n int64) bool &#123; s := strconv.FormatInt(n, 10) l := len(s) var sum int64 = 0 for _, c := range s &#123; num, _ := strconv.Atoi(fmt.Sprintf(&quot;%c&quot;, c)) sum += int64(math.Pow(float64(num), float64(l))) &#125; return sum == n&#125; 性能对比： 12345678go test -bench=. -run=nonegoos: darwingoarch: amd64pkg: gomod/aaaBenchmarkIsNarcissistic-4 1 93848583244 ns/opBenchmarkIsNarcissusFew-4 1 31639945040 ns/opPASSok gomod/aaa 125.791s 5.6 goto, break, continue LABEL用法：1234567891011121314func main() &#123;LABEL1: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; // break LABEL1 goto LABEL2 &#125; &#125; &#125; LABEL2: fmt.Println(&quot;OK&quot;)&#125; 6. 随机数12345func main() &#123; rand.Seed(time.Now().UnixNano()) // 种子变化越大，随机性越好 n := rand.Intn(100) + 1 fmt.Println(n)&#125; 7. 时间和日期函数1234567891011121314151617181920func main() &#123; now := time.Now() // time.Time year := now.Year() month := int(now.Month()) day := now.Day() fmt.Printf(&quot;%04d-%02d-%02d\\n&quot;, year, month, day) weekday := now.Weekday() fmt.Println(weekday) ts := now.Unix() // timestamp nano := now.UnixNano() fmt.Println(ts, nano) dateStr := now.Format(&quot;2006-01-02 15:04:05&quot;) fmt.Println(dateStr)&#125;time.Sleep(100 * time.MilliSecond) 8. 内置函数12345678910len // string, array, slice, map, channelclose // channelnew // 分配内存, 值类型 int, float, struct等，返回指针make // 分配内存, 引用类型 chan, map, slice等，返回类型本身，而非指针nptr = new(int) // *intappend // 追加元素到array, slice中panic/recover // 错误处理 9. new和make的区别 new(T) 返回 T 的指针 *T 并指向 T 的零值。 make(T) 返回的初始化的 T，只能用于 slice，map，channel。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Git","slug":"Git","date":"2017-05-01T09:35:40.000Z","updated":"2021-06-22T10:50:49.701Z","comments":true,"path":"2017/05/01/Git/","link":"","permalink":"https://elihe2011.github.io/2017/05/01/Git/","excerpt":"1. 基本概念1.1 git特点1) 直接存储文件快照(特定时间点的完整文件)，而非存储差异。2) 几乎所有操作都在本地执行，只有同步版本库才需要联网。3) 天然的数据完整性校验(SHA-1, 40bits).","text":"1. 基本概念1.1 git特点1) 直接存储文件快照(特定时间点的完整文件)，而非存储差异。2) 几乎所有操作都在本地执行，只有同步版本库才需要联网。3) 天然的数据完整性校验(SHA-1, 40bits). 1.2 git文件变更操作文件变更的三个阶段: 修改(modified) 暂存(staged): 已加入下次提交列表) 提交(committed): 保存到版本数据目录 三个阶段数据存放区域: 工作目录(workspace) 暂存索引文件(.git/index) 本地数据目录(.git/objects) Git Data Transport Commands (http://osteele.com) 2. 初始化设置2.1 配置用户123456git config --global user.name &#x27;eli.he&#x27;git config --global user.email &#x27;eli.he@live.cn&#x27;git config --global core.autocrlf falsegit config --list 2.2 密钥设置1) 生成密钥 1ssh-keygen -t rsa -C &#x27;eli.he@live.cn&#x27; 2) 上传公钥 id_rsa.pub 至SSH keys管理 1cat ~/.ssh/id_rsa.pub 3) 测试连通性 1ssh -T git@github.com 2.3 设置忽略文件 全局(.gitignore) 个人(.git/info/exclude) 3. 版本库3.1 新建版本库12345mkdir testcd testgit initgit remote add origin git@github.com:elihe2011/test.git 3.2 克隆版本库12345# 默认远程仓库名为origingit clone https://github.com/elihe2011/abc.git# 指定远程仓库名为git_prjgit clone -o git_prj https://github.com/elihe2011/abc.git 3.3 查看远程版本库12git remote -vgit remote show origin 3.4 获取远程版本，但不合并12git fetch origin mastergit fetch ～/github/new_test master 3.5 获取远程版本，并合并12git pull origin mastergit pull ～/github/new_test master 3.6 代码修改提交1234567git add .git commit -m &#x27;add a.txt&#x27; a.txtgit commit -m &#x27;add all&#x27;git commit -am &#x27;commit tracked files&#x27;git commit -m --amend --no-edit # 使用新的commit替代原有的，保持commit描述不变 3.7 推送至远程库12345git push -u origin master # -u, --set-upstream 第一次push的时候需要，自动添加如下配置branch.master.remote=originbranch.master.merge=refs/heads/master 4. 文件操作4.1 检查修改12345git diff hello.py # workspace, stagedgit diff --cached # staged, local-repositorygit diff master origin/master # local-repo remote-repo 4.2 撤销操作4.2.1 checkoutworkspace和staged撤销修改 123456# 撤销本次修改，commit前均可操作git checkout hello.py # 使用特定commit的文件，替换staged和workspace下的文件git checkout ad12sa1 hello.py cat .git/HEAD # defd8bb.... 4.2.2 reset不可恢复的撤销 (谨慎操作) 1234567891011121314# staged区回滚，git add的反操作git reset [&lt;files&gt;]# staged区和workspace回滚，回到最近一次提交git reset [&lt;files&gt;] --hard# staged区回滚到指定commit，之前的提交全部删除git reset &lt;commit&gt;# workspace区也回滚git reset &lt;commit&gt; --hard# 作用于staged区git reset --mixed HEAD 实例：12345git reset HEAD -- a.txtgit reset a.txt# HEAD^表示上个版本，HEAD^^上上个版本，HEAD~N往上N个版本git reset HEAD^^ -- a.txt 4.2.3 revert 仅反转提交撤销已提交的快照，但不从项目中删除这个commit，而是新生成一个commit 实例123456789touch 1.txt 2.txt 3.txtgit add .git commit -m &#x27;add 1.txt&#x27; 1.txtgit commit -m &#x27;add 2.txt&#x27; 2.txtgit commit -m &#x27;add 3.txt&#x27; 3.txtgit log --oneline -5git revert cc79f5a # revert 2.txtls -l [1-3].txt # 1.txt, 3.txt reset和revert的区别:reset: 被设计用来撤销本地的修改，它会完整地删除一个change set。revert: 被设计用来安全地撤销一个公共commit，会保留最初的change set，通过新建一个commit来撤销 4.2.4 撤销操作场景1) 已修改，未暂存 12git checkout .git reset --hard 2) 已暂存，未提交 123456git resetgit checkout .orgit reset --hard 3) 已提交，未推送 1git reset --hard origin/master 4) 已推送 12git reset --hard HEAD^git push -f origin master 4.2.5 撤销命令说明 命令 操作区域 checkout staged -&gt; workspace reset committed -&gt; staged reset –hard committed -&gt; staged -&gt; workspace 4.3 删除文件4.3.1 删除已traced文件1234567891011# 删除workspace中的文件，如果已在staged中，报错git rm a.txt# 同时删除workspace &amp; staged文件，保留committed文件git rm -f a.txt# 同时删除staged &amp; committed文件，保留workspace文件git rm --cached a.txt# 清理已被删除的所有文件git rm $(git ls-files --deleted) 4.3.2 删除未traced的文件12git clean -fgit clean -df 5. 标签5.1 创建标签12345678# 为当前分支最近一次提交创建标签git tag 1.0# 标签 develop/1.1git tag develop_1.1 develop# 为某个历史提交创建标签git tag 1.2 66cbbb4 5.2 查询标签123git taggit tag -l &#x27;1.2.*&#x27;git show 1.1 5.3 检出标签1git checkout 1.0 5.4 按标签创建分支123git branch test 1.1git checkout -b develop 1.2 5.5 删除标签1git tag -d 1.1 6. 日志6.1 查询日志123456789101112131415161718192021222324252627282930git loggit log -5git log stat # 详细日志git log -p # 更详细日志git log --author=&#x27;eli&#x27;git log --grep=&#x27;modify&#x27; # 过滤提交描述git log --graphgit log --graph --decorate --onelinegit log --onelinegit log ada6cb2..62a89cfgit log --mergesgit log --no-merges # 过滤merge提交git log --since=&#x27;2017-11-20&#x27; --until=&#x27;2017-12-01&#x27;git log --pretty=format:&quot;%cn committed %h on %cd&quot; # 格式化参数%cn committer name%h commit hash%cd commit date%s short messagegit log --pretty=&quot;%h - %s&quot; --author=&#x27;eli&#x27; --since=&#x27;2017-11-27 00:00:00&#x27; --before=&#x27;2017-11-27 11:59:59&#x27; 6.2 git reflog 所有分支的日志1git reflog --relative-date 6.3 git shortlog1git shortlog 7. 分支7.1 创建分支12345678# 从当前分支创建新分支，但不切换git branch develop# 从当前分支创建新分支，并切换git checkout -b develop# 从develop分支创建新分支git checkout -b test develop 7.2 删除分支12345# 删除已merge的分支git branch -d develop# 强制删除分支，不管是否已mergegit branch -D develop 7.3 更改分支名1git branch -m dev 7.4 切换分支本质上是更新HEAD指向给定的branch或commit 12345678git checkout developgit checkout -b test# 产生detached HEAD状态，detached意味着当前所有修改和项目发展的其他部分完全脱离，无法被mergegit checkout &lt;commit&gt;git checkout &lt;tag&gt; 7.5 合并分支12345# 自动指定merge算法git merge &lt;branch&gt;# 强制fast-forword merge算法git merge --on-ff &lt;branch&gt; 7.6 rebase 合并分支（重定义分支起点）1git rebase &lt;base&gt; # base: commit, tag, branch, HEAD~N 123456789101112131415git checkout -b developtouch echo.pygit add echo.pygit commit -m &#x27;add echo.py on develop branch&#x27;git checkout mastertouch print.pygit add print.pygit commit -m &#x27;add print.py on master branch&#x27;git checkout developgit rebase master # 将整个develop分支的commit放在master分支之后，不会创建merge commit，但会为develop分支的每个commit创建一个新的commitgit checkout mastergit merge develop # 只产生merge commit，分支commit不合入 7.7 merge和rebase的区别： merge: 产生一个merge commit，不会合入分支的commit rebase: 不产生merge commit，但合入分支的commit 示意图 git pullgit pull: 按merge方式合并git pull –rebase: 按rebase方式合并 merge未产生merge commit的原因：只有在存在冲突，解决完冲突后才自动产生一个merge commit git mergegit merge: 被合并之前的commit全部抹除，只保留一个解决冲突的merge commitgit merge –on-ff: 在没有冲突下，也自动产生一个merge commit 8. 远程分支操作8.1 查询远程分支1git ls-remote 8.2 跟踪远程分支123git checkout -b daily origin/dailygit checkout --track origin/daily # 本地和远程的分支名保持一致 8.3 添加本地分支与远程分支的关联关系（–set-upstream-to=）1git branch -u origin/daily 8.4 查询当前已跟踪的分支1git branch -vv 8.5 删除远程分支1git push origin --delete daily 8.6 远程仓库被删除，导致无法pull1git remote prune origin 9. 导出版本库1git archive --format=zip HEAD &gt; `date +%s`.zip 10. 撤销操作详细说明10.1 resetreset将一个分支的末端指向另一个提交，并移除当前分支的一些提交 12git checkout hotfixgit reset HEAD~2 hotfix分支末端的两个提交变成悬挂提交，下次Git执行垃圾回收时，这两个提交会被删除。 撤销缓存区和工作目录： –soft 缓存区和工作目录均不修改 –mixed 默认项，缓存区同步到你指定的提交，但工作目录不受影响 –hard 缓存区和工作目录均同步到你指定的提交 使用前提：你的更改未分享给别人，git reset是撤销这些更改的简单方法 10.2 revertrevert撤销一个提交同时会创建一个新的提交。比reset安全，且不会重写提交历史 12git checkout hotfixgit revert HEAD~2 10.3 总结git revert可以用在公共分支 git reset应该用在私有分支上 11. 配置项说明11.1 区分大小写1git config core.ignorecase false","categories":[{"name":"Tools","slug":"Tools","permalink":"https://elihe2011.github.io/categories/Tools/"}],"tags":[{"name":"git","slug":"git","permalink":"https://elihe2011.github.io/tags/git/"}]}]}