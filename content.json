{"meta":{"title":"Eli's Blog","subtitle":null,"description":null,"author":"Eli He","url":"https://elihe2011.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-11-19T08:24:36.000Z","updated":"2021-06-22T10:50:49.750Z","comments":true,"path":"categories/index.html","permalink":"https://elihe2011.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Go 相关概念","slug":"Go 相关概念","date":"2020-07-17T03:42:23.000Z","updated":"2021-06-22T10:50:49.750Z","comments":true,"path":"2020/07/17/Go 相关概念/","link":"","permalink":"https://elihe2011.github.io/2020/07/17/Go%20%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","excerpt":"1. 逃逸分析1.1 堆和栈： 堆（Heap）： 一般情况下，手动申请、分配、释放。内存大小并不定，较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 堆在内存分配中类似于往一个房间里摆放各种家具，家具的尺寸有大有小。 引用类型 (指针、slice、map、chan、interface)的地址对应的数据存储内存通常分配在堆上 栈（Stack）： 由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数，局部变量等等都会存放在栈上 栈是一种拥有特殊规则的线性表数据结构,只允许线性表的一端放入数据,之后再这一端取出数据,按照后进先出(lifo)的顺序 值类型 (整型、浮点型、bool、string、array和struct) 的变量直接存储值，内存通常分配在栈上","text":"1. 逃逸分析1.1 堆和栈： 堆（Heap）： 一般情况下，手动申请、分配、释放。内存大小并不定，较大的对象。另外其分配相对慢，涉及到的指令动作也相对多 堆在内存分配中类似于往一个房间里摆放各种家具，家具的尺寸有大有小。 引用类型 (指针、slice、map、chan、interface)的地址对应的数据存储内存通常分配在堆上 栈（Stack）： 由编译器进行管理，自动申请、分配、释放。一般不会太大，我们常见的函数参数，局部变量等等都会存放在栈上 栈是一种拥有特殊规则的线性表数据结构,只允许线性表的一端放入数据,之后再这一端取出数据,按照后进先出(lifo)的顺序 值类型 (整型、浮点型、bool、string、array和struct) 的变量直接存储值，内存通常分配在栈上 1.2 逃逸分析逃逸分析就是确定一个变量要放堆上还是栈上，规则如下： 是否有在其他地方（非局部）被引用。只要有可能被引用了，那么它一定分配到堆上。否则分配到栈上 即使没有被外部引用，但对象过大，无法存放在栈区上。依然有可能分配到堆上 1.3 需要逃逸的原因频繁申请、分配堆内存是有一定 “代价” 的。会影响应用程序运行的效率，间接影响到整体系统。因此 “按需分配” 最大限度的灵活利用资源，才是正确的治理之道 1.4 查看逃逸分析1.4.1 通过编译器命令，就可以看到详细的逃逸分析过程1234go build -gcflags &#x27;-m -l&#x27; main.go-m: 进行内存分配分析-l: 禁用掉 inline 函数内联, 避免程序内联 1.4.2 通过反编译命令查看1go tool compile -S main.go 1.5 逃逸案例1.5.1 指针1) 外部引用，逃逸 1234567891011121314151617type User struct &#123; ID int Name string Age byte&#125;func GetUser() *User &#123; return &amp;User&#123; ID: 1, Name: &quot;jack&quot;, Age: 12, &#125;&#125;func main() &#123; _ = GetUser()&#125; 12345678$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:10:9: &amp;User literal escapes to heap$ go tool compile -S main.go | grep CALL 0x0028 00040 (main.go:10) CALL runtime.newobject(SB) 0x005f 00095 (main.go:9) CALL runtime.morestack_noctxt(SB) 2）外部未引用，不逃逸 1234func main() &#123; s := new(string) *s = &quot;abc&quot;&#125; 12345$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:4:10: new(string) does not escape$ go tool compile -S main.go | grep CALL 1.5.2 未确定类型1234567func main() &#123; s := new(string) *s = &quot;abc&quot; //fmt.Println(*s) // not escape fmt.Println(s) // escape to heap&#125; 原因：func Println(a ...interface&#123;&#125;) (n int, err error)接收任意类型，在编译时无法确定具体类型，因此产生逃逸 1.5.3 泄漏参数12345678910111213type User struct &#123; ID int Name string Age byte&#125;func GetUser(u *User) *User &#123; return u&#125;func main() &#123; _ = GetUser(&amp;User&#123;ID: 1, Name: &quot;jack&quot;, Age: 12&#125;)&#125; 1234$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:9:14: leaking param: u to result ~r1 level=0./main.go:14:14: &amp;User literal does not escape 使其逃逸：被外部所引用，将分配到堆上 12345678910111213type User struct &#123; ID int Name string Age byte&#125;func GetUser(u User) *User &#123; return &amp;u&#125;func main() &#123; _ = GetUser(User&#123;ID: 1, Name: &quot;jack&quot;, Age: 12&#125;)&#125; 123$ go build -gcflags &quot;-m -l&quot; main.go # command-line-arguments./main.go:9:14: moved to heap: u 2. new和make： new： 分配内存 设置零值 返回指针（重要） make: sice, map, chan 分配内存 返回对象 (对象本身为引用类型，不需要返回指针) 3. Go类型断言：1) Type Assertion 12t := o.(T)t, ok := o.(T) 2) Type Switch 123456switch o.(type) &#123;case int:case string:case nil:...&#125; 4. slice4.1 slice扩容的内存管理 翻新扩展：当前元素为 kindNoPointers，将在老 Slice cap 的地址后继续申请空间用于扩容 举家搬迁：重新申请一块内存地址，整体迁移并扩容 cap &lt; 1024: cap = cap * 2cap &gt;= 1024: cap = cap + cap/4 4.2 empty &amp; nil slicelen 和 cap 均等于0 1) empty: arary -&gt; []int&#123;&#125; 指向空数组 12s := []int&#123;&#125;s = make([]int, 0) 2) nil: array -&gt; nil 1var s []int 5. 指针5.1 空指针12345678910func main() &#123; var p1 *int var p2 = new(int) fmt.Println(p1 == nil) // true fmt.Println(p2 == nil) // false fmt.Println(*p1) // panic: nil pointer dereference fmt.Println(*p2) // 0&#125; 6. slice 参数 可通过下标修改原始slice的元素值 append操作，会改变slice指向的底层数组 1234567891011121314151617181920func main() &#123; a := make([]int, 1, 2) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a) foo(a) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a) bar(&amp;a) fmt.Printf(&quot;a=%v, len=%d, cap=%d, ptr=%p\\n&quot;, a, len(a), cap(a), &amp;a)&#125;func foo(a []int) &#123; a[0] = 9 // slice副本指向的 array 未变，所以能够修改原始 a 的值 a = append(a, 1, 2) // append操作，a指向的地址改变 fmt.Printf(&quot;%p\\n&quot;, &amp;a)&#125;func bar(a *[]int) &#123; *a = append(*a, 5, 6)&#125; 7. 并发读写mapfatal error: concurrent map read and map write 123456789101112131415func mapTest() &#123; m := make(map[int]int) go func() &#123; for &#123; m[0] = 1 &#125; &#125;() go func() &#123; for &#123; _ = m[0] &#125; &#125;()&#125; 解决方案：sync.Map 12345678910111213141516171819202122232425func main() &#123; //mapTest() syncMap() select &#123; case &lt;-time.After(time.Second): break &#125;&#125;func syncMap() &#123; m := sync.Map&#123;&#125; go func() &#123; for &#123; m.Store(0, 1) &#125; &#125;() go func() &#123; for &#123; _, _ = m.Load(0) &#125; &#125;()&#125; 8. Go 接口Go 接口为非侵入式接口 非侵入式接口: 接口的定义者无需知道接口被哪些类型实现了, 而接口的实现者也不需要知道实现了哪些接口, 无需指明已经实现了哪些接口, 只需要关注自己实现的是什么样的接口即可. 编译器会自己识别哪个类型实现哪些接口 侵入式接口: 主要体现是实现接口的类需要很明确的声明自己实现了哪个接口 9. Go 并发CSP: Communicating Sequential Process 通信顺序进程，消息传递模型 Goroutine: 轻量级线程, 简称协程。一个Goroutine 的栈启动很小(2k或者4k)。当Goroutine的栈空间不够的时候,会根据需要动态伸缩栈大小(甚至可到到1G)。 Go 语言线程模型： M: 内核线程（物理线程） P: 执行Go代码所必须的资源（上下文环境） G: 待执行的Go代码，即协程本身 9.1 sync.Mutex 互斥锁解决 goroutine 抢占公共资源问题 12345678910111213141516171819202122232425var m = make(map[int]int)var lock sync.Mutexfunc main() &#123; for i := 1; i &lt;= 10; i++ &#123; go factorial(i) &#125; time.Sleep(time.Second * 2) for k, v := range m &#123; fmt.Printf(&quot;%d!=%d\\n&quot;, k, v) &#125;&#125;func factorial(n int) &#123; res := 1 for i := 1; i &lt;= n; i++ &#123; res *= i &#125; lock.Lock() m[n] = res lock.Unlock()&#125; 9.2 并发数据同步1234567891011121314151617181920212223242526272829303132func add(n int) &#123; defer wg.Done() // method1: Found 1 data race for i := 0; i &lt; n; i++ &#123; runtime.Gosched() c++ &#125; // method2: 正常 /* for i := 0; i &lt; n; i++ &#123; atomic.AddInt64(&amp;c, 1) runtime.Gosched() &#125;*/ // method3: 正常 /* defer lock.Unlock() lock.Lock() for i := 0; i &lt; n; i++ &#123; c++ &#125;*/&#125;func main() &#123; wg.Add(2) go add(3) go add(4) wg.Wait() fmt.Println(&quot;c =&quot;, c)&#125; 检测并发竞争状态：go run --race main.go sync.WaitGroup: 等待组。用于等待一组线程的结束。 123func (wg *WaitGroup) Add(delta int) // 等待个数计数器func (wg *WaitGroup) Done() // 子线程结束，计数器减1func (wg *WaitGroup) Wait() // 阻塞等待所有子线程结束，即计数器为0 sync/atomic: 原子操作包。以底层的加锁机制来同步访问整型变量和指针。 123func AddInt64(addr *int64, delta int64) (new int64)func LoadInt64(addr *int64) (val int64)func StoreInt64(addr *int64, val int64)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Context","slug":"Go Context","date":"2020-07-16T03:20:08.000Z","updated":"2021-06-22T10:50:49.749Z","comments":true,"path":"2020/07/16/Go Context/","link":"","permalink":"https://elihe2011.github.io/2020/07/16/Go%20Context/","excerpt":"1. 简介context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据 1.1 结构图","text":"1. 简介context 管理了一组呈现树状结构的 Goroutine, 让每个Goroutine 都拥有相同的上下文, 并且可以在这个上下文中传递数据 1.1 结构图 1.2 Context interface12345678910111213type Context interface &#123; // 标识deadline是否已经设置了, 没有设置时, ok的值是false, 并返回初始的time.Time Deadline() (deadline time.Time, ok bool) // 返回一个channel, 当返回关闭的channel时可以执行一些操作 Done() &lt;-chan struct&#123;&#125; // 描述context关闭的原因,通常在Done()收到关闭通知之后才能知道原因 Err() error // 获取上游Goroutine 传递给下游Goroutine的某些数据 Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 方法说明： Deadline: 设置截止时间。第一个参数表示截止时间点，第二个参数是否设置了截止时间。未设置截止时间，需要通过cancel()来取消 Done(): 在被cancel时返回的一个只读通道 Err(): 被cancel的原因 Value(): 绑定到Context上的值 1.3 emptyCtx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// An emptyCtx is never canceled, has no values, and has no deadline. It is not// struct&#123;&#125;, since vars of this type must have distinct addresses.type emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123; return&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil&#125;func (*emptyCtx) Err() error &#123; return nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return nil&#125;func (e *emptyCtx) String() string &#123; switch e &#123; case background: return &quot;context.Background&quot; case todo: return &quot;context.TODO&quot; &#125; return &quot;unknown empty Context&quot;&#125;var ( background = new(emptyCtx) todo = new(emptyCtx))// Background returns a non-nil, empty Context. It is never canceled, has no// values, and has no deadline. It is typically used by the main function,// initialization, and tests, and as the top-level Context for incoming// requests.func Background() Context &#123; return background&#125;// TODO returns a non-nil, empty Context. Code should use context.TODO when// it&#x27;s unclear which Context to use or it is not yet available (because the// surrounding function has not yet been extended to accept a Context// parameter).func TODO() Context &#123; return todo&#125; 1.4 cancelCtx对外暴露了 Err() Done() String() 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// A cancelCtx can be canceled. When canceled, it also cancels any children// that implement canceler.type cancelCtx struct &#123; Context mu sync.Mutex // protects following fields done chan struct&#123;&#125; // created lazily, closed by first cancel call children map[canceler]struct&#123;&#125; // set to nil by the first cancel call err error // set to non-nil by the first cancel call&#125;func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; c.mu.Lock() if c.done == nil &#123; c.done = make(chan struct&#123;&#125;) &#125; d := c.done c.mu.Unlock() return d&#125;func (c *cancelCtx) Err() error &#123; c.mu.Lock() err := c.err c.mu.Unlock() return err&#125;func (c *cancelCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithCancel&quot;, c.Context)&#125;// cancel closes c.done, cancels each of c&#x27;s children, and, if// removeFromParent is true, removes c from its parent&#x27;s children.func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; if err == nil &#123; panic(&quot;context: internal error: missing cancel error&quot;) &#125; c.mu.Lock() if c.err != nil &#123; c.mu.Unlock() return // already canceled &#125; c.err = err if c.done == nil &#123; c.done = closedchan &#125; else &#123; close(c.done) &#125; for child := range c.children &#123; // NOTE: acquiring the child&#x27;s lock while holding parent&#x27;s lock. child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() if removeFromParent &#123; removeChild(c.Context, c) &#125;&#125; 1.5 valueCtx通过 valueCtx 结构知道仅是在Context 的基础上增加了元素 key 和 value 1234567891011121314151617// A valueCtx carries a key-value pair. It implements Value for that key and// delegates all other calls to the embedded Context.type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125;func (c *valueCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithValue(%#v, %#v)&quot;, c.Context, c.key, c.val)&#125;func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; return c.Context.Value(key)&#125; 1.6 timerCtx在cancelCtx 基础上增加了字段 timer 和 deadline 12345678910111213141516171819202122232425262728type timerCtx struct &#123; cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time&#125;func (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123; return c.deadline, true&#125;func (c *timerCtx) String() string &#123; return fmt.Sprintf(&quot;%v.WithDeadline(%s [%s])&quot;, c.cancelCtx.Context, c.deadline, time.Until(c.deadline))&#125;func (c *timerCtx) cancel(removeFromParent bool, err error) &#123; c.cancelCtx.cancel(false, err) if removeFromParent &#123; // Remove this timerCtx from its parent cancelCtx&#x27;s children. removeChild(c.cancelCtx.Context, c) &#125; c.mu.Lock() if c.timer != nil &#123; c.timer.Stop() c.timer = nil &#125; c.mu.Unlock()&#125; 2. 使用示例 通过 Background() 和 TODO() 创建最 emptyCtx 实例 ,通常是作为根节点 通过 WithCancel() 创建 cancelCtx 实例 通过 WithValue() 创建 valueCtx 实例 通过 WithDeadline 和 WithTimeout 创建 timerCtx 实例 2.1 WithCancel1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func Operate1(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Operate1 done.&quot;) return default: fmt.Println(&quot;Operate1&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func Operate2(ctx context.Context) &#123; fmt.Println(&quot;Operate2&quot;)&#125;func Do1(ctx context.Context) &#123; go Do2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Do1 done.&quot;) fmt.Println(ctx.Err()) return default: fmt.Println(&quot;Do1:&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func Do2(ctx context.Context) &#123; go Operate1(ctx) go Operate2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Do2 done.&quot;) fmt.Println(ctx.Err()) return default: fmt.Println(&quot;Do2:&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;)) time.Sleep(2 * time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) go Do1(ctx) time.Sleep(5 * time.Second) fmt.Println(&quot;Stop all goroutines&quot;) cancel() time.Sleep(2 * time.Second)&#125; 2.2 WithDeadline12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func task1(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(ctx.Err()) return default: fmt.Println(&quot;task1:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func task2(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(ctx.Err()) return default: fmt.Println(&quot;task2:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func main() &#123; after5Sec := time.Now().Add(5 * time.Second) ctx, cancel := context.WithDeadline(context.Background(), after5Sec) defer cancel() go task1(ctx) go task2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;Main done:&quot;, ctx.Err()) return &#125; &#125;&#125; 2.3 WithTimeout12345678910111213141516171819202122232425262728293031323334353637func task(ctx context.Context) &#123; n := 1 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;task is done.&quot;) return default: fmt.Println(&quot;task:&quot;, n) n++ time.Sleep(time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithTimeout(context.Background(), 6*time.Second) defer cancel() go task(ctx) n := 1 for &#123; select &#123; case &lt;-time.Tick(2 * time.Second): if n == 9 &#123; return &#125; fmt.Printf(&quot;n=%d\\n&quot;, n) n++ //case &lt;-ctx.Done(): // fmt.Println(&quot;Main done:&quot;, ctx.Err()) // return &#125; &#125;&#125; 2.4 WithValue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func v1(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;v1 done:&quot;, ctx.Err()) return default: fmt.Println(ctx.Value(&quot;key&quot;)) time.Sleep(3 * time.Second) &#125; &#125;&#125;func v2(ctx context.Context) &#123; fmt.Println(ctx.Value(&quot;key&quot;)) fmt.Println(ctx.Value(&quot;v3&quot;)) ctx = context.WithValue(ctx, &quot;key&quot;, &quot;modify from v2&quot;) go v1(ctx)&#125;func v3(ctx context.Context) &#123; if v := ctx.Value(&quot;key&quot;); v != nil &#123; fmt.Println(&quot;Key =&quot;, v) &#125; ctx = context.WithValue(ctx, &quot;v3&quot;, &quot;value of v3&quot;) go v2(ctx) for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;v3 done:&quot;, ctx.Err()) return default: fmt.Println(&quot;v3&quot;) time.Sleep(2 * time.Second) &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) ctx = context.WithValue(ctx, &quot;key&quot;, &quot;main&quot;) go v3(ctx) time.Sleep(10 * time.Second) cancel() time.Sleep(3 * time.Second)&#125; 3. 其他示例3.1 关闭协程3.1.1 使用channel1234567891011121314151617181920212223242526272829func main() &#123; c := make(chan bool) for i := 0; i &lt; 5; i++ &#123; go monitor(c, i) &#125; time.Sleep(time.Second) // 关闭channel close(c) time.Sleep(5 * time.Second) fmt.Println(&quot;Done&quot;)&#125;func monitor(c chan bool, num int) &#123; for &#123; select &#123; case v := &lt;-c: fmt.Printf(&quot;Monitor[%d], receive [%v], stopping.\\n&quot;, num, v) return default: fmt.Printf(&quot;Monitor[%d] is running now.\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.1.2 使用Context1234567891011121314151617181920212223242526272829func main() &#123; ctx, cancel := context.WithCancel(context.Background()) for i := 0; i &lt; 5; i++ &#123; go monitor(ctx, i) &#125; time.Sleep(time.Second) // 取消操作 cancel() time.Sleep(5 * time.Second) fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case v := &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d], receive [%v], stopping.\\n&quot;, num, v) return default: fmt.Printf(&quot;Monitor[%d] is running now.\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.2 WithDeadline 和 WithTimeout123456789101112131415161718192021222324252627282930func main() &#123; //ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Second)) ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := 0; i &lt; 5; i++ &#123; go monitor(ctx, i) &#125; time.Sleep(5 * time.Second) if err := ctx.Err(); err != nil &#123; fmt.Printf(&quot;Reason: %v\\n&quot;, err) &#125; fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d] stopped.\\n&quot;, num) return default: fmt.Printf(&quot;Monitor[%d] is running...\\n&quot;, num) time.Sleep(2 * time.Second) &#125; &#125;&#125; 3.3 WithValue1234567891011121314151617181920212223242526272829303132func main() &#123; ctx1, cancel := context.WithCancel(context.Background()) ctx2, cancel := context.WithTimeout(ctx1, time.Second) ctx3 := context.WithValue(ctx2, &quot;name&quot;, &quot;jack&quot;) defer cancel() for i := 0; i &lt; 5; i++ &#123; go monitor(ctx3, i) &#125; time.Sleep(5 * time.Second) if err := ctx3.Err(); err != nil &#123; fmt.Printf(&quot;Reason: %v\\n&quot;, err) &#125; fmt.Println(&quot;Done&quot;)&#125;func monitor(ctx context.Context, num int) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Printf(&quot;Monitor[%d] stopped.\\n&quot;, num) return default: value := ctx.Value(&quot;name&quot;) fmt.Printf(&quot;Monitor[%d] is running, value is %v\\n&quot;, num, value) time.Sleep(2 * time.Second) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"asyncio","slug":"Python asyncio","date":"2020-05-11T06:22:18.000Z","updated":"2021-06-22T10:50:49.749Z","comments":true,"path":"2020/05/11/Python asyncio/","link":"","permalink":"https://elihe2011.github.io/2020/05/11/Python%20asyncio/","excerpt":"1. 可等待对象1.1 实现__wait__(self)方法Coroutine和Future均实现了该方法，Task继承于Future，所以a waitable对象，主要有下列三种类型： 协程(coroutines): async def func() 任务(Tasks): asyncio.create_task()(py3.7+) asyncio.ensure_future()(less reable) loop.create_task() Futures: loop.run_in_executor(executor, func) await 的目的： 获取协程的结果 挂起当前协程，将控制交由事件循环，切换到其他协程，然后等待结果，最后恢复协程继续执行","text":"1. 可等待对象1.1 实现__wait__(self)方法Coroutine和Future均实现了该方法，Task继承于Future，所以a waitable对象，主要有下列三种类型： 协程(coroutines): async def func() 任务(Tasks): asyncio.create_task()(py3.7+) asyncio.ensure_future()(less reable) loop.create_task() Futures: loop.run_in_executor(executor, func) await 的目的： 获取协程的结果 挂起当前协程，将控制交由事件循环，切换到其他协程，然后等待结果，最后恢复协程继续执行 1.2 Coroutine coroutine function: async def foo() coroutine object: obj = foo() generator-based coroutines：@asyncio.coroutine() 装饰的生成器 123456789101112131415161718@asyncio.coroutinedef a(): yield from asyncio.sleep(1)@types.coroutinedef b(): yield from asyncio.sleep(1)async def c(): await asyncio.sleep(1)print(asyncio.iscoroutinefunction(a)) # Trueprint(asyncio.iscoroutinefunction(b)) # Falseprint(asyncio.iscoroutinefunction(c)) # Trueprint(asyncio.iscoroutine(a())) # Trueprint(asyncio.iscoroutine(b())) # Trueprint(asyncio.iscoroutine(c())) # True 相关apis: coroutine.send(value) coroutine.throw(type[, value[, traceback]]) coroutine.close() 新旧协程： 1234567# 基于生成器的协程@asyncio.coroutinedef old_style_coroutine(): yield from asyncio.sleep(1)async def main(): await old_style_coroutine() 1.2 Future用于桥接低层的回调代码和高层的 async/await 代码。 Future 代表异步操作的最终结果，非线程安全。 Future 可等待对象，协程可以 await Future 对象，直到有结果或发生异常，或被取消。 Future 底层回调代码与高层async/await代码衔接时使用 建议用 loop.create_future() 来创建 Future 对象，该方法会将 loop 绑定到创建的 future 上。 12345678910111213async def set_after(future, delay, value): await asyncio.sleep(delay) future.set_result(value)async def main(): loop = asyncio.get_running_loop() future = loop.create_future() await set_after(future, 3, &#x27;world&#x27;) print(&#x27;hello ...&#x27;) print(future.result()) 相关apis： 12345678910111213141516asyncio.isfuture(obj)asyncio.ensure_future(obj, *, loop=None)asyncio.wrap_future(future, *, loop=None)future.result()future.set_result(result)future.set_exception(exception)future.cancel()future.exception()future.done()future.cancelled()future.add_done_callback(callback, *, context=None)future.remove_done_callback(callback) 12345678910111213async def foo(): print(&#x27;OK&#x27;) await asyncio.sleep(2) return 12def get_result(future): print(future.result()) loop.stop()loop = asyncio.get_event_loop()task = loop.create_task(foo())task.add_done_callback(get_result)loop.run_forever() Future对象与concurrent.futures.Future的差异： concurrent.futures.Future不可被await asyncio.Future.result()和asyncio.Future.exception()没有timeout参数 asyncio.Future.add_done_callback()注册的回调，不会被立即调用，需要被loop.call_soon()计划调用 不支持concurrent.futures.wait()和concurrent.futures.as_completed() 1.3 Task 类似Future的对象，运行在协程中，非线程安全。 事件循环使用协作式调度：一个循环事件一次运行一个 Task，当 Task await Future 的完成时，事件循环就会去运行其他的 Tasks、回调或者执行 IO 操作。 123456789101112async def coro(): pass # python3.7+task = asyncio.create_task(coro())# less readabletask = asyncio.ensure_future(coro())# looploop = events.get_event_loop()task = loop.create_task(coro()) 相关apis： 1234567891011121314# 实类方法cancel()cancelled()done()result()exception()add_done_callback(callback, *, context=None)remove_done_callback(callback)get_stack(*, limit=None)print_stack(*, limit=None, file=None)# 类方法classmethod all_tasks(loop=None)classmethod current_task(loop=None) 12345678910111213141516171819async def say_after(delay, what): await asyncio.sleep(delay) print(what)async def test1(): print(&#x27;started at &#123;&#125;&#x27;.format(time.strftime(&#x27;%X&#x27;))) await say_after(1, &#x27;hello&#x27;) await say_after(2, &#x27;world&#x27;) print(&#x27;finished at &#123;&#125;&#x27;.format(time.strftime(&#x27;%X&#x27;))) # 总共耗时3sasync def test2(): print(&#x27;started at &#123;&#125;&#x27;.format(time.strftime(&#x27;%X&#x27;))) task1 = asyncio.create_task(say_after(1, &#x27;hello&#x27;)) task2 = asyncio.create_task(say_after(2, &#x27;world&#x27;)) await task1 await task2 print(&#x27;finished at &#123;&#125;&#x27;.format(time.strftime(&#x27;%X&#x27;))) # 总共耗时2s 2. 事件循环 Event Loop事件循环是 asyncio 应用的核心，事件循环运行异步 tasks 和 callbacks，执行网络 IO 操作，运行子进程 subprocesses。 2.1 获取事件循环 asyncio.get_running_loop() 返回当前 OS 线程中正在运行的事件循环。 asyncio.get_event_loop() 获取当前事件循环。 如果当前 OS 线程没有设置当前事件循环并且 set_event_loop() 还没有被调用，asyncio 将创建一个新的事件循环并将其设置为当前循环。 由于此函数具有相当复杂的行为（特别是在使用了自定义事件循环策略的时候），更推荐在协程和回调中使用 get_running_loop() 函数而非 get_event_loop()。 应该考虑使用 asyncio.run() 函数而非使用低层级函数来手动创建和关闭事件循环。 asyncio.set_event_loop(loop) 将 loop 设置为当前 OS 线程的当前事件循环。 asyncio.new_event_loop() 创建一个新的事件循环。 2.2 运行和停止循环 loop.run_until_complete(future) loop.run_forever() loop.stop() loop.is_running() loop.close() coroutine loop.shutdown_asyncgens() 计划用 aclose() 调用将当前所有开着的异步生成器对象关闭。调用此方法后，如果新的异步生成器还在迭代，事件循环会引起警告。该方法会可靠地终结所有计划关闭的异步生成器。 2.3 安排回调 loop.call_soon(callback, *args, context=None) loop.call_soon_threadsafe(callback, *args, context=None) 123456789101112131415161718192021async def foo(): print(&#x27;OK&#x27;) return &#x27;done&#x27;def callback1(args): print(*args) loop.stop()def callback2(a, b=None): print(a, b)loop = asyncio.get_event_loop()task = loop.create_task(foo())loop.call_soon(callback1, (1, 2, 3))loop.call_soon(partial(callback2, 10, b=11))loop.run_forever() Python3.7增加上下文变量Context Variables, 替代全局变量，因为全部变量可能会被其他协程修改，不安全 1234567891011121314151617future_var = ContextVar(&#x27;future&#x27;)async def foo(): print(&#x27;OK&#x27;) return &#x27;done&#x27;def get_result(): future = future_var.get(&#x27;future&#x27;) print(future.result()) loop.stop()loop = asyncio.get_event_loop()task = loop.create_task(foo())future_var.set(task)loop.call_soon(get_result)loop.run_forever() 2.4 安排延迟的回调事件循环还提供了机制，将回调在 future 的某个时间点调用，事件循环用 monotonic clocks 追踪时间。 loop.call_later(delay, callback, *args, context=None) loop.call_at(when, callback, *args, context=None) loop.time() 返回当前时间，浮点数值，根据事件循环的内部 monotonic clock。单调时间，所谓单调，就是只会不停的往前增长，不受校时操作的影响，这个时间是自进程启动以来的秒数。 1234567891011121314def callback(n): print(f&#x27;执行callback &#123;n&#125;&#x27;)async def main(): loop = asyncio.get_running_loop() print(&#x27;注册 callbacks ...&#x27;) loop.call_later(.1, callback, 1) loop.call_later(.5, callback, 2) # 来不及调用 loop.call_soon(callback, 3) await asyncio.sleep(0.4)asyncio.run(main()) 1234567891011121314151617def callback(n, loop): print(f&#x27;执行callback &#123;n&#125; 于 &#123;loop.time()&#125;&#x27;)async def main(): loop = asyncio.get_running_loop() now = loop.time() print(f&#x27;clock time: &#123;time.time()&#125;&#x27;) print(f&#x27;loop time: &#123;now&#125;&#x27;) print(&#x27;注册 callbacks ...&#x27;) loop.call_later(now + 0.1, callback, 1, loop) loop.call_later(now + 0.2, callback, 2, loop) loop.call_soon(callback, 3, loop) await asyncio.sleep(1)asyncio.run(main()) 2.5 创建 Futures 和 Tasks loop.create_future() 创建依附于 loop 的 asyncio.Future 对象。 这是在 asyncio 中创建 Future 更好的方式，给第三方事件循环提供了可选的 Future 对象实现。 loop.create_task(coro) 安排 Coroutines 的执行，返回 Task 对象。 loop.set_task_factory(factory) 用 loop.create_task(coro) 设置 task 工厂。 如果 factory 为 None，那么将会用默认的 factory 设置。否则 factory 必须拥有匹配 (loop, coro) 签名的 callable，loop 为激活的事件循环的引用，coro 是协程对象，callable 必须返回 asyncio.Future 兼容对象。 loop.get_task_factory()返回 task factory，如果使用的默认 factory，则返回 None。 2.6 在线程或进程池中执行 awaitable loop.run_in_executor(executor, func, *args) 安排函数在指定的 executor 中调用。executor 参数是 concurrent.futures.Executor 实例。如果 executor 为 None，则使用默认的 executor。返回 asyncio.Future 对象。 set_default_executor(executor) 给 run_in_executor() 设置默认的 executor，executor 参数是 concurrent.futures.ThreadPoolExecutor 实例。 1234567891011121314151617181920def blocking_io(): with open(&#x27;/dev/urandom&#x27;, &#x27;rb&#x27;) as f: return f.read(100)def cpu_bound(): return sum(i * i for i in range(10 ** 7))async def main(): loop = asyncio.get_running_loop() result = await loop.run_in_executor(None, blocking_io) print(&#x27;default thread pool:&#x27;, result) with concurrent.futures.ThreadPoolExecutor() as pool: result = await loop.run_in_executor(pool, blocking_io) print(&#x27;custom thread pool:&#x27;, result) with concurrent.futures.ProcessPoolExecutor() as pool: result = await loop.run_in_executor(pool, cpu_bound) print(&#x27;custom process pool:&#x27;, result) 2.7 启用调试模式 loop.get_debug() 环境变量 PYTHONASYNCIODEBUG 非空，则返回 True，否则返回 False。 loop.set_debug(enabled: bool) 2.8 运行子进程推荐用高级的 asyncio.create_subprocess_shell() 和 asyncio.create_subprocess_exec() 代替 loop 的低级 API。 注意：默认的 asyncio 事件循环在 Windows 上不支持子进程，在 Windows 上应用 ProactorEventLoop 代替。 12asyncio.set_event_loop_policy( asyncio.WindowsProactorEventLoopPolicy()) coroutine asyncio.create_subprocess_exec(*args, stdin=None, stdout=None, stderr=None, loop=None, limit=None, **kwds) limit：如果给 stdout 和 stderr 参数设置了 subprocess.PIPE，那么会设置包裹了 Process.stdout 和 Process.stderr 的 StreamReader 的缓冲大小限制。 coroutine asyncio.create_subprocess_shell(cmd, stdin=None, stdout=None, stderr=None, loop=None, limit=None, **kwds) 1234567891011121314151617181920async def get_date(): code = &#x27;import datetime; print(datetime.datetime.now())&#x27; # Create the subprocess proc = await asyncio.create_subprocess_exec( sys.executable, &#x27;-c&#x27;, code, stdout=asyncio.subprocess.PIPE ) # Read one line of output data = await proc.stdout.readline() line = data.decode(&#x27;ascii&#x27;).rstrip() # Wait for the subprocess exit await proc.wait() return linedate = asyncio.run(get_date())print(f&#x27;Current date: &#123;date&#125;&#x27;) 12345678910111213141516171819202122async def run(cmd): proc = await asyncio.create_subprocess_shell( cmd, stdin=asyncio.subprocess.PIPE, stdout=asyncio.subprocess.PIPE ) stdout, stderr = await proc.communicate() print(f&#x27;[&#123;cmd!r&#125; exited with &#123;proc.returncode&#125;]&#x27;) if stdout: print(f&#x27;[stdout]\\n&#123;stdout.decode()&#125;&#x27;) if stderr: print(f&#x27;[stderr]\\n&#123;stderr.decode()&#125;&#x27;)async def main(): await asyncio.gather( run(&#x27;ls /tmp&#x27;), run(&#x27;sleep 1; echo &quot;hello&quot;&#x27;) )asyncio.run(main()) asyncio.subprocess.Process实类方法： coroutine wait_for(timeout) 函数； coroutine wait() 等待子进程终结，返回 returncode 属性。是异步的，而 subprocess.Popen.wait() 用阻塞的 busy loop实现的； 注意：当 stdout=PIPE 或 stderr=PIPE，子进程产生太多的输出，该方法可能造成死锁，阻塞系统 pipe 缓冲等待接收更多的数据。用 pipes 时，应该使用 communicate() 方法以避免这种情况。 coroutine communicate(input=None) 和 process 交互： 如果 input 不是 None，会像标准输入发送数据 从标准输出和标准错误读取数据，当遇到 EOF 时停止。 等待进程终结。 可选参数 input 是将发送给子进程的数据（bytes 对象）。 返回 (stdout_data, stderr_data) 元组。 要向进程的标准输入发送数据，请用 stdin=PIPE。同理，返回的元组要获取数据，请用 stdout=PIPE 或 stderr=PIPE。 send_signal(signal) terminate() 杀死子进程，POSIX 系统上发送 signal.SIGTERM 命令杀死子进程，Windows 上调用 TerminateProcess() 停止子进程。 kill() 杀死子进程，POSIX 系统上发送 SIGKILL 命令杀死子进程，Windows 上是 terminate() 的别名。 stdin stdout stderr pid returncode 2.8 事件循环实现asyncio 有两种事件循环实现：SelectorEventLoop 和 ProactorEventLoop。 asyncio.SelectorEventLoop: 基于 selectors 模块的事件循环。Unix、Windows。 asyncio.ProactorEventLoop: 基于 Windows 的 “I/O Completion Ports” (IOCP) 实现的事件循环。Windows独有。 asyncio.AbstractEventLoop: 抽象基类 2.9 回调处理 asyncio.Handle loop.call_soon()、loop.call_soon_threadsafe() 返回的包裹回调的对象 ​ - cancel() 取消回调，如果回调已经取消或执行，那么无效。​ - cancelled() 如果回调被取消，返回 True。 asyncio.TimerHandle loop.call_later()、loop.call_at() 返回的包裹回调的对象，是 Handle 的子类。 ​ -when() 返回回调安排的时间，浮点数的秒，该时间是一个完全时间戳，和 loop.time() 引用同样的时间。 3. 运行Task3.1 loop.run_until_complete(future)一直运行到 future（Future 实例）完成，返回 Future 的结果，或者引发异常。 如果参数是 coroutine，内部会隐式调用将其包裹成 asyncio.Task 对象，并加入运行计划。 12345678910async def foo(): print(&#x27;OK&#x27;) return &#x27;done&#x27;loop = asyncio.get_event_loop()try: result = loop.run_until_complete(foo()) print(result)finally: loop.close() 3.1.1 asyncio.ensure_future(f())将 coroutine 包裹成 asyncio.Task 对象 123456789101112async def foo(): print(&#x27;OK&#x27;) return &#x27;done&#x27;task = asyncio.ensure_future(foo())loop = asyncio.get_event_loop()try: result = loop.run_until_complete(task) print(result) print(task.result())finally: loop.close() 3.1.2 asyncio.create_task(coro)必须先有事件循环 123456789101112async def foo(): print(&#x27;OK&#x27;) return &#x27;done&#x27;task = asyncio.create_task(foo()) # error no running event looploop = asyncio.get_event_loop()try: result = loop.run_until_complete(task) print(result) print(task.result())finally: loop.close() 修改为： 12345678910111213async def done(): return &#x27;done&#x27;async def foo(): print(&#x27;OK&#x27;) return asyncio.create_task(done())loop = asyncio.get_event_loop()try: result = loop.run_until_complete(foo()) print(result.result())finally: loop.close() 3.1.3 loop.create_task(coro())1234567891011121314async def done(): return &#x27;done&#x27;async def foo(): print(&#x27;OK&#x27;) return asyncio.create_task(done())loop = asyncio.get_event_loop()task = loop.create_task(foo())try: result = loop.run_until_complete(task) print(result.result())finally: loop.close() 3.1.4 loop.create_future()123456789101112def mark_done(future): future.set_result(&#x27;done&#x27;)loop = asyncio.get_event_loop()try: future = loop.create_future() loop.call_soon(mark_done, future) result = loop.run_until_complete(future) print(result)finally: loop.close() 3.2 loop.run_forever()123456789101112131415161718192021222324252627282930313233now = lambda: time.time()async def do_some_work(x): print(&#x27;Waiting: &#x27;, x) await asyncio.sleep(x) return &#x27;Done after &#123;&#125;s&#x27;.format(x)coroutine1 = do_some_work(1)coroutine2 = do_some_work(2)coroutine3 = do_some_work(2)tasks = [ asyncio.ensure_future(coroutine1), asyncio.ensure_future(coroutine2), asyncio.ensure_future(coroutine3)]start = now()loop = asyncio.get_event_loop()try: loop.run_until_complete(asyncio.wait(tasks))except KeyboardInterrupt as e: print(asyncio.Task.all_tasks()) for task in asyncio.Task.all_tasks(): print(task.cancel()) loop.stop() loop.run_forever()finally: loop.close()print(&#x27;TIME: &#x27;, now() - start) 3.3 asyncio.run(coro, *, debug=False)3.4 并发运行 Tasks awaitable asyncio.gather(*aws, loop=None, return_exceptions=False) deprecated 并发运行 coroutine asyncio.wait_for(aw, timeout, *, loop=None) 超时 coroutine asyncio.wait(aws, *, loop=None, timeout=None, return_when=ALL_COMPLETED) asyncio.as_completed(aws, *, loop=None, timeout=None) 3.4.1 并发运行(gather)123456789101112131415async def factorial(name, n): f = 1 for i in range(2, n+1): print(f&#x27;Task &#123;name&#125;: Compute factorial &#123;i&#125;...&#x27;) await asyncio.sleep(1) f *= i print(f&#x27;Task &#123;name&#125;: factorial(&#123;n&#125;) = &#123;f&#125;&#x27;)async def main(): await asyncio.gather( factorial(&#x27;A&#x27;, 2), factorial(&#x27;B&#x27;, 3), factorial(&#x27;C&#x27;, 4) ) 3.4.2 超时(wait_for)1234567891011async def eternity(): await asyncio.sleep(10) print(&#x27;done&#x27;)async def main(): try: await asyncio.wait_for(eternity(), timeout=1) except asyncio.TimeoutError: print(&#x27;timeout&#x27;)asyncio.run(main()) 3.4.3 wait12345678910async def foo(): return 42task = asyncio.create_task(foo())done, pending = await asyncio.wait(&#123;task&#125;)if task in done: # Everything will work as expected now. pass 3.4.4 as_completed并发运行 aws 集合中的 awaitable 对象，返回 Future 对象的迭代器，每一个返回的 Future 对象代表了剩余 awaitables 集合的结果。 1234567891011121314151617async def phase(i): print(f&#x27;phase &#123;i&#125;&#x27;) return iasync def main(num): phases = [phase(i) for i in range(num)] print(&#x27;waiting for phases to complete&#x27;) results = [] for next_to_complete in asyncio.as_completed(phases): result = await next_to_complete print(f&#x27;received answer &#123;result&#125;&#x27;) results.append(result) print(f&#x27;results: &#123;results&#125;&#x27;)asyncio.run(main(3)) 4. 屏蔽取消操作awaitable asyncio.shield(aw, *, loop=None) 12res = await shield(something()) # 不可取消res = await something() # 可取消 5. 队列设计和 queue 模块相似，不过 asyncio queues 不是线程安全的，因为它们设计的目的是用于 async/await 代码中。 asyncio.Queue(maxsize=0, *, loop=None) asyncio.PriorityQueue asyncio.LifoQueue 实例方法： maxsize empty() full() coroutine get() get_nowait() coroutine join() coroutine put(item) put_nowait(item) qsize() task_done() 6. Synchronization Primitives和 threading 模块设计是相似的，不同点： asyncio primitives 不是线程安全的，因此不应该用于系统的线程同步，此情况应该用 threading。 asyncio 的 synchronization primitives 不接受 timeout 参数，用 asyncio.wait_for() 函数执行有 timeout 的操作。 6.1 Lock实现了用于 asyncio tasks 的独占锁， 非线程安全。asyncio lock 可以保证对资源互斥访问。 asyncio.Lock(*, loop=None) 实例方法： coroutine acquire() 获取锁 release() locked() 12345lock = asyncio.Lock()# ... laterasync with lock: # access shared state 等价于 12345678lock = asyncio.Lock()# ... laterawait lock.acquire()try: # access shared statefinally: lock.release() 123456789101112131415161718192021222324252627282930def unlock(lock): print(&#x27;callback releasing lock&#x27;) lock.release()async def coro1(lock): print(&#x27;coro1 waiting for the lock&#x27;) async with lock: print(&#x27;coro1 acquired lock&#x27;) print(&#x27;coro1 released lock&#x27;)async def coro2(lock): print(&#x27;coro2 waiting for the lock&#x27;) async with lock: print(&#x27;coro2 acquired lock&#x27;) print(&#x27;coro2 released lock&#x27;)async def main(): loop = asyncio.get_running_loop() lock = asyncio.Lock() print(&#x27;acquiring the lock before starting coroutines&#x27;) await lock.acquire() print(f&#x27;lock acquired: &#123;lock.locked()&#125;&#x27;) loop.call_later(1, partial(unlock, lock)) print(&#x27;waiting for coroutines&#x27;) await asyncio.wait(&#123;coro1(lock), coro2(lock)&#125;)asyncio.run(main()) 6.2 Eventasyncio.Event(*, loop=None) event 对象，非线程安全。 asyncio event 用于通知多个 asyncio tasks 某个 event 发生了。 Event 对象管理内部 flag，该 flag 可以用 set() 设置为 True，或者用 clear() 重置为 False。wait() 方法阻塞，直到 flag 被设置为 True。初始时 flag 被设置为 False。 实例方法： coroutine wait() 等待，直到 event 被设置 set() 设置 event clear() 清除 event is_set() 1234567891011121314151617181920async def waiter(event): print(&#x27;waiting for it ...&#x27;) await event.wait() print(&#x27;... got it!&#x27;)async def main(): # Create an Event object. event = asyncio.Event() # Spawn a Task to wait until &#x27;event&#x27; is set. waiter_task = asyncio.create_task(waiter(event)) # Sleep for 1 second and set the event. await asyncio.sleep(1) event.set() # Wait until the waiter task is finished. await waiter_taskasyncio.run(main()) 6.3 Conditionasyncio.Condition(lock=None, *, loop=None) Condition 对象，非线程安全。 实例方法： coroutine acquire(): 获取底层的锁 notify(n=1): 唤醒最多 n 个等待该 condition 的 tasks（默认为 1） locked() notify_all() release(): 释放底层的锁。 coroutine wait(): 等待被通知。 coroutine wait_for(predicate): 等待，直到 predicate 变成 True。predicate 必须是 callable，result 会被解释成布尔值，最终的 value 是返回值。 12345678910111213141516171819202122232425262728293031323334353637383940414243async def consumer(condition, n): async with condition: print(&#x27;consumer &#123;&#125; is waiting&#x27;.format(n)) await condition.wait() print(&#x27;consumer &#123;&#125; triggered&#x27;.format(n)) print(&#x27;ending consumer &#123;&#125;&#x27;.format(n))async def manipulate_condition(condition): print(&#x27;starting manipulate_condition&#x27;) # pause to let consumers start await asyncio.sleep(0.1) for i in range(1, 3): async with condition: print(&#x27;notifying &#123;&#125; consumers&#x27;.format(i)) condition.notify(n=i) await asyncio.sleep(0.1) async with condition: print(&#x27;notifying remaining consumers&#x27;) condition.notify_all() print(&#x27;ending manipulate_condition&#x27;)async def main(): # Create a condition condition = asyncio.Condition() # Set up tasks watching the condition consumers = [ consumer(condition, i) for i in range(5) ] # Schedule a task to manipulate the condition variable task = asyncio.create_task(manipulate_condition(condition)) # Wait for the consumers to be done await asyncio.wait(consumers) await taskasyncio.run(main()) 6.4 Semaphoreasyncio.Semaphore(value=1, *, loop=None) Semaphore 对象，非线程安全。 Semaphore 管理内部计数，每次 acquire() 调用时会减 1，release() 调用时加 1。该计数不会到 0 以下，当 acquire() 发现计数为 0，会阻塞，直到遇到某个 task 调用 release()。 可选的 value 参数指定初始 value 用于内部计数器（默认是 1）。如果给定的 value 比 0 小，会引发 ValueError。 实例方法： coroutine acquire(): 获取 semaphore。如果内部计数器比 0 大，会减 1，然后立即返回 True locked() release(): 释放 semaphore，内部计数器加 1，可以唤醒等待获取 semaphore 的任务。 12345sem = asyncio.Semaphore(10)# ... laterasync with sem: # work with shared resource 6.5 BoundedSemaphoreasyncio.BoundedSemaphore(value=1, *, loop=None) 有界的 semaphore 对象，非线程安全。 Bounded Semaphore 是 Semaphore 的另一个版本，如果计数超过了初始的 value，会在 release() 时引发 ValueError。 7. Asynchronous Iterate7.1 Asynchronous Iterators1234567def __aiter__(self): # 返回异步迭代器对象 passdef __anext__(self) # 返回 awaitable对象 pass 123456789101112class Reader: async def readline(self): ... def __aiter__(self): return self async def __anext__(self): val = await self.readline() if val == b&#x27;&#x27;: raise StopAsyncIteration return val 7.2 Asynchronous Generator123456789async def gen(n): for i in range(n): yield iasync def main(): async for result in gen(10): print(result)asyncio.run(main()) 8. Asynchronous Context Managers1234567def __aenter__(self): # 返回 awaitable对象 passdef __aexit__(self) # 返回 awaitable对象 pass 9. 同步代码与异步代码衔接9.1 async from async123456789async def io_blocking(): await asyncio.sleep(3) return 1async def main(): result = await io_blocking() print(result)asyncio.run(main()) 9.2 sync from async1234567891011def io_blocking(): time.sleep(3) return 1async def main(): executor = concurrent.futures.ThreadPoolExecutor(max_workers=3) loop = asyncio.get_running_loop() result = await loop.run_in_executor(executor, io_blocking) print(result)asyncio.run(main()) 使用asgiref.sync: 123456789from asgiref.sync import sync_to_asyncdef io_blocking(): time.sleep(3) return 1async def main(): result = await sync_to_async(io_blocking)() print(result) 或者： 12345678910@sync_to_asyncdef io_blocking(): time.sleep(3) return 5async def main(): result = await io_blocking() print(result)asyncio.run(main()) 9.3 async from sync12345678910111213async def io_blocking(): await asyncio.sleep(3) return 5def main(): # loop = asyncio.new_event_loop() # asyncio.set_event_loop(loop) # result = loop.run_until_complete(io_blocking()) result = asyncio.run(io_blocking()) # Python3.7+ print(result) main() 也可以使用asgiref.sync.async_to_sync去装饰coroutine 10. 高并发相关概念： TPS: 每秒事务数 (新建或修改) QPS: 每秒查询数 并发数：同一时刻与服务器进行交互的在线用户数量。并发用户数是指对Server产生压力的用户数 响应时间 10.1 tornado如何提高并发： 提高cpu的利用率 协程比多线程和多进程更能提高cpu的利用率 在高并发的爬虫中拥有远比多线程和多进程高并发的效率 10.2 提高并发的常用方法： 缓存 (Redis等) 提高数据库性能 索引优化 分库分表 分区表 分布式 分布式锁 分布式缓存 分布式事务 一致性哈希 业务分离 服务集群 11. GIL造成python低效？ GIL: 全局解释器锁，造成了同一个进程中的多个线程，只能运行在一个cpu上，且同一时刻，只能运行一个线程。 python慢的根本原因：将python代码转换为机器码时，插入了大量的代码，导致执行速度变慢 Web系统，绝大部分时候，都是IO操作，CPU闲置率高 解决GIL问题：启动多个进程 12. 实践中的异步下各项同步（阻塞）的，如果在 tornado 中按照之前的方式只用它们，就是把 tornado 的非阻塞、异步优势削减了。 数据库的所有操作，不管你的数据是 SQL 还是 noSQL，connect、insert、update 等 文件操作，打开，读取，写入等 time.sleep smtplib，发邮件的操作 一些网络操作，比如 tornado 的 httpclient 以及 pycurl 等 解决方法 在数据库方面，由于种类繁多，不能一一说明，比如 mysql，可以使用adb模块来实现 python 的异步 mysql 库；对于 mongodb 数据库，有一个非常优秀的模块，专门用于在 tornado 和 mongodb 上实现异步操作，它就是 motor。 文件操作方面也没有替代模块，只能尽量控制好 IO，或者使用内存型（Redis）及文档型（MongoDB）数据库。 time.sleep() 在 tornado 中有替代：yield tornado.gen.sleep() 或者tornado.ioloop.IOLoop.instance().add_timeout smtp 发送邮件，推荐改为 tornado-smtp-client。 对于网络操作，要使用 tornado.httpclient.AsyncHTTPClient。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[{"name":"tornado","slug":"tornado","permalink":"https://elihe2011.github.io/tags/tornado/"}]},{"title":"MySQL","slug":"MySQL","date":"2020-03-24T05:19:50.000Z","updated":"2021-06-22T10:50:49.748Z","comments":true,"path":"2020/03/24/MySQL/","link":"","permalink":"https://elihe2011.github.io/2020/03/24/MySQL/","excerpt":"","text":"1. 查找字段相同的数据123select a.id from group_member a,(select group_id, user_id, status from group_member group by group_id, user_id, status having count(*) &gt; 1) bwhere a.group_id=b.group_id and a.user_id=b.user_id and a.status=b.status; 2. 循环更新数据12UPDATE contact a INNER JOIN users b ON a.inviter=b.phone SET a.inviter_id=b.id;UPDATE contact a INNER JOIN users b ON a.invitee=b.phone SET a.invitee_id=b.id; 3. 强制删除外键引用的表123SET FOREIGN_KEY_CHECKS = 0drop table users;SET FOREIGN_KEY_CHECKS = 1; 4. 事务隔离级别1234select @@tx_isolation;set global transaction isolation level repeatable read;set [session] transaction isolation level repeatable read; 隔离级别： Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 Read committed (读已提交)：可避免脏读的发生。 Read uncommitted (读未提交)：最低级别，任何情况都无法保证。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://elihe2011.github.io/categories/MySQL/"}],"tags":[]},{"title":"Go 缓存淘汰策略","slug":"Go 缓存淘汰策略","date":"2020-01-12T07:17:57.000Z","updated":"2021-06-22T10:50:49.748Z","comments":true,"path":"2020/01/12/Go 缓存淘汰策略/","link":"","permalink":"https://elihe2011.github.io/2020/01/12/Go%20%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","excerpt":"1. LRULeast Recently Used, 最近最少使用缓存。目的：淘汰最长时间未被使用的元素 快速存取原始 固定的最大容量，不会无限制增长 达到最大容量后，新增元素时，会把最近最少使用的元素删除，再放入新元素","text":"1. LRULeast Recently Used, 最近最少使用缓存。目的：淘汰最长时间未被使用的元素 快速存取原始 固定的最大容量，不会无限制增长 达到最大容量后，新增元素时，会把最近最少使用的元素删除，再放入新元素 1.1 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103type Entry struct &#123; Key string Value interface&#123;&#125; pre *Entry next *Entry&#125;type Cache struct &#123; cache map[string]*Entry capacity int head *Entry tail *Entry&#125;func newCache(cap int) *Cache &#123; return &amp;Cache&#123;cache: make(map[string]*Entry), capacity: cap&#125;&#125;var lock sync.RWMutexfunc (cache *Cache) Put(key string, val interface&#123;&#125;) interface&#123;&#125; &#123; lock.Lock() defer lock.Unlock() if existVal, exist := cache.cache[key]; exist &#123; cache.moveToHead(existVal) return nil &#125; // 重设 head 元素 e := &amp;Entry&#123;Key: key, Value: val, next: cache.head&#125; if cache.head != nil &#123; cache.head.pre = e &#125; cache.head = e // 第一次新增元素时，tail 为 nil if cache.tail == nil &#123; cache.tail = e &#125; cache.cache[key] = e if len(cache.cache) &lt;= cache.capacity &#123; return nil &#125; // 处理超出容量范围的元素 removedEntry := cache.tail cache.tail = cache.tail.pre removedEntry.pre = nil cache.tail.next = nil delete(cache.cache, removedEntry.Key) return removedEntry.Value&#125;func (cache *Cache) Get(key string) interface&#123;&#125; &#123; lock.Lock() defer lock.Unlock() if existVal, exist := cache.cache[key]; exist &#123; cache.moveToHead(existVal) return existVal.Value &#125; return nil&#125;func (cache *Cache) moveToHead(e *Entry) &#123; if e == cache.head &#123; return &#125; // 从link中断开，并连接前后元素 e.pre.next = e.next if e == cache.tail &#123; cache.tail = e.pre &#125; else &#123; e.next.pre = e.pre &#125; e.pre = nil e.next = cache.head cache.head.pre = e cache.head = e&#125;func main() &#123; cache := newCache(2) cache.Put(&quot;1&quot;, &quot;Golang&quot;) fmt.Println(cache.Get(&quot;1&quot;)) cache.Put(&quot;2&quot;, &quot;Python&quot;) fmt.Println(cache.Get(&quot;1&quot;)) cache.Put(&quot;3&quot;, &quot;Java&quot;) fmt.Println(cache.Get(&quot;1&quot;)) fmt.Println(cache.Get(&quot;2&quot;)) // nil fmt.Println(cache.Get(&quot;3&quot;)) // Java&#125; 1.2 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263type LinkNode struct &#123; key, val int pre, next *LinkNode&#125;type LRUCache struct &#123; m map[int]*LinkNode cap int head, tail *LinkNode&#125;func Constructor(capacity int) LRUCache &#123; head := &amp;LinkNode&#123;0, 0, nil, nil&#125; tail := &amp;LinkNode&#123;0, 0, nil, nil&#125; head.next = tail tail.pre = head return LRUCache&#123;make(map[int]*LinkNode), capacity, head, tail&#125;&#125;func (this *LRUCache) Get(key int) int &#123; cache := this.m if v, exist := cache[key]; exist &#123; this.MoveToHead(v) return v.val &#125; else &#123; return -1 &#125;&#125;func (this *LRUCache) RemoveNode(node *LinkNode) &#123; node.pre.next = node.next node.next.pre = node.pre&#125;func (this *LRUCache) AddNode(node *LinkNode) &#123; head := this.head node.next = head.next head.next.pre = node node.pre = head head.next = node&#125;func (this *LRUCache) MoveToHead(node *LinkNode) &#123; this.RemoveNode(node) this.AddNode(node)&#125;func (this *LRUCache) Put(key int, value int) &#123; tail := this.tail cache := this.m if v, exist := cache[key]; exist &#123; v.val = value this.MoveToHead(v) &#125; else &#123; v := &amp;LinkNode&#123;key, value, nil, nil&#125; if len(cache) == this.cap &#123; delete(cache, tail.pre.key) this.RemoveNode(tail.pre) &#125; this.AddNode(v) cache[key] = v &#125;&#125; 2. LFULFU（Least Frequently Used）算法根据数据的历史访问频率来淘汰数据，其核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。LFU的每个数据块都有一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。LFU需要记录所有数据的访问记录，内存消耗较高；需要基于引用计数排序，性能消耗较高。在算法实现复杂度上，LFU要远大于LRU。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package maintype LFUCache struct &#123; cache map[int]*Node freq map[int]*DoubleList ncap, size, minFreq int&#125;func (this *LFUCache) IncrFreq(node *Node) &#123; _freq := node.freq this.freq[_freq].RemoveNode(node) if this.minFreq == _freq &amp;&amp; this.freq[_freq].IsEmpty() &#123; this.minFreq++ delete(this.freq, _freq) &#125; node.freq++ if this.freq[node.freq] == nil &#123; this.freq[node.freq] = createDL() &#125; this.freq[node.freq].AddFirst(node)&#125;func Constructor(capacity int) LFUCache &#123; return LFUCache&#123; cache: make(map[int]*Node), freq: make(map[int]*DoubleList), ncap: capacity, &#125;&#125;func (this *LFUCache) Get(key int) int &#123; if node, ok := this.cache[key]; ok &#123; this.IncrFreq(node) return node.val &#125; return -1&#125;func (this *LFUCache) Put(key int, value int) &#123; if this.ncap == 0 &#123; return &#125; //节点存在 if node, ok := this.cache[key]; ok &#123; node.val = value this.IncrFreq(node) &#125; else &#123; if this.size &gt;= this.ncap &#123; node := this.freq[this.minFreq].RemoveLast() delete(this.cache, node.key) this.size-- &#125; x := &amp;Node&#123;key: key, val: value, freq: 1&#125; this.cache[key] = x if this.freq[1] == nil &#123; this.freq[1] = createDL() &#125; this.freq[1].AddFirst(x) this.minFreq = 1 this.size++ &#125;&#125;//节点nodetype Node struct &#123; key, val, freq int prev, next *Node&#125;//双链表type DoubleList struct &#123; tail, head *Node&#125;//创建一个双链表func createDL() *DoubleList &#123; head, tail := &amp;Node&#123;&#125;, &amp;Node&#123;&#125; head.next, tail.prev = tail, head return &amp;DoubleList&#123; tail: tail, head: head, &#125;&#125;func (this *DoubleList) IsEmpty() bool &#123; return this.head.next == this.tail&#125;//将node添加为双链表的第一个元素func (this *DoubleList) AddFirst(node *Node) &#123; node.next = this.head.next node.prev = this.head this.head.next.prev = node this.head.next = node&#125;func (this *DoubleList) RemoveNode(node *Node) &#123; node.next.prev = node.prev node.prev.next = node.next node.next = nil node.prev = nil&#125;func (this *DoubleList) RemoveLast() *Node &#123; if this.IsEmpty() &#123; return nil &#125; lastNode := this.tail.prev this.RemoveNode(lastNode) return lastNode&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://elihe2011.github.io/tags/algorithm/"}]},{"title":"Go 遍历树","slug":"Go 遍历树","date":"2020-01-09T02:51:19.000Z","updated":"2021-06-22T10:50:49.747Z","comments":true,"path":"2020/01/09/Go 遍历树/","link":"","permalink":"https://elihe2011.github.io/2020/01/09/Go%20%E9%81%8D%E5%8E%86%E6%A0%91/","excerpt":"1. 二叉树遍历123456789101112 1 / \\ 2 3 / \\ / \\4 5 6 7 / \\ 8 9前序输出: 1 2 4 5 3 6 8 9 7中序输出: 4 2 5 1 8 6 9 3 7后序输出: 4 5 2 8 9 6 7 3 1层序输出: 1 2 3 4 5 6 7 8 9","text":"1. 二叉树遍历123456789101112 1 / \\ 2 3 / \\ / \\4 5 6 7 / \\ 8 9前序输出: 1 2 4 5 3 6 8 9 7中序输出: 4 2 5 1 8 6 9 3 7后序输出: 4 5 2 8 9 6 7 3 1层序输出: 1 2 3 4 5 6 7 8 9 2. 实现代码2.1 构建二叉树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051type Tree struct &#123; Val int Left *Tree Right *Tree IsRoot bool&#125;var root = &amp;Tree&#123; Val: 1, Left: node2, Right: node3, IsRoot: true,&#125;var node2 = &amp;Tree&#123; Val: 2, Left: node4, Right: node5,&#125;var node3 = &amp;Tree&#123; Val: 3, Left: node6, Right: node7,&#125;var node4 = &amp;Tree&#123; Val: 4,&#125;var node5 = &amp;Tree&#123; Val: 5,&#125;var node6 = &amp;Tree&#123; Val: 6, Left: node8, Right: node9,&#125;var node7 = &amp;Tree&#123; Val: 7,&#125;var node8 = &amp;Tree&#123; Val: 8,&#125;var node9 = &amp;Tree&#123; Val: 9,&#125; 2.2 前序遍历123456789func preorder(t *Tree) &#123; if t == nil &#123; return &#125; fmt.Printf(&quot;%d, &quot;, t.Val) preorder(t.Left) preorder(t.Right)&#125; 2.3 中序遍历123456789func inorder(t *Tree) &#123; if t == nil &#123; return &#125; inorder(t.Left) fmt.Printf(&quot;%d, &quot;, t.Val) inorder(t.Right)&#125; 2.4 后序遍历123456789func postorder(t *Tree) &#123; if t == nil &#123; return &#125; postorder(t.Left) postorder(t.Right) fmt.Printf(&quot;%d, &quot;, t.Val)&#125; 2.5 层序遍历先将二叉树改造为队列 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type Queue struct &#123; Val []*Tree Length int&#125;func (q *Queue) Push(t *Tree) &#123; q.Val = append(q.Val, t)&#125;func (q *Queue) Pop() *Tree &#123; len := q.Len() if len == 0 &#123; panic(&quot;Queue is empty&quot;) &#125; node := q.Val[0] if len == 1 &#123; q.Val = []*Tree&#123;&#125; &#125; else &#123; q.Val = q.Val[1:] &#125; return node&#125;func (q *Queue) Len() int &#123; q.Length = len(q.Val) return q.Length&#125;func levelorder(t *Tree) &#123; queue := Queue&#123;&#125; queue.Push(root) for queue.Len() &gt; 0 &#123; node := queue.Pop() if node == nil &#123; panic(&quot;node is nil&quot;) &#125; if node.IsRoot &#123; fmt.Printf(&quot;%d, &quot;, node.Val) &#125; if node.Left != nil &#123; fmt.Printf(&quot;%d, &quot;, node.Left.Val) queue.Push(node.Left) &#125; if node.Right != nil &#123; fmt.Printf(&quot;%d, &quot;, node.Right.Val) queue.Push(node.Right) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://elihe2011.github.io/tags/algorithm/"}]},{"title":"Go Etcd","slug":"Go Etcd","date":"2020-01-03T06:26:16.000Z","updated":"2021-06-22T10:50:49.747Z","comments":true,"path":"2020/01/03/Go Etcd/","link":"","permalink":"https://elihe2011.github.io/2020/01/03/Go%20Etcd/","excerpt":"","text":"1. etcd 介绍概念：高可用的分布式key-value存储，可用于配置共享和服务发现 类似项目：zookeeper 和 consul 接口：提供restful的http接口，使用简单 实现算法：基于raft算法的强一致性、高可用的服务存储目录 应用场景: 服务注册与发现 配置中心 分布式锁 master选举 2. etcd 安装 (docker)1234567891011121314151617181920212223242526272829303132333435$ docker pull gcr.io/etcd-development/etcd:v3.4.13 $ rm -rf /tmp/etcd-data.tmp &amp;&amp; mkdir -p /tmp/etcd-data.tmp$ docker run \\ -p 2379:2379 \\ -p 2380:2380 \\ --mount type=bind,source=/tmp/etcd-data.tmp,destination=/etcd-data \\ --name etcd-gcr-v3.4.13 \\ --detach gcr.io/etcd-development/etcd:v3.4.13 \\ /usr/local/bin/etcd \\ --name s1 \\ --data-dir /etcd-data \\ --listen-client-urls http://0.0.0.0:2379 \\ --advertise-client-urls http://0.0.0.0:2379 \\ --listen-peer-urls http://0.0.0.0:2380 \\ --initial-advertise-peer-urls http://0.0.0.0:2380 \\ --initial-cluster s1=http://0.0.0.0:2380 \\ --initial-cluster-token tkn \\ --initial-cluster-state new \\ --log-level info \\ --logger zap \\ --log-outputs stderr $ docker exec -it etcd-gcr-v3.4.13 /bin/sh# etcdctl versionetcdctl version: 3.4.13API version: 3.4# etcdctl endpoint health127.0.0.1:2379 is healthy: successfully committed proposal: took = 29.242978ms# etcdctl put name jackOK# etcdctl get namenamejack 3. etcd 使用3.1 连接 etcd12345678// 客户端配置config := clientv3.Config &#123; Endpoints: []string&#123;&quot;localhost:2379&quot;&#125;, DialTimeout: 5 * time.Second,&#125;// 建立连接cli, err := clientv3.New(config) 3.2 新增或修改数据123456789101112131415func put(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) putResp, err := cli.Put(ctx, &quot;/logagent/conf/&quot;, &quot;sample_value&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(putResp.Header.Revision) if putResp.PrevKv != nil &#123; fmt.Println(&quot;prev Value:&quot;, putResp.PrevKv.Value) fmt.Println(&quot;CreateRevision:&quot;, putResp.PrevKv.CreateRevision) fmt.Println(&quot;ModRevision:&quot;, putResp.PrevKv.ModRevision) fmt.Println(&quot;Version:&quot;, putResp.PrevKv.Version) &#125;&#125; 3.3 获取数据123456789101112func get(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/conf/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125;&#125; 3.4 删除数据12345678910111213141516func del(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) delResp, err := cli.Delete(ctx, &quot;/logagent/conf/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; if len(delResp.PrevKvs) &gt; 0 &#123; for _, ev := range delResp.PrevKvs &#123; fmt.Printf(&quot;Delete %s: %s\\n&quot;, ev.Key, ev.Value) &#125; &#125; fmt.Println(delResp.Deleted)&#125; 3.5 设置租期12345678910111213141516171819202122232425262728293031323334353637func lease(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) leaseGrantResp, err := cli.Grant(ctx, 10) cancel() if err != nil &#123; log.Fatal(err) &#125; leaseId := leaseGrantResp.ID ctx, cancel = context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, &quot;/logagent/ttl/&quot;, &quot;10s&quot;, clientv3.WithLease(leaseId)) cancel() if err != nil &#123; log.Fatal(err) &#125; for &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/ttl/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; if getResp.Count == 0 &#123; fmt.Println(&quot;ttl expire&quot;) break &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125; time.Sleep(2 * time.Second) &#125;&#125; 3.6 延迟租期1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func extentLease(cli *clientv3.Client) &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) leaseGrantResp, err := cli.Grant(ctx, 10) cancel() if err != nil &#123; log.Fatal(err) &#125; leaseId := leaseGrantResp.ID ctx, cancel = context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, &quot;/logagent/ttl/&quot;, &quot;10s&quot;, clientv3.WithLease(leaseId)) cancel() if err != nil &#123; log.Fatal(err) &#125; time.Sleep(5 * time.Second) ctx, cancel = context.WithTimeout(context.Background(), time.Second) leaseKeepAliveResp, err := cli.KeepAlive(ctx, leaseId) if err != nil &#123; log.Fatal(err) &#125; go func() &#123; for &#123; select &#123; case keepResp := &lt;-leaseKeepAliveResp: if keepResp == nil &#123; fmt.Println(&quot;Lease expire&quot;) return &#125; else &#123; fmt.Println(&quot;Receive lease extent resp&quot;) &#125; &#125; &#125; &#125;() ctx, cancel = context.WithTimeout(context.Background(), time.Second) getResp, err := cli.Get(ctx, &quot;/logagent/ttl/&quot;) cancel() if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125;&#125; 3.7 watch 功能123456789101112131415161718192021222324252627282930313233343536373839404142434445func watch(cli *clientv3.Client) &#123; kv := clientv3.NewKV(cli) // 模拟KV变化 go func() &#123; for &#123; _, _ = kv.Put(context.TODO(), &quot;/language&quot;, &quot;go&quot;) _, _ = kv.Delete(context.TODO(), &quot;language&quot;) time.Sleep(time.Second) &#125; &#125;() getResp, err := kv.Get(context.TODO(), &quot;language&quot;) if err != nil &#123; log.Fatal(err) &#125; for _, ev := range getResp.Kvs &#123; fmt.Printf(&quot;Get %s: %s\\n&quot;, ev.Key, ev.Value) &#125; watchStartVersion := getResp.Header.Revision + 1 fmt.Printf(&quot;Start watching from version: %d\\n&quot;, watchStartVersion) watcher := clientv3.NewWatcher(cli) ctx, cancel := context.WithCancel(context.TODO()) time.AfterFunc(5*time.Second, func() &#123; cancel() &#125;) watchRespChan := watcher.Watch(ctx, &quot;language&quot;, clientv3.WithRev(watchStartVersion)) for watchResp := range watchRespChan &#123; for _, event := range watchResp.Events &#123; switch event.Type &#123; case mvccpb.PUT: fmt.Printf(&quot;Modify: %s, %v, %v\\n&quot;, event.Kv.Value, event.Kv.CreateRevision, event.Kv.ModRevision) case mvccpb.DELETE: fmt.Printf(&quot;Delete: %v\\n&quot;, event.Kv.ModRevision) &#125; &#125; &#125;&#125; 1234567891011121314151617181920func main() &#123; cli, err := clientv3.New(clientv3.Config&#123; Endpoints: []string&#123;&quot;localhost:2379&quot;&#125;, DialTimeout: 5 * time.Second, &#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() for &#123; rch := cli.Watch(context.Background(), &quot;/logagent/conf/&quot;) for wresp := range rch &#123; for _, ev := range wresp.Events &#123; fmt.Printf(&quot;%s %q : %q\\n&quot;, ev.Type, ev.Kv.Key, ev.Kv.Value) &#125; &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"文本处理命令","slug":"Linux文本处理命令","date":"2019-12-19T07:48:58.000Z","updated":"2021-06-22T10:50:49.746Z","comments":true,"path":"2019/12/19/Linux文本处理命令/","link":"","permalink":"https://elihe2011.github.io/2019/12/19/Linux%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/","excerpt":"","text":"1. find123find PATH -option [-print] [-exec|-ok cmd] &#123;&#125; \\;-print \\n-print0 \\0, NULL 1.1 time123456-atime N-ctime N-mtime N-newer FILE-amin M-mmin M.. 实例： 12345find . -amin -10 # 10分钟内访问的文件find . -mtime -2 # 2天内修改的文件find . -mmin +60 # 60分钟前被修改的文件find /etc -mmin -120 # 两小时内被修改的文件find / -mtime 0 # 将过去24 小时内有改变过内容的文件 1.2 user &amp; group123456-uid n-gid n-user name-group name-nouser-nogroup 实例： 12find /var -uid +1048 # uid大于等于1048find /home -user test 1.3 file123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687-name FILENAME-type TYPE （f，b，c，d，l，s，p）-size SIZE-empty-inum n-links NUM-depth sub-diectory first-maxdepth level Decend at most [level] levels of directories below the command-mindepth level Don&#x27;t apply tests or actions at levels less than [level]-xdev 不跨越filesystem -mount unix不支持-fstype TYPE（ext3，proc）-follow dereference symbolic links-L-prune Ignore directory or file-perm MODE 许可位正好是MODE-perm -MODE 许可位完全符合MODE-perm +MODE 许可位部分符合MODE， 老式写法/MODE``` 实例：```bashfind . -maxdepth 1 find . -maxdepth 2 find . -mindepth 4 find . -mindepth 2 -maxdepth 3find . -path ./.svnfind . -path /var/log -prune -o -print find . \\(-path /var/log -o -path /var/spool \\) -prune -o -print find . -size 1000 # 1000 blocks, 1Block=512Bytesfind . -size +70Mfind . -size 20c # 20 bytesfind . -size +10M -a -size -20Mfind . -empty # 空文件或空目录find . -links +2 # 链接数超过2find /mnt -name a.txt -fstype vfatfind / ！-fstype proc &#x27;(&#x27; -name &#x27;.??*&#x27; -o -name &#x27;.[^.]&#x27; &#x27;)&#x27;find / -perm 664 # 权限精确等于664find / -perm -664 # 权限完全满足664，但可包含额外权限，665，777find / -perm +664 # 权限部分满足664，例如660和600find . -perm -007 # others用户具有rwx权限find . -perm -100 # 属主至少具有x权限特殊权限SGID，SUID，SBIT(---s--s--t)find . -perm +7000 # 至少具有一个特殊权限位find . -perm -7000 # 具有全部特殊权位# 删除7天内未被读取的core文件，只涉及/所在的文件系统(-xdev)find / -xdev -type f &#x27;(&#x27; -name core -o name &#x27;core.[0-9]*&#x27; &#x27;)&#x27; -atime +7 -exec rm -f &#123;&#125; &#x27;;&#x27; # 删除那些用#, .#或.nfs开头，或者以~及。CKP结尾且3天内都未被访问过的文件find / -xdev -atime +3 &#x27;(&#x27; -name &#x27;#*&#x27; -o -name &#x27;.#*&#x27; -o -name &#x27;*.CKP&#x27;, -o -name &#x27;*~&#x27;, -o -name &#x27;.nfs*&#x27; &#x27;)&#x27; -exec rm -f &#123; &#125; &#x27;;&#x27;# 删除/tmp下载72小时内未被修的所有子目录cd /tmp; find . ! -name . ! -name lost+found -type d -mtime +3 -exec /bin/rm -rf &#123;&#125; \\;# 嵌入时间BACKUPFILE=backup-$(date +%m-%d-%Y)# 备份一天前的文件, 缺陷：发现太多的文件或文件名包含空格，执行失败tar cvf - `find . -mtime -1 -type f -print` &gt; $archive.tar# 改进型，GNU版本的find, this one is more betterfind . -mtime -1 -type f -print0 | xargs -0 tar rvf &quot;$archive.tar&quot;# 改进型，Unix风格的find，较慢find . -mtime -1 -type f -exec tar rvf &quot;$archive.tar&quot; &#123;&#125; \\; # remove file or directory it contains special charactersls -ilfind . -inum inode_num -exec rm -rf &#123;&#125; \\; 2. xargs可读入stdin的数据，并且以空格或换行符做分割，将stdin分割成arguments 1.1 选项说明1234567891011121314151617181920212223242526272829303132333435363738391) terminated by a null character, every character is taken literally, (`, \\, whitespace)--null-0 2) terminated by the specified character--delimiter=delim -d delim 3) use at most max-lines nonblank input lines per command line--max-lines[=max-lines]-l[max-lines] 4) use at most max-args arguments per command line.--max-args=max-args-n max-args 5) replace occurrences of replace-str(&#123;&#125; by default) in the initial-arguments with names read from standard input-I replace-str--replace[=replace-str]-i[replace-str] .6) a placeholder for output text&#123;&#125; 7) run up to max-procs processes at a time; 1 by default; 0: run as many as possible--max-procs=max-procs-P max-procs8) set the end of file string to EOF--eof=[EOF]-e[EOF] 9) prompt--interactive-p10) print the command line on the standard error output before executing it.--verbose-t 2.2 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768find -print0 | xargs -0# 单行输出cat a.txt | xargs# 每行3个参数cat a.txt | xargs -n3 # list files in 8 columnls | xargs -n 8 echo# 前3个用户活动情况cut -d&quot;:&quot; -f1 /etc/passwd | head -n 3 | xargs -p fingercut -d&quot;:&quot; -f1 /etc/passwd | xargs -p -e&quot;lp&quot; finger# 文件名含空格等find /home -size +1M -print0 | xargs -0 ls -l# core文件列表find / -name &quot;core&quot; -print | xargs echo &quot;&quot; &gt; core.log# 清除other组的可执行权限find . -perm -7 -print | xargs chmod o-x# 多文件过滤find . -name \\* -type f | xargs grep &quot;abc&quot;# 定界符echo &quot;aXbXc&quot; | xargs -dX# 拷贝整个目录ls | xargs -i -t cp ./&#123;&#125; /tmp/eli# 杀掉所有mysql进程ps ax | grep mysql | awk &#x27;&#123;print $1&#125;&#x27; | xargs -i kill &#123;&#125;# 参数-I和-icat a.shecho $*cat args.txtaaabbbccccat args.txt | xargs -I &#123;&#125; ./a.sh -p &#123;&#125; -l-p aaa -l-p bbb -l-p ccc -lcat args.txt | xargs -i ./a.sh -p &#123;&#125; -lcat args.txt | xargs -I % ./a.sh -p % -l# 逐一拷贝图片ls *.jpg | xargs -n 1 -i cp &#123;&#125; /home/images# 压缩文件，每次一个ls | xargs -p -l gzip# to handle arguments containing whitespace or quotesfind / -type f -print0 | xargs -0 grep -liwZ GUI | xargs -0 rm -f# 开启两个处理进程，每次压缩一个文件ls *.txt | xargs -t -n1 -P2 gzip# grep输出的文件名以\\0结尾grep -lZ &#x27;abc&#x27; &quot;*.txt&quot; | xargs -0 3. sedsed, stream editor , 按顺序逐行方式工作 i. 从输入读取一行数据存入临时缓冲区，即模式空间(pattern space) ii. 按指定的sed编辑命令处理缓冲区中的内容 iii. 把模式空间的内容送往屏幕，并将此行内容从模式空间中删除 iv. 读取下一行，重复上述过程直至全部处理 模式空间(pattern space) 保留空间(hold space) 3.1 参数说明123456sed [OPTION] [-e] cmd1 [[-e cmd2] [-e cmd3] ... [-e cmdn]] [input-file]sed [OPTION] -f script-file [input-file]-n 不打印模式空间-r 使用E-REGEX-i 直接修改文件 3.2 Address1234567811,1001,+5 &lt;=&gt; 1,65,10!1~2 &lt;=&gt;1,3,5/pattern//pattern1/,/pattern2/ 3.3 Command123456789101112131415161718d 从pattern space删除所有行D 从pattern space删除第一行p 打印pattern space中所有行P 打印pattern space中的第一行sed &#x27;3,$d&#x27; sed &#x27;/line/&#x27;d sed -n &#x27;$p&#x27;# delete spaces in front of each rowsed &#x27;s/^[ ]*/g&#x27; sed &#x27;s/^ */g&#x27; sed &#x27;s/^[[:space:]]*//g # grep &#x27;pattern&#x27;sed -n &#x27;/pattern/p&#x27;sed &#x27;/pattern/!d&#x27; 123456789101112r file 读取文件，将文件内容追加到匹配行w file 将匹配行写入文件a\\string 行后面追加一行文本i\\string 行前面插入一行文本s/pattern/string/ 用string替换pattern sed &#x27;s/abc/123/g&#x27; sed &#x27;s#\\(abc\\)defg#\\1#&#x27; sed &#x27;s/2/*/8&#x27; # 第8个&quot;2&quot;替换为&quot;*&quot; 123456789101112131415161718192021222324252627282930313233h cat pattern-space &gt; hold-spaceH cat &quot;\\n&quot;pattern-space &gt;&gt; hold-spaceg cat hold-space &gt; pattern-spaceG cat &quot;\\n&quot;hold-space &gt;&gt; pattern-spacex exchange hold-space with pattern-space! no actions # tac sed &#x27;1!G;h;$!d&#x27; # 新增空行 sed G # 多个空行变一个 sed &#x27;/^$/d;G&#x27; # add a blank line before the matching one sed &#x27;/python/&#123;x;p;x&#125;&#x27; # add a blank line after the matching one sed &#x27;/python/G&#x27; # add a blank line before and after the matching one sed &#x27;/python/&#123;x;p;x;G&#125;&#x27; # 匹配行的前一行 sed -n &#x27;/python/&#123;g;1!p&#125;;h&#x27; # 先h, 将ps保存至hs; 当匹配时，g使用hs替换ps, 如果不是第一行，则打印 # 匹配行的后一行 sed -n &#x27;/python/&#123;n;p&#125;&#x27; 123456789n 读取下一行至pattern space，此时pattern space有2行，后续命令，只操作n读入的行N 读取下一行至pattern space，但将当前读入行和N命令读入的下一行看成“一行&quot; # 匹配行的后一行，做替换操作 sed &#x27;/python/&#123;n;s/job/task/&#125;&#x27; # 删除偶数行 sed &#x27;n;d&#x27; sed -n &#x27;1~2p&#x27; 12y 与tr类似，字符替换 sed &#x27;1y/abcdef/ABCDEF/&#x27; 123= 打印行号 sed -n &#x27;/python/=&#x27; sed -n &#x27;$=&#x27; 1234567891011q 退出 # head -2 sed 2q # tail -2 sed &#x27;$!N;$!D&#x27; # tail -1 sed -e :a -e &#x27;$q;N;2,$D;ba&#x27; sed &#x27;$!d&#x27; sed -n &#x27;$p&#x27; 3.4 实例 1234567891011121314151617181920212223242526272829303132333435# replace Unix to Unix/Linuxsed -e &#x27;s#Unix#&amp;/Linux#g&#x27;# squeeze continuous c to single csed &#x27;s/cc*/c/g&#x27;# delete space at head of linesed &#x27;s/^[ \\t]*//&#x27;# delete dot at end of linesed &#x27;s/\\.$//g&#x27; # delete first character each linesed &#x27;s/.//g&#x27; # delete space at end of linesed &#x27;s/ *$//g&#x27; # insert two space before head each linesed &#x27;s/^/ /g&#x27; # remove punctuation(. , ? !)sed &#x27;s/\\.//g&#x27; -e &#x27;s/\\,//g&#x27; -e &#x27;s/\\?//g&#x27; -e &#x27;s/\\!//g&#x27;# more effectivesed &#x27;s/foo/bar/g&#x27; sed &#x27;/foo/ s/foo/bar/g&#x27; sed &#x27;/foo/ s//bar/g&#x27; # only replacement once, use &#x27;q&#x27;sed &#x27;s/foo/ s/foo/bar/;q&#125;&#x27; # delete blank linessed &#x27;/^$/d&#x27; sed &#x27;/./!d&#x27; 4. awk1234567891011awk [options] &#x27;BEGIN&#123;action&#125;pattern&#123;action&#125;...END&#123;action&#125;&#x27; fileawk [options] -f program.awk fileoptions:-F fs use fs for the input field separator-v val=val assign the value to the variable var, before execution of the program begins.pattern:/regex/: extended regular expressionrelational expression: if..else.. pattern1, pattern2: pattern range 4.1 Built-in Variables:123456789101112131415161718192021222324252627282930313233343536373839401. NF, NRNF The number of fieldsNR The total number of input records seen so far2. FS, RS, OFS, ORSFS The input field separator, a space by defaultRS The input record separator, by default a newlineOFS The output field separator, a space by defaultORS The output record separator, by default a newline3. IGNORECASE Not case-sensitivity4. ENVIRON# awk &#x27;BEGIN&#123;for(i in ENVIRON) print i, ENVIRON[i]&#125;&#x27;# awk &#x27;BEGIN&#123;print ENVIRON[&quot;JAVA_HOME&quot;]&#125;&#x27;5. ARGC, ARGV, ARGINDARGC: the number of argumentsARGIND: the index in ARGV of the current file being processedARGV: Array of arguments# awk &#x27;BEGIN&#123;print &quot;ARGC=&quot;ARGC; for(i in ARGV) print i&quot;=&quot;ARGV[i]&#125;&#x27; /etc/passwdARGC=2, 0=awk, 1=/etc/passwd 6. FILENAME : the name of the current input file# awk &#x27;BEGIN&#123;print FILENAME&#125;&#123;print FILENAME; exit&#125;&#x27;7. OFMT : number output format &quot;.6g&quot;# awk &#x27;BEGIN&#123;printf(&quot;%.2f %.2f\\n&quot;, 1/6, 3.1415926)&#125;&#x27;# awk &#x27;BEGIN&#123;OFMT=&quot;%.2f&quot;; print 1/6, 3.1415926)&#125;&#x27;8. FIELDWIDTH : set fields by fixed width# date +&quot;%Y%m%d%H%M%S&quot; | awk &#x27;BEGIN&#123;FIELDWIDTH=&quot;4 2 2 2 2 2&quot;&#125;&#123;print $1&quot;-&quot;$2&quot;-&quot;$3, $4&quot;:&quot;$5&quot;:&quot;$6&#125;&#x27;9. RSTART, RLENGTHRSTART: the index of the first character matched by match(), 0RLENGTH: the length of the string matched by matched by match(), -1# awk &#x27;BEGIN&#123;start=match(&quot;this is match test&quot;, /m[a-z]+/); print start, RSTART, RLENGTH&#125;&#x27;9 9 5 4.2 Built-in Functions:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611. Numericint(x)sqrt(x)rand(): return a random number, [0-1)srand([expr]): use expr as a seed for random generator, if not provided, use system current time# awk &#x27;BEGIN&#123;print int(2.3), int(012), int(0xFF), int(3a), int(a3)&#125;&#x27; 2 10 255 3 0# awk &#x27;BEGIN&#123;print rand(), 10*rand()&#125;&#x27;# awk &#x27;BEGIN&#123;srand(); print rand(), 10*rand()&#125;&#x27;2. Stringsub(regex, replacement[, target]): use the replacement to replace the regex matched in string target(by default $0)gsub(regex, replacement[, target]): global subgensub(regex, replacement, how[, target]): gawkgensub(regex, replacement, &quot;g|G&quot; target) =&gt; gsubgensub(regex, replacement, 0, target) =&gt; gsub, but with warninggensub(regex, replacement, N, target) =&gt; N is a digit from 1 to 9, index of the matched sub-expression# awk &#x27;BEGIN&#123;info=&quot;this is a test2010test!&quot;; gsub(/[0-9]+/,info); print info&#125;&#x27;# gawk &#x27;BEGIN&#123;a=&quot;abc def&quot;; b=gensub(/(.+) (.+)/, &quot;\\\\2 \\\\1&quot;, &quot;g&quot;, a); print b&#125;&#x27; def abc# echo &quot;a b c a b c&quot; | gawk &#x27;&#123;print gensub(/a/,&quot;AA&quot;,2)&#125;&#x27; a b c AA b cindex(string, find): index of the find in the string, or 0 if not presentmatch(string, regex[, array]): position of the regex occurring in the stringlength([string])substr(string, position[, len])split(string, array[, regexp]): split the string into the array on the regex# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print index(s, &quot;a&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print index(s, &quot;a&quot;) ? &quot;ok&quot; : :no found&quot;&#125;&#x27;# awk &#x27;BEGIN&#123;s=&quot;this is a match test&quot;; pos=match(s, /m[a-z]+/, array); print pos; for(i in array) print i, array[i]&#125;&#x27;110start 110length 50 match# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print substr(s, 9, 1)&#125;&#x27;a# awk &#x27;BEGIN&#123;s=&quot;this is a test&quot;; print substr(s, 9)&#125;&#x27;a test# awk &#x27;BEGIN&#123;s=&quot;this is a split test&quot;; len=split(s,array); print len; for(i in array) print i, array[i]&#125;&#x27;54 split5 test1 this2 is3 a# awk &#x27;BEGIN&#123;FS=&quot;:&quot;&#125;/^root/&#123;split($0,array); for(i in array) print i, array[i]&#125;&#x27; /etc/passwd# awk &#x27;/^root/&#123;split($0,array,/:/); for(i in array) print i, array[i]&#125;&#x27; /etc/passwd4 05 root6 /root7 /bin/bash1 root2 x3 0Associative Arraysa. sorting by valueslen = asort(s) # s: changed, the indexes are replaced with sequential integerslen = asort(s, d) # s: unchanged; d: a sorted duplicate array of sb. sorting by indexeslen = asorti(s) # s: changed, restorted by indexeslen = asorti(s, d) # s: unchanged; d: a new array of sorted indexes# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i in a) print i, a[i]&#125;&#x27; abc.txt10 3512 3022 1324 20# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i=1;i&lt;=asort(a,b);i++) print i, b[i]&#125;&#x27; abc.txt1 132 203 304 40# awk &#x27;&#123;a[$1]=$2&#125;END&#123;for(i=1;i&lt;=asorti(a,b);i++) print i, b[i]&#125;&#x27; abc.txt1 102 123 224 24sprintf(format, expr): return the printed expr according to the formattolower(string)toupper(string)# awk &#x27;BEGIN&#123;s=sprintf(&quot;%.2g %s %d&quot;, 3.1415926, 3.1415926, 3.1415926); print s&#125;&#x27;3.1 3.14159 33. Timemktime(&quot;YYYY MM DD HH MM SS[ DST]&quot;): return a time stampsystime(): return current time stmapstrftime([format[, ts])# awk &#x27;BEGIN&#123;print mktime(&quot;2014 12 20 14 25 32&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;print systime()&#125;&#x27;# awk &#x27;BEGIN&#123;print strftime()&#125;&#x27;# awk &#x27;BEGIN&#123;print strftime(&quot;%c&quot;, systime())&#125;&#x27; # date +%c4. IOclose(file[, how]): close file, pipe or co-process; how is either &quot;from&quot; or &quot;to&quot;getline set $0 from next input record, set NF, NR, FNRgetline &lt;file set $0 from next record of file, set NFgetline var set var from next input record, set NR, FNRgetline var &lt;file set vat from next record of filecommand | getline [var] run command piping the output either into $0 or varcommand | &amp; getline [var] run command as a co-process piping the output either into $0 or var. co-processes are a gawk extensionnext: stop processing the current input recordprint [expr-list [&gt;file] ]printf [format, expr-list [&gt;file] ]system(&quot;cmd&quot;) execute the command, and return the exit statusfflush([file]) flush any buffersprint ... | command write on a pipeprint ... |&amp; command write on a co-process# awk &#x27;BEGIN&#123;while(&quot;cat /etc/passwd&quot; | getline) print; close(&quot;/etc/passwd&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;while(getline &lt;&quot;/etc/passwd&quot;) print; close(&quot;/etc/passwd&quot;)&#125;&#x27;# awk &#x27;BEGIN&#123;&quot;date&quot; | getline d; print d&#125;&#x27;# awk &#x27;BEGIN&#123;&quot;date&quot; | getline d; split(d,mon); print mon[2]&#125;&#x27;# awk &#x27;BEGIN&#123;while(&quot;ls&quot; | getline) print&#125;&#x27;# awk &#x27;BEGIN&#123;printf(&quot;Enter your account: &quot;); getline name; print name&#125;&#x27;awk &#x27;BEGIN&#123;l=system(&quot;ls -l&quot;); print l&#125;&#x27;// prompting, wait for input# awk &#x27;BEGIN&#123;printf &quot;What is your name? &quot;; getline name &lt;&quot;/dev/tty&quot;&#125; $1~name &#123;print &quot;Found&quot; name &quot;on line &quot;, NR&quot;.&#125; END&#123;print &quot;See you,&quot; name &quot;.&quot;&#125;&#x27; /etc/passwd// count number of file# awk &#x27;BEGIN&#123;while(getline &lt;&quot;/etc/passwd&quot; &gt;0) lc++; print lc&#125;// sort# awk &#x27;&#123;print $1, $2 | &quot;sort&quot;&#125; END&#123;close(&quot;sort)&#125;&#x27; abc.txt 4.3 FILE SPACING:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# insert a blank lineawk &#x27;1; &#123;print &quot;&quot;&#125;&#x27;awk &#x27;BEGIN&#123;ORS=&quot;\\n\\n&quot;&#125;; 1&#x27;# insert two blank linesawk &#x27;1;&#123;print &quot;\\n&quot;&#125;NUMBERING AND CALCULATIONS:# using a TAB instead of space will perserve marginsawk &#x27;&#123;print FNR &quot;\\t&quot; $0&#125;&#x27;awk &#x27;&#123;print NR &quot;\\t&quot; $0&#125;&#x27;# number each line of a fileawk &#x27;&#123;printf(&quot;%5d : %s\\n, NR, $0)&#125;&#x27;# number each line of a file, but only print numbers if line is not blankawk &#x27;NF&#123;$0=++a &quot;:&quot; $0&#125;;&#123;print&#125;&#x27;awk &#x27;&#123;print (NF ? ++a &quot;:&quot; : &quot;&quot;) $0&#125;&#x27;# wc -lawk &#x27;END&#123;print NR&#125;&#x27;# wc -wawk &#x27;&#123;total=total+NF&#125;END&#123;print total&#125;&#x27;# print the sum of the fields of every lineawk &#x27;&#123;s=0; for(i=1;i&lt;=NF;i++) s=s+$i; print s&#125;&#x27;# add all fields in all lines and print the sumawk &#x27;&#123;for(i=1;i&lt;=NF;i++) s=s+$i&#125;END&#123;print s&#125;&#x27;# print absolute value of fieldsawk &#x27;&#123;for(i=1;i&lt;=NF;i++) if($i&lt;0) $i=-$i; print&#125;&#x27;awk &#x27;(for(i=1;i&lt;=NF;i++) $i = ($i&lt;0) ? -$i : $i; print&#125;&#x27;# print the total number of lines that contains &quot;Beth&quot;awk &#x27;/Beth/&#123;n++&#125;; END&#123;print n+0&#125;&#x27;# print the largest first fieldawk &#x27;$1&gt;max&#123;max=$1; maxline=$0&#125;; END&#123;print max, maxline&#125;&#x27;# print the last fieldawk &#x27;&#123;print $NF&#125;&#x27;# print the last field of the last lineawk &#x27;&#123;field=$NF&#125;; END&#123;print feild&#125;&#x27;TEXT CONVERSION AND SUBSTITUTION:# dos2unixawk &#x27;&#123;sub(/\\r$/,&quot;&quot;); print&#125;&#x27;# unix2dosawk &#x27;&#123;sub(/$/,&quot;\\r&quot;); print&#125;&#x27;# delete leading whitespaceawk &#x27;&#123;sub(/^[ \\t]+/,&quot;&quot;); print&#125;&#x27;# delete trailing whitespaceawk &#x27;&#123;sub(/[ \\t]+$/,&quot;&quot;); print&#125;&#x27;# delete both leading and trailing whitespaceawk &#x27;&#123;sub(/^[ \\t]+|[ \\t]+$/); print&#125;&#x27;# insert 5 whitespace at the beginning of lineawk &#x27;&#123;sub/^/, &quot; &quot;); print&#125;&#x27;# align all text flush right in a 70-column widthawk &#x27;&#123;printf &quot;%79s\\n&quot;, $0&#125;&#x27;# center all text on a 79-character widthawk &#x27;&#123;l=length(); s=int((79-l)/2); printf &quot;%&quot;(s+l&#125;&quot;s\\n&quot;,$0&#125;&#x27;# substituteawk &#x27;&#123;sub(/foo/,&quot;bar&quot;); print&#125;&#x27; # 1stawk &#x27;&#123;$0=gensub(/foo/,&quot;bar&quot;,4); print&#125;&#x27; # 4stawk &#x27;&#123;gsub(/foo/,&quot;bar&quot;); print&#125;&#x27; # all#awk &#x27;&#123;gsub(/scarlet|ruby|puce/, &quot;red&quot;); print&#125;# tacawk &#x27;&#123;a[i++]=$0&#125;END&#123;for(j=i-1;i&gt;=0;j--) print a[j]&#125;# append the next line, if line ends with a backslash.(fails to handle mutiple lines ending with backslash)awk &#x27;/\\\\$/&#123;sub(/\\\\$/,&quot;&quot;); getline t; print $0 t; next&#125;; 1&#x27;# sortawk -F&quot;:&quot; &#x27;&#123;print $1 | &quot;sort&quot;&#125;&#x27; /etc/passwd# delete the 2nd fieldawk &#x27;&#123;$2=&quot;&quot;; print&#125;&#x27;# print in reverse order the fieldsawk &#x27;&#123;for(i=NF;i&gt;0;i--) printf(&quot;%s &quot;,i); print &quot;&quot;&#125;&#x27;# remove duplicate, consecutive lines, uniqawk &#x27;a!~$0; &#123;a=$0&#125;&#x27;# remove duplicate, nonconsecutive linesawk &#x27;!a[$0]++&#x27;awk &#x27;!($0 in a)&#123;a[$0]; print&#125;&#x27; # most efficient# concatenate every 5 lines of input, using a comma separatorawk &#x27;ORS=%NR%5 ? &quot;,&quot; : &quot;\\n&quot;&#x27; 4.4 SLECTIVE PRINTING OF CERTAIN LINES:12345678910111213141516171819202122232425262728293031323334353637383940# headawk &#x27;NR&lt;11&#x27;# head -1awk &#x27;NR&gt;1&#123;exit&#125;;1&#x27;# tail -2awk &#x27;&#123;y=x &quot;\\n&quot; $0; x=$0&#125; END&#123;print y&#125;&#x27;# tail -1awk &#x27;END&#123;print&#125;&#x27;# grepawk &#x27;/regex/&#x27;# print the line immediately before a regexawk &#x27;/regex/&#123;print x&#125;;&#123;x=$0&#125;&#x27; # grep &#x27;regex&#x27; -B1# print the line immediately after a regexawk &#x27;/regex/&#123;getline; print&#125;&#x27; # grep &#x27;regex&#x27; -A1# grep -E &quot;AAA|BBB|CCC&quot;awk &#x27;/AAA/;/BBB/;/CCC/&#x27;# print only lines of 65 characters or longerawk &#x27;length&gt;64&#x27;# print section of file from regular expression to end of fileawk &#x27;/regex/,0&#x27;awk &#x27;/regex/,EOF&#x27;# print section of file based on line numbers(lines 8-12)awk&#x27;NR==8,NR==12&#x27;# print line 8 &amp; 12awk &#x27;NR==8;NR==12&#x27;# print line number 52awk &#x27;NR==52&#x27;awk &#x27;NR==52&#123;print; exit&#125;&#x27; # more efficient 4.5 SELECTIVE DELETION OF CERTAIN LINES:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# delete all blank linesawk NFawk &#x27;/./&#x27;# print x by 512 timesawk &#x27;BEGIN&#123;while(++a&lt;512) s=s &quot;x&quot;; print s&#125;&#x27;# merge fileawk &#x27;NR==FNR&#123;a[$0]=1; print&#125; NR&gt;FNR&#123;if(!a[$0]) print&#125;&#x27;awk &#x27;&#123;a[$0]&#125;END&#123;for(i in a) print i&#125;&#x27;# sortawk &#x27;&#123;a[j++]=$0&#125; END&#123;len=asort(a); for(i=1;i&lt;=len;i++) print a[i]&#125;&#x27;44. convert DEC to OTCecho 37 | awk &#x27;&#123;printf &quot;%o\\n&quot;, $0&#125;&#x27;45. print single quotaawk &#x27;BEGIN&#123;print &quot;\\0472004-12-12\\047&quot;&#125;&#x27;# obtain total memorycat /proc/meminfo | grep -i memtotal | awk -F&#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27;cat /proc/meminfo | grep -i memtotal | awk -F\\: &#x27;&#123;print $2&#125;&#x27;# display all NICs exclude localifconfig -a | grep &#x27;^\\w&#x27; | awk &#x27;!/lo/&#123;print $1&#125;&#x27;# obtain IP address of NIC eth0ifconfig eth0 | grep &#x27;inet &#x27;ifconfig eth0 | grep &#x27;inet &#x27; | awk -F&#x27;:&#x27; &#x27;&#123;print $2&#125;&#x27; | awk &#x27;&#123;print $1&#125;&#x27;ifconfig eth0 | grep &#x27;inet &#x27; | tr &#x27;:&#x27; &#x27; &#x27; | awk &#x27;&#123;print $3&#125;&#x27;ifconfig eth0 | awk -F&#x27;:&#x27; &#x27;/inet / &#123;print $2&#125;&#x27; | awk &#x27;&#123;print $1&#125;&#x27;# $1 is a space, cause it begins with spacesifconfig eth0 | grep &#x27;inet &#x27; | awk -F&#x27;[ :]+&#x27; &#x27;&#123;print $4&#125;&#x27; # kill all process named fookill `ps -ax | grep &#x27;foo&#x27; | grep -v &#x27;grep&#x27; | awk &#x27;&#123;print $1&#125;&#x27;`# print the result that executed command &quot;date&quot;awk &#x27;BEGIN&#123;&quot;date&quot; | getline d;print d&#125;&#x27;# print monthawk &#x27;BEGIN&#123;&quot;date&quot; | getline d; split(d, mon); print mon[2]&#125;&#x27;# print the result that executed comand &quot;ls&quot;awk &#x27;BEGIN&#123;while(&quot;ls&quot; | getline) print&#125;&#x27;# prompting, wait for inputawk &#x27;BEGIN&#123;printf &quot;What is your name? &quot;; getline name &lt;&quot;/dev/tty&quot; &#125; $1~name &#123;print &quot;Found &quot; name &quot; on line &quot;, NR&quot;.&quot;&#125; END&#123;print &quot;See you,&quot; name &quot;.&quot;&#125;&#x27; /etc/passwd# count number of linux usersawk &#x27;BEGIN&#123;while(getline&lt;&quot;/etc/passwd&quot; &gt;0) lc++; print lc&#125;&#x27; # must be contain quotationsawk &#x27;&#123;print $1, $2 | &quot;sort&quot; &#125;END&#123;close(&quot;sort&quot;)&#125;&#x27; myfileawk &#x27;BEGIN&#123;system(&quot;clear&quot;)&#125;&#x27;awk &#x27;&#123;gsub(/test/, &quot;xxxx&quot;, $2); print&#125;&#x27; myfileawk &#x27;BEGIN&#123;print index(&quot;mytest&quot;, &quot;test&quot;)&#125;&#x27; # 3# 多维数组，array[index1,index2,……] ，SUBSEP是数组下标分割符，默认为 &quot;\\034&quot;awk &#x27;BEGIN&#123;SUBSEP=&quot;:&quot;; array[&quot;a&quot;,&quot;b&quot;]=1; for(i in array) print i&#125;&#x27;awk &#x27;BEGIN&#123;array[&quot;a&quot;&quot;:&quot;&quot;b&quot;]=1;for(i in array) print i&#125;&#x27;# cat file1g1.1 2g2.2 4g2.1 5g4.1 3# cat file2g1.1 2g1.2 3g4.1 4# cat file3g1.2 3g5.1 3# awk &#x27;&#123;a[ARGIND&quot; &quot;$1]=$2; b[$1]&#125; END &#123; for(i in b) &#123; printf i&quot; &quot;; for(j=1;j&lt;=ARGIND;j++) printf &quot;%s &quot;, a[j&quot; &quot;i] ? a[j&quot; &quot;i] : &quot;-&quot;; print &quot;&quot;; &#125; &#125;&#x27; file1 file2 file3g2.2 4 - -g5.1 - - 3g1.1 2 2 -g1.2 - 3 3g4.1 3 4 -g2.1 5 - - echo &quot;37&quot; |awk &#x27;&#123;printf &quot;%o\\n&quot;,$0&#125;&#x27;/home/lee#awk &#x27;BEGIN&#123;print &quot;\\0472004-12-12\\047&quot;&#125;&#x27;&#x27;2004-12-12&#x27; 5. chatrr123chattr +i /etc/passwdchatrr +a /etc/passwdlsattr /etc/passwd 6. grep1234567891011121314151617181920212223242526# 网卡信息dmesg | grep -n --color=auto eth# 显示关键字前3行和后2行dmesg | grep -n -A2 -B3 --color=always eth0# 扩展表达式egrep &#x27;^$|^#&#x27;myfile# 前面的字符出现1次以上egrep -n --color=auto &#x27;go+d&#x27; myfile# 前面的字符出现0~1次egrep -n --color=auto &#x27;go?d&#x27; myfile# or方式匹配egrep -n --color=auto &#x27;gd|good|dog&#x27; myfile# 组匹配egrep -n --color=auto &#x27;g(la|oo)d&#x27; myfile# 多重复组匹配echo &#x27;AxyzxyzxyzxyzC&#x27; | egrep &#x27;A(xyz)+C&#x27;man grep | col -c &gt; grep.txt 7. sort123456789101112131415161718192021222324252627282930313233343536373839404142434445# output sorted resultsort -o result.out video.txt # split the fields by &#x27;:&#x27;sort -t: -r video.txt # test whether it has been sortedsort -c video.txt # sort by 2nd fieldsort -t: +1 video.txt # sort 3rd field using ascii ordersort -t: +2 video.txt sort -t: -k3 video.txt# sort 3rd field using number order sort -t: +2n video.txtsort -t: -k3n video.txt # uniqsort -u video.txt# sort 4th field, then sort 1st fieldsort -t: -k4 -k1 video.txt# sort +field_number.characters_in# sort 2nd filed, begining with 3rd charactersort -t: +1.2 video.txt# list all unix userscat /etc/passwd | sort -t: +0 | awk -F&quot;:&quot; &#x27;&#123;print $1&#125;&#x27;# only not duplicate. here, sort is recommendablesort video.txt | uniq -u # only duplicatesort video.txt | uniq -d# count dulicate timessort video.txt | uniq -c# sorting ignore case sensitivesort -f 8. join12345678910111213141516171819202122232425262728293031323334353637# join, the files must have a common content; the fields must be splited by single tab or spacejoin [options] input-file1 input-file2-an n, the number of file. -a1, means joining files based on file 1-o n.m n, the number of file; m, the number of field. -o 1.3, means display field 3 of file 1-jn m n, the number of file; m, the number of field.-t delimiter# join crossjoin names.txt town.txt# mismatch connections, join alljoin -a1 -a2 names.txt town.txt# base on file1, join alljoin -a1 names.txt town.txt# selective joinjoin -o 1.1,2.2 names.txt town.txt# different field join# extract 3rd field of file 1, 2nd field of file 2, then join them togetherjoin -j1 3 -j2 2 file1 file2cat persP.Jones Office Runner ID897S.Round UNIX admin ID666L.Clip Personl Chief ID982cat pers2Dept2C ID897 6 yearsDept3S ID666 2 yearsDept5Z ID982 1 yearjoin -j1 4 -j2 2 pers pers2ID897 P.Jones Office Runner Dept2C 6 yearsID666 S.Round UNIX admin Dept3S 2 yearsID982 L.Clip Personl Chief Dept5Z 1 year 9. cut12345678910111213141516cut [options] file1 file2-c LIST, select only these characters-f LIST, select only these fields-d, delimitercut -d: -f4 perscut -d: -f1,3 perscut -d: -f1-3 perscut -d: -f1,6 /etc/passwd# file permisionls -l | cut -c1-10echo $PATH | tr &quot;:&quot; &quot;\\n&quot; | nlecho $PATH | cut -d&quot;:&quot; -f3,5 10. paste1234567891011paste -d -s - file1 file2-d, delimiter-s, paste one file at a time instead of in parallelpaste -d: pas1 pas2# list file name, 3 files each rowls | paste -d&quot; &quot; - - -# list file name, ls -l|awk &#x27;NF&gt;3&#123;print $8&#125;&#x27;ls | paste -d&quot;&quot; - 11. split123split -output_file_size input-filename output-filename-output_file_size, default 1000 linesoutput-filename, default x[aa]-&gt;x[zz] 12. dos2unix, ^M=ctrl+v ctrl ^ enter12345678910111213dos2uninx dosfilesed -e &#x27;s/^M//&#x27; dosfiletr -s &quot;\\r\\n&quot; &quot;\\n&quot; &lt; dosfiletr -d &quot;\\015&quot; &lt; dosfilecol -bx &lt; dosfile# delete ^M in vim:set ff=unix:%s/\\r//g:%s/^M//gc 13. lsof, list open file1234567891011121314151617181920212223242526272829lsof filename 显示打开指定文件的所有进程 lsof -a 表示两个参数都必须满足时才显示结果 lsof -c string 显示COMMAND列中包含指定字符的进程所有打开的文件 lsof -u username 显示所属user进程打开的文件 lsof -g gid 显示归属gid的进程情况 lsof +d /DIR/ 显示目录下被进程打开的文件 lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长 lsof -d FD 显示指定文件描述符的进程 lsof -n 不将IP转换为hostname，缺省是不加上-n参数 lsof -i 用以显示符合条件的进程情况 lsof -i[46] [protocol][@hostname|hostaddr][:service|port] lsof -i tcp:22lsof -i :22lsof -i @10.40.53.22lsof /etc/passwdlsof /etc/cdromlsof `which httpd`lsof -c bashlsof -u apachelsof +D /tmplsof -i # port 80 14. echo12345678910echo -n 取消行末换行echo -E 关闭反斜线控制字符转换echo -e 启用反斜线控制字符转换\\c 取消行末换行符\\n newline =&gt; \\012\\r return\\t TAB =&gt; \\011\\num ASCII八进制编码\\xnum ASCII十六进制编码 15. 删除空格123456sed &quot;/^\\s*$/d&quot;sed &#x27;/^$/d&#x27;sed -i &#x27;/^$/d&#x27;awk &#x27;NF&gt;0&#x27;perl -i.backup -n -e &quot;print if /\\S/&quot;grep -v &#x27;^$&#x27;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Linux知识点","slug":"Linux知识点","date":"2019-12-18T08:25:32.000Z","updated":"2021-06-22T10:50:49.746Z","comments":true,"path":"2019/12/18/Linux知识点/","link":"","permalink":"https://elihe2011.github.io/2019/12/18/Linux%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"1. buffer和cachebuffer强调写，cache强调读，读写都带的时候，几乎无差别。buffer另外也有排队等待被处理的意思，cache基本没有。 2. bash配置文件2.1 全局配置123/etc/profile/etc/profile.d/*.sh /etc/bashrc ###2.2 用户配置 12~/.bash_profile, ~/.bash_login, ~/.profile(同时存在时，依次读取)~/.bashrc 2.3 profile和bashrc1) profile文件： 设定环境变量 运行命令和脚本 2) bashrc文件： 设定本地变量 定义别名 2.4 登录shell和非登录shell1) Login Shell: 通过终端登录 123su - USERNAMEsu -l USERNAME/etc/profile --&gt; /etc/profile.d/*.sh --&gt; ~/.bash_profile --&gt; ~/.bashrc --&gt; /etc/bashrc 2) Non-Login Shell: 1234su USERNAMEGUI终端下打开Console自动执行的shell脚本~/.bashrc --&gt; /etc/bashrc --&gt; /etc/profile.d/*.sh 3. 随机数12345678910# datedate | md5sumdate +%s | sha256sum | base64 | head -c 32; echo# opensslopenssl rand -base64 32# /dev/urandomcat /dev/urandom | tr -dc &#x27;a-zA-Z0-9&#x27; | fold -w 32 | head -1strings /dev/urandom | grep -o &#x27;[a-zA-Z0-9]&#x27; | head -32 | tr -d &#x27;\\n&#x27;; echo 4. 脚本中修改用户密码4.1 使用代码组123456&#123; echo &#x27;pass&#x27; sleep 1 echo &#x27;pass&#x27; sleep 1&#125; | passwd abc 4.2 --stdin1echo &#x27;pass&#x27; | passwd --stdin abc 4.3 查看是否已设置密码12# 已设置密码，PS或Ppasswd -S abc | awk &#x27;&#123;print $2&#125;&#x27; 5. 使用stdin来屏蔽敏感信息12345678910111213$ cat shield_sensitive_info.sh #!/bin/shname=$1read passecho &quot;username=$name&quot;echo &quot;password=$pass&quot;$ echo 123 | ./shield_sensitive_info.sh abc$ ./shield_sensitive_info.sh abc &lt;&lt;EOF123EOF 6. 释放内存查看系统内存使用情况 12free -mcat /proc/meminfo 释放内存 12345678# to free pagecacheecho 1 &gt; /proc/sys/vm/drop_caches# to free dentries and inodesecho 2 &gt; /proc/sys/vm/drop_caches# to free pagecache, dentries and inodes, use echo 3 &gt;/proc/sys/vm/drop_caches 7. 磁盘管理7.1 创建分区（fdisk, sfdisk, part）1) 分区操作 123456fdisk /dev/sdbn add a new partitionp print the partition tablew write table to disk and exitl list known partition typest 82: swap, 83: linux, 8e: lvm, fd: raid 2) 查看分区信息 1fdisk -l /dev/sdb 3) 查看内核识别的分区 123cat /proc/partionspartprobe [/dev/sda] partx -a /dev/sda # RHEL6 4) 大磁盘分区，2TB以上 1234parted /dev/sdbparted /dev/sdc printparted /dev/sdc mkpart logical ext3 19.2GB 19.7GBparted /dev/sdc rm 8 7.2 创建文件系统默认支持的文件系统：mkfs.xx VFS: Virtual Filesystem ext[2-4], xfs iso9660 nfs, cifs jfs, resiserfs, vfat gfs, sfs2, ocfs 1) mkfs 123mkfs -t ext3 /dev/sdb1mkfs.ext3 /dev/sdb2mkfs.ext3 -b 1024 /dev/sdb3 # 设置block大小 1024, 2048, 4096 2) mke2fs (/etc/mke2fs.conf) 1234567-b [1024|2048|4096]-i bytes-per-inode # 多少个字节预留一个inode，默认8192 (每8K一个inode)-N numbers-of-inode-L label-j # ext3-m ratio # 预留给超级用户的磁盘百分比，默认%5-r blocks # 预留的blocks数量 123456mke2fs -j -L &quot;ora_logical&quot; -b 2048 -i 8192 /dev/sdb1mke2fs -j /dev/sdb1 mke2fs -t ext4 -m 2 /dev/sdb1 # 预留2%磁盘块tune2fs -l /dev/sdb1 | grep &quot;Reserved&quot; 3) tune2fs 调整文件系统属性 123456-j # ext2-&gt;ext3-L label -m N # 调整预留百分比-c N # 指定挂载次数达到N次，进行自检，0或-1关闭自检-i N # 每挂载使用多少天自检，默认180，0或-1关闭自检-l # 显示超级块中的信息， dumpe2fs 12tune2fs -j /dev/sda5 # ext3tune2fs -l /dev/sda5 | grep &#x27;Block size&#x27; 4) e2label 查看或定义卷标 12e2label /dev/sda5e2label /dev/sda5 mydisk 5) blkid 查看设备的相关属性属性(UUID, FSTYPE, LABEL) 1blkid /dev/sda5 6) dumpe2fs 分区系统，BLOCK-GROUPs 1dumpe2fs -h /dev/sdb1 # super-block信息 7.3 检查文件系统1) fsck 123-t FSTYPE -a # 自动修复，不询问-f # 强制价差 12fsck -C -f -t ext3 /dev/sdb1fsck -f /dev/sdb1 2) e2fsck 专用修复ext2,ext3 12-f # 强制价差-p # 自动修复，不询问 12345# 检测修复文件系统(单用户模式执行)fsck -y /dev/sda1e2fsck -p /dev/sdb1mke2fs -c /dev/sdb1 7.4 挂载1) mount [options] DEVICE MOUNT_POINT DEVICE: DEV LABEL=”mysql-data” UUID=”uuid” options: 12345678910111213-t fstype-a 挂载/etc/fstab中全部auto的分区-r readonly-n, --no-mtab 不更新/etc/mtab-odefaults rw,suid,dev,exec,auto,nousers,async,realtimero readonlynoatime 访问不更新atimenoauto mount -a不挂载sync 同步写入nodev 不读文件系统上的字符或块设备remount 重新挂载loop 本地回环设备 1234mount -o remount,ro /dev/sdb1mount -o ro /dev/cdrom /mediamount -o loop,ro /root/RHEL6.iso /media 2) umount [DEVICE|MOUNT_POINT] 1234umount /mntumount: /mnt: device is busy.fuser -km /mnt","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"C10K问题","slug":"C10问题","date":"2019-12-16T08:35:23.000Z","updated":"2021-06-22T10:50:49.745Z","comments":true,"path":"2019/12/16/C10问题/","link":"","permalink":"https://elihe2011.github.io/2019/12/16/C10%E9%97%AE%E9%A2%98/","excerpt":"","text":"1. C10K问题由来随着互联网的普及，应用的用户群体几何倍增长，此时服务器性能问题就出现。最初的服务器是基于进程/线程模型。新到来一个TCP连接，就需要分配一个进程。假如有C10K，就需要创建1W个进程，可想而知单机是无法承受的。那么如何突破单机性能是高性能网络编程必须要面对的问题，进而这些局限和问题就统称为C10K问题，最早是由Dan Kegel进行归纳和总结的，并且他也系统的分析和提出解决方案。 2. C10K问题的本质C10K问题的本质上是操作系统的问题。对于Web 1.0/2.0时代的操作系统，传统的同步阻塞I/O模型处理方式都是requests per second。当创建的进程或线程多了，数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞，进程/线程上下文切换消耗大， 导致操作系统崩溃，这就是C10K问题的本质。 可见, 解决C10K问题的关键就是尽可能减少这些CPU资源消耗。 3. C10K问题的解决方案从网络编程技术的角度来说，主要思路： 每个连接分配一个独立的线程/进程 同一个线程/进程同时处理多个连接 3.1 每个进程/线程处理一个连接该思路最为直接，但是申请进程/线程是需要系统资源的，且系统需要管理这些进程/线程，所以会使资源占用过多，可扩展性差 3.2 每个进程/线程同时处理 多个连接(I/O多路复用) select方式：使用fd_set结构体告诉内核同时监控那些文件句柄，使用逐个排查方式去检查是否有文件句柄就绪或者超时。该方式有以下缺点：文件句柄数量是有上线的，逐个检查吞吐量低，每次调用都要重复初始化fd_set。 poll方式：该方式主要解决了select方式的2个缺点，文件句柄上限问题(链表方式存储)以及重复初始化问题(不同字段标注关注事件和发生事件)，但是逐个去检查文件句柄是否就绪的问题仍然没有解决。 epoll方式：该方式可以说是C10K问题的killer，他不去轮询监听所有文件句柄是否已经就绪。epoll只对发生变化的文件句柄感兴趣。其工作机制是，使用”事件”的就绪通知方式，通过epoll_ctl注册文件描述符fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd, epoll_wait便可以收到通知, 并通知应用程序。而且epoll使用一个文件描述符管理多个描述符,将用户进程的文件描述符的事件存放到内核的一个事件表中, 这样数据只需要从内核缓存空间拷贝一次到用户进程地址空间。而且epoll是通过内核与用户空间共享内存方式来实现事件就绪消息传递的，其效率非常高。但是epoll是依赖系统的(Linux)。 异步I/O以及Windows，该方式在windows上支持很好。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"MongoDB","slug":"MongoDB","date":"2019-11-07T08:20:21.000Z","updated":"2021-06-22T10:50:49.745Z","comments":true,"path":"2019/11/07/MongoDB/","link":"","permalink":"https://elihe2011.github.io/2019/11/07/MongoDB/","excerpt":"1. 基本概念 面向集合(Collection-Oriented):数据存储在集合中，每个集合在数据库中都有唯一的标识名，可以包含无限数量的文档 模式自由(Schema-Free):集合类似RMDB中的Table，但无Schema 文档型(Document File):存储数据是键值对的集合”JSON”，键是字符串，值可以是任意类型。存储数据类型称为BSON(Binary Serialized Document Notation) 1.1 数据逻辑结构 文档(document): RMDB中的行 集合(collection): RMDB中的表，由多个文档构成 数据库(database): 与RMDB一致","text":"1. 基本概念 面向集合(Collection-Oriented):数据存储在集合中，每个集合在数据库中都有唯一的标识名，可以包含无限数量的文档 模式自由(Schema-Free):集合类似RMDB中的Table，但无Schema 文档型(Document File):存储数据是键值对的集合”JSON”，键是字符串，值可以是任意类型。存储数据类型称为BSON(Binary Serialized Document Notation) 1.1 数据逻辑结构 文档(document): RMDB中的行 集合(collection): RMDB中的表，由多个文档构成 数据库(database): 与RMDB一致 2. 相关命令2.1 查看帮助123helpdb.help()db.account.help() 2.2 数据库管理1234567891011121314151617181920show dbsuse mydbdb.copyDatabase(&#x27;mydb&#x27;, &#x27;temp&#x27;, &#x27;127.0.0.1&#x27;)db.cloneDatabase(&#x27;10.137.5.44&#x27;)use tempdb.dropDatabase() # 删当前数据库db.repairDatabase()db.getName() # 当前数据库名db.getMongo() # 服务器地址db.stats()db.version()use admindb.shutdownServer() 2.3 集合操作12345678910db.createCollection(&#x27;account&#x27;, &#123;size:20, capped:5, max:100&#125;)db.getCollection(&#x27;account&#x27;)db.getCollectionNames()db.account.help()db.account.count()db.account.dataSize()db.account.totalSize()db.account.getDB()db.account.renameCollection(&#x27;accounts&#x27;) 2.4 用户管理123456789show rolesdb.createUser(&#123;user: &#x27;eli&#x27;,pwd: &#x27;123&#x27;,roles: [&#123;role: &#x27;userAdmin&#x27;, db: &#x27;mydb&#x27;&#125;]&#125;)db.auth(&#x27;eli&#x27;, &#x27;123&#x27;) 2.5 增删改查12345db.account.save(&#123;name: &#x27;mongo&#x27;&#125;)db.account.insert(&#123;x:1&#125;)db.account.find(&#123;name: &#x27;mongo&#x27;&#125;)db.account.update(&#123;name: &#x27;mongo&#x27;&#125;, &#123;$set, &#123;name: &#x27;new_mongo&#x27;&#125;&#125;)db.account.remove(&#123;name: &#x27;new_mongo&#x27;&#125;) update语法： 123456db.collection.update( &lt;query&gt;, &lt;update&gt;, upsert:&lt;boolean&gt;, multi:&lt;boolean&gt; // 默认只修改一条数据) 更新操作： ———｜————–｜名称 ｜描述｜———｜————–｜$inc ｜根据要添加的值递增该字段的值。｜$mul ｜将该字段的值乘以指定的值｜$rename ｜重命名字段｜$setOnInsert ｜操作时,操作给相应的字段赋值｜$set ｜用来指定一个键的值，如果不存在则创建它｜$unset ｜用来指定一个键的值，如果不存在不创建创建它｜$min ｜只有当指定的值小于现有字段值时才更新该字段。｜$max ｜只有当指定的值大于现有字段值时才更新该字段。｜$currentDate ｜设置当前日期字段的值，或者作为一个日期或时间戳。｜ 3. 查询操作12345db.test.insert(&#123;name:&#x27;jack&#x27;, age:29, gender:&#x27;male&#x27;, email:&#x27;jack@outlook.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;lucy&#x27;, age:21, gender:&#x27;female&#x27;, email:&#x27;lucy@gmail.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;tom&#x27;, age:30, gender:&#x27;male&#x27;, email:&#x27;tom@abc.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;bonnie&#x27;, age:29, gender:&#x27;female&#x27;, email:&#x27;bonnie@abc.com&#x27;&#125;)db.test.insert(&#123;name:&#x27;jack&#x27;, age:25, gender:&#x27;male&#x27;, email:&#x27;jack@hotmail.com&#x27;&#125;) 3.1 基本查询1234567db.test.find() # alldb.test.findOne(). # just onedb.test.find(&#123;name:&#x27;jack&#x27;&#125;)db.test.find(&#123;name:&#x27;jack&#x27;, age:29&#125;)db.test.find(&#123;&#125;, &#123;name:1, gender:1&#125;) # 只返回name, gender字段db.test.find(&#123;&#125;, &#123;email:0&#125;) # 不返回email字段 3.2 条件查询($gt, $lt, $gte, $lte, $ne, $or, $in, $nin)123456789db.test.find(&#123;age: &#123;$gt: 25, $lt: 30&#125;&#125;)db.test.find(&#123;gender: &#123;$ne: &#x27;male&#x27;&#125;&#125;)db.test.find(&#123;age: &#123;$in: [21, 30]&#125;&#125;)db.test.find(&#123;age: &#123;$nin: [21, 30]&#125;&#125;)db.test.find(&#123;name: &#123;$not: &#123;$in: [&#x27;jack&#x27;, &#x27;lily&#x27;]&#125;&#125;&#125;)db.test.find(&#123;age: &#123;$mod: [10,1]&#125;&#125;)db.test.find(&#123;name: &#123;$exists: true&#125;&#125;)db.test.find(&#123;$or: [&#123;name:&#x27;jack&#x27;&#125;, &#123;name:&#x27;tom&#x27;&#125;]) 3.3 null类型查询12345db.test.update(&#123;name:&#x27;jack&#x27;&#125;, &#123;$set: &#123;addr: null&#125;&#125;)db.test.update(&#123;name:&#x27;tom&#x27;&#125;, &#123;$set: &#123;addr: &#123;city:&#x27;NJ&#x27;, prov:&#x27;JS&#x27;&#125;&#125;&#125;)db.test.find(&#123;addr: null&#125;)db.test.find(&#123;addr: &#123;$in: [null], $exists: true&#125;&#125;) 3.4 正则表达式12db.test.find(&#123;name:/Jack?/i&#125;)db.test.find(&#123;name: &#123;$not: /^b.*/&#125;&#125;) # not like &#x27;b%&#x27; 3.5 js和$where查询123456db.test.find(&#123;age: &#123;$lt: 30&#125;&#125;)db.test.find(&#123;$where: &quot;this.age &gt; 30&quot;&#125;)db.test.find(&quot;this.age &gt; 30&quot;)f = function() &#123;return this.age&gt;30;&#125;db.test.find(f) 3.6 count, limit, skip, sort1234db.test.find().count()db.test.find().limit(5)db.test.find().skip(3).limit(5)db.test.find().sort(&#123;age:-1&#125;) 3.7 数组1234567891011121314151617181920212223db.fruits.insert(&#123;fruit: [&#x27;apple&#x27;, &#x27;orange&#x27;, &#x27;peach&#x27;]&#125;)db.fruits.insert(&#123;fruit: [&#x27;apple&#x27;, &#x27;kuaquat&#x27;, &#x27;blueberry&#x27;]&#125;)db.fruits.insert(&#123;fruit: [&#x27;pear&#x27;, &#x27;strawberry&#x27;, &#x27;banana&#x27;]&#125;)db.fruits.find(&#123;fruit: &#x27;apple&#x27;&#125;)db.fruits.find(&#123;fruit: &#123;$in: [&#x27;apple&#x27;]&#125;&#125;) # same as abovedb.fruits.find(&#123;fruit: &#123;$all: [&#x27;apple&#x27;, &#x27;orange&#x27;]&#125;&#125;)db.fruits.find(&#123;fruit: [&#x27;apple&#x27;, &#x27;orange&#x27;, &#x27;peach&#x27;]&#125;)db.fruits.find(&#123;&#x27;fruit.2&#x27;: &#x27;peach&#x27;&#125;)db.fruits.find(&#123;fruit: &#123;$size: 3&#125;&#125;)db.fruits.update(&#123;&#125;, &#123;$set: &#123;size:3&#125;&#125;, false, true)db.fruits.find()db.fruits.update(&#123;&#125;, &#123;$push: &#123;fruit:&#x27;grape&#x27;&#125;, $inc: &#123;size:1&#125;&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:2&#125;, size: 0&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:-2&#125;, size: 0&#125;)db.fruits.find(&#123;&#125;, &#123;fruit: &#123;$slice:[2,1]&#125;, size: 0&#125;) 3.8 查询组合条件3.8.1 $in满足列表中任意一个值 1db.funds.find(&#123;&#x27;Fee&#x27;: &#123;&#x27;$in&#x27;: [15, 21]&#125;&#125;) 3.8.2 $all满足列表中全部值 1db.funds.find(&#123;&#x27;Fee&#x27;: &#123;&#x27;$all&#x27;: [15, 21]&#125;&#125;) 3.8.3 $or1db.funds.find(&#123;&#x27;$or&#x27;: [&#123;&#x27;Fee&#x27;: 15&#125;, &#123;&#x27;Fee&#x27;: 21&#125;]&#125;) 3.8.4 $and1db.funds.find(&#123;&#x27;$and&#x27;: [&#123;&#x27;Fee&#x27;: 15&#125;, &#123;&#x27;Fee&#x27;: 21&#125;]&#125;) 3.8.5 $exist节点存在，不关心值是否为null 1db.test.find(&#123;&quot;Fee&quot;: &#123;&#x27;$exists&#x27;: true&#125;&#125;) 节点不存在或者节点存在但值为null 1db.test.find(&#123;&quot;Fee&quot;: null&#125;) 3.8.6 $ne1db.test.find(&#123;&quot;Fee&quot;: &#123;&#x27;$ne&#x27;: 21&#125;&#125;) 1&#123;&#x27;$and&#x27;: [&quot;BasicInfo.offshoreFund&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;, &quot;BasicInfo.cayman&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;, &quot;BasicInfo.America&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;]&#125;, &quot;BasicInfo.BVI&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125;]&#125; 123456db.funds.find(&#123; &#x27;$and&#x27;: [ &quot;BasicInfo.America&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;]&#125;, &quot;BasicInfo.BVI&quot;: &#123;&#x27;$in&#x27;: [&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;]&#125; ] &#125;).count() 3.9 聚合查询12345678910&#123; &quot;_id&quot; : 1, &quot;domainName&quot; : &quot;test1.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 2, &quot;domainName&quot; : &quot;test2.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot;&#125;&#123; &quot;_id&quot; : 3, &quot;domainName&quot; : &quot;test3.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 4, &quot;domainName&quot; : &quot;test4.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 5, &quot;domainName&quot; : &quot;test5.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 6, &quot;domainName&quot; : &quot;test6.com&quot;, &quot;hosting&quot; : &quot;cloud.google.com&quot; &#125;&#123; &quot;_id&quot; : 7, &quot;domainName&quot; : &quot;test7.com&quot;, &quot;hosting&quot; : &quot;aws.amazon.com&quot; &#125;&#123; &quot;_id&quot; : 8, &quot;domainName&quot; : &quot;test8.com&quot;, &quot;hosting&quot; : &quot;hostgator.com&quot; &#125;&#123; &quot;_id&quot; : 9, &quot;domainName&quot; : &quot;test9.com&quot;, &quot;hosting&quot; : &quot;cloud.google.com&quot; &#125;&#123; &quot;_id&quot; : 10, &quot;domainName&quot; : &quot;test10.com&quot;, &quot;hosting&quot; : &quot;godaddy.com&quot; &#125; 导入数据： 1mongoimport -d testdb -c website --file website.json --upsert 3.9.1 group &amp; sort1234567891011121314151617// group bydb.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;]);// sortdb.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]);// matchdb.website.aggregate([ &#123; $match: &#123; hosting: &quot;aws.amazon.com&quot; &#125; &#125;, &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]); 3.9.2 export result12345678var group_data = db.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;]); print(group_data.toArray()) db.websitegroup.insert(group_data.toArray()) 123mongoexport -d testdb -c websitegroup -o websitegroup.jsonmongoexport -d testdb -c websitegroup -f _id,total -o websitegroup.csv --type=csv 3.9.3 Large sort operation: (sort in memory 100M)123456db.website.aggregate([ &#123; $group: &#123; _id: &quot;$hosting&quot;, total: &#123; $sum: 1 &#125; &#125; &#125;, &#123; $sort: &#123; total: -1 &#125; &#125;], &#123; allowDiskUse: true &#125;); 3.10 查询Embeded数据12345678910111213141516171819202122&#123; &quot;_id&quot;: &quot;alpha&quot;, &quot;name&quot;: &quot;Storage Alpha&quot;, &quot;items&quot;: [ &#123; &quot;category&quot;: &quot;food&quot;, &quot;name&quot;: &quot;apple&quot; &#125;, &#123; &quot;category&quot;: &quot;food&quot;, &quot;name&quot;: &quot;banana&quot; &#125;, &#123; &quot;category&quot;: &quot;tool&quot;, &quot;name&quot;: &quot;hammer&quot; &#125;, &#123; &quot;category&quot;: &quot;furniture&quot;, &quot;name&quot;: &quot;couch&quot; &#125; ]&#125; 3.10.1 查询整个文档:1234567db.storage.find(&#123; &#x27;items.category&#x27;: &#123; $eq: &#x27;food&#x27; &#125;&#125;);// result 3.10.2 映射操作符（Projection Operator）1) $ 操作符会限制 array 类型数据的返回结果，使其仅返回第一个满足条件的元素。 123456789101112131415161718192021db.storage.find(&#123; &#x27;items.category&#x27;: &#123; $eq: &#x27;food&#x27; &#125;&#125;,&#123; &#x27;items.$&#x27;: 1&#125;);// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125; ]&#125; 2) $elemMatch 和 $ 的区别在于，$ 使用的是数据查询条件作为来映射（或者说过滤）array 中的数据，而 $elemMatch 需要指定单独的条件（可以指定多个条件） 1234567891011121314151617181920212223db.storage.find(&#123; &#x27;_id&#x27;: &#x27;alpha&#x27;&#125;,&#123; &#x27;items&#x27;: &#123; &#x27;$elemMatch&#x27;: &#123; &#x27;category&#x27;: &#x27;food&#x27; &#125; &#125;&#125;)// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125; ]&#125; 3.10.3 聚合1) $filter 123456789101112131415161718192021222324252627282930db.storage.aggregate([&#123; $project: &#123; &quot;items&quot;: &#123; $filter: &#123; input: &quot;$items&quot;, as: &quot;item&quot;, cond: &#123; $eq: [ &#x27;$$item.category&#x27;, &#x27;food&#x27; ] &#125; &#125; &#125; &#125;&#125;])// result&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;items&quot; : [ &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125;, &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;banana&quot; &#125; ]&#125; 2) $unwind 如果文档中包含 array 类型字段、并且其中包含多个元素，使用 $unwind 操作符会根据元素数量输出多个文档，每个文档的 array 字段中仅包含 array 中的单个元素。 123456789101112131415161718192021222324252627282930313233343536db.storage.aggregate([&#123; $match: &#123; &#x27;items.category&#x27;: &#x27;food&#x27; &#125;&#125;,&#123; $unwind: &#x27;$items&#x27;&#125;,&#123; $match: &#123; &#x27;items.category&#x27;: &#x27;food&#x27; &#125;&#125;])// result/* 1 */&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;name&quot; : &quot;Storage Alpha&quot;, &quot;items&quot; : &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;apple&quot; &#125;&#125;/* 2 */&#123; &quot;_id&quot; : &quot;alpha&quot;, &quot;name&quot; : &quot;Storage Alpha&quot;, &quot;items&quot; : &#123; &quot;category&quot; : &quot;food&quot;, &quot;name&quot; : &quot;banana&quot; &#125;&#125; 4. 索引4.1 基础索引1234db.test.ensureIndex(&#123;age:1&#125;)db.test.ensureIndex(&#123;age:1&#125;, &#123;background:true&#125;)db.test.getIndexes() 4.2 文档索引1234db.test.update(&#123;addr:null&#125;, &#123;$set: &#123;addr: &#123;city:&#x27;BJ&#x27;, prov:&#x27;BJ&#x27;&#125;&#125;&#125;)db.test.ensureIndex(&#123;addr:1&#125;)db.test.find(&#123;addr: &#123;city:&#x27;BJ&#x27;, prov:&#x27;BJ&#x27;&#125;&#125;) # 使用索引db.test.find(&#123;addr: &#123;prov:&#x27;BJ&#x27;, city:&#x27;BJ&#x27;&#125;&#125;) # 不使用索引 4.3 组合索引1db.test.ensureIndex(&#123;name:1, age:1&#125;) 4.4 唯一索引1db.test.ensureIndex(&#123;name:1&#125;, &#123;unique:true&#125;) 4.5 强制使用索引 (hint)12db.test.ensureIndex(&#123;name:1, age:1&#125;)db.test.find(&#123;age: &#123;$gt:25&#125;&#125;).hint(&#123;name:1, age:1&#125;).explain() 4.6 删除索引12db.test.dropIndex(&#123;name:1&#125;)db.test.dropIndexes() 5. 存储过程5.1 定义函数1function addNumbers(x, y) &#123;return x+y;&#125; 5.2 放入js表中12db.system.js.save(&#123;_id:&#x27;addNumbers&#x27;, value:addNumbers&#125;)db.system.js.save(&#123;_id:&#x27;addNumbers&#x27;, value:function(x, y) &#123;return x+y;&#125;&#125;) 5.3 执行存储过程1db.eval(&#x27;addNumbers(1,2)&#x27;) 6. 工具和命令6.1 常用命令123456789bsondump bson格式文件转换为jsonmongo 客户端, js解释器mongod 服务器，每个实例启动一个进程mongodump/mongorestoremongoexport/mongoimportmongofile GridFS管理器，实现二进制文件存取mongos 分片路由，使用sharding功能时，应用程序连接mongos，而不是mongodmongosniff tcpdump，监控mongodb相关包请求，并已指定可读形式输出mongostat 实时监控工具 6.2 数据导出1234567mongoexport-d, --db-c, --collection-o, --out-f, --fields--host/--port-csv, --type=csv 12mongoexport -d mydb -c test -o test.jsonmongoexport -d mydb -c test -f name,addr --type=csv -o test.csv 6.3 数据导入12345678910mongoimport-d, --db-c, --collection-f, --fields--host/--port-csv, --type=csv--drop =&gt; drop collecion first if exists--stopOnError--file--headerline # 忽略第一行 1mongoimport -d mydb -c test --headerline --type=csv --drop --file test.csv 6.4 数据库备份恢复12345678910111213141) mongodump-d, --db-c, --collection-o, --out-q, --querymongodump -d mydb # 生成dump目录，该目录下保存数据文件2) mongorestore-d, --db-c, --collection--objcheck--filter--drop","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://elihe2011.github.io/categories/NoSQL/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://elihe2011.github.io/tags/mongodb/"}]},{"title":"tornado","slug":"Python tornado","date":"2019-11-03T08:15:00.000Z","updated":"2021-06-22T10:50:49.745Z","comments":true,"path":"2019/11/03/Python tornado/","link":"","permalink":"https://elihe2011.github.io/2019/11/03/Python%20tornado/","excerpt":"1. 整体架构1.1 tornado组件Tornado: Web框架和HTTP服务器一起组成的WSGI的全栈替代品 Web框架主要包括RequestHandler用于创建Web应用程序和各种支持类的子类 HTTP服务器与客户端主要包括HTTPServer和AsyncHTTPClient 异步网络库主要包括IOLoop和IOStream作为HTTP组件的构建块 协程库 WebSocket","text":"1. 整体架构1.1 tornado组件Tornado: Web框架和HTTP服务器一起组成的WSGI的全栈替代品 Web框架主要包括RequestHandler用于创建Web应用程序和各种支持类的子类 HTTP服务器与客户端主要包括HTTPServer和AsyncHTTPClient 异步网络库主要包括IOLoop和IOStream作为HTTP组件的构建块 协程库 WebSocket 1.2 模块1.2.1 Core Web Framework 核心Web框架 tornado.web 包括Web框架大部分主要功能，包括RequestHandler和Application类。 tornado.httpserver一个无阻塞HTTP服务器的实现 tornado.template模板系统 tornado.escape HTML、JSON、URLs等编码解码和字符串操作 tornado.locale国际化支持 1.2.2 Asynchronous Networking 异步网络底层模块 tornado.ioloop 核心IO循环 tornado.iostream对非阻塞的Socket的简单封装以方便常用读写操作 tornado.httpclient无阻塞的HTTP服务器实现 tornado.netutil网络应用的实现主要是TCPServer类 1.2.3 Integration With Other Services 系统集成服务 tornado.auth 使用OpenId和OAuth进行第三方登录 tornado.database MySQL服务端封装 tornado.platform.twisted 在Tornado上运行Twisted实现的代码 tornado.websocket实现和浏览器的双向通信 tornado.wsgi 其他Python网络框架或服务器的相互操作 1.2.4 Utilities 应用模块 tornado.autoload产生环境中自动检查代码更新 tornado.gen基于生成器的接口，使用该模块 保证代码异步运行。 tornado.httputil分析HTTP请求内容 tornado.options解析终端参数 tornado.process多进程实现的封装 tornado.stack_context异步环境中对回调函数上下文保存、异常处理 tornado.testing单元测试 1.2.5 Tornado服务器的三个底层核心模块 httpserver 服务于web模块的一个简单的HTTP服务器的实现Tornado的HTTPConnection类用来处理HTTP请求，包括读取HTTP请求头、读取POST传递的数据，调用用户自定义的处理方法，以及把响应数据写给客户端的socket。 iostream 对非阻塞式的socket的封装以便于常见读写操作为了在处理请求时实现对socket的异步读写，Tornado实现了IOStream类用来处理socket的异步读写。 ioloop 核心的I/O循环Tornado为了实现高并发和高性能，使用了一个IOLoop事件循环来处理socket的读写事件，IOLoop事件循环是基于Linux的epoll模型，可以高效地响应网络事件，这是Tornado高效的基础保证。 1.3 设计模型Tornado不仅仅是一个Web框架，它完整地实现了HTTP服务器和客户端，再此基础上提供了Web服务，它可分为四层： Web框架：最上层，包括处理器、模板、数据库连接、认证、本地化等Web框架所需功能。 HTTP/HTTPS层：基于HTTP协议实现了HTTP服务器和客户端 TCP层：实现TCP服务器负责数据传输 Event层：最底层、处理IO事件 2. 入门2.1 请求处理1234567891011121314import tornado.webimport tornado.ioloopclass MainHandler(tornado.web.RequestHandler): def get(self): self.write(&#x27;Hello World!&#x27;)application = tornado.web.Application([ (r&#x27;/&#x27;, MainHandler),])if __name__ == &#x27;__main__&#x27;: application.listen(5000) tornado.ioloop.IOLoop.current().start() 2.1.1 获取请求参数：1234567891011# URLget_query_argument(name, default=_ARG_DEFAULT, strip=True)get_query_arguments(name, strip=True)# Formget_body_argument(name, default=_ARG_DEFAULT, strip=True)get_body_arguments(name, strip=True)# URL+FORMget_argument(name, default=_ARG_DEFAULT, strip=True)get_arguments(name, strip=True) 2.1.2 请求的其他信息获取：RequestHandler.request对象属性 12345678methodhosturi = request.path + request.queryversionheadersbodyremote_ipfiles 其中，files为字典类型： 1234&#123; &quot;form_filename1&quot;: [&lt;tornado.httputil.HTTPFile&gt;, &lt;tornado.httputil.HTTPFile&gt;], &quot;form_filename2&quot;: [&lt;tornado.httputil.HTTPFile&gt;]&#125; tornado.httputil.HTTPFile是接收到的文件对象，有以下三个属性： filename 实际文件名 body 文件数据实体 content_type 文件类型 2.1.3 响应输出12345678910111213write(chunk) # str, dict(Content-Type: application/json)finish(chunk) # same as aboveset_header(&#x27;Content-Type&#x27;, &#x27;application/json&#x27;)add_header(&#x27;Token&#x27;, &#x27;aasaswqwqqw&#x27;)set_status(404, &#x27;Not Found&#x27;)set_cookie(name, value)clear_all_cookie(path=&#x27;/&#x27;, domain=None)redirect(&#x27;/v1/api/users&#x27;)send_error(500, **kwargs) # 抛出异常 2.1.4 重写set_default_header()方法:1234class MainHandler(tornado.web.RequestHandler): def set_default_headers(self): self.set_header(&#x27;Content-Type&#x27;, &#x27;application/json&#x27;) self.set_header(&#x27;Token&#x27;, &#x27;asasaasxasas&#x27;) 2.1.5 重写write_error()方法捕获异常：1234class MainHandler(tornado.web.RequestHandler): def write_error(self, status_code, **kwargs): self.write(&#x27;出错了&lt;br&gt;&#x27;) self.write(&#x27;详情: &#123;&#125;&lt;br&gt;&#x27;.format(kwargs.get(&#x27;reason&#x27;, &#x27;&#x27;))) 2.1.5 接口调用顺序：1234567891011121314151617set_default_headers()initialize()prepare() # 预处理，打印日志，打开文件等get()head() # 与get类似，但只返回头post()delete()patch() # 修改局部数据put()options() # 返回给定URL支持的所有方法# 当使用send_error()抛出异常后，会增加调用如下两个方法set_default_headers()write_error()on_finish() # 请求处理完成后调用，通常用来进行资源释放或记录处理日志 2.2 静态资源12345678910111213routes = [ (r&#x27;/main&#x27;, MainHandler), (r&#x27;/upload&#x27;, UploadFileHandler), (r&#x27;/(.*)&#x27;, tornado.web.StaticFileHandler, &#123;&#x27;path&#x27;: os.path.join(current_path, &#x27;static/html&#x27;), &#x27;default_filename&#x27;: &#x27;index.html&#x27;&#125;)]settings = dict( debug=True, static_path=os.path.join(current_path, &#x27;static&#x27;), template_path=os.path.join(current_path, &#x27;templates&#x27;),) 1234&lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;&#123; static_url(&#x27;style.css&#x27;) &#125;&#125;&quot;&gt;&lt;!-- 自动将文件hash值带上 --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/style.css?v=sasyqwzias&quot;&gt; 2.3 安全应用 Cookie操作 安全Cookie 跨站请求伪造原理 XSRF保护 模板 请求体 HTTP报文头 用户验证 authenticated装饰器 get_current_user()方法 login_url设置 2.3.1 Cookie:123456set_cookie(name, value, domain=None, expires=None, path=&#x27;/&#x27;, expires_days=None)get_cookie(name, default=None)clear_cookie(name, path=&#x27;/&#x27;, domain=None)clear_all_cookies() 安全Cookie: 12345678910111213# 1. 生成混淆密钥import base64, uuidsecret = base64.b64encode(uuid.uuid4().bytes + uuid.uuid4().bytes).decode()# 2. app中设置参数app = tornado.web.Application( [(r&#x27;/&#x27;, MainHandler),], cookie_secret = &#x27;7nORa+paQiux7VIjrK9KyALYFJSdMkzKu1qCJkFbPXI=&#x27;)# 3. 使用安全cookieset_secure_cookie(name, value, expires_days=30)get_secure_cookie(name, default=None, max_age_days=31) 2|1:0|10:1587804406|3:abc|4:MTIz|44d2066a5c4f4dcfca3de809b67f07c780f7d4cb6b0f585f68625f5036d2412a 安全cookie版本, 默认2 默认0 时间戳 cookie名 base64编码的cookie值 签名值，不带长度说明的前缀 2.3.2 XSRF: Cross-site request forgery开启XSRF保护： 12345app = tornado.web.Application( [(r&#x27;/&#x27;, MainHandler),], cookie_secret=&#x27;7nORa+paQiux7VIjrK9KyALYFJSdMkzKu1qCJkFbPXI=&#x27; xsrf_cookie=True) 模板表单中增加XSRF保护： 1234&lt;form method=&quot;POST&quot;&gt; &#123;% module xsrf_form_html() %&#125; &lt;input type=&quot;text&quot; name=&quot;message&quot;&gt;&lt;/form&gt; 非模板：方法1，通过js脚本获取cookie中的_xsrf值 123456789101112&lt;script type=&quot;text/javascript&quot;&gt;function getCookie(name) &#123; var r = document.cookie.match(&quot;\\\\b&quot; + name + &quot;([^;]*)\\\\b&quot;); return r ? r[1] : undefined;&#125;function xsrfPost() &#123; var xsrf = getCookie(&quot;_xsrf&quot;); $.post(&quot;/new&quot;, &quot;_xsrf=&quot; + xsrf + &quot;&amp;key1=value1&quot;, function(data) &#123; alert(&quot;ok&quot;); &#125;);&#125;&lt;/script&gt; 非模板：方法2，HTTP头重设置X-XSRFToken(json请求时) 12345678910111213141516171819202122232425&lt;script type=&quot;text/javascript&quot;&gt;function getCookie(name) &#123; var r = document.cookie.match(&quot;\\\\b&quot; + name + &quot;([^;]*)\\\\b&quot;); return r ? r[1] : undefined;&#125;function xsrfPost() &#123; var xsrf = getCookie(&quot;_xsrf&quot;); var data = &#123; k1: 1, k2: 2 &#125;; var json_data = JSON.stringify(data) $.ajax(&#123; url: &quot;/new&quot;, method: &quot;POST&quot;, headers: &#123; &quot;X-XSRFToken&quot;: xsrf &#125;, data: json_data, success: function(data) &#123; alert(&quot;ok&quot;); &#125; &#125;);&#125;&lt;/script&gt; 2.4 用户验证：认证装饰器：tornado.web.authenticated 当前登录用户：get_current_user() 验证失败，重定向到: login_url 1234567app = tornado.web.Application( [ (r&#x27;/&#x27;, MainHandler), (r&#x27;/login&#x27;, LoginHandler), ], &quot;login_url&quot;: &quot;/login&quot;,) 2.5 协程：2.5.1 通过tornado.gen.coroutine来装饰生成器12345678910@corountinedef yield_test(): yield 1 yield 2 yield 3 return &#x27;Done&#x27; @coroutinedef main(): yield from yield_test() 2.5.2 通过async1234567async def yield_test(): yield 1 yield 2 yield 3async def main() await yield_test() 异步代码的执行，必须放入事件循环中： 1234567891011121314151617181920async def fetch(): http_client = httpclient.AsyncHTTPClient() try: resp = await http_client.fetch(&#x27;http://www.nasa.gov&#x27;) except Exception as e: print(&quot;Error: %s&quot; % e) else: print(resp.body.decode(&#x27;utf-8&#x27;))if __name__ == &#x27;__main__&#x27;: # 使用tornado # ioloop = tornado.ioloop.IOLoop.current() # ioloop.run_sync(fetch) # run_sync方法，可以在运行完某个协程后停止循环事件 # 使用asyncio # asyncio.ensure_future(fetch()) # asyncio.get_event_loop().run_forever() asyncio.get_event_loop().run_until_complete(fetch()) 2.6 RequestHandler 有用子类2.6.1 RedirectHandlerurls = [ (‘/abc/‘, RedirectHandler, ‘/‘), ] 2.6.2 StaticFileHandlersettings = dict( static_path=’/home/eli/static’, static_url_prefix=’/static2/‘, # 默认为static) urls = [ (‘/static3/(.*)’, StaticFileHandler, {‘path’: ‘/home/eli/static’})] 2.7 使用模板：123456settings = dict( templates=os.path.join(os.path.dirname(__file__), &#x27;templates&#x27;) # 方法1 template_path=&#x27;templates&#x27; # 方法2)self.render(&#x27;index.html&#x27;) 2.8. ORM aiomysql peewee peewee-async 1234567obj = Person()obj.name = &#x27;jack&quot;obj.save()obj = Person.get(Person.id == 1)obj = Person.get_by_id(1) # 需要try...catch obj = Person[1] # __getitem__ =&gt; get_by_id 2.8.1 返回ModelSelect对象1234567891011persons = Person.select() persons = Person.select(Person.name, Person.gender)persons = Person.select().where(Pereson.age &gt; 20)persons = Person.select().where((Person.age &gt; 10) &amp; (Person.gender == &#x27;M&#x27;)) # andpersons = Person.select().where(Person.name.contains(&#x27;ck&#x27;)) # likepersons = Person.select().where(Person.id.in_([1, 3])) # inpersons = Person.select().order_by(Person.age.desc()).paginate(1, 10) 2.8.2 返回ModelUpdate对象1Person.update(age=24).where(Person.name=&#x27;jack&#x27;).execute() 2.8.3 删除数据12obj = Person.get(Person.id== 1)obj.delete_instance() 2.8.4 使用异步查询1234567891011121314151617181920212223import peewee_async# asyncdb = peewee_async.MySQLDatabase(&#x27;test&#x27;, host=&#x27;localhost&#x27;, port=3306, user=&#x27;root&#x27;, password=&#x27;&#x27;)objects = peewee_async.Manager(db)db.set_allow_sync(False)async def handler(): # person = dict( # name=&#x27;jack&#x27;, # gender=0, # birthday=date(1992, 9, 1), # age=28, # email=&#x27;jack@gmail.com&#x27; # ) # await objects.create(Person, **person) persons = await objects.execute(Person.select()) for person in persons: print(person.name, person.age)loop = asyncio.get_event_loop()loop.run_until_complete(handler()) 2.9 表单验证： wtforms wtforms-tornado 2.9.1 集成wtforms-json1234567# 集成wtforms-json，用于json参数验证 # monkey_patch Form.from_json wtforms_json.init()params = self.request.body.decode(&#x27;utf8&#x27;)params = json.loads(params)form = LoginForm.from_json(params) 2.10 JWT: Json Web Token由3部分组成： Header Payload Signature 2.10.1 使用jwt1234567891011121314151617181920# Headerbase64enc(&#123; &quot;alg&quot;: &quot;HS256&quot;, &quot;typ&quot;: &quot;JWT&quot;&#125;)# Payloadbase64enc(&#123; &quot;iss&quot;: &quot;eli.xyz&quot;, &quot;iat&quot;: 1588352657, &quot;exp&quot;: 1588573638, &quot;company&quot;: &quot;Eli Inc&quot;, &quot;awesome&quot;: true&#125;)# SignatureHMACSSHA256(base64enc(header) + &quot;.&quot; + base64enc(payload),secretKey) 2.10.2 JWT和session的区别 set-cookie: 前后端分离时，如果不使用同一个域名，set-cookie是无效的； session: 服务器随机生成的一段字符串，保持在服务器，可以以任意方式给浏览器（接口返回或者放到cookie中），它和cookie没有本质的关联关系，只要能给给前端就行。前端请求服务器时，把这个session带上，服务器可通过拦截器通过session把相关用户找出。 jwt: 本质上是加密技术，本身已包含用户的相关信息。安全性比session低。（PyJWT） 3. 异步和协程3.1 同步IO和异步IO 同步IO: 请求进程阻塞，直到IO完成操作 异步IO: 请求进程不阻塞 123456from tornado.httpclient import HTTPClientdef synchronous_visit(): client = HTTPClient() resp = client.fetch(&#x27;http://www.baidu.com&#x27;) print(resp.body) 123456789from tornado.httpclient import AsyncHTTPClientdef handle_response(resp): print(resp.body)def asynchronous_visit(): client = AsyncHTTPClient() future = client.fetch(&#x27;http://www.baidu.com&#x27;) future.add_done_callback(lambda self: future.set_result(self.result())) 3.2 协程协程不使用线程，减少了线程上下文切换消耗 1）协程函数 12345678from tornado import gen # 协程库from tornado.httpclient import AsyncHTTPClient@gen.coroutinedef coroutine_visit(): client = AsyncHTTPClient() resp = yield client.fetch(&#x27;http://baidu.com&#x27;) print(resp.body) 2）调用协程函数 在另一个协程函数中，通过yield调用 IOLoop未启动，通过run_sync()函数调用 IOLoop已启动，通过spawn_callback()函数调用 1234567891011@gen.coroutinedef coroutine_visit(): client = AsyncHTTPClient() resp = yield client.fetch(&#x27;http://baidu.com&#x27;) print(resp.body)@gen.coroutinedef outer_coroutine(): print(&#x27;start call...&#x27;) yield coroutine_visit() print(&#x27;done.&#x27;) 启动IOLoop -&gt; 调用被lambda封装的协程函数 -&gt; 停止IOLoop 1234def func_normal(): print(&#x27;start call...&#x27;) IOLoop.current().run_sync(lambda: coroutine_visit()) print(&#x27;done&#x27;) spawn_callback不会等待协程执行完毕 1234def func_normal2(): print(&#x27;start call...&#x27;) IOLoop.current().spawn_callback(coroutine_visit) print(&#x27;done&#x27;) 3）协程中调用阻塞函数 12345678910111213141516from concurrent.futures.thread import ThreadPoolExecutorfrom tornado import genthread_pool = ThreadPoolExecutor(2)def my_sleep(count): import time for _ in range(count): time.sleep(1)@gen.coroutinedef call_blocking(): print(&#x27;start call...&#x27;) yield thread_pool.submit(my_sleep, 10) print(&#x27;done&#x27;) 4）协程中等待多个异步调用 123456789@gen.coroutinedef coroutine_visit_many(): client = AsyncHTTPClient() resps = yield [client.fetch(&#x27;http://baidu.com&#x27;), client.fetch(&#x27;http://sina.com&#x27;), client.fetch(&#x27;http://qq.com&#x27;), client.fetch(&#x27;http://utime.com&#x27;)] for resp in resps: print(resp.body) 4. WebSocket实现获取消息： 前端轮询：后端提供接口，前端定时去调用，有无数据变更，立即回复 长轮训：同上，但数据未改变，不做回应；数据变更，服务器才回复响应 websocket：html5规范中的新协议（ws://URL)。是独立建立在TCP上的协议，和HTTP的唯一关系是使用HTTP协议状态码101进行协议切换，使用80端口，可绕过大多数防火墙 4.1 WebSocket特点： 适合服务器端主动推送的场景 相对于Ajax和Long poll等技术，通信模型更高效 仍然与HTTP完成Internet通信 是HTML5技术标准，不受企业防火墙拦截 4.2 WebSocket通信，特殊的HTTP Header1234Connection: UpgradeSec-WebSocket-Key: u*******==Upgrade: websocketSec-WebSocket-Version: 13 4.3 WebSocketHandler方法(服务端)12345678open()on_message(msg)on_close()write_message(msg, binary=False)close(code=None, reason=None)check_origin(origin) # 判断请求源，符合条件允许连接，否则返回403 4.4 WebSocket方法(JS)1234567onopen()onmessage()onerror()onclose()send(data)close() 4.5 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import threadingimport timeimport tornado.ioloopimport tornado.webimport tornado.genimport tornado.websocketfrom tornado.options import parse_command_line, define, optionsimport asynciodefine(&#x27;port&#x27;, default=5000, help=&#x27;run on the given port&#x27;, type=int)clients = &#123;&#125;class IndexHandler(tornado.web.RequestHandler): @tornado.gen.coroutine def get(self): self.render(&#x27;index.html&#x27;)class MyWebSocketHandler(tornado.websocket.WebSocketHandler): def open(self, *args): self.id = self.get_argument(&#x27;Id&#x27;) # self.stream.set_nodelay(True) clients[self.id] = &#123;&#x27;id&#x27;: self.id, &#x27;object&#x27;: self&#125; def on_message(self, message): print(&#x27;Client %s received a message: %s&#x27; % (self.id, message)) def on_close(self): if self.id in clients: del clients[self.id] print(&#x27;Client %s is closed&#x27; % self.id) def check_origin(self, origin): return Trueapp = tornado.web.Application([ (r&#x27;/&#x27;, IndexHandler), (r&#x27;/websocket&#x27;, MyWebSocketHandler),])# 启动独立线程，每隔1s向所有客户端推送当前时间def send_time(): # tornado 5+, 启动线程，需要增加 asyncio.set_event_loop(asyncio.new_event_loop()) from datetime import datetime while True: for key in clients.keys(): msg = str(datetime.now()) clients[key][&#x27;object&#x27;].write_message(msg) print(&#x27;write to client %s: %s&#x27; % (key, msg)) time.sleep(1)if __name__ == &#x27;__main__&#x27;: threading.Thread(target=send_time).start() parse_command_line() app.listen(options.port) tornado.ioloop.IOLoop.instance().start() 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;WebSocket&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;a href=&quot;javascript:WebSocketTest()&quot;&gt;Run WebSocket&lt;/a&gt; &lt;div id=&quot;message&quot; style=&quot;height: 200px; background: black; color: white;&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;script type=&quot;text/javascript&quot;&gt; var messageContainer = document.getElementById(&quot;message&quot;); function WebSocketTest() &#123; if (&quot;WebSocket&quot; in window) &#123; messageContainer.innerHTML = &quot;WebSocket is supported by your Browser!&quot;; var tid = Math.floor(Math.random() * 10000); var ws = new WebSocket(&#x27;ws://localhost:5000/websocket?Id=&#x27; + tid) ws.onopen = function () &#123; ws.send(&quot;Message to send&quot;); &#125;; ws.onmessage = function (evt) &#123; var received_msg = evt.data; messageContainer.innerHTML = messageContainer.innerHTML + &quot;&lt;br/&gt;Message is received: &quot; + received_msg; &#125;; ws.onclose = function () &#123; messageContainer.innerHTML = messageContainer.innerHTML + &quot;&lt;br/&gt;Connection is closed.&quot;; &#125; &#125; else &#123; messageContainer.innerHTML = &quot;WebSocket Not supported by your Browser!&quot;; &#125; &#125;&lt;/script&gt;&lt;/html&gt; 5. 模拟实现异步：5.1 通过回调函数实现异步123456789101112131415161718192021222324252627282930313233343536import timeimport randomimport _threaddef long_io(cb): def run(callback): print(&#x27;Start doing time-consuming work&#x27;) time.sleep(5) print(&#x27;Time-consuming work is done&#x27;) result = random.randint(1, 10) callback(result) _thread.start_new_thread(run, (cb,))def on_finish(ret): print(&#x27;result=&#123;&#125;&#x27;.format(ret))def req_a(): print(&#x27;Start calling request A&#x27;) long_io(on_finish) print(&#x27;Request A is done&#x27;)def req_b(): print(&#x27;Start calling request B&#x27;) time.sleep(2) print(&#x27;Request B is done&#x27;)def main(): req_a() req_b() while True: passif __name__ == &#x27;__main__&#x27;: main() 5.2 通过yield实现异步123456789101112131415161718192021222324252627282930313233343536373839404142import timeimport randomimport _threadgen = Nonedef long_io(): def run(): print(&#x27;Start doing time-consuming work&#x27;) time.sleep(5) print(&#x27;Time-consuming work is done&#x27;) result = random.randint(1, 10) try: gen.send(result) except StopIteration: pass _thread.start_new_thread(run, ())def req_a(): print(&#x27;Start calling request A&#x27;) ret = yield long_io() print(&#x27;result=&#123;&#125;&#x27;.format(ret)) print(&#x27;Request A is done&#x27;)def req_b(): print(&#x27;Start calling request B&#x27;) time.sleep(2) print(&#x27;Request B is done&#x27;)def main(): global gen gen = req_a() next(gen) req_b() while True: passif __name__ == &#x27;__main__&#x27;: main() 改成装饰器： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import timeimport randomimport _threadgen = Nonedef long_io(): def run(): print(&#x27;Start doing time-consuming work&#x27;) time.sleep(5) print(&#x27;Time-consuming work is done&#x27;) result = random.randint(1, 10) try: gen.send(result) except StopIteration: pass _thread.start_new_thread(run, ())def gen_coroutine(func): def wrapper(): global gen gen = func() next(gen) return wrapper@gen_coroutinedef req_a(): print(&#x27;Start calling request A&#x27;) ret = yield long_io() print(&#x27;result=&#123;&#125;&#x27;.format(ret)) print(&#x27;Request A is done&#x27;)def req_b(): print(&#x27;Start calling request B&#x27;) time.sleep(2) print(&#x27;Request B is done&#x27;)def main(): req_a() req_b() while True: passif __name__ == &#x27;__main__&#x27;: main() 再次优化，用装饰器来控制整个异步： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import timeimport randomimport _threaddef long_io(): print(&#x27;Start doing time-consuming work&#x27;) time.sleep(5) result = random.randint(1, 10) print(&#x27;Time-consuming work is done&#x27;) yield resultdef gen_coroutine(func): def wrapper(): gen = func() gen_long_io = next(gen) def f(): ret = next(gen_long_io) try: gen.send(ret) except StopIteration: pass _thread.start_new_thread(f, ()) return wrapper@gen_coroutinedef req_a(): print(&#x27;Start calling request A&#x27;) ret = yield long_io() print(&#x27;result=&#123;&#125;&#x27;.format(ret)) print(&#x27;Request A is done&#x27;)def req_b(): print(&#x27;Start calling request B&#x27;) time.sleep(2) print(&#x27;Request B is done&#x27;)def main(): req_a() req_b() while True: passif __name__ == &#x27;__main__&#x27;: main()","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[{"name":"tornado","slug":"tornado","permalink":"https://elihe2011.github.io/tags/tornado/"}]},{"title":"Alipay","slug":"Alipay","date":"2019-10-23T02:24:42.000Z","updated":"2021-06-22T10:50:49.744Z","comments":true,"path":"2019/10/23/Alipay/","link":"","permalink":"https://elihe2011.github.io/2019/10/23/Alipay/","excerpt":"1. 生成密钥密钥生成工具：https://docs.open.alipay.com/291/106097/ 2. 应用配置2.1 沙箱应用蚂蚁开放平台https://openhome.alipay.com，进入【开发者中心】-&gt;【研发服务】-&gt;【沙箱应用】","text":"1. 生成密钥密钥生成工具：https://docs.open.alipay.com/291/106097/ 2. 应用配置2.1 沙箱应用蚂蚁开放平台https://openhome.alipay.com，进入【开发者中心】-&gt;【研发服务】-&gt;【沙箱应用】 2.2 正式应用蚂蚁开放平台https://openhome.alipay.com，【开发者中心】-&gt;【网页&amp;移动应用】 3. 接入支付宝3.1 安装sdk12345pip alipay-sdk-pythonpip uninstall pycrypto # 默认加密库pip uninstall pycryptodomepip install pycryptodome 3.2 生成order_info 参数列表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from __future__ import unicode_literalsimport loggingfrom _datetime import datetimeimport randomfrom alipay.aop.api.AlipayClientConfig import AlipayClientConfigfrom alipay.aop.api.DefaultAlipayClient import DefaultAlipayClientfrom alipay.aop.api.request.AlipayTradeAppPayRequest import AlipayTradeAppPayRequestfrom alipay.aop.api.constant.ParamConstants import P_NOTIFY_URLlogger = logging.getLogger(__name__)def create_order_number(): &quot;&quot;&quot; 生成订单号 &quot;&quot;&quot; date = datetime.now().strftime(&quot;%Y%m%d%H%M%S&quot;) # 生成4为随机数作为订单号的一部分 random_str = str(random.randint(1, 9999)) random_str = random_str.rjust(4, &#x27;0&#x27;) serial_no = &#x27;U%s%s&#x27; % (date, random_str) return serial_nodef alipay(app_pay_model, app_id, app_private_key, alipay_public_key, notify_url, server_url): &quot;&quot;&quot; 设置配置，包括支付宝网关地址、app_id、应用私钥、支付宝公钥等，其他配置值可以查看AlipayClientConfig的定义。 &quot;&quot;&quot; alipay_client_config = AlipayClientConfig() alipay_client_config.server_url = server_url alipay_client_config.app_id = app_id alipay_client_config.app_private_key = app_private_key alipay_client_config.alipay_public_key = alipay_public_key alipay_client_config.sign_type = &#x27;RSA2&#x27; &quot;&quot;&quot; 得到客户端对象。 注意，一个alipay_client_config对象对应一个DefaultAlipayClient，定义DefaultAlipayClient对象后，alipay_client_config不得修改，如果想使用不同的配置，请定义不同的DefaultAlipayClient。 logger参数用于打印日志，不传则不打印，建议传递。 &quot;&quot;&quot; client = DefaultAlipayClient(alipay_client_config=alipay_client_config, logger=logger) request = AlipayTradeAppPayRequest(biz_model=app_pay_model) udf_params = dict() # 设置回调url udf_params[P_NOTIFY_URL] = notify_url request.udf_params = udf_params print(request.get_params()) response = client.sdk_execute(request) return response 3.3 flask 应用集成123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778@bp_donate.route(&quot;/api/donate/alipay&quot;, methods=[&quot;POST&quot;])@util.jsonapi(login_required=True)def donate_alipay(): &quot;&quot;&quot; 用户赞助(支付宝) 请求地址: /api/donate/alipay 请求类型: POST URL参数: 无 提交参数: amount: [int/float], # 赞助金额 &quot;&quot;&quot; user_id = current_user.id params = request._get_data() amount = params.get(&#x27;amount&#x27;) if not isinstance(amount, (int, float)): raise error.InvalidArguments if amount &lt;= 0: raise error.InvalidArguments data = &#123; &#x27;order_info&#x27;: &#x27;&#x27;, &#x27;out_trade_no&#x27;: &#x27;&#x27; &#125; # 赞助金额格式化 amount = &#x27;&#123;:.2f&#125;&#x27;.format(amount) # 新增赞助记录 key = &#x27;lock:donate:alipay:%s&#x27; % user_id with util.Lockit(Redis, key) as locked: if locked: return error.TooManyOperate # 商户订单号 out_trade_no = create_order_number() # 初始化赞助数据 try: Donate.add_donate_alipay(out_trade_no, user_id, amount) except Exception as e: return e try: # 构造唤起支付宝客户端支付时传递的请求串示例：alipay.trade.app.pay model = AlipayTradeAppPayModel() model.total_amount = amount model.product_code = &quot;QUICK_MSECURITY_PAY&quot; # 商品信息，支付宝回调时回传给商户服务器 body = &#123; &#x27;user_id&#x27;: user_id, &#x27;amount&#x27;: amount, &#x27;name&#x27;: &#x27;支付宝赞助&#x27; &#125; model.body = body model.subject = &#x27;支付宝赞助&#x27; model.out_trade_no = out_trade_no alipay_appid = current_app.config.get(&#x27;ALIPAY_APPID&#x27;) alipay_app_private_key = current_app.config.get(&#x27;ALIPAY_APP_PRIVATE_KEY&#x27;) alipay_public_key = current_app.config.get(&#x27;ALIPAY_PUBLIC_KEY&#x27;) alipay_callback_api = current_app.config.get(&#x27;ALIPAY_CALLBACK_API&#x27;) server_url = current_app.config.get(&#x27;ALIPAY_GATEWAY&#x27;) order_info = alipay(model, alipay_appid, alipay_app_private_key, alipay_public_key, alipay_callback_api, server_url) data[&#x27;order_info&#x27;] = order_info data[&#x27;out_trade_no&#x27;] = model.out_trade_no except Exception as e: print(e) return error.AlipayDonateOrderError return data 3.4 支付宝支付异步回调https://docs.open.alipay.com/203/105286/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@bp_donate.route(&quot;/api/alipay_callback/&quot;, methods=[&quot;POST&quot;])def alipay_callback(): &quot;&quot;&quot; 支付宝异步回调接口 &quot;&quot;&quot; data = request.form.to_dict() current_app.logger.info(data) alipay_public_key = current_app.config.get(&#x27;ALIPAY_PUBLIC_KEY&#x27;) try: # sign, sign_type 都要从数据中取出，否则签名通不过 sign, sign_type = data.pop(&#x27;sign&#x27;), data.pop(&#x27;sign_type&#x27;) params = sorted(data.items(), key=lambda e: e[0], reverse=False) message = &quot;&amp;&quot;.join(u&quot;&#123;&#125;=&#123;&#125;&quot;.format(k, v) for k, v in params).encode() if verify_with_rsa(alipay_public_key.encode(&#x27;utf-8&#x27;).decode(&#x27;utf-8&#x27;), message, sign): out_trade_no = data.get(&#x27;out_trade_no&#x27;) # 商户订单号 trade_no = data.get(&#x27;trade_no&#x27;) # 支付宝交易号 buyer_id = data.get(&#x27;buyer_id&#x27;) # 买家支付宝用户号 trade_status = data.get(&#x27;trade_status&#x27;) # 交易状态 total_amount = data.get(&#x27;total_amount&#x27;) # 订单金额 receipt_amount = data.get(&#x27;receipt_amount&#x27;) # 实收金额 subject = data.get(&#x27;subject&#x27;) # 订单标题 gmt_payment = data.get(&#x27;gmt_payment&#x27;) # 交易付款时间 current_app.logger.info(out_trade_no) current_app.logger.info(trade_no) current_app.logger.info(buyer_id) current_app.logger.info(trade_status) current_app.logger.info(total_amount) current_app.logger.info(receipt_amount) current_app.logger.info(subject) current_app.logger.info(gmt_payment) # 交易状态： # TRADE_FINISHED 交易完成 false（不触发通知） # TRADE_SUCCESS 支付成功 true（触发通知） # WAIT_BUYER_PAY 交易创建 false（不触发通知） # TRADE_CLOSED 交易关闭 true（触发通知） if trade_status == &#x27;TRADE_SUCCESS&#x27;: status = 0 elif trade_status == &#x27;WAIT_BUYER_PAY&#x27;: status = 1 # 等待付款 else: status = 2 # 交易失败 trade_time = datetime.strptime(gmt_payment, &#x27;%Y-%m-%d %H:%M:%S&#x27;) gmt_payment = int(trade_time.timestamp() * 1000) # 更新数据库 try: Donate.confirm_donate_alipay(out_trade_no, trade_no, status, buyer_id, gmt_payment) except Exception as e: current_app.logger.info(e) print(e) # 一定是success这个单词，其他的alipay不认 return Response(&#x27;success&#x27;) else: abort(400) except: abort(400)","categories":[{"name":"EPay","slug":"EPay","permalink":"https://elihe2011.github.io/categories/EPay/"}],"tags":[{"name":"alipay","slug":"alipay","permalink":"https://elihe2011.github.io/tags/alipay/"}]},{"title":"Python 疑惑知识点","slug":"Python 疑惑知识点","date":"2019-10-23T02:24:42.000Z","updated":"2021-06-22T10:50:49.744Z","comments":true,"path":"2019/10/23/Python 疑惑知识点/","link":"","permalink":"https://elihe2011.github.io/2019/10/23/Python%20%E7%96%91%E6%83%91%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"1. 两个元组相等，即 a==b 且 a is b，那么相同索引的元素（如a[0] 、b[0]）是否必然相等?12345678a = (float(&#x27;nan&#x27;),)b = aa is b # Truea == b # Truehash(a) == hash(b) # Truea[0] == b[0] # False 2. 特殊浮点数(nan)12345a = float(&#x27;nan&#x27;)b = float(&#x27;nan&#x27;)a == b # Falsehash(a) == hash(b) # True 3. 特殊浮点数(inf)12345a = float(&#x27;inf&#x27;)b = float(&#x27;infinity&#x27;)a == b # Truehash(a) == hash(b) # True","text":"1. 两个元组相等，即 a==b 且 a is b，那么相同索引的元素（如a[0] 、b[0]）是否必然相等?12345678a = (float(&#x27;nan&#x27;),)b = aa is b # Truea == b # Truehash(a) == hash(b) # Truea[0] == b[0] # False 2. 特殊浮点数(nan)12345a = float(&#x27;nan&#x27;)b = float(&#x27;nan&#x27;)a == b # Falsehash(a) == hash(b) # True 3. 特殊浮点数(inf)12345a = float(&#x27;inf&#x27;)b = float(&#x27;infinity&#x27;)a == b # Truehash(a) == hash(b) # True 4. float(‘nan’) 的哈希值相等，这通常意味着它们不可以作为字典的不同键值，但是事实却出人意料12345a = &#123;float(&#x27;nan&#x27;): 1, float(&#x27;nan&#x27;): 2&#125;print(a) # &#123;nan: 1, nan: 2&#125;b = &#123;float(&#x27;inf&#x27;): 1, float(&#x27;inf&#x27;): 2&#125;print(b) # &#123;inf: 2&#125; 5. hash值123hash(float(&#x27;nan&#x27;)) # 0hash(float(&#x27;inf&#x27;)) # 314159 6. 异或运算, 赋值交换1234567a = 1b = 2a = a ^ b 01^10 =&gt; 11b = a ^ b 11^10 =&gt; 01a = a ^ b 11^01 =&gt; 10","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Celery","slug":"Celery","date":"2019-10-14T06:08:58.000Z","updated":"2021-06-22T10:50:49.743Z","comments":true,"path":"2019/10/14/Celery/","link":"","permalink":"https://elihe2011.github.io/2019/10/14/Celery/","excerpt":"1. 安装celery1234567891011121314151617pip install celery# 使用 librabbitmq 的 C 库pip install librabbitmq# 使用 Redis 作为消息传输方式或结果后端pip install redis# 序列化pip install celery[auth]pip install celery[msgpack]pip install celery[yaml]# 并发pip install eventletpip install geventpip install threads","text":"1. 安装celery1234567891011121314151617pip install celery# 使用 librabbitmq 的 C 库pip install librabbitmq# 使用 Redis 作为消息传输方式或结果后端pip install redis# 序列化pip install celery[auth]pip install celery[msgpack]pip install celery[yaml]# 并发pip install eventletpip install geventpip install threads 2. 集成celery1234567891011121314151617from celery import Celerydef make_celery(flask_app): _celery = Celery( flask_app.import_name, backend=flask_app.config[&#x27;CELERY_RESULT_BACKEND&#x27;], broker=flask_app.config[&#x27;CELERY_BROKER_URL&#x27;] ) _celery.conf.update(flask_app.config) class ContextTask(_celery.Task): def __call__(self, *args, **kwargs): with flask_app.app_context(): return self.run(*args, **kwargs) _celery.Task = ContextTask return _celery 1234from flask import Flaskapp = Flask(__name__)celery = make_celery(app) 3. 启动celery123456789celery -A embo.celery worker --loglevel=info# eventlet库有bug，不支持requests库 https请求celery -A embo.celery --broker=amqp://utime:******@localhost:5672/ut_vhost worker -P eventlet -c 1000 --loglevel=infocelery -A embo.celery --broker=amqp://utime:welovetime@localhost:5672/ut_vhost worker --pool=solo --loglevel=info# 开启监控celery flower --broker=amqp://utime::******@localhost:5672/ut_vhost --port=5555 4. 使用supervisord管理1234567891011121314151617181920212223242526272829vi /etc/supervisord.conf.d/celery.conf[program:celery-worker]command=/home/utime/.env/py3/bin/celery -A embo.celery --broker=amqp://utime:******@localhost:5672/ut_vhost worker -n celery@localhost --pool=solo --loglevel=infoautostart=trueautorestart=truedirectory=/data/www/lp-service/user=utimestdout_logfile=/var/log/celery-worker-stdout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/celery-worker-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot;[program:celery-flower]command=/home/utime/.env/py3/bin/celery flower --broker=amqp://utime::******@localhost:5672/ut_vhost --port=5555autostart=trueautorestart=truedirectory=/data/www/lp-service/user=utimestdout_logfile=/var/log/celery-flower-stdout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/celery-flower-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot; 5. 发布任务5.1 异步任务 (发送短信)任务代码： 1234567891011121314151617181920212223242526272829303132import jsonfrom embo import celeryfrom celery.utils.log import get_task_loggerfrom embo.base import errorlogger = get_task_logger(__name__)@celery.task(bind=True)def send_sms_async(self, phone, code): from embo.platforms.smsserver import SmsServer from embo.base.xredis import Redis logger.info(&#x27;send sms to [%s][%s]&#x27; % (phone, code)) try: resp = SmsServer.send_verification_code(phone, code) logger.info(&#x27;resp: %s&#x27; % resp) logger.info(&#x27;resp.text: %s&#x27; % resp.text) ret = json.loads(resp.text).get(&#x27;code&#x27;) == 0 if not ret: raise error.SendSmsFailed except Exception as e: logger.info(&#x27;exception: %s&#x27; % e) raise self.retry(exc=e, countdown=10, max_retries=5) # 成功，将短信写入缓存 Redis.setex(phone, 300, code) return ret 执行任务： 1send_sms_async.delay(phone, code) 5.2 定点时刻任务12345# utc时间action_time = datetime.utcfromtimestamp(clock) + timedelta(minutes=-5)task = add_timed_notify.apply_async(args=(doc.id,), eta=action_time)print(task.id) 6. 错误失败处理6.1 方式一：绑定任务1) bind=True2) def send_sms_async(self3) raise self.retry(exc=e, countdown=10, max_retries=5) retry参数： exc：指定抛出的异常 throw：重试时是否通知worker是重试任务 eta：指定重试的时间／日期 countdown：在多久之后重试（每多少秒重试一次） max_retries：最大重试次数 6.2 方式二：重写Task123456789101112from celery import Taskclass DebugTask(Task): abstract = True def after_return(self, *args, **kwargs): print(&#x27;Task returned: &#123;0!r&#125;&#x27;.format(self.request)@app.task(base=DebugTask)def add(x, y): return x + y Handlers: 1) after_return(self, status, retval, task_id, args, kwargs, einfo)Handler called after the task returns. status – Current task state.retval – Task return value/exception.task_id – Unique id of the task.args – Original arguments for the task that returned.kwargs – Original keyword arguments for the task that returned.einfo – ExceptionInfo instance, containing the traceback (if any).The return value of this handler is ignored. 2) on_failure(self, exc, task_id, args, kwargs, einfo)This is run by the worker when the task fails. exc – The exception raised by the task.task_id – Unique id of the failed task.args – Original arguments for the task that failed.kwargs – Original keyword arguments for the task that failed.einfo – ExceptionInfo instance, containing the traceback.The return value of this handler is ignored. 3) on_retry(self, exc, task_id, args, kwargs, einfo)This is run by the worker when the task is to be retried. exc – The exception sent to retry().task_id – Unique id of the retried task.args – Original arguments for the retried task.kwargs – Original keyword arguments for the retried task.einfo – ExceptionInfo instance, containing the traceback.The return value of this handler is ignored. 4) on_success(self, retval, task_id, args, kwargs)Run by the worker if the task executes successfully. retval – The return value of the task.task_id – Unique id of the executed task.args – Original arguments for the executed task.kwargs – Original keyword arguments for the executed task.The return value of this handler is ignored.","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://elihe2011.github.io/categories/RabbitMQ/"}],"tags":[{"name":"celery","slug":"celery","permalink":"https://elihe2011.github.io/tags/celery/"}]},{"title":"RabbitMQ","slug":"RabbitMQ","date":"2019-10-14T06:04:07.000Z","updated":"2021-06-22T10:50:49.743Z","comments":true,"path":"2019/10/14/RabbitMQ/","link":"","permalink":"https://elihe2011.github.io/2019/10/14/RabbitMQ/","excerpt":"1. RabbitMQ介绍 面向消息的中间件，用于组件之间的解藕，主要体现在消息的发送者和消费者之间无强依赖关系 1.1 消息中间件消息中间件：在消息传输过程中保存消息的容器。主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它为止。当然，消息队列保存消息也是有期限的。 1.1.1 消息中间传递模型： 点对点 (PTP) 发布订阅 (Pub/Sub) 1.1.2 AMQP: Advanced Message Queue Protocol","text":"1. RabbitMQ介绍 面向消息的中间件，用于组件之间的解藕，主要体现在消息的发送者和消费者之间无强依赖关系 1.1 消息中间件消息中间件：在消息传输过程中保存消息的容器。主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它为止。当然，消息队列保存消息也是有期限的。 1.1.1 消息中间传递模型： 点对点 (PTP) 发布订阅 (Pub/Sub) 1.1.2 AMQP: Advanced Message Queue Protocol 1.2 RabbitMQ核心组件： Exchange Queue 1.3 RabbitMQ术语： Server(broker): 接受客户端连接，实现AMQP消息队列和路由功能的进程 Virtual Host: 并不真实存在，类似权限控制组，一个Virtual Host里面可以有若干个Exchange和Queue，但权限控制的最小粒度为Virtual Host Exchange: 接收生产者发送的消息，并根据Binding规则将消息苦雨给服务器中的队列。ExchangeType决定于Exchange路由消息的行为。在RabbitMQ中，ExchangeType有direct、Fanout和Topic三种，不同类型的Exchange路由行为不一样 Message Queue：消息队列，用于存储还未被消费者消费的消息 Message：由Header和Body组成，Header是生产者添加的各种属性的集合，包含Message是否被持久化、由那个Message Queue接受，优先级是多少等。而Body则是真正需要传输的APP数据 BindingKey: 绑定关键字。绑定就是将一个特定的Exchange和一个特定的Queue绑定起来。 1.4 Exchange分类： Direct Exchange：直接交互式路由键。需要将一个队列绑定到交换机上，要求该消息一一个特定的路由完全匹配。例如一个队列绑定到该交换机上要求路由键为”dog”，只有被标记为”dog”的消息能够被转发。 Fanout Exchange: 广播式路由键。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。 Topic Exchange：主题式交换器。通过消息的路由关键字和绑定的关键字的模糊匹配，将消息路由到被绑定的队列中。支持通配符：*匹配一个词组，#零个或多个词组。*.stock.#匹配路由关键字usd.stock和eur.stock.db，但不匹配stock.nasdaq 2. 安装RabbitMQRabbitMQ 3.7.19: Upgrading to Erlang 21.x or Later Versions 2.1 安装12345678910111213141516yum repolist yum clean allyum makecache yum list erlangcd /etc/yum.repos.d/# erlangcurl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh | sudo bashyum install erlang# rabbitmqcurl -s https://packagecloud.io/install/repositories/rabbitmq/rabbitmq-server/script.rpm.sh | sudo bashyum install rabbitmq-server-3.7.19-1.el7 2.2 RabbitMQ配置文件(默认没有)1) /etc/rabbitmq/rabbitmq-env.conf 1234RABBITMQ_NODE_IP_ADDRESS: 127.0.0.1RABBITMQ_NODE_PORT: 5672RABBITMQ_NODE_CONFIG_FILE: *.configRABBITMQ_NODE_LOG_BASE: 2) /etc/rabbitmq/rabbitmq.config 123tcp_listeners 5672disk_free_limitvm_memory_high_watermark 0.4 2.3 启动123systemctl enable rabbitmq-serversystemctl start rabbitmq-server 2.4 Mac安装RabbitMQ123456789101112131415brew install rabbitmq# 配置环境变量export RABBIT_HOME=/usr/local/Cellar/rabbitmq/3.8.0export PATH=$PATH:$RABBIT_HOME/sbin# 启动\b服务sudo rabbitmq-serversudo rabbitmq-server -detached # 后台运行# 停止服务rabbitmqctl stop# 配置文件位置cd /usr/local/etc/rabbitmq 3. rabbitmq控制命令3.1 插件命令12345# 插件列表rabbitmq-plugins list# 开启管理工具 （支持http://localhost:15672/）rabbitmq-plugins enable rabbitmq_management 3.2 操作命令1234567891011121314151617181920212223# 虚拟主机rabbitmqctl add_vhost ut_vhostrabbitmqctl list_vhosts# 新增账号rabbitmqctl add_user utime welovetimerabbitmqctl list_users# 修改密码rabbitmqctl change_password utime utime@celery123# 设置tagsudo rabbitmqctl set_user_tags utime administrator# 设置权限rabbitmqctl set_permissions -p ut_vhost utime &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;rabbitmqctl list_permissions# 队列状态rabbitmqctl list_queues rabbitmqctl list_queues name messages messages_ready messages_unacknowledged rabbitmqctl list_queues name consumersrabbitmqctl list_queues name memory 4. RabbitMQ核心概念 Virtual Host: 数据隔离 Connection: Exchange: 交换机，中转消息 Channel: 通信 Queue: 队列，绑定交换机；临时存储消息 Binding: 绑定队列到交换机 5. RabbitMQ的工作模式5.1 Simple模式1go get github.com/streadway/amqp 最简单常用的模式 P -&gt; Queue -&gt; C 12345678910111213141516171819202122232425func NewRabbitMQ(queueName, exchange, key string) *RabbitMQ &#123; return &amp;RabbitMQ&#123; QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL, &#125;&#125;// 设置queueNamefunc NewRabbitMQPubSub(queueName string) *RabbitMQ &#123; rabbitmq := NewRabbitMQ(queueName, &quot;&quot;, &quot;&quot;) var err error // 创建连接 rabbitmq.conn, err = amqp.Dial(rabbitmq.Mqurl) rabbitmq.failOnErr(err, &quot;创建连接失败&quot;) // 创建channel rabbitmq.channel, err = rabbitmq.conn.Channel() rabbitmq.failOnErr(err, &quot;获取channel失败&quot;) return rabbitmq&#125; 5.2 Work, 工作模式一个消息只能被一个消费者获取。与Simple模式的区别，只在于开启了多个消费者端，负载均衡。 P -&gt; Queue –&gt; C1, C2, … 5.3 Publish/Subscribe, 订阅模式消息被路由投递给多个队列，一个消息被多个消费者获取 P -&gt; X -&gt; Queue -&gt; C1 | Queue -&gt; C2 12345678910111213141516171819202122232425func NewRabbitMQ(queueName, exchange, key string) *RabbitMQ &#123; return &amp;RabbitMQ&#123; QueueName: queueName, Exchange: exchange, Key: key, Mqurl: MQURL, &#125;&#125;// 设置exchangeNamefunc NewRabbitMQPubSub(exchangeName string) *RabbitMQ &#123; rabbitmq := NewRabbitMQ(&quot;&quot;, exchangeName, &quot;&quot;) var err error // 创建连接 rabbitmq.conn, err = amqp.Dial(rabbitmq.Mqurl) rabbitmq.failOnErr(err, &quot;创建连接失败&quot;) // 创建channel rabbitmq.channel, err = rabbitmq.conn.Channel() rabbitmq.failOnErr(err, &quot;获取channel失败&quot;) return rabbitmq&#125; 5.4 Routing, 路由模式一个消息被多个消费者获取，并且消息的目标队列可被生产者指定","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://elihe2011.github.io/categories/RabbitMQ/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://elihe2011.github.io/tags/rabbitmq/"}]},{"title":"远程端口检查","slug":"远程端口检查","date":"2019-10-12T03:39:18.000Z","updated":"2021-06-22T10:50:49.742Z","comments":true,"path":"2019/10/12/远程端口检查/","link":"","permalink":"https://elihe2011.github.io/2019/10/12/%E8%BF%9C%E7%A8%8B%E7%AB%AF%E5%8F%A3%E6%A3%80%E6%9F%A5/","excerpt":"","text":"1. telnet1telnet baidu.com 80 2. nc (NetCat)1nc -v baidu.com 80 3. nmap1nmap baidu.com -p 80","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"sudo","slug":"sudo","date":"2019-10-10T02:32:10.000Z","updated":"2021-06-22T10:50:49.742Z","comments":true,"path":"2019/10/10/sudo/","link":"","permalink":"https://elihe2011.github.io/2019/10/10/sudo/","excerpt":"1. sudo条目语法1who host=(runas) TAG:command 2. 配置示例123456789visudooracle ALL=(root) NOPASSWD:/sbin/useradd, PASSWD:/sbin/userdel%admin ALL=(root) NOPASSWD:/sbin/shutdownweb ALL=(operator) /etc/webhook/mytest.shtest ALL=(ALL) /bin/cat /var/log/secure*, !/bin/cat /var/log/secure* *","text":"1. sudo条目语法1who host=(runas) TAG:command 2. 配置示例123456789visudooracle ALL=(root) NOPASSWD:/sbin/useradd, PASSWD:/sbin/userdel%admin ALL=(root) NOPASSWD:/sbin/shutdownweb ALL=(operator) /etc/webhook/mytest.shtest ALL=(ALL) /bin/cat /var/log/secure*, !/bin/cat /var/log/secure* * 3. 执行sudo123456su - oraclesudo /sbin/useradd test123su - websudo -u operator /etc/webhook/mytest.sh","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Hexo","slug":"Hexo","date":"2019-09-24T08:06:10.000Z","updated":"2021-06-22T10:50:49.742Z","comments":true,"path":"2019/09/24/Hexo/","link":"","permalink":"https://elihe2011.github.io/2019/09/24/Hexo/","excerpt":"1. 安装hexo12345678npm install hexo-cli -g hexo init blogcd blognpm installhexo serv","text":"1. 安装hexo12345678npm install hexo-cli -g hexo init blogcd blognpm installhexo serv 2. 安装主题123git clone https://github.com/xaoxuu/hexo-theme-material-x themes/material-xnpm i -S hexo-generator-search hexo-generator-json-content hexo-renderer-less","categories":[{"name":"Tools","slug":"Tools","permalink":"https://elihe2011.github.io/categories/Tools/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://elihe2011.github.io/tags/hexo/"}]},{"title":"Nginx安装配置","slug":"Nginx安装","date":"2019-09-19T02:32:10.000Z","updated":"2021-06-22T10:50:49.741Z","comments":true,"path":"2019/09/19/Nginx安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/19/Nginx%E5%AE%89%E8%A3%85/","excerpt":"1. 添加nginx用户123groupadd nginx useradd -g nginx -s /sbin/nologin -M nginx","text":"1. 添加nginx用户123groupadd nginx useradd -g nginx -s /sbin/nologin -M nginx 2. 安装123456789101112131415161718192021wget http://openresty.org/download/openresty-1.15.8.2.tar.gztar zxvf openresty-1.15.8.2.tar.gzcd openresty-1.15.8.2# 解决openssl支撑包问题, 删除.opensslvi bundle/nginx-1.15.8/auto/lib/openssl/confCORE_INCS=&quot;$CORE_INCS $OPENSSL/.openssl/include&quot;CORE_DEPS=&quot;$CORE_DEPS $OPENSSL/.openssl/include/openssl/ssl.h&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libssl.a&quot;CORE_LIBS=&quot;$CORE_LIBS $OPENSSL/.openssl/lib/libcrypto.a&quot;./configure -j2 --prefix=/usr/local/openresty --with-openssl=/usr/local/opensslmakemake installvi ~/.bash_profileexport PATH=/usr/local/openresty/nginx/sbin:/usr/local/openresty/bin:$PATH 3. 开机启动1234567891011121314151617vi /usr/lib/systemd/system/nginx.serviceDescription=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/openresty/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 4. 管理ngnix123systemctl enable nginx.servicesystemctl start nginx 5. 配置123456789101112131415161718192021222324252627282930313233343536373839404142mkdir -p /usr/local/openresty/nginx/conf.dvi /usr/local/openresty/nginx/conf/nginx.confhttp &#123; # 去除注释 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27; &#x27;$request_time $upstream_response_time&#x27;; ... # 节点末尾添加 include /usr/local/openresty/nginx/conf.d/*.conf;&#125;vi /usr/local/openresty/nginx/conf.d/test.confserver &#123; listen 80; server_name 192.168.1.21; access_log /var/log/nginx/embo.access.log main; error_log /var/log/nginx/embo.error.log; error_page 404 = /404; error_page 403 = /403; location / &#123; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; #include proxy_params; proxy_pass http://127.0.0.1:20002/; proxy_redirect off; &#125; location = / &#123; root /data/www/lp-web/; index index.html; &#125; location ~* \\.(html|ico)$ &#123; root /data/www/lp-web/; &#125;&#125; 6. nginx相关命令1234567nginxnginx -tnginx -s stopnginx -s reload 7. 安装问题7.1 PCRE未安装1234567891011121314checking for SA_RESTART ... found + ngx_stream_lua_module was configuredchecking for PCRE library ... not foundchecking for PCRE library in /usr/local/ ... not foundchecking for PCRE library in /usr/include/pcre/ ... not foundchecking for PCRE library in /usr/pkg/ ... not foundchecking for PCRE library in /opt/local/ ... not found./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 1yum -y install pcre-devel 8. systemctl启动服务，日志异常12345Dec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Starting nginx.service...Dec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal nginx[26980]: nginx: the configuration file /usr/local/openresty/nginx/conf/nginx.conf syntax is okDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal nginx[26980]: nginx: configuration file /usr/local/openresty/nginx/conf/nginx.conf test is successfulDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Failed to read PID from file /usr/local/openresty/nginx/logs/nginx.pid: Invalid argumentDec 09 10:19:11 ip-172-31-12-17.cn-northwest-1.compute.internal systemd[1]: Started nginx.service. 原因：启动成功瞬间，暂未找到nginx.pid文件 解决：增加睡眠时间 123456789101112131415161718vi /usr/lib/systemd/system/nginx.serviceDescription=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/openresty/nginx/logs/nginx.pid ExecStartPre=/usr/local/openresty/nginx/sbin/nginx -t -c /usr/local/openresty/nginx/conf/nginx.conf ExecStart=/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf ExecStartPost=/bin/sleep 0.1 # 新增项ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 12345systemctl daemon-reloadsystemctl restart nginx.servicesystemctl status nginx","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://elihe2011.github.io/tags/nginx/"}]},{"title":"Supervisor安装配置","slug":"Supervisor安装","date":"2019-09-16T03:11:14.000Z","updated":"2021-06-22T10:50:49.741Z","comments":true,"path":"2019/09/16/Supervisor安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/16/Supervisor%E5%AE%89%E8%A3%85/","excerpt":"1. 安装12345678910su - rootpip3 install supervisor/usr/local/python37/bin/echo_supervisord_conf &gt; /etc/supervisord.conf#supervisord -c /etc/supervisord.confln -s /usr/local/python37/bin/supervisord /usr/bin/supervisordln -s /usr/local/python37/bin/supervisorctl /usr/bin/supervisorctl","text":"1. 安装12345678910su - rootpip3 install supervisor/usr/local/python37/bin/echo_supervisord_conf &gt; /etc/supervisord.conf#supervisord -c /etc/supervisord.confln -s /usr/local/python37/bin/supervisord /usr/bin/supervisordln -s /usr/local/python37/bin/supervisorctl /usr/bin/supervisorctl 2. 修改配置123456789101112131415161718192021mkdir -p /etc/supervisord.conf.dvi /etc/supervisord.conf[unix_http_server];file=/tmp/supervisor.sock ; the path to the socket filefile=/var/run/supervisor.sock ;[supervisord];logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.loglogfile=/var/log/supervisord.log ;;pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pidpidfile=/var/run/supervisord.pid ;[supervisorctl];serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socketserverurl=unix:///var/run/supervisor.sock ;[include]files = /etc/supervisord.conf.d/*.conf 3. 开机启动12345678910111213141516vi /usr/lib/systemd/system/supervisord.service[Unit] Description=Supervisor daemon[Service] Type=forking ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf ExecStop=/usr/bin/supervisorctl shutdown ExecReload=/usr/bin/supervisorctl reload KillMode=process Restart=on-failure RestartSec=42s[Install] WantedBy=multi-user.target 4. 系统管理12345systemctl enable supervisordsystemctl start supervisordps -ef | grep supervisor 5. 新增配置5.1 webhhok12345678910111213141516171819vi /etc/supervisord.conf.d/webhook.conf [program:webhook]user=utimedirectory=/tmp/command=webhookit -c /etc/webhook/config.py -p 18340autostart=trueautorestart=truestartretries=10exitcodes=0stopsignal=KILLstopwaitsecs=10redirect_stderr=truestdout_logfile=/var/log/webhook-out.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/webhook-error.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5 5.2 业务123456789101112131415vi /etc/supervisord.conf.d/lp-service.conf[program:lp-service]command=/home/utime/.venv/py3/bin/gunicorn -b 127.0.0.1:20002 --worker-class eventlet -w 4 manage:app --access-logfile /tmp/lp-service-gunicorn.logautostart=trueautorestart=truedirectory=/home/utime/lp-service/user=utimestdout_logfile=/var/log/lp-service-stdout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/lp-service-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot; 6. 启动123supervisorctl updatesupervisorctl status","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"supervisor","slug":"supervisor","permalink":"https://elihe2011.github.io/tags/supervisor/"}]},{"title":"Python Supervisor","slug":"Python Supervisor","date":"2019-09-15T03:12:17.000Z","updated":"2021-06-22T10:50:49.726Z","comments":true,"path":"2019/09/15/Python Supervisor/","link":"","permalink":"https://elihe2011.github.io/2019/09/15/Python%20Supervisor/","excerpt":"1. 安装和配置1.1 安装1234pip install supervisor# 生成配置文件","text":"1. 安装和配置1.1 安装1234pip install supervisor# 生成配置文件 1.2 主配置文件/etc/supervisord/supervisord.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136[unix_http_server]file=/tmp/supervisor.sock ; the path to the socket file;chmod=0700 ; socket file mode (default 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; default is no username (open server);password=123 ; default is no password (open server);[inet_http_server] ; inet (TCP) server disabled by default;port=127.0.0.1:9001 ; ip_address:port specifier, *:port for all iface;username=user ; default is no username (open server);password=123 ; default is no password (open server)[supervisord]logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.loglogfile_maxbytes=50MB ; max main logfile bytes b4 rotation; default 50MBlogfile_backups=10 ; # of main logfile backups; 0 means none, default 10loglevel=debug ; log level; default info; others: debug,warn,tracepidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pidnodaemon=false ; start in foreground if true; default falseminfds=1024 ; min. avail startup file descriptors; default 1024minprocs=200 ; min. avail process descriptors;default 200;umask=022 ; process file creation umask; default 022;user=chrism ; default is current user, required if root;identifier=supervisor ; supervisord identifier, default is &#x27;supervisor&#x27;;directory=/tmp ; default is not to cd during start;nocleanup=true ; don&#x27;t clean up tempfiles at start; default false;childlogdir=/tmp ; &#x27;AUTO&#x27; child log dir, default $TEMP;environment=KEY=&quot;value&quot; ; key value pairs to add to environment;strip_ansi=false ; strip ansi escape codes in logs; def. false; The rpcinterface:supervisor section must remain in the config file for; RPC (supervisorctl/web interface) to work. Additional interfaces may be; added by defining them in separate [rpcinterface:x] sections.[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface; The supervisorctl section configures how supervisorctl will connect to; supervisord. configure it match the settings in either the unix_http_server; or inet_http_server section.[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as in [*_http_server] if set;password=123 ; should be same as in [*_http_server] if set;prompt=mysupervisor ; cmd line prompt (default &quot;supervisor&quot;);history_file=~/.sc_history ; use readline history if available; The sample program section below shows all possible program subsection values.; Create one or more &#x27;real&#x27; program: sections to be able to control them under; supervisor.;[program:theprogramname];command=/bin/cat ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=999 ; the relative start priority (default 999);autostart=true ; start at supervisord start (default: true);startsecs=1 ; # of secs prog must stay up to be running (def. 1);startretries=3 ; max # of serial start failures when starting (default 3);autorestart=unexpected ; when to restart if exited after running (def: unexpected);exitcodes=0,2 ; &#x27;expected&#x27; exit codes used with autorestart (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=true ; redirect proc stderr to stdout (default false);stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10);stdout_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=&quot;1&quot;,B=&quot;2&quot; ; process environment additions (def no adds);serverurl=AUTO ; override serverurl computation (childutils); The sample eventlistener section below shows all possible eventlistener; subsection values. Create one or more &#x27;real&#x27; eventlistener: sections to be; able to handle event notifications sent by supervisord.;[eventlistener:theeventlistenername];command=/bin/eventlistener ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);events=EVENT ; event notif. types to subscribe to (req&#x27;d);buffer_size=10 ; event buffer queue size (default 10);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=-1 ; the relative start priority (default -1);autostart=true ; start at supervisord start (default: true);startsecs=1 ; # of secs prog must stay up to be running (def. 1);startretries=3 ; max # of serial start failures when starting (default 3);autorestart=unexpected ; autorestart if exited after running (def: unexpected);exitcodes=0,2 ; &#x27;expected&#x27; exit codes used with autorestart (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=false ; redirect_stderr=true is not allowed for eventlisteners;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=&quot;1&quot;,B=&quot;2&quot; ; process environment additions;serverurl=AUTO ; override serverurl computation (childutils); The sample group section below shows all possible group values. Create one; or more &#x27;real&#x27; group: sections to create &quot;heterogeneous&quot; process groups.;[group:thegroupname];programs=progname1,progname2 ; each refers to &#x27;x&#x27; in [program:x] definitions;priority=999 ; the relative start priority (default 999); The [include] section can just contain the &quot;files&quot; setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.;[include];files = relative/directory/*.ini[include]files = /etc/supervisord.conf.d/*.conf 2. 相关命令1234567891011121314151617181920# 查看所有守护的进程supervisorctl# 添加新配置，会自动启动新增配置supervisorctl update# 重启配置中的所有程序supervisorctl reload# 启动进程supervisorctl start lp-doc# 停止进程supervisorctl stop lp-doc# 重启进程supervisorctl restart lp-doc# 停止全部进程，update和reload将不再自动启动进程supervisorctl stop all 3. 实例3.1 webhook实例12cat /etc/supervisord.conf.d/webhook.confsupervisorctl restart webhook 1234567891011121314151617[program:webhook]user=utimedirectory=/tmp/command=webhookit -c /etc/webhook/config.py -p 18340autostart=trueautorestart=truestartretries=10exitcodes=0stopsignal=KILLstopwaitsecs=10redirect_stderr=truestdout_logfile=/var/log/webhook-out.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/webhook-error.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5 3.2 新增程序12cat /etc/supervisord.conf.d/lp-doc.confsupervisorctl update 1234567891011121314151617181920212223[program:lp-doc]command=/home/utime/.env/lp-service/bin/gunicorn -b 127.0.0.1:20030 --worker-class eventlet -w 2 manage:app --access-logfile /tmp/lp-doc-gunicorn.logautostart=trueautorestart=truedirectory=/data/www/lp-doc/user=utimestdout_logfile=/var/log/lp-doc-strout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/lp-doc-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot;[program:embo-persist-content]command=/home/utime/.env/lp-service/bin/python -u service/persistence_worker.pynumprocs=1autostart=trueautorestart=truedirectory=/data/www/lp-doc/user=utimestdout_logfile=/var/log/embo-persist-content-stdout.logstderr_logfile=/var/log/embo-persist-content-stderr.log","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python安装配置","slug":"Python安装","date":"2019-09-15T03:12:17.000Z","updated":"2021-06-22T10:50:49.741Z","comments":true,"path":"2019/09/15/Python安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/15/Python%E5%AE%89%E8%A3%85/","excerpt":"1. 安装支撑包1yum install zlib-devel bzip2-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel xz-devel gdbm-devel 2. 升级 openssl2.1 检查openssl，版本需要满足1.1.X1/usr/bin/openssl version","text":"1. 安装支撑包1yum install zlib-devel bzip2-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel xz-devel gdbm-devel 2. 升级 openssl2.1 检查openssl，版本需要满足1.1.X1/usr/bin/openssl version 2.2 升级openssl1234567891011121314151617181920212223cd ~wget http://www.openssl.org/source/openssl-1.1.1c.tar.gztar zxvf openssl-1.1.1c.tar.gzcd openssl-1.1.1c./config --prefix=/usr/local/openssl no-zlib makemake installecho &quot;export LD_LIBRARY_PATH=/usr/local/openssl/lib&quot; &gt; /etc/profile.d/openssl.shexport LD_LIBRARY_PATH=/usr/local/openssl/libmv /usr/bin/openssl /usr/bin/openssl.$(date &quot;+%Y%m%d&quot;)mv /usr/include/openssl /usr/include/openssl.$(date &quot;+%Y%m%d&quot;)ln -s /usr/local/openssl/include/openssl /usr/include/opensslln -s /usr/local/openssl/bin/openssl /usr/bin/openssl# 增加动态库搜索路径echo &#x27;/usr/local/openssl/lib&#x27; &gt; /etc/ld.so.conf.d/openssl.confldconfig -v | grep ssl 3. 安装Python 3.712345678910111213141516cd ~wget https://www.python.org/ftp/python/3.7.7/Python-3.7.7.tgztar zxvf Python-3.7.7.tgzcd Python-3.7.7./configure --prefix=/usr/local/python37 --with-openssl=/usr/local/openssl | grep sslchecking for openssl/ssl.h in /usr/local/openssl... yeschecking for X509_VERIFY_PARAM_set1_host in libssl... yeschecking for --with-ssl-default-suites... pythonmake # 注意检查_ssl是否已正确包含make installln -s /usr/local/python37/bin/python3 /usr/bin/python3ln -s /usr/local/python37/bin/pip3 /usr/bin/pip3 4. 添加业务运行用户12useradd -d /home/utime su - utime 5. 配置pip国内源1234567mkdir -p ~/.pipvi ~/.pip/pip.conf[global]index-url = http://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com 6. 虚拟环境6.1 环境创建123mkdir ~/.envcd ~/.envpython3 -m venv py3 6.2 安装项目支撑包1234cd /data/www/lp-servicesource ~/.venv/py3/bin/activatepip install -r requirements.txt # 包含gunicorn","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Webhook安装配置","slug":"Webhook安装","date":"2019-09-14T01:45:17.000Z","updated":"2021-06-22T10:50:49.740Z","comments":true,"path":"2019/09/14/Webhook安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/14/Webhook%E5%AE%89%E8%A3%85/","excerpt":"1. 包选择网易git-webhook 旧版本, 比较简洁的webhook 以旧版本安装为例 2. 安装pip2python3支持较差, 继续系统自带使用python2.7, 需要单独安装pip 123curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pypython get-pip.py","text":"1. 包选择网易git-webhook 旧版本, 比较简洁的webhook 以旧版本安装为例 2. 安装pip2python3支持较差, 继续系统自带使用python2.7, 需要单独安装pip 123curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pypython get-pip.py 3. 安装webhook12pip install tornado==4.5.1 # 先装tornado, 避免webhookit自动安装最新的tornado, 导致问题pip install webhookit 4. 配置webhook123mkdir /etc/webhook webhookit_config &gt; /etc/webhook/config.py 5. 新增执行脚本123456789101112131415161718192021222324252627282930vi /etc/webhook/publish.lp-service.sh#!/usr/bin/env bashLOG=&quot;/tmp/publish.lp-service.log&quot;begin_at=$(date &quot;+%Y-%m-%d %H:%M:%S&quot;)echo &quot;--BEGIN [$&#123;begin_at&#125;] -----------------&quot; &gt;&gt; $&#123;LOG&#125;# work directoryTARGET=&quot;/data/www/lp-service&quot;mkdir -p $&#123;TARGET&#125;# pull the latest codecd /data/git/lp-servicegit checkout developgit pull# deploy code\\cp -r /data/git/lp-service/* $&#123;TARGET&#125;# restart processecho &quot;Restart process [lp-service]&quot; | tee -a $&#123;LOG&#125;ps aux | grep &quot;manage:app&quot; | grep -v &quot;lp-doc&quot; | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | while read piddo echo $pid kill $piddoneend_at=$(date &quot;+%Y-%m-%d %H:%M:%S&quot;)echo &quot;--END [$&#123;end_at&#125;] -----------------&quot; &gt;&gt; $&#123;LOG&#125; 6. 添加执行脚本1234567891011vi /etc/webhook/config.py WEBHOOKIT_CONFIGURE = &#123; &#x27;lp-service/refs/heads/develop&#x27;: [&#123; &#x27;HOST&#x27;: &#x27;&#x27;, &#x27;PORT&#x27;: &#x27;&#x27;, &#x27;USER&#x27;: &#x27;&#x27;, &#x27;PWD&#x27;: &#x27;&#x27;, &#x27;SCRIPT&#x27;: &#x27;/etc/webhook/publish.lp-service.sh&#x27; &#125;],&#125;","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"webhook","slug":"webhook","permalink":"https://elihe2011.github.io/tags/webhook/"}]},{"title":"Redis安装配置","slug":"Redis安装","date":"2019-09-13T04:00:17.000Z","updated":"2021-06-22T10:50:49.740Z","comments":true,"path":"2019/09/13/Redis安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/13/Redis%E5%AE%89%E8%A3%85/","excerpt":"1. 安装12345678910111213141516wget http://download.redis.io/releases/redis-5.0.5.tar.gz tar zxvf redis-5.0.5.tar.gzcd redis-5.0.5makemkdir -p /usr/local/rediscp redis.conf /usr/local/rediscp src/redis-server /usr/local/rediscp src/redis-cli /usr/local/redisln -s /usr/local/redis/redis-server /usr/bin/redis-serverln -s /usr/local/redis/redis-cli /usr/bin/redis-cli","text":"1. 安装12345678910111213141516wget http://download.redis.io/releases/redis-5.0.5.tar.gz tar zxvf redis-5.0.5.tar.gzcd redis-5.0.5makemkdir -p /usr/local/rediscp redis.conf /usr/local/rediscp src/redis-server /usr/local/rediscp src/redis-cli /usr/local/redisln -s /usr/local/redis/redis-server /usr/bin/redis-serverln -s /usr/local/redis/redis-cli /usr/bin/redis-cli 2. 配置123vi /usr/local/redis/redis.confdaemonize yes 3. 开机启动123456789101112131415vi /etc/systemd/system/redis-server.service[Unit]Description=The redis-server Process ManagerAfter=syslog.target network.target[Service]Type=simplePIDFile=/var/run/redis_6379.pidExecStart=/usr/local/redis/redis-server /usr/local/redis/redis.confExecReload=/bin/kill -USR2 $MAINPIDExecStop=/bin/kill -SIGINT $MAINPID[Install]WantedBy=multi-user.target 4. 管理12345systemctl enable redis-server.servicesystemctl daemon-reloadsystemctl start redis-server 5. 相关命令12345678910111213redis-server /etc/redis.confredis-benchmark ： 用于测试redis的性能。redis-check-aof : 当aof备份文件被损坏，可通过该工具对aof文件进行修复，使用方式：redis-check-aof --fix 要修复的aof文件。redis-check-rdb : 修复损坏的rdb备份文件。redis-cli : redis客户端，用于连接服务端。redis-server ： redis服务器端，用于启动redis服务器。redis-sentinel : 哨兵模式（实际使用较多） 在master-slave模式下（slave默认不支持写），当master出现异常时，自动在slave中选择一台作为master。 6. 常用配置项12345678910bind 127.0.0.1 服务IPprotected-mode yes # 以保护模式运行，只接受本地链接，不能外网访问port 6379 daemonize no # 是否后台运行，若为yes，客户端窗口将被锁定maxmemory # 最大使用内存maxmemory-policy # 内存达到最大值时的驱逐策略 7. 数据持久化支持两种模式：RDB和AOF RDB：rdb方式的持久化是通过快照完成的，当符合一定条件时redis会自动将内存中的所有数据执行快照操作并存储到硬盘上。默认存储在redis根目录的dump.rdb文件中。(文件名在配置文件中dbfilename) redis进行快照的时机（在配置文件redis.conf中） save 900 1：表示900秒内至少一个键被更改则进行快照。 save 300 10 save 60 10000 dbfilename dump.rdb 快照保存文件名dir ./ 快照保存地址 也可通过redis客服端执行命令save或者bgsave保存快照： 两个命令的区别在于，save是由主进程进行快照操作，会阻塞其它请求。bgsave是由redis执行fork函数复制出一个子进程来进行快照操作。文件修复：redis-check-dumprdb的优缺点优点：由于存储的有数据快照文件，恢复数据很方便。缺点：会丢失最后一次快照以后更改的所有数据。 AOF:aof方式的持久化是通过日志文件的方式，记录下redis服务器的每一条修改指令。默认情况下redis没有开启aof，可以通过参数appendonly参数开启。appendonly yesaof文件的保存位置和rdb文件的位置相同，都是dir参数设置的，默认的文件名是appendonly.aof，可以通过 appendfilename参数修改appendfilename appendonly.aofredis写命令同步的时机： appendfsync always 每次都会执行 appendfsync everysec 默认 每秒执行一次同步操作（推荐，默认） appendfsync no不主动进行同步，由操作系统来做，30秒一次 redis服务器启动时会读取appendonly.aof中的指令，进行执行，这样便保证了重启后数据不会丢失。 注意：当redis启动时，如果rdb持久化和aof持久化都打开了，那么程序会优先使用aof方式来恢复数据集，因为aof方式所保存的数据通常是最完整的。","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://elihe2011.github.io/tags/redis/"}]},{"title":"MongoDB安装配置","slug":"MongoDB安装","date":"2019-09-12T03:12:17.000Z","updated":"2021-06-22T10:50:49.739Z","comments":true,"path":"2019/09/12/MongoDB安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/12/MongoDB%E5%AE%89%E8%A3%85/","excerpt":"1. 配置yum源12345678vi /etc/yum.repos.d/mongodb-org-3.6.repo[mongodb-org-3.6]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/gpgcheck=0enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc","text":"1. 配置yum源12345678vi /etc/yum.repos.d/mongodb-org-3.6.repo[mongodb-org-3.6]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/gpgcheck=0enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc 2. 安装MongoDB123yum makecacheyum install mongodb-org 3. 修改配置123456789101112131415161718192021222324252627282930vi /etc/mongod.confsystemLog: destination: file path: /var/log/mongodb.log logAppend: truestorage: journal: enabled: true dbPath: /data/mongodb/wtfunds directoryPerDB: true engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 4 directoryForIndexes: true collectionConfig: blockCompressor: zlib indexConfig: prefixCompression: truenet: bindIp: 127.0.0.1 port: 27017# clusterRole: shardsvr# how the process runsprocessManagement: fork: true 4. 启动1systemctl start mongod","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://elihe2011.github.io/tags/mongodb/"}]},{"title":"MySQL安装配置","slug":"MySQL安装","date":"2019-09-11T08:34:17.000Z","updated":"2021-06-22T10:50:49.739Z","comments":true,"path":"2019/09/11/MySQL安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/11/MySQL%E5%AE%89%E8%A3%85/","excerpt":"1. 环境检查123rpm -qa | grep mysqlrpm -e mysql-libs --nodeps 2. mysql安装源2.1 安装yum源1rpm -ivh http://repo.mysql.com/yum/mysql-5.7-community/el/6/x86_64/mysql-community-release-el6-7.noarch.rpm","text":"1. 环境检查123rpm -qa | grep mysqlrpm -e mysql-libs --nodeps 2. mysql安装源2.1 安装yum源1rpm -ivh http://repo.mysql.com/yum/mysql-5.7-community/el/6/x86_64/mysql-community-release-el6-7.noarch.rpm 2.2 修改yum源1234567891011121314151617vi /etc/yum.repos.d/mysql-community.repo# Disable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/6/$basearch/enabled=0 # 1 =&gt; 0gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.7[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/6/$basearch/enabled=1 # 0 =&gt; 1gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 3. 安装1yum install mysql-community-client mysql-community-devel mysql-community-server 4. 修改配置123456vi /etc/my.cnf[mysqld]innodb_file_per_table = 1 # 独立表空间模式，每个数据库的每个表都会生成一个数据目录innodb_buffer_pool_size = 512M # 默认值：128M，设置为操作系统内存的70%-80%最佳 5. 启动数据库1service mysqld start 6. 配置账号密码1mysqladmin -uroot password &#x27;mypass&#x27; 7. 创建数据库123456mysql -uroot -pcreate database `test` DEFAULT CHARSET utf8mb4 COLLATE utf8mb4_unicode_ci;grant all privileges on *.* to root@&#x27;%&#x27;;flush privileges; 8. 导出导入数据123mysqldump -uroot -p embo &gt; embo.sqlmysql -uroot -p embo &lt; embo.sql","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://elihe2011.github.io/tags/mysql/"}]},{"title":"Git安装配置","slug":"Git安装","date":"2019-09-10T06:22:17.000Z","updated":"2021-06-22T10:50:49.739Z","comments":true,"path":"2019/09/10/Git安装/","link":"","permalink":"https://elihe2011.github.io/2019/09/10/Git%E5%AE%89%E8%A3%85/","excerpt":"1. 安装1yum install git 2. 配置12345678ssh-keygen -t rsa -C &quot;abc@test.com&quot;cat ~/.ssh/id_rsa.pub # 粘贴到gitlabgit config --global user.name usernamegit config --global user.email abc@test.comssh -p 10022 -T git@IP","text":"1. 安装1yum install git 2. 配置12345678ssh-keygen -t rsa -C &quot;abc@test.com&quot;cat ~/.ssh/id_rsa.pub # 粘贴到gitlabgit config --global user.name usernamegit config --global user.email abc@test.comssh -p 10022 -T git@IP 3. 拉取代码123makdir ~/gitcd ~/gitgit clone ssh://git@IP:10022/abc/test.git","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"git","slug":"git","permalink":"https://elihe2011.github.io/tags/git/"}]},{"title":"Go RabbitMQ","slug":"Go RabbitMQ","date":"2019-07-25T07:28:26.000Z","updated":"2021-06-22T10:50:49.738Z","comments":true,"path":"2019/07/25/Go RabbitMQ/","link":"","permalink":"https://elihe2011.github.io/2019/07/25/Go%20RabbitMQ/","excerpt":"","text":"1. RabbitMQ1.1 AMQPAdvanced Message Queuing Protocol 高级消息队列协议 (消息中间件) 消息中间件的作用： 解藕 削峰 异步处理 缓存存储 消息通知 提供系统的拓展性 1.2 主要概念 Producer Consumer RabbitMQ Broker: 单机时为 RabbitMQ 服务器 Queue: 存储消息数据 Binding: 交换机(Exchange) 将 消息(Message) 路由给 队列(Queue) 所遵循的规则 RoutingKey: 路由规则 Exchange: fanout: 扇形交换机。消息分发到所有与该交换机相连的队列中。忽略RoutingKey，直接“广播”到绑定的队列中 direct: 直连交换机。根据消息携带的RoutingKey来投递消息到对应的队列中。不指定RoutingKey，在此类型下创建的Queue，RoutingKey名称与Queue一致 topic: 主题交换机。RoutingKey中使用 . 来分割；BindingKey中也使用 . 来分割，另外用 *(匹配一个单词) 和 #(匹配任意个单词) 来进行模糊匹配 RoutingKey。 headers 2. Golang 使用 RabbitMQ2.1 安装支撑包1go get github.com/streadway/amqp 2.2 基础队列2.2.1 连接 RabbitMQ123456789func GetRabbitMQConn() (*amqp.Connection, error) &#123; username := &quot;guest&quot; password := &quot;guest&quot; host := &quot;127.0.0.1&quot; port := 5672 url := fmt.Sprintf(&quot;amqp://%s:%s@%s:%d&quot;, username, password, host, port) return amqp.Dial(url)&#125; 2.2.2 生产者123456789101112131415161718192021222324252627282930313233343536373839type demo struct &#123; Name string `json:&quot;name&quot;` Addr string `json:&quot;addr&quot;`&#125;func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() data := demo&#123; Name: &quot;Jack&quot;, Addr: &quot;Montreal&quot;, &#125; bs, _ := json.Marshal(data) err = ch.Publish( &quot;&quot;, // exchange &quot;simple:queue&quot;, // key, RoutingKey, same as Queue.Name when the exchange mode is direct. false, // mandatory false, // immediate amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, Body: bs, &#125;) if err != nil &#123; log.Fatalf(&quot;Failed to publish a message: %v&quot;, err) &#125; log.Printf(&quot;[*] sent %s&quot;, bs)&#125; 2.2.3 消费者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() q, err := ch.QueueDeclare( &quot;simple:queue&quot;, // name false, // durable false, // autoDelete false, // exclusive false, // noWait nil, // args ) if err != nil &#123; log.Fatalf(&quot;Failed to declare a queue: %v&quot;, err) &#125; // 定义一个消费者 msgs, err := ch.Consume( q.Name, // queue (string) &quot;&quot;, // consumer true, // autoAck false, // exclusive false, // noLocal false, // noWait nil, // args ) if err != nil &#123; log.Fatalf(&quot;Failed to register a consume: %v&quot;, err) &#125; go func() &#123; for msg := range msgs &#123; log.Printf(&quot;Received a message: %s\\n&quot;, msg.Body) &#125; &#125;() log.Println(&quot;[*] Waiting for messages. To exit press CTRL+C&quot;) select &#123;&#125;&#125; 2.3 任务队列为了避免等待执行一些耗时的任务, 而是将需要执行的任务封装为消息发送给工作队列, 后台运行的工作进程将任务消息取出来并执行相关任务。多个后台工作进程同时间进行, 那么任务在他们之间共享. 2.3.1 发布任务 (task.py)12345678910111213141516171819202122232425262728293031323334353637383940414243func bodyForm(args []string) string &#123; var s string if (len(args) &lt; 2) || os.Args[1] == &quot;&quot; &#123; s = &quot;no task&quot; &#125; else &#123; s = strings.Join(args[1:], &quot; &quot;) &#125; return s&#125;func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() body := bodyForm(os.Args) err = ch.Publish( &quot;&quot;, &quot;task:queue&quot;, false, false, amqp.Publishing&#123; ContentType: &quot;text/plain&quot;, DeliveryMode: amqp.Persistent, Body: []byte(body), &#125;, ) if err != nil &#123; log.Fatalf(&quot;Failed to publish a message&quot;) &#125; log.Printf(&quot;sent %s\\n&quot;, body)&#125; 2.3.2 执行任务 (worker.py)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func main() &#123; conn, err := GetRabbitMQConn() if err != nil &#123; log.Fatalf(&quot;Failed to connect to RabbitMQ: %v&quot;, err) &#125; defer conn.Close() ch, err := conn.Channel() if err != nil &#123; log.Fatalf(&quot;Failed to open a channel: %v&quot;, err) &#125; defer ch.Close() q, err := ch.QueueDeclare( &quot;task:queue&quot;, false, false, false, false, nil, ) if err != nil &#123; log.Fatalf(&quot;Failed to declare a queue: %v&quot;, err) &#125; // 计数器 err = ch.Qos( 1, // prefetch count 0, // prefetch size false, // global ) if err != nil &#123; log.Fatalf(&quot;Failed to set Qos: %v&quot;, err) &#125; msgs, err := ch.Consume( q.Name, &quot;&quot;, false, false, false, false, nil, ) if err != nil &#123; log.Fatalf(&quot;Failed to register a consumer: %v&quot;, err) &#125; done := make(chan bool) go func() &#123; for msg := range msgs &#123; log.Printf(&quot;Received a message: %s\\n&quot;, msg.Body) msg.Ack(false) &#125; &#125;() log.Printf(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;) &lt;-done&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://elihe2011.github.io/tags/rabbitmq/"}]},{"title":"Go gRPC Gateway","slug":"Go gRPC Gateway","date":"2019-07-20T07:18:06.000Z","updated":"2021-06-22T10:50:49.737Z","comments":true,"path":"2019/07/20/Go gRPC Gateway/","link":"","permalink":"https://elihe2011.github.io/2019/07/20/Go%20gRPC%20Gateway/","excerpt":"1. gRPC 回顾总结1.1 gRPC1go get -u google.golang.org/grpc 强大的 IDL，使用 Protocol Buffers 作为数据交换格式 跨语言、跨平台 支持HTTP2，双向传输、多路复用、认证等 grpc下常用包： metadata: 提供方法对 grpc 元数据结构MD 进行获取和处理 credentials: 封装了客户端对服务端进行身份验证所需的所有状态，并做出各种断言 codes: grpc 标准错误码","text":"1. gRPC 回顾总结1.1 gRPC1go get -u google.golang.org/grpc 强大的 IDL，使用 Protocol Buffers 作为数据交换格式 跨语言、跨平台 支持HTTP2，双向传输、多路复用、认证等 grpc下常用包： metadata: 提供方法对 grpc 元数据结构MD 进行获取和处理 credentials: 封装了客户端对服务端进行身份验证所需的所有状态，并做出各种断言 codes: grpc 标准错误码 1.2 Protoc Plugin编译插件 1go get -u github.com/golang/protobuf/protoc-gen-go 1.3 Protocol Buffers v3Google 推出的一种数据描述语言，支持多语言、跨平台，二进制格式。 1.4 protocProtocol Buffers 运用程序 123456wget https://github.com/google/protobuf/releases/download/v3.5.1/protobuf-all-3.5.1.zipunzip protobuf-all-3.5.1.zipcd protobuf-3.5.1/./configuremakemake install 生成 golang 源文件： 1protoc --go_out=plugins=grpc,import_path=mypkg:. *.proto 2. gRPC-Gatewaygrpc-gateway 是proto的一个插件，它读取gRPC服务定义，并生成一个反向代理服务器，将RESTful JSON API转换为gRPC. 2.1 安装1go get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gateway 2.2 proto文件2.2.1 google.apigoogle 官方提供的 api 描述文件，主要针对 grpc-gateway 的 http 转换支持，定义了 Protocol Buffer 所扩展的 HTTP Option 1) annotations.proto 1234567891011121314151617181920212223242526272829// Copyright (c) 2015, Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.syntax = &quot;proto3&quot;;package google.api;import &quot;google/api/http.proto&quot;;import &quot;google/protobuf/descriptor.proto&quot;;option java_multiple_files = true;option java_outer_classname = &quot;AnnotationsProto&quot;;option java_package = &quot;com.google.api&quot;;extend google.protobuf.MethodOptions &#123; // See `HttpRule`. HttpRule http = 72295728;&#125; 2) http.proto 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281// Copyright 2016 Google Inc.//// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);// you may not use this file except in compliance with the License.// You may obtain a copy of the License at//// http://www.apache.org/licenses/LICENSE-2.0//// Unless required by applicable law or agreed to in writing, software// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.// See the License for the specific language governing permissions and// limitations under the License.syntax = &quot;proto3&quot;;package google.api;option cc_enable_arenas = true;option java_multiple_files = true;option java_outer_classname = &quot;HttpProto&quot;;option java_package = &quot;com.google.api&quot;;// Defines the HTTP configuration for a service. It contains a list of// [HttpRule][google.api.HttpRule], each specifying the mapping of an RPC method// to one or more HTTP REST API methods.message Http &#123; // A list of HTTP rules for configuring the HTTP REST API methods. repeated HttpRule rules = 1;&#125;// `HttpRule` defines the mapping of an RPC method to one or more HTTP// REST APIs. The mapping determines what portions of the request// message are populated from the path, query parameters, or body of// the HTTP request. The mapping is typically specified as an// `google.api.http` annotation, see &quot;google/api/annotations.proto&quot;// for details.//// The mapping consists of a field specifying the path template and// method kind. The path template can refer to fields in the request// message, as in the example below which describes a REST GET// operation on a resource collection of messages://// ```proto// service Messaging &#123;// rpc GetMessage(GetMessageRequest) returns (Message) &#123;// option (google.api.http).get = &quot;/v1/messages/&#123;message_id&#125;/&#123;sub.subfield&#125;&quot;;// &#125;// &#125;// message GetMessageRequest &#123;// message SubMessage &#123;// string subfield = 1;// &#125;// string message_id = 1; // mapped to the URL// SubMessage sub = 2; // `sub.subfield` is url-mapped// &#125;// message Message &#123;// string text = 1; // content of the resource// &#125;// ```//// This definition enables an automatic, bidrectional mapping of HTTP// JSON to RPC. Example://// HTTP | RPC// -----|-----// `GET /v1/messages/123456/foo` | `GetMessage(message_id: &quot;123456&quot; sub: SubMessage(subfield: &quot;foo&quot;))`//// In general, not only fields but also field paths can be referenced// from a path pattern. Fields mapped to the path pattern cannot be// repeated and must have a primitive (non-message) type.//// Any fields in the request message which are not bound by the path// pattern automatically become (optional) HTTP query// parameters. Assume the following definition of the request message://// ```proto// message GetMessageRequest &#123;// message SubMessage &#123;// string subfield = 1;// &#125;// string message_id = 1; // mapped to the URL// int64 revision = 2; // becomes a parameter// SubMessage sub = 3; // `sub.subfield` becomes a parameter// &#125;// ```//// This enables a HTTP JSON to RPC mapping as below://// HTTP | RPC// -----|-----// `GET /v1/messages/123456?revision=2&amp;sub.subfield=foo` | `GetMessage(message_id: &quot;123456&quot; revision: 2 sub: SubMessage(subfield: &quot;foo&quot;))`//// Note that fields which are mapped to HTTP parameters must have a// primitive type or a repeated primitive type. Message types are not// allowed. In the case of a repeated type, the parameter can be// repeated in the URL, as in `...?param=A&amp;param=B`.//// For HTTP method kinds which allow a request body, the `body` field// specifies the mapping. Consider a REST update method on the// message resource collection://// ```proto// service Messaging &#123;// rpc UpdateMessage(UpdateMessageRequest) returns (Message) &#123;// option (google.api.http) = &#123;// put: &quot;/v1/messages/&#123;message_id&#125;&quot;// body: &quot;message&quot;// &#125;;// &#125;// &#125;// message UpdateMessageRequest &#123;// string message_id = 1; // mapped to the URL// Message message = 2; // mapped to the body// &#125;// ```//// The following HTTP JSON to RPC mapping is enabled, where the// representation of the JSON in the request body is determined by// protos JSON encoding://// HTTP | RPC// -----|-----// `PUT /v1/messages/123456 &#123; &quot;text&quot;: &quot;Hi!&quot; &#125;` | `UpdateMessage(message_id: &quot;123456&quot; message &#123; text: &quot;Hi!&quot; &#125;)`//// The special name `*` can be used in the body mapping to define that// every field not bound by the path template should be mapped to the// request body. This enables the following alternative definition of// the update method://// ```proto// service Messaging &#123;// rpc UpdateMessage(Message) returns (Message) &#123;// option (google.api.http) = &#123;// put: &quot;/v1/messages/&#123;message_id&#125;&quot;// body: &quot;*&quot;// &#125;;// &#125;// &#125;// message Message &#123;// string message_id = 1;// string text = 2;// &#125;// ```//// The following HTTP JSON to RPC mapping is enabled://// HTTP | RPC// -----|-----// `PUT /v1/messages/123456 &#123; &quot;text&quot;: &quot;Hi!&quot; &#125;` | `UpdateMessage(message_id: &quot;123456&quot; text: &quot;Hi!&quot;)`//// Note that when using `*` in the body mapping, it is not possible to// have HTTP parameters, as all fields not bound by the path end in// the body. This makes this option more rarely used in practice of// defining REST APIs. The common usage of `*` is in custom methods// which don&#x27;t use the URL at all for transferring data.//// It is possible to define multiple HTTP methods for one RPC by using// the `additional_bindings` option. Example://// ```proto// service Messaging &#123;// rpc GetMessage(GetMessageRequest) returns (Message) &#123;// option (google.api.http) = &#123;// get: &quot;/v1/messages/&#123;message_id&#125;&quot;// additional_bindings &#123;// get: &quot;/v1/users/&#123;user_id&#125;/messages/&#123;message_id&#125;&quot;// &#125;// &#125;;// &#125;// &#125;// message GetMessageRequest &#123;// string message_id = 1;// string user_id = 2;// &#125;// ```//// This enables the following two alternative HTTP JSON to RPC// mappings://// HTTP | RPC// -----|-----// `GET /v1/messages/123456` | `GetMessage(message_id: &quot;123456&quot;)`// `GET /v1/users/me/messages/123456` | `GetMessage(user_id: &quot;me&quot; message_id: &quot;123456&quot;)`//// # Rules for HTTP mapping//// The rules for mapping HTTP path, query parameters, and body fields// to the request message are as follows://// 1. The `body` field specifies either `*` or a field path, or is// omitted. If omitted, it assumes there is no HTTP body.// 2. Leaf fields (recursive expansion of nested messages in the// request) can be classified into three types:// (a) Matched in the URL template.// (b) Covered by body (if body is `*`, everything except (a) fields;// else everything under the body field)// (c) All other fields.// 3. URL query parameters found in the HTTP request are mapped to (c) fields.// 4. Any body sent with an HTTP request can contain only (b) fields.//// The syntax of the path template is as follows://// Template = &quot;/&quot; Segments [ Verb ] ;// Segments = Segment &#123; &quot;/&quot; Segment &#125; ;// Segment = &quot;*&quot; | &quot;**&quot; | LITERAL | Variable ;// Variable = &quot;&#123;&quot; FieldPath [ &quot;=&quot; Segments ] &quot;&#125;&quot; ;// FieldPath = IDENT &#123; &quot;.&quot; IDENT &#125; ;// Verb = &quot;:&quot; LITERAL ;//// The syntax `*` matches a single path segment. It follows the semantics of// [RFC 6570](https://tools.ietf.org/html/rfc6570) Section 3.2.2 Simple String// Expansion.//// The syntax `**` matches zero or more path segments. It follows the semantics// of [RFC 6570](https://tools.ietf.org/html/rfc6570) Section 3.2.3 Reserved// Expansion.//// The syntax `LITERAL` matches literal text in the URL path.//// The syntax `Variable` matches the entire path as specified by its template;// this nested template must not contain further variables. If a variable// matches a single path segment, its template may be omitted, e.g. `&#123;var&#125;`// is equivalent to `&#123;var=*&#125;`.//// NOTE: the field paths in variables and in the `body` must not refer to// repeated fields or map fields.//// Use CustomHttpPattern to specify any HTTP method that is not included in the// `pattern` field, such as HEAD, or &quot;*&quot; to leave the HTTP method unspecified for// a given URL path rule. The wild-card rule is useful for services that provide// content to Web (HTML) clients.message HttpRule &#123; // Selects methods to which this rule applies. // // Refer to [selector][google.api.DocumentationRule.selector] for syntax details. string selector = 1; // Determines the URL pattern is matched by this rules. This pattern can be // used with any of the &#123;get|put|post|delete|patch&#125; methods. A custom method // can be defined using the &#x27;custom&#x27; field. oneof pattern &#123; // Used for listing and getting information about resources. string get = 2; // Used for updating a resource. string put = 3; // Used for creating a resource. string post = 4; // Used for deleting a resource. string delete = 5; // Used for updating a resource. string patch = 6; // Custom pattern is used for defining custom verbs. CustomHttpPattern custom = 8; &#125; // The name of the request field whose value is mapped to the HTTP body, or // `*` for mapping all fields not captured by the path pattern to the HTTP // body. NOTE: the referred field must not be a repeated field. string body = 7; // Additional HTTP bindings for the selector. Nested bindings must // not contain an `additional_bindings` field themselves (that is, // the nesting may only be one level deep). repeated HttpRule additional_bindings = 11;&#125;// A custom pattern is used for defining custom HTTP verb.message CustomHttpPattern &#123; // The name of this custom HTTP verb. string kind = 1; // The path matched by this custom verb. string path = 2;&#125; 2.2.2 hello.proto12345678910111213141516171819202122syntax = &quot;proto3&quot;;package proto;import &quot;google/api/annotations.proto&quot;;service HelloWorld &#123; rpc SayHelloWorld(HelloWorldRequest) returns (HelloWorldResponse) &#123; option (google.api.http) = &#123; post: &quot;/hello_world&quot; body: &quot;*&quot; &#125;; &#125;&#125;message HelloWorldRequest &#123; string referer = 1;&#125;message HelloWorldResponse &#123; string message = 1;&#125; 2.3 编译 proto12345678# 编译google.apiprotoc -I . --go_out=plugins=grpc,Mgoogle/protobuf/descriptor.proto=github.com/golang/protobuf/protoc-gen-go/descriptor:. google/api/*.proto# 编译hello_http.proto为hello_http.pb.protoprotoc -I . --go_out=plugins=grpc,Mgoogle/api/annotations.proto=go-grpc-example/proto/google/api:. ./hello.proto# 编译hello_http.proto为hello_http.pb.gw.protoprotoc --grpc-gateway_out=logtostderr=true:. ./hello.proto 3. 命令行模块3.1 安装Cobra命令行工具1go get -u github.com/spf13/cobra 1) root.go 12345678910var rootCmd = &amp;cobra.Command&#123; Use: &quot;grpc&quot;, Short: &quot;Run the gRPC hello-world server&quot;,&#125;func Execute() &#123; if err := rootCmd.Execute(); err != nil &#123; log.Fatalf(&quot;rootCmd.Execute err: %v&quot;, err) &#125;&#125; 2) server.go 12345678910111213141516171819202122var serverCmd = &amp;cobra.Command&#123; Use: &quot;server&quot;, Short: &quot;Run the gRPC hello-world server&quot;, Run: func(cmd *cobra.Command, args []string) &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Println(&quot;Recover error: %v&quot;, err) &#125; &#125;() server.Serve() &#125;,&#125;func init() &#123; serverCmd.Flags().StringVarP(&amp;server.ServerPort, &quot;port&quot;, &quot;p&quot;, &quot;9005&quot;, &quot;server port&quot;) serverCmd.Flags().StringVarP(&amp;server.CertPath, &quot;cert&quot;, &quot;c&quot;, &quot;../../certs/server.pem&quot;, &quot;cert path&quot;) serverCmd.Flags().StringVarP(&amp;server.KeyPath, &quot;key&quot;, &quot;k&quot;, &quot;../../certs/server.key&quot;, &quot;key path&quot;) serverCmd.Flags().StringVarP(&amp;server.CertName, &quot;name&quot;, &quot;n&quot;, &quot;go-grpc-example&quot;, &quot;server hostname&quot;) rootCmd.AddCommand(serverCmd)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go gRPC","slug":"Go gRPC","date":"2019-07-18T01:23:17.000Z","updated":"2021-06-22T10:50:49.737Z","comments":true,"path":"2019/07/18/Go gRPC/","link":"","permalink":"https://elihe2011.github.io/2019/07/18/Go%20gRPC/","excerpt":"1. RPC1.1 什么是RPCRPC: Remote Procedure Call，远程过程调用。调用过程包括传输协议和对象编码（序列化）。 1.2 RPC框架 负载均衡 服务注册和发现 服务治理 1.3 为什么使用RPC简单、通用、安全、效率","text":"1. RPC1.1 什么是RPCRPC: Remote Procedure Call，远程过程调用。调用过程包括传输协议和对象编码（序列化）。 1.2 RPC框架 负载均衡 服务注册和发现 服务治理 1.3 为什么使用RPC简单、通用、安全、效率 2. ProtobufProtocol Buffers 是一种与语言、平台无关，可扩展的序列化结构化数据的方法，常用于通信协议、数据存储等。相较于JSON、XML，它更小、更快、更简单。 123456789101112131415syntax = &quot;proto3&quot;;service SearchService &#123; rpc Search (SearchRequest) returns (SearchResponse);&#125;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125;message SearchResponse &#123; ...&#125; 3. gRPCgRPC 是一个高性能、开源和通用的RPC框架，面向移动和 HTTP/2 设计 特点： HTTP/2 Protobuf 客户端、服务端基于同一份IDL 移动网络支持良好 支持多语言 3.1 安装gRPC: 1go get -u google.golang.org/grpc Protocol Buffers v3: 12brew search protobufbrew install protobuf@3.6 Protoc Plugin: 12345# 会自动编译安装protoc-gen-go可执行插件文件go get -u github.com/golang/protobuf/protoc-gen-go# 编译安装 (不要做这个操作，应该使用上面一个protoc-gen-go)#go install google.golang.org/protobuf/cmd/protoc-gen-go 3.2 入门3.2.1 编写 IDL1234567891011121314151617syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;; // 重要package proto;service SearchService &#123; rpc Search(SearchRequest) returns (SearchResponse) &#123;&#125;&#125;message SearchRequest &#123; string request = 1;&#125;message SearchResponse &#123; string response = 1;&#125; 3.2.2 生成 pb.go文件1234protoc --go_out=. *.proto# 比前一个多了注册函数等protoc --go_out=plugins=grpc:. *.proto 3.2.3 服务端12345678910111213141516171819type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;const HOST = &quot;:9001&quot;func main() &#123; server := grpc.NewServer() pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, HOST) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 3.2.4 客户端1234567891011121314151617func main() &#123; conn, err := grpc.Dial(HOST, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 4. gRPC 流gRPC 的流式，有三种类型： Server-side Streaming Client-side Streaming Bidirectional Streaming 适合用 Streaming RPC 的场景： 大规模数据包 实时场景 4.1 IDL 和 基础模板1234567891011121314151617181920212223242526syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;;package proto;service StreamService &#123; rpc List(StreamRequest) returns (stream StreamResponse) &#123;&#125;; rpc Record(stream StreamRequest) returns (stream StreamResponse) &#123;&#125;; rpc Route(stream StreamRequest) returns (stream StreamResponse) &#123;&#125;;&#125;message StreamPoint &#123; string name = 1; int32 value = 2;&#125;message StreamRequest &#123; StreamPoint pt = 1;&#125;message StreamResponse &#123; StreamPoint pt = 1;&#125; 服务器： 1234567891011121314151617181920212223func main() &#123; server := grpc.NewServer() pb.RegisterStreamServiceServer(server, &amp;StreamService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9002&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error &#123; return nil&#125;func (s *StreamService) Record(stream pb.StreamService_RecordServer) error &#123; return nil&#125;func (s *StreamService) Route(stream pb.StreamService_RouteServer) error &#123; return nil&#125; 客户端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func main() &#123; conn, err := grpc.Dial(&quot;:9002&quot;, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;grpc.Dial err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewStreamServiceClient(conn) err = printList(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: List&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printList.err: %v&quot;, err) &#125; err = printRecord(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: Record&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printRecord.err: %v&quot;, err) &#125; err = printRoute(client, &amp;pb.StreamRequest&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Client: Route&quot;, Value: 2020, &#125;, &#125;) if err != nil &#123; log.Fatalf(&quot;printRoute.err: %v&quot;, err) &#125;&#125;func printList(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125;func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125;func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; return nil&#125; 4.2 服务器端流式 RPC 单向流 Server 为 Stream，多次向客户端发送数据 Client 为普通 RPC 请求 4.2.1 服务端12345678910111213141516func (s *StreamService) List(r *pb.StreamRequest, stream pb.StreamService_ListServer) error &#123; for n := 0; n &lt;= 6; n++ &#123; err := stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: r.Pt.Name, Value: r.Pt.Value + int32(n), &#125;, &#125;) if err != nil &#123; return nil &#125; &#125; return nil&#125; stream.Send() 方法： 12345678type StreamService_ListServer interface &#123; Send(*StreamResponse) error grpc.ServerStream&#125;func (x *streamServiceListServer) Send(m *StreamResponse) error &#123; return x.ServerStream.SendMsg(m)&#125; SendMsg() 方法： 消息体（对象）序列化 压缩序列化后的消息体 对正在传输的消息体增加5个字节的header 判断消息体总长度是否大于预设的maxSendMessageSize (默认math.MaxInt32)，超过则报错 写入给流的数据集 4.2.2 客户端12345678910111213141516171819202122func printList(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.List(context.Background(), r) if err != nil &#123; return err &#125; for &#123; resp, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;resp: pt.name: %s, pt.value: %d\\n&quot;, resp.Pt.Name, resp.Pt.Value) &#125; return nil&#125; stream.Recv()方法： 12345678910111213type StreamService_ListClient interface &#123; Recv() (*StreamResponse, error) grpc.ClientStream&#125;func (x *streamServiceListClient) Recv() (*StreamResponse, error)&#123; m := new(StreamResponse) if err := x.ClientStream.RecvMsg(m); err != nil &#123; return nil, err &#125; return m, nil&#125; RecvMsg()方法： 阻塞等待 流结束 (Close)时，返回 io.EOF 可能的错误 io.EOF io.ErrUnexpectedEOF transport.ConnectionError google.golang.org/grpc/codes 4.3 客户端流式RPC 单向流 客户端多次RPC请求服务端 服务端发起一次响应给客户端 4.3.1 服务端12345678910111213141516171819func (s *StreamService) Record(stream pb.StreamService_RecordServer) error &#123; for &#123; r, err := stream.Recv() if err == io.EOF &#123; return stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gRPC Stream Server: Record&quot;, Value: 1, &#125;, &#125;) &#125; if err != nil &#123; return err &#125; log.Printf(&quot;stream.Recv pt.name: %s, pt.value: %d&quot;, r.Pt.Name, r.Pt.Value) &#125; return nil&#125; 4.3.2 客户端12345678910111213141516171819202122232425262728func printRecord(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.Record(context.Background()) if err != nil &#123; return err &#125; for n := 0; n &lt; 6; n++ &#123; err := stream.Send(r) if err != nil &#123; return err &#125; &#125; // 主动关闭send err = stream.CloseSend() if err != nil &#123; return err &#125; resp, err := stream.Recv() if err != nil &#123; return nil &#125; log.Printf(&quot;resp: pt.name: %s, pt.value: %d&quot;, resp.Pt.Name, resp.Pt.Value) return nil&#125; 4.4 双向流RPC4.4.1 服务端12345678910111213141516171819202122232425262728func (s *StreamService) Route(stream pb.StreamService_RouteServer) error &#123; n := 0 for &#123; err := stream.Send(&amp;pb.StreamResponse&#123; Pt: &amp;pb.StreamPoint&#123; Name: &quot;gPRC Stream Client: Route&quot;, Value: int32(n), &#125;, &#125;) if err != nil &#123; return err &#125; r, err := stream.Recv() if err == io.EOF &#123; return nil &#125; if err != nil &#123; return err &#125; n++ log.Printf(&quot;stream.Recv pt.name: %s, pt.value: %d&quot;, r.Pt.Name, r.Pt.Value) &#125; return nil&#125; 4.4.2 客户端12345678910111213141516171819202122232425262728func printRoute(client pb.StreamServiceClient, r *pb.StreamRequest) error &#123; stream, err := client.Route(context.Background()) if err != nil &#123; return err &#125; for n := 0; n &lt; 6; n++ &#123; err = stream.Send(r) if err != nil &#123; return err &#125; resp, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;resp: pt.name: %s, pt.value %d&quot;, resp.Pt.Name, resp.Pt.Value) &#125; stream.CloseSend() return nil&#125; 5. TLS 证书认证5.1 生成证书5.1.1 私钥1openssl ecparam -genkey -name secp384r1 -out server.key 5.1.2 自签公钥1openssl req -new -x509 -sha256 -key server.key -out server.pem -days 3650 5.2 服务端123456789101112131415161718192021222324252627type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;const HOST = &quot;:9001&quot;func main() &#123; // 1. 支持TLS creds, err := credentials.NewServerTLSFromFile(&quot;../certs/server.pem&quot;, &quot;../certs/server.key&quot;) if err != nil &#123; log.Fatalf(&quot;credentials.NewServerTLSFromFile err: %v&quot;, err) &#125; // 2. 加入认证 server := grpc.NewServer(grpc.Creds(creds)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, HOST) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 5.3 客户端1234567891011121314151617181920212223242526const HOST = &quot;:9001&quot;func main() &#123; // 1. 支持TLS creds, err := credentials.NewClientTLSFromFile(&quot;../certs/server.pem&quot;, &quot;go-grpc-example&quot;) if err != nil &#123; log.Fatalf(&quot;credentials.NewClientTLSFromFile err: %v&quot;, err) &#125; // 2. 传输认证 conn, err := grpc.Dial(HOST, grpc.WithTransportCredentials(creds)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 6. 基于 CA 的 TLS 证书认证6.1 CA6.1.1 生成CA证书根证书(root certificate)是属于根证书颁发机构（CA）的公钥证书。可以通过验证CA的签名从而信任CA，任何人都可以得到CA的证书（含公钥），用以验证它所签发的证书。 12345# 生成Keyopenssl genrsa -out ca.key 2048# 生成密钥openssl req -new -x509 -days 7200 -key ca.key -out ca.pem 6.1.2 服务端证书CSR: Cerificate Signing Request，证书请求文件。主要作用是 CA 会利用 CSR 文件进行签名使得攻击者无法伪装或篡改原有证书。 12345# 生成CSRopenssl req -new -key server.key -out server.csr# 基于CA签发openssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in server.csr -out server.pem 6.1.3 客户端证书12345678# 生成Keyopenssl ecparam -genkey -name secp384r1 -out client.key# 生成CSRopenssl req -new -key client.key -out client.csr# 基于CA签发openssl x509 -req -sha256 -CA ca.pem -CAkey ca.key -CAcreateserial -days 3650 -in client.csr -out client.pem 6.2 TLS认证代码6.2.1 服务端认证123456789101112131415161718192021222324252627282930313233343536373839type Server struct &#123; CaFile string CertFile string KeyFile string&#125;func (t *Server) GetCredentialsByCA() (credentials.TransportCredentials, error) &#123; cert, err := tls.LoadX509KeyPair(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; ca, err := ioutil.ReadFile(t.CaFile) if err != nil &#123; return nil, err &#125; certPool := x509.NewCertPool() if ok := certPool.AppendCertsFromPEM(ca); !ok &#123; return nil, errors.New(&quot;certPool.AppendCertsFromPEM err&quot;) &#125; c := credentials.NewTLS(&amp;tls.Config&#123; Certificates: []tls.Certificate&#123;cert&#125;, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, &#125;) return c, nil&#125;func (t *Server) GetTLSCredentials() (credentials.TransportCredentials, error) &#123; c, err := credentials.NewServerTLSFromFile(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; return c, nil&#125; 6.2.2 客户端认证12345678910111213141516171819202122232425262728293031323334353637383940type Client struct &#123; ServerName string CaFile string CertFile string KeyFile string&#125;func (t *Client) GetCredentialsByCA() (credentials.TransportCredentials, error) &#123; cert, err := tls.LoadX509KeyPair(t.CertFile, t.KeyFile) if err != nil &#123; return nil, err &#125; ca, err := ioutil.ReadFile(t.CaFile) if err != nil &#123; return nil, err &#125; certPool := x509.NewCertPool() if ok := certPool.AppendCertsFromPEM(ca); !ok &#123; return nil, errors.New(&quot;certPool.AppendCertsFromPEM err&quot;) &#125; c := credentials.NewTLS(&amp;tls.Config&#123; Certificates: []tls.Certificate&#123;cert&#125;, ServerName: t.ServerName, RootCAs: certPool, &#125;) return c, nil&#125;func (t *Client) GetTLSCredentials() (credentials.TransportCredentials, error) &#123; c, err := credentials.NewClientTLSFromFile(t.CertFile, t.ServerName) if err != nil &#123; return nil, err &#125; return c, nil&#125; 6.3 实现代码6.3.1 服务端1234567891011121314151617181920212223242526272829type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125; 6.3.2 客户端1234567891011121314151617181920212223242526272829func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/client.pem&quot;, KeyFile: &quot;../../certs/client.key&quot;, &#125; c, err := tlsClient.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetCredentialsByCA err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9001&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 大致流程： Client 通过请求得到 Server 端的证书 使用 CA 认证的根证书对 Server 端证书进行可靠性、有效性等校验 校验 ServerName 是否有效 同样，在设置了 tls.RequireAndVerifyClientCert 模式下，Server 也会使用 CA 认证的根证书对Client的证书进行可靠性、有效性校验。 6.4 补充知识点：ssl/tls 单向认证双向认证 单向认证：只有一个对象校验对端的证书合法性。通常client来校验服务器的合法性。那么client需要一个ca.crt,服务器需要server.crt,server.key。 双向认证：相互校验，服务器需要校验每个client,client也需要校验服务器。server 需要 server.key、server.crt、ca.crt，client 需要 client.key、client.crt、ca.crt。 7. 拦截器7.1 Unary and Stream interceptor 普通方法：一元拦截器 grpc.UnaryInterceptor 流方法：流拦截器 grpc.StreamInterceptor 7.1.1 grpc.UnaryInterceptor12345678910func UnaryInterceptor(i UnaryServerInterceptor) ServerOption &#123; return func(o *options) &#123; if o.unaryInt != nil &#123; panic(&quot;The unary server interceptor was already set and may not be reset.&quot;) &#125; o.unaryInt = i &#125;&#125;type UnaryServerInterceptor func(ctx context.Context, req interface&#123;&#125;, info *UnaryServerInfo, handler UnaryHandler) (resp interface&#123;&#125;, err error) 7.1.2 grpc.StreamInterceptor123func StreamInterceptor(i StreamServerInterceptor) ServerOptionstype StreamServerInterceptor func(srv interface&#123;&#125;, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error 7.2 实现多个拦截器gRPC本身只能设置一个拦截器，但可以采用go-grpc-middleware项目来解决问题 12345678910import &quot;github.com/grpc-ecosystem/go-grpc-middleware&quot;myServer := grpc.NewServer( grpc.StreamInterceptor(grpc_middleware.ChainStreamServer( ... )), grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer( ... )),) 7.3 实现 logging 和 recover 拦截器7.3.1 logging123456func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125; 7.3.2 recover12345678910func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 7.3.3 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; // 服务选项 opts := []grpc.ServerOption&#123; grpc.Creds(c), grpc_middleware.WithUnaryServerChain( RecoveryInterceptor, LoggingInterceptor, ), &#125; server := grpc.NewServer(opts...) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125;func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 8. 同时提供 HTTP 服务8.1 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; http.ListenAndServeTLS( &quot;:9003&quot;, &quot;../../certs/server.pem&quot;, &quot;../../certs/server.key&quot;, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if r.ProtoMajor == 2 &amp;&amp; strings.Contains(r.Header.Get(&quot;Content-Type&quot;), &quot;application/grpc&quot;) &#123; GetHTTPServeGrpc().ServeHTTP(w, r) &#125; else &#123; GetHTTPServeMux().ServeHTTP(w, r) &#125; &#125;), )&#125;func GetHTTPServeGrpc() *grpc.Server &#123; tlsServer := gtls.Server&#123; CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetTLSCredentials err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) return server&#125;func GetHTTPServeMux() *http.ServeMux &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/&quot;, func(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte(&quot;result: go-grpc-example&quot;)) &#125;) return mux&#125; 8.2 gRPC 客户端123456789101112131415161718192021222324252627func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CertFile: &quot;../../certs/server.pem&quot;, &#125; c, err := tlsClient.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetTLSCredentials err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9003&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 8.3 http/1.1 直接访问123curl -k --cert client.pem --key client.key https://127.0.0.1:9003curl -k --cacert ca.pem https://127.0.0.1:9003 9. 自定义认证9.1 自定义认证接口1234567type PerRPCCredentials interface &#123; // 获取当前请求认证所需的元数据 (metadata) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) // 是否需要基于TLS认证安全传输 RequireTransportSecurity() bool&#125; 9.2 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273type SearchService struct &#123; auth *Auth&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; if err := s.auth.Check(ctx); err != nil &#123; return nil, err &#125; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetTLSCredentials err: %v&quot;, err) &#125; server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9004&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;type Auth struct &#123; appKey string appSecret string&#125;func (a *Auth) Check(ctx context.Context) error &#123; md, ok := metadata.FromIncomingContext(ctx) if !ok &#123; return status.Errorf(codes.Unauthenticated, &quot;metadata.FromIncomingContext err&quot;) &#125; var ( appKey string appSecret string ) if value, ok := md[&quot;app_key&quot;]; ok &#123; appKey = value[0] &#125; if value, ok := md[&quot;app_secret&quot;]; ok &#123; appSecret = value[0] &#125; if appKey != a.GetAppKey() || appSecret != a.GetAppSecret() &#123; return status.Errorf(codes.Unauthenticated, &quot;invalid token&quot;) &#125; return nil&#125;func (a *Auth) GetAppKey() string &#123; return &quot;wx20200719163021&quot;&#125;func (a *Auth) GetAppSecret() string &#123; return &quot;7d13b90ae8e40c0160209c4a985b3bdf01321b15&quot;&#125; 9.3 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type Auth struct &#123; AppKey string AppSecret string&#125;func (a *Auth) GetRequestMetadata(ctx context.Context, uri ...string) (map[string]string, error) &#123; return map[string]string&#123; &quot;app_key&quot;: a.AppKey, &quot;app_secret&quot;: a.AppSecret, &#125;, nil&#125;func (a *Auth) RequireTransportSecurity() bool &#123; return true&#125;func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CertFile: &quot;../../certs/server.pem&quot;, &#125; c, err := tlsClient.GetTLSCredentials() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetTLSCredentials err: %v&quot;, err) &#125; auth := Auth&#123; AppKey: &quot;wx20200719163021&quot;, AppSecret: &quot;7d13b90ae8e40c0160209c4a985b3bdf01321b15&quot;, &#125; conn, err := grpc.Dial(&quot;:9004&quot;, grpc.WithTransportCredentials(c), grpc.WithPerRPCCredentials(&amp;auth)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125; 10. gRPC Deadline10.1 为什么要设置Deadline? 未设置 Deadlines 时，将采用默认的 DEADLINE_EXCEEDED（该时间非常大） 产生阻塞等待时，会造成大量正在进行的请求被保留，直到这些请求都达到最大超时 会导致资源耗尽的风险，也会增加服务的延迟，最坏时可能导致整个进出崩溃 10.2 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061type SearchService struct&#123;&#125;func (s *SearchService) Search(ctx context.Context, r *pb.SearchRequest) (*pb.SearchResponse, error) &#123; // Deadline if ctx.Err() == context.Canceled &#123; return nil, status.Errorf(codes.Canceled, &quot;SearchService.Search canceled&quot;) &#125; return &amp;pb.SearchResponse&#123;Response: r.GetRequest() + &quot; Server&quot;&#125;, nil&#125;func main() &#123; tlsServer := gtls.Server&#123; CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/server.pem&quot;, KeyFile: &quot;../../certs/server.key&quot;, &#125; c, err := tlsServer.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsServer.GetCredentialsByCA err: %v&quot;, err) &#125; // 服务选项 opts := []grpc.ServerOption&#123; grpc.Creds(c), grpc_middleware.WithUnaryServerChain( RecoveryInterceptor, LoggingInterceptor, ), &#125; server := grpc.NewServer(opts...) pb.RegisterSearchServiceServer(server, &amp;SearchService&#123;&#125;) ln, err := net.Listen(&quot;tcp&quot;, &quot;:9001&quot;) if err != nil &#123; log.Fatalf(&quot;net.Listen err: %v&quot;, err) &#125; server.Serve(ln)&#125;func LoggingInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface&#123;&#125;, error) &#123; log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, req) resp, err := handler(ctx, req) log.Printf(&quot;gRPC method: %s, %v&quot;, info.FullMethod, resp) return resp, err&#125;func RecoveryInterceptor(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; defer func() &#123; if e := recover(); e != nil &#123; debug.PrintStack() err = status.Errorf(codes.Internal, &quot;Panic err: %v&quot;, e) &#125; &#125;() return handler(ctx, req)&#125; 10.3 客户端12345678910111213141516171819202122232425262728293031323334353637383940func main() &#123; tlsClient := gtls.Client&#123; ServerName: &quot;go-grpc-example&quot;, CaFile: &quot;../../certs/ca.pem&quot;, CertFile: &quot;../../certs/client.pem&quot;, KeyFile: &quot;../../certs/client.key&quot;, &#125; c, err := tlsClient.GetCredentialsByCA() if err != nil &#123; log.Fatalf(&quot;tlsClient.GetCredentialsByCA err: %v&quot;, err) &#125; conn, err := grpc.Dial(&quot;:9001&quot;, grpc.WithTransportCredentials(c)) if err != nil &#123; log.Fatalf(&quot;grpc.Dail err: %v&quot;, err) &#125; defer conn.Close() // Deadlines ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Duration(5*time.Second))) defer cancel() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(ctx, &amp;pb.SearchRequest&#123; Request: &quot;gRPC&quot;, &#125;) if err != nil &#123; statusErr, ok := status.FromError(err) if ok &#123; if statusErr.Code() == codes.DeadlineExceeded &#123; log.Fatalf(&quot;client.Search err: deadline&quot;) &#125; &#125; log.Fatalf(&quot;client.Search err: %v&quot;, err) &#125; log.Printf(&quot;resp: %s&quot;, resp.GetResponse())&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go 加密签名","slug":"Go 加密签名","date":"2019-07-07T01:21:53.000Z","updated":"2021-06-22T10:50:49.736Z","comments":true,"path":"2019/07/07/Go 加密签名/","link":"","permalink":"https://elihe2011.github.io/2019/07/07/Go%20%E5%8A%A0%E5%AF%86%E7%AD%BE%E5%90%8D/","excerpt":"1. 加密字符串格式密钥、密文、签名的加密字符串格式 1.1 hex123hex.DecodeString(s string)hex.EncodeToString(src []byte) string","text":"1. 加密字符串格式密钥、密文、签名的加密字符串格式 1.1 hex123hex.DecodeString(s string)hex.EncodeToString(src []byte) string 1.2 base64123base64.StdEncoding.DecodeString(s string) ([]byte, error)base64.StdEncoding.EncodeToString(src []byte) string 2. 私钥格式2.1 PKCS11x509.ParsePKCS1PrivateKey(der []byte) (key interface&#123;&#125;, err error) 2.2 PKCS81x509.ParsePCKS8PrivateKey(der []byte) (key interface&#123;&#125;, err error) 3. SHA算法3.1 SHA1123hash := sha1.New()hash.Write([]byte(plainText))cipherText, err := rsa.SignPKCS1v15(rand.Reader, prvKey, crypto.SHA1, hash.Sum(nil)) 3.2 SHA256123hash := sha256.New()hash.Write([]byte(plainText))cipherText, err := rsa.SignPKCS1v15(rand.Reader, prvKey, crypto.SHA256, hash.Sum(nil)) 4. RSA4.1 加密1rsa.EncryptPKCS1v15(rand io.Reader, pub *PublicKey, plaintext []byte) ([]byte, error) 4.2 解密1rsa.DecryptPKCS1v15(rand io.Reader, priv *PrivateKey, ciphertext []byte) ([]byte, error) 4.3 签名1rsa.SignPKCS1v15(rand io.Reader, priv *PrivateKey, hash crypto.Hash, hashed []byte) ([]byte, error) 4.4 验签1rsa.VerifyPKCS1v15(pub *PublicKey, hash crypto.Hash, hashed []byte, sig []byte) error 5. 应用示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import ( &quot;crypto&quot; &quot;crypto/rand&quot; &quot;crypto/rsa&quot; &quot;crypto/sha1&quot; &quot;crypto/x509&quot; &quot;encoding/base64&quot; &quot;encoding/hex&quot;)func RsaEncryptWithSha1Base64(plaintext, publicKey string) (string, error) &#123; key, _ := base64.StdEncoding.DecodeString(publicKey) pubKey, _ := x509.ParsePKIXPublicKey(key) ciphertext, err := rsa.EncryptPKCS1v15(rand.Reader, pubKey.(*rsa.PublicKey), []byte(plaintext)) if err != nil &#123; return &quot;&quot;, err &#125; return base64.StdEncoding.EncodeToString(ciphertext), nil&#125;func RsaDecryptWithSha1Base64(ciphertext, privateKey string) (string, error) &#123; ciphertextBytes, err := base64.StdEncoding.DecodeString(ciphertext) if err != nil &#123; return &quot;&quot;, err &#125; key, _ := base64.StdEncoding.DecodeString(privateKey) prvKey, _ := x509.ParsePKCS1PrivateKey(key) plaintext, err := rsa.DecryptPKCS1v15(rand.Reader, prvKey, ciphertextBytes) return string(plaintext), err&#125;func RsaSignWithSha1Hex(data, privateKey string) (string, error) &#123; key, err := hex.DecodeString(privateKey) if err != nil &#123; return &quot;&quot;, err &#125; prvKey, err := x509.ParsePKCS8PrivateKey(key) if err != nil &#123; return &quot;&quot;, err &#125; hash := sha1.New() hash.Write([]byte(data)) signature, err := rsa.SignPKCS1v15(rand.Reader, prvKey.(*rsa.PrivateKey), crypto.SHA1, hash.Sum(nil)) if err != nil &#123; return &quot;&quot;, err &#125; return hex.EncodeToString(signature), nil&#125;func RsaVerifySignWithSha1Base64(data, signature, publicKey string) error &#123; sign, err := base64.StdEncoding.DecodeString(signature) if err != nil &#123; return err &#125; key, _ := base64.StdEncoding.DecodeString(publicKey) pubKey, err := x509.ParsePKIXPublicKey(key) if err != nil &#123; return err &#125; hash := sha1.New() hash.Write([]byte(data)) return rsa.VerifyPKCS1v15(pubKey.(*rsa.PublicKey), crypto.SHA1, hash.Sum(nil), sign)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 包管理","slug":"Go 包管理","date":"2019-07-01T08:41:28.000Z","updated":"2021-06-22T10:50:49.736Z","comments":true,"path":"2019/07/01/Go 包管理/","link":"","permalink":"https://elihe2011.github.io/2019/07/01/Go%20%E5%8C%85%E7%AE%A1%E7%90%86/","excerpt":"1. Go Modules1.1 简介Go Modules 是官方最新的包管理方式，它解决了如下问题： 所有的依赖包必须在 GOPATH 下，但同一个库只能保存一个版本 工作目录必须在 GOPATH/src 目录下 使用 Go Modules 之后，可在 GOPATH/src 之外创建目录和管理包 设置 go mod 和 go proxy: 12345go env -w GOBIN=/Users/eli/go/bingo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,directgo env GO111MODULE: on: 强制使用modules, 不再去GOPATH下查找 off: 不使用modules，去GOPATH和vendor下查找 auto: 默认值，如果当前目录下有go.mod文件，则使用modules","text":"1. Go Modules1.1 简介Go Modules 是官方最新的包管理方式，它解决了如下问题： 所有的依赖包必须在 GOPATH 下，但同一个库只能保存一个版本 工作目录必须在 GOPATH/src 目录下 使用 Go Modules 之后，可在 GOPATH/src 之外创建目录和管理包 设置 go mod 和 go proxy: 12345go env -w GOBIN=/Users/eli/go/bingo env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,directgo env GO111MODULE: on: 强制使用modules, 不再去GOPATH下查找 off: 不使用modules，去GOPATH和vendor下查找 auto: 默认值，如果当前目录下有go.mod文件，则使用modules 1.2 基础命令123456789101112go help modgo mod &lt;command&gt; [arguments]download download modules to local cacheedit edit go.mod from tools or scriptsgraph print module requirement graphinit initialize new module in current directorytidy add missing and remove unused modulesvendor make vendored copy of dependenciesverify verify dependencies have expected contentwhy explain why packages or modules are needed 1.3 基本使用1.3.1 初始化123go mod init github.com/elihe2011/gomodgo get -u github.com/gin-gonic/gin 生成的文件： go.mod: 模块管理文件 module语句: 指定包的名字（路径） require语句: 指定的依赖项模块 replace语句: 可以替换依赖项模块 exclude语句: 可以忽略依赖项模块 go.sum: 记录依赖看的版本和哈希值 解决获取包时的代理错误： 12345678$ go get -u github.com/gin-gonic/gingo get github.com/gin-gonic/gin: module github.com/gin-gonic/gin: Get &quot;https://proxy.golang.org/github.com/gin-gonic/gin/@v/list&quot;: dial tcp 34.64.4.113:443: i/o timeout# go包管理,默认使用的是proxy.golang.org，在国内无法访问，换为go env -w GOPROXY=https://goproxy.cn,direct # 七牛云go env -w GOPROXY=https://mirrors.aliyun.com/goproxy/,direct 1.3.2 下载指定版本的依赖库1234567891011# 当前模块和支撑包go list -m all# 可用版本go list -m -versions github.com/gin-gonic/gin# 删除无效的modulesgo mod tidy# 获取指定版本go get github.com/gin-gonic/gin@ 1.4 编译打包1.4.1 使用GOPATH模式进行打包123export GO111MODULE=offexport CGO_ENABLED=0go build -a -v -o app main.go 1.4.2 使用vendor目录下包来进行打包123export GO111MODULE=onexport CGO_ENABLED=0go build -mod=vendor -a -v -o app main.go 1.5 go modules包管理特点 第三方包存储路径：$GOPATH/pkg/mod $GOPATH/pkg/mod 下可以保存相同包的不同版本 当项目放在 $GOPATH/src 时，GO111MODULE=auto 自动模式 依赖包中的地址失效了怎么办？比如 golang.org/x/… 下的包都无法下载怎么办？ 在go.mod文件里用 replace 替换包，例如replace golang.org/x/text =&gt; github.com/golang/text latest这样，go会用 github.com/golang/text 替代golang.org/x/text，原理就是下载github.com/golang/text 的最新版本到 $GOPATH/pkg/mod/golang.org/x/text下 2. govendorgovendor只是用来管理项目的依赖包，如果GOPATH中本身没有项目的依赖包，则需要通过go get先下载到GOPATH中，再通过govendor add +external拷贝到vendor目录中。Go 1.6以上版本默认开启GO15VENDOREXPERIMENT环境变量。 2.1 安装1go get -u -v github.com/kardianos/govendor 2.2 常用命令1234567891011121314151617181920212223# 初始化, 生成vender目录等govendor init# 添加包govendor add github.com/fvbock/endlessgovendor add +external# 移除包govendor remove github.com/fvbock/endlessgovendor remove +unused# 查看包govendor list# 列出所有缺失、过期和修改过的包govendor status# 本地存在 vendor.json 时候拉去依赖包，匹配所记录的版本govendor sync# 获取包govendor get github.com/gorilla/websocketgovendor fetch github.com/gorilla/websocket 2.3 包状态 状态 缩写状态 含义 +local l 本地包，即项目自身的包组织 +external e 外部包，即被 $GOPATH 管理，但不在 vendor 目录下 +vendor v 已被 govendor 管理，即在 vendor 目录下 +std s 标准库中的包 +unused u 未使用的包，即包在 vendor 目录下，但项目并没有用到 +missing m 代码引用了依赖包，但该包并没有找到 +program p 主程序包，意味着可以编译为执行文件 +outside o 外部包和缺失的包 +all a 所有的包","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Redis","slug":"Go Redis","date":"2019-05-20T02:49:39.000Z","updated":"2021-06-22T10:50:49.735Z","comments":true,"path":"2019/05/20/Go Redis/","link":"","permalink":"https://elihe2011.github.io/2019/05/20/Go%20Redis/","excerpt":"1. 入门1.1 安装1go get -u github.com/go-redis/redis 1.2 初始化连接1234567891011121314151617181920const ( REDIS_IP = &quot;127.0.0.1&quot; REDIS_PORT = &quot;6379&quot; REDIS_PWD = &quot;&quot; REDIS_DB = 0)var ( ctx = context.Background() rdb *redis.Client)func init() &#123; rdb = redis.NewClient(&amp;redis.Options&#123; Addr: REDIS_IP + &quot;:&quot; + REDIS_PORT, Password: REDIS_PWD, DB: REDIS_DB, PoolSize: 20, &#125;)&#125;","text":"1. 入门1.1 安装1go get -u github.com/go-redis/redis 1.2 初始化连接1234567891011121314151617181920const ( REDIS_IP = &quot;127.0.0.1&quot; REDIS_PORT = &quot;6379&quot; REDIS_PWD = &quot;&quot; REDIS_DB = 0)var ( ctx = context.Background() rdb *redis.Client)func init() &#123; rdb = redis.NewClient(&amp;redis.Options&#123; Addr: REDIS_IP + &quot;:&quot; + REDIS_PORT, Password: REDIS_PWD, DB: REDIS_DB, PoolSize: 20, &#125;)&#125; 2. 操作2.1 基本操作12345678910111213141516171819202122232425func Basic() &#123; keys := rdb.Keys(ctx, &quot;*&quot;).Val() fmt.Println(keys) size := rdb.DBSize(ctx).Val() fmt.Println(size) exist := rdb.Exists(ctx, &quot;name&quot;, &quot;age&quot;) fmt.Println(exist) del := rdb.Del(ctx, &quot;abc&quot;).Val() fmt.Println(del) ttl := rdb.TTL(ctx, &quot;age&quot;).Val() fmt.Println(ttl) expire := rdb.Expire(ctx, &quot;age&quot;, time.Second*60).Val() fmt.Println(expire) _type := rdb.Type(ctx, &quot;name&quot;).Val() fmt.Println(_type) key := rdb.RandomKey(ctx).Val() fmt.Println(key)&#125; 2.2 String1234567891011121314151617181920212223242526272829303132func String() &#123; var ret interface&#123;&#125; ret = rdb.Set(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour*24).Val() fmt.Println(ret) // set if not exist ret = rdb.SetNX(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour).Val() fmt.Println(ret) // set if exist ret = rdb.SetXX(ctx, &quot;name&quot;, &quot;eli&quot;, time.Hour*12).Val() fmt.Println(ret) ret = rdb.Get(ctx, &quot;name&quot;) fmt.Println(ret) ret = rdb.MGet(ctx, &quot;name&quot;, &quot;age&quot;) fmt.Println(ret) ret = rdb.Incr(ctx, &quot;age&quot;).Val() fmt.Println(ret) ret = rdb.Decr(ctx, &quot;age&quot;).Val() fmt.Println(ret) ret = rdb.Append(ctx, &quot;name&quot;, &quot;he&quot;) fmt.Println(ret) ret = rdb.StrLen(ctx, &quot;name&quot;) fmt.Println(ret)&#125; 2.3 Hashmap1234567891011121314151617181920212223242526272829303132func Hashmap() &#123; key := &quot;account&quot; field := &quot;name&quot; fields := map[string]interface&#123;&#125;&#123; &quot;city&quot;: &quot;beijing&quot;, &quot;age&quot;: 27, &quot;skills&quot;: &quot;golang&quot;, &#125; rdb.HSet(ctx, key, field, &quot;jack&quot;) rdb.HMSet(ctx, key, fields) name := rdb.HGet(ctx, key, &quot;name&quot;) fmt.Println(name) items := rdb.HKeys(ctx, key).Val() fmt.Println(items) vals := rdb.HVals(ctx, key).Val() fmt.Println(vals) exist := rdb.HExists(ctx, key, &quot;city&quot;) fmt.Println(exist) rdb.HIncrBy(ctx, key, &quot;age&quot;, 1) values := rdb.HMGet(ctx, key, &quot;name&quot;, &quot;age&quot;).Val() fmt.Println(values) valuesAll := rdb.HGetAll(ctx, key).Val() fmt.Println(valuesAll)&#125; 2.4 List1234567891011121314151617181920212223242526272829func List() &#123; key := &quot;list&quot; rdb.Del(ctx, key) for i := 0; i &lt; 5; i++ &#123; rdb.RPush(ctx, key, strconv.Itoa(i)) &#125; for i := 5; i &lt; 10; i++ &#123; rdb.LPush(ctx, key, strconv.Itoa(i)) &#125; length := rdb.LLen(ctx, key).Val() fmt.Println(length) value := rdb.LIndex(ctx, key, 1).Val() fmt.Println(value) rdb.LSet(ctx, key, 1, &quot;golang&quot;) value = rdb.LPop(ctx, key).Val() fmt.Println(value) n := rdb.LRem(ctx, key, 0, &quot;5&quot;).Val() fmt.Println(n) l := rdb.LRange(ctx, key, 0, -1).Val() fmt.Println(l)&#125; 2.5 Set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func Set() &#123; key1 := &quot;set1&quot; key2 := &quot;set2&quot; rdb.Del(ctx, key1, key2) rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 5; i++ &#123; rdb.SAdd(ctx, key1, rand.Intn(10)) rdb.SAdd(ctx, key2, rand.Intn(10)) &#125; n1 := rdb.SCard(ctx, key1).Val() fmt.Println(n1) e1 := rdb.SIsMember(ctx, key1, 3).Val() fmt.Println(e1) v1 := rdb.SRandMember(ctx, key1).Val() fmt.Println(v1) v2 := rdb.SRandMemberN(ctx, key1, 3).Val() fmt.Println(v2) v3 := rdb.SPop(ctx, key1).Val() fmt.Println(v3) n2 := rdb.SRem(ctx, key1, 2).Val() fmt.Println(n2) v4 := rdb.SMembers(ctx, key1) fmt.Println(v4) v5 := rdb.SMembers(ctx, key2) fmt.Println(v5) v6 := rdb.SInter(ctx, key1, key2).Val() fmt.Println(v6) v7 := rdb.SUnion(ctx, key1, key2).Val() fmt.Println(v7) v8 := rdb.SDiff(ctx, key1, key2).Val() fmt.Println(v8) rdb.SInterStore(ctx, &quot;set3&quot;, key1, key2) rdb.SUnionStore(ctx, &quot;set4&quot;, key1, key2) rdb.SDiffStore(ctx, &quot;set5&quot;, key1, key2)&#125; 2.6 SortedSet1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465func SortedSet() &#123; key1, key2 := &quot;zset1&quot;, &quot;zset2&quot; rdb.Del(ctx, key1, key2) rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 10; i++ &#123; score := float64(rand.Intn(100)) member := &quot;golang-&quot; + strconv.Itoa(i) data := &amp;redis.Z&#123; score, member, &#125; rdb.ZAdd(ctx, key1, data) &#125; for i := 0; i &lt; 10; i++ &#123; score := float64(rand.Intn(100)) member := &quot;golang-&quot; + strconv.Itoa(i) data := &amp;redis.Z&#123; score, member, &#125; rdb.ZAdd(ctx, key2, data) &#125; n1 := rdb.ZCard(ctx, key1) fmt.Println(n1) s1 := rdb.ZScore(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s1) v1 := rdb.ZIncrBy(ctx, key1, 50, &quot;golang-3&quot;).Val() fmt.Println(v1) s2 := rdb.ZRank(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s2) s3 := rdb.ZRevRank(ctx, key1, &quot;golang-3&quot;).Val() fmt.Println(s3) s4 := rdb.ZRange(ctx, key1, 0, -1).Val() fmt.Println(s4) s5 := rdb.ZRevRange(ctx, key2, 0, -1).Val() fmt.Println(s5) v2 := rdb.ZRem(ctx, key2, &quot;golang-3&quot;).Val() fmt.Println(v2) key3, key4 := &quot;zset3&quot;, &quot;zset4&quot; kslice := []string&#123;key1, key2&#125; wslice := []float64&#123;1.00, 1.00&#125; z := &amp;redis.ZStore&#123; kslice, wslice, &quot;SUM&quot;, &#125; r1 := rdb.ZInterStore(ctx, key3, z).Val() fmt.Println(r1) r2 := rdb.ZUnionStore(ctx, key4, z).Val() fmt.Println(r2)&#125; 2.7 订阅和发布12345678910111213141516171819202122232425262728293031323334func Subscription() &#123; channels := []string&#123;&quot;news&quot;, &quot;it&quot;, &quot;sports&quot;, &quot;shopping&quot;&#125; sub := rdb.PSubscribe(ctx, channels...) _, err := sub.Receive(ctx) if err != nil &#123; fmt.Println(err) &#125; ch := sub.Channel() for msg := range ch &#123; fmt.Printf(&quot;%v: %v\\n&quot;, msg.Channel, msg.Payload) &#125;&#125;func Publish() &#123; var msg string channels := []string&#123;&quot;news&quot;, &quot;it&quot;, &quot;sports&quot;, &quot;shopping&quot;&#125; rand.Seed(time.Now().UnixNano()) for &#123; fmt.Printf(&quot;please input some message: &quot;) fmt.Scanln(&amp;msg) if msg == &quot;quit&quot; &#123; break &#125; channel := channels[rand.Intn(4)] result := rdb.Publish(ctx, channel, msg).Val() if result == 1 &#123; fmt.Printf(&quot;send info to [%v] success\\n&quot;, channel) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go GORM","slug":"Go GORM","date":"2019-05-18T08:09:03.000Z","updated":"2021-06-22T10:50:49.735Z","comments":true,"path":"2019/05/18/Go GORM/","link":"","permalink":"https://elihe2011.github.io/2019/05/18/Go%20GORM/","excerpt":"1. 入门1.1 安装1go get -u github.com/jinzhu/gorm 1.2 驱动1234import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot;import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot;import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot;","text":"1. 入门1.1 安装1go get -u github.com/jinzhu/gorm 1.2 驱动1234import _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;import _ &quot;github.com/jinzhu/gorm/dialects/postgres&quot;import _ &quot;github.com/jinzhu/gorm/dialects/sqlite&quot;import _ &quot;github.com/jinzhu/gorm/dialects/mssql&quot; 2. 操作2.1 表结构定义123456789101112131415161718192021type Admin struct &#123; ID int64 Username string `gorm:&quot;size:50;not null&quot;` Password string `gorm:&quot;size:128&quot;`&#125;type Account struct &#123; gorm.Model // ID, CreatedAt, UpdatedAt, DeletedAt Appkey string `gorm:&quot;type:varchar(15);index:idx_appkey;not null&quot;` Company string `gorm:&quot;column:company_name;size:30&quot;` Status int8 `gorm:&quot;default:1&quot;`&#125;func (Admin) TableName() string &#123; return &quot;tbl_admin&quot;&#125;func (Account) TableName() string &#123; return &quot;tbl_account&quot;&#125; 2.2 连接数据库1234567891011121314151617181920212223242526272829303132const ( DBUSER = &quot;root&quot; DBPASS = &quot;&quot; HOST = &quot;127.0.0.1&quot; PORT = &quot;3306&quot; DBNAME = &quot;blog&quot;)func GetConn() *gorm.DB &#123; connStr := fmt.Sprintf(&quot;%s:%s@tcp(%s:%s)/%s?charset=utf8&amp;parseTime=True&amp;loc=Local&amp;timeout=10ms&quot;, DBUSER, DBPASS, HOST, PORT, DBNAME) fmt.Println(connStr) db, err := gorm.Open(&quot;mysql&quot;, connStr) if err != nil &#123; log.Fatalf(&quot;mysql connect error: %v&quot;, err) &#125; db.DB().SetMaxIdleConns(10) db.DB().SetMaxOpenConns(100) // 自动创建和更新表结构 if !db.HasTable(&quot;tbl_admin&quot;) &#123; db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Admin&#123;&#125;) &#125; if !db.HasTable(&quot;tbl_account&quot;) &#123; db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB&quot;).AutoMigrate(&amp;Account&#123;&#125;) &#125; return db&#125; 2.3 新增数据12345678910111213141516171819202122232425262728293031323334func Insert(db *gorm.DB) &#123; c := make(chan Admin) go generateData(c) for v := range c &#123; db.NewRecord(v) // 检查主键是否存在 db.Create(&amp;v) &#125;&#125;func generateRandomString(n int) string &#123; s := &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890_&quot; bs := make([]byte, n) for i := 0; i &lt; n; i++ &#123; bs[i] = s[rand.Intn(len(s))] &#125; return string(bs)&#125;func md5Encrypt(s string) string &#123; return fmt.Sprintf(&quot;%x&quot;, md5.Sum([]byte(s)))&#125;func generateData(c chan Admin) &#123; for i := 0; i &lt; 20; i++ &#123; name := generateRandomString(6) pass := md5Encrypt(name + &quot;_123456&quot;) c &lt;- Admin&#123;Username: name, Password: pass&#125; &#125; close(c)&#125; 2.4 查询数据12345678910111213func Select(db *gorm.DB) &#123; a := Admin&#123;&#125; db.Select([]string&#123;&quot;id&quot;, &quot;username&quot;, &quot;password&quot;&#125;).Where(&quot;id = ?&quot;, 1).First(&amp;a) fmt.Println(a)&#125;func SelectMany(db *gorm.DB) &#123; as := []Admin&#123;&#125; db.Where(&quot;username like &#x27;%4%&#x27;&quot;).Find(&amp;as) for _, a := range as &#123; fmt.Println(a) &#125;&#125; 2.5 更新数据1234567891011121314151617func Update(db *gorm.DB) &#123; a := Admin&#123;&#125; db.Where(&quot;id = ?&quot;, 1).First(&amp;a) a.Username = &quot;elihe123&quot; a.Password = md5Encrypt(&quot;123456&quot;) db.Save(a) // 数据必须有变化，否则无法保存 b := Admin&#123; ID: 30, Username: &quot;rania123&quot;, Password: md5Encrypt(&quot;654321&quot;), &#125; db.Save(b) // id不存在时，自动创建 c := Admin&#123;ID: 10&#125; db.Model(&amp;c).Update(&quot;username&quot;, &quot;eli&quot;)&#125; 2.6 删除数据1234func Delete(db *gorm.DB) &#123; a := Admin&#123;ID: 30&#125; db.Delete(&amp;a)&#125; 3. 钩子函数(callbacks) 创建: BeforeSave, BeforeCreate, AfterCreate, AfterSave 更新: BeforeSave, BeforeUpdate, AfterUpdate, AfterSave 删除: BeforeDelete, AfterDelete 查询: AfterFind 123456789func (Account) BeforeCreate(scope *gorm.Scope) error &#123; scope.SetColumn(&quot;CreatedAt&quot;, time.Now().Unix()) return nil&#125;func (Account) BeforeUpdate(scope *gorm.Scope) error &#123; scope.SetColumn(&quot;UpdatedAt&quot;, time.Now().Unix()) return nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Gin框架","slug":"Go Gin框架","date":"2019-05-17T02:22:58.000Z","updated":"2021-07-07T03:28:58.890Z","comments":true,"path":"2019/05/17/Go Gin框架/","link":"","permalink":"https://elihe2011.github.io/2019/05/17/Go%20Gin%E6%A1%86%E6%9E%B6/","excerpt":"1. Gin简介1.1 核心术语 Engine: 实现 ServeHTTP 接口的 Handler MethodTree： 根据http请求方法分别维护的路由树 RouterGroup：路由表分组，方便中间件统一处理 Context：上下文，在 Handler 之间传递参数 1.2 HttpRoutergin 使用路由框架 httprouter，它使用动态压缩前缀树 (compact prefix trie) 或称基数树 (radix tree) ，具有共同前缀的节点拥有相同的父节点，内存开销极小，没有反射。 12345678910111213141516171819202122// router.gotype Router struct &#123; trees map[string]*node // 每种请求方法，单独管理一棵树 RedirectTrailingSlash bool // 自动处理URL尾部的 “/” RedirectFixedPath bool // 路径矫正，如../和// HandleMethodNotAllowed bool HandleOPTIONS bool // 开启OPTIONS自动匹配, 手动匹配优先级更高 NotFound http.Handler MethodNotAllowed http.Handler PanicHandler func(http.ResponseWriter, *http.Request, interface&#123;&#125;)&#125;// tree.gotype node struct &#123; path string indices string // 分支的首字母：indices = eu，下面的 s [earch, upport] wildChild bool // 是否为参数节点，参数节点用:name表示 nType nodeType // static：没有handler，root: 第一个插入的节点，catchAll: 有*匹配的节点，param: 参数节点如:post priority uint32 // 子节点越多，或说绑定handle方法越多的节点，priority优先级越高 children []*node handle Handle&#125;","text":"1. Gin简介1.1 核心术语 Engine: 实现 ServeHTTP 接口的 Handler MethodTree： 根据http请求方法分别维护的路由树 RouterGroup：路由表分组，方便中间件统一处理 Context：上下文，在 Handler 之间传递参数 1.2 HttpRoutergin 使用路由框架 httprouter，它使用动态压缩前缀树 (compact prefix trie) 或称基数树 (radix tree) ，具有共同前缀的节点拥有相同的父节点，内存开销极小，没有反射。 12345678910111213141516171819202122// router.gotype Router struct &#123; trees map[string]*node // 每种请求方法，单独管理一棵树 RedirectTrailingSlash bool // 自动处理URL尾部的 “/” RedirectFixedPath bool // 路径矫正，如../和// HandleMethodNotAllowed bool HandleOPTIONS bool // 开启OPTIONS自动匹配, 手动匹配优先级更高 NotFound http.Handler MethodNotAllowed http.Handler PanicHandler func(http.ResponseWriter, *http.Request, interface&#123;&#125;)&#125;// tree.gotype node struct &#123; path string indices string // 分支的首字母：indices = eu，下面的 s [earch, upport] wildChild bool // 是否为参数节点，参数节点用:name表示 nType nodeType // static：没有handler，root: 第一个插入的节点，catchAll: 有*匹配的节点，param: 参数节点如:post priority uint32 // 子节点越多，或说绑定handle方法越多的节点，priority优先级越高 children []*node handle Handle&#125; 路由的保存： 123456789101112131415161718Priority Path Handle9 \\ *&lt;1&gt;3 ├s nil2 |├earch\\ *&lt;2&gt;1 |└upport\\ *&lt;3&gt;2 ├blog\\ *&lt;4&gt;1 | └:post nil1 | └\\ *&lt;5&gt;2 ├about-us\\ *&lt;6&gt;1 | └team\\ *&lt;7&gt;1 └contact\\ *&lt;8&gt;GET(&quot;/search/&quot;, h1)GET(&quot;/support/&quot;, h2)GET(&quot;/blog/:post/&quot;, h3)GET(&quot;/about-us/&quot;, h4)GET(&quot;/about-us/team/&quot;, h5)GET(&quot;/contact/&quot;, h6) r.Handle：r.Get, r.Post等方法的具体实现 123456789101112131415161718func (r *Router) Handle(method, path string, handle Handle) &#123; if path[0] != &#x27;/&#x27; &#123; panic(&quot;path must begin with &#x27;/&#x27; in path &#x27;&quot; + path + &quot;&#x27;&quot;) &#125; if r.trees == nil &#123; r.trees = make(map[string]*node) &#125; // 按方法创建路由树 root := r.trees[method] if root == nil &#123; root = new(node) r.trees[method] = root &#125; root.addRoute(path, handle)&#125; 2. 使用2.1 安装1go get -u github.com/gin-gonic/gin 2.2 入门12func (c *Context) JSON(code int, obj interface&#123;&#125;)type H map[string]interface&#123;&#125; 12345678910111213func main() &#123; // 路由 r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(200, gin.H &#123; &quot;id&quot;: 1, &quot;content&quot;: &quot;hello world!&quot;, &#125;) &#125;) r.Run(&quot;:8080&quot;)&#125; 2.3 请求参数2.3.1 路由参数1func (c *Context) Param(key string) string 1234567891011121314151617181920func main() &#123; r := gin.Default() r.GET(&quot;/user/:name&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) c.String(http.StatusOK, &quot;hello %s&quot;, name) &#125;) // 将匹配 /user/john/ 和 /user/john/send // 如果没有其他路由匹配 /user/john，它将重定向到 /user/john/ r.GET(&quot;/user/:name/*action&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) action := c.Param(&quot;action&quot;) msg := name + &quot; is doing &quot; + action c.String(http.StatusOK, msg) &#125;) r.Run()&#125; 2.3.2 Query参数123func (c *Context) Query(key string) string func (c *Context) GetQuery(key string) (string, bool) func (c *Context) DefaultQuery(key, defaultValue string) string 12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/user&quot;, func(c *gin.Context) &#123; filters := c.Query(&quot;filters&quot;) pageIndex := c.DefaultQuery(&quot;page_index&quot;, &quot;1&quot;) pageSize := c.DefaultQuery(&quot;page_size&quot;, &quot;10&quot;) c.JSON(http.StatusOK, gin.H&#123;&quot;filters&quot;: filters, &quot;page_index&quot;: pageIndex, &quot;page_size&quot;: pageSize&#125;) &#125;) r.Run()&#125; 2.3.3 Form参数12func (c *Context) PostForm(key string) stringfunc (c *Context) DefaultPostForm(key, defaultValue string) string 123456789101112131415161718func main() &#123; r := gin.Default() r.POST(&quot;/login&quot;, func(c *gin.Context) &#123; username := c.PostForm(&quot;username&quot;) password := c.DefaultPostForm(&quot;password&quot;, &quot;123456&quot;) c.JSON(http.StatusOK, gin.H&#123; &quot;username&quot;: username, &quot;password&quot;: password, &#125;) &#125;) r.Run()&#125;// curl -d &#x27;username=tom&amp;password=abc123&#x27; -X POST http://127.0.0.1:8080/login 2.3.4 参数相关方法 查询参数 Form表单 说明 Query PostForm 获取key对应的值，不存在为空字符串 GetQuery GetPostForm 多返回一个key是否存在的结果 QueryArray PostFormArray 获取key对应的数组，不存在返回一个空数组 GetQueryArray GetPostFormArray 多返回一个key是否存在的结果 QueryMap PostFormMap 获取key对应的map，不存在返回空map GetQueryMap GetPostFormMap 多返回一个key是否存在的结果 DefaultQuery DefaultPostForm key不存在的话，可以指定返回的默认值 2.4 文件操作调整文件上传表单大小： 12// 给表单限制上传大小，默认 32MiBr.MaxMultipartMemory = 128 &lt;&lt; 20 // 128MB 2.4.1 单文件上传1234567891011121314151617181920212223242526272829303132333435363738394041func upload(c *gin.Context) &#123; // 限制文件大小 err := c.Request.ParseMultipartForm(4 &lt;&lt; 20) // 4Mb if err != nil &#123; c.String(http.StatusBadRequest, &quot;file is too large&quot;) return &#125; // header, err := c.FormFile(&quot;file&quot;) file, header, err := c.Request.FormFile(&quot;file&quot;) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; defer file.Close() fmt.Printf(&quot;filename: %s, size: %d&quot;, header.Filename, header.Size) err = saveFile(header.Filename, file) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; c.String(http.StatusOK, &quot;uploaded!&quot;)&#125;func saveFile(name string, input multipart.File) (err error) &#123; var output *os.File output, err = os.OpenFile(name, os.O_CREATE|os.O_RDWR, 0644) if err != nil &#123; return &#125; defer output.Close() _, err = io.Copy(output, input) return&#125;curl -X POST http://192.168.80.1:8080/upload \\ -F &quot;file=@/home/ubuntu/ryu-socket_20210527.tar&quot; \\ -H &quot;Content-Type: multipart/form-data&quot; 2.4.2 多文件上传12345678910111213141516171819202122232425262728293031323334func uploadFiles(c *gin.Context) &#123; form, err := c.MultipartForm() if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; files := form.File[&quot;upload[]&quot;] fmt.Printf(&quot;file numbers: %d\\n&quot;, len(files)) for i, _ := range files &#123; file, err := files[i].Open() if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; fmt.Printf(&quot;filename: %s, size: %d\\n&quot;, files[i].Filename, files[i].Size) err = saveFile(files[i].Filename, file) if err != nil &#123; c.String(http.StatusBadRequest, err.Error()) return &#125; &#125; c.String(http.StatusOK, &quot;uploaded&quot;)&#125;curl -X POST http://192.168.80.1:8080/uploadFiles \\ -F &quot;upload[]=@/home/ubuntu/clean_ryu_imgs.sh&quot; \\ -F &quot;upload[]=@/home/ubuntu/.profile&quot; \\ -F &quot;upload[]=@/home/ubuntu/vegeta_12.8.4_linux_amd64.tar.gz&quot; \\ -H &quot;Content-Type: multipart/form-data&quot; 2.4.3 文件下载123456789101112func download(c *gin.Context) &#123; txt := c.Query(&quot;content&quot;) content := &quot;hello, 我是文件, &quot; + txt c.Writer.WriteHeader(http.StatusOK) c.Header(&quot;Content-Disposition&quot;, &quot;attachment; filename=hello.txt&quot;) c.Header(&quot;Content-Type&quot;, &quot;application/text/plain&quot;) c.Header(&quot;Accept-Length&quot;, fmt.Sprintf(&quot;%d&quot;, len(content))) c.Writer.Write([]byte(content))&#125;curl http://192.168.80.1:8080/download?content=abc 4. 高级功能4.1 路由分组12345678910111213func main() &#123; r := gin.Default() v1 := r.Group(&quot;/v1&quot;) &#123; v1.POST(&quot;/login&quot;, LoginHandler) &#125; v2 := r.Group(&quot;/v2&quot;) &#123; v2.POST(&quot;/login&quot;, LoginV2Handler) &#125;&#125; 4.2 中间件1func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes 1234567891011121314151617181920func main() &#123; // 不使用默认中间件： Logger 和 Recovery r := gin.New() // 全局中间件 r.Use(gin.Logger()) r.Use(gin.Recovery()) // 路由中间件 r.GET(&quot;/location&quot;, LocationLogger(), LocationHandler) // 分组中间件 auth := r.Group(&quot;/auth&quot;) auth.Use(AuthRequired()) &#123; auth.POST(&quot;/user&quot;, UserHandler) &#125; r.Run()&#125; 4.2.1 自定义中间件12345678910111213141516171819202122232425262728293031323334func main() &#123; r := gin.New() r.Use(Logger()) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; time.Sleep(time.Second * 5) c.JSON(http.StatusOK, gin.H&#123; &quot;msg&quot;: c.MustGet(&quot;foo&quot;), &#125;) &#125;) r.Run()&#125;func Logger() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; // before request t := time.Now() // set a variable c.Set(&quot;foo&quot;, &quot;bar&quot;) // DO request c.Next() // after request latency := time.Since(t) log.Println(latency) // access the result status status := c.Writer.Status() log.Println(status) &#125;&#125; 4.2.2 BasicAuth中间件12345678910111213141516171819202122232425262728293031// simulate private datavar secrets = gin.H&#123; &quot;foo&quot;: gin.H&#123;&quot;email&quot;: &quot;foo@abc.com&quot;, &quot;phone&quot;: &quot;13302254321&quot;&#125;, &quot;jack&quot;: gin.H&#123;&quot;email&quot;: &quot;jack@abc.com&quot;, &quot;phone&quot;: &quot;18952098765&quot;&#125;,&#125;func main() &#123; r := gin.Default() authorized := r.Group(&quot;/admin&quot;, gin.BasicAuth(gin.Accounts&#123; &quot;foo&quot;: &quot;bar&quot;, &quot;jack&quot;: &quot;1234&quot;, &#125;)) authorized.GET(&quot;/secrets&quot;, func(c *gin.Context) &#123; user := c.MustGet(gin.AuthUserKey).(string) if secret, ok := secrets[user]; ok &#123; c.JSON(http.StatusOK, gin.H&#123; &quot;user&quot;: user, &quot;secret&quot;: secret, &#125;) &#125; else &#123; c.JSON(http.StatusUnauthorized, gin.H&#123; &quot;user&quot;: user, &quot;secret&quot;: &quot;NO SECRET&quot;, &#125;) &#125; &#125;) r.Run()&#125; 4.3 记录日志4.3.1 日志文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107var ( LogSavePath = &quot;logs/&quot; LogSaveName = &quot;gin&quot; LogSaveFileExt = &quot;log&quot; TimeFormat = &quot;20060102&quot;)type Level intvar ( F *os.File DefaultPrefix = &quot;&quot; DefaultCallerDepth = 2 logger *log.Logger logPrefix = &quot;&quot; levelFlags = []string&#123;&quot;DEBUG&quot;, &quot;INFO&quot;, &quot;WRAN&quot;, &quot;ERROR&quot;, &quot;FATAL&quot;&#125;)const ( DEBUG Level = iota INFO WARNING ERROR FATAL)func init() &#123; filePath := getLogFileFullPath() F = openLogFile(filePath) // 新建日志处理 logger = log.New(F, DefaultPrefix, log.LstdFlags)&#125;func getLogFilePath() string &#123; return fmt.Sprintf(&quot;%s&quot;, LogSavePath)&#125;func getLogFileFullPath() string &#123; prefixPath := getLogFilePath() suffixPath := fmt.Sprintf(&quot;%s%s.%s&quot;, LogSaveName, time.Now().Format(TimeFormat), LogSaveFileExt) return fmt.Sprintf(&quot;%s%s&quot;, prefixPath, suffixPath)&#125;func openLogFile(filePath string) *os.File &#123; _, err := os.Stat(filePath) switch &#123; case os.IsNotExist(err): makeDir() case os.IsPermission(err): log.Fatalf(&quot;Permission: %v&quot;, err) &#125; handle, err := os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil &#123; log.Fatalf(&quot;Failed to OpenFile: %v&quot;, err) &#125; return handle&#125;func makeDir() &#123; pwd, _ := os.Getwd() err := os.MkdirAll(pwd+&quot;/&quot;+getLogFilePath(), os.ModePerm) if err != nil &#123; panic(err) &#125;&#125;func Debug(v ...interface&#123;&#125;) &#123; setPrefix(DEBUG) logger.Println(v)&#125;func Info(v ...interface&#123;&#125;) &#123; setPrefix(INFO) logger.Println(v)&#125;func Warn(v ...interface&#123;&#125;) &#123; setPrefix(WARNING) logger.Println(v)&#125;func Error(v ...interface&#123;&#125;) &#123; setPrefix(ERROR) logger.Println(v)&#125;func Fatal(v ...interface&#123;&#125;) &#123; setPrefix(FATAL) logger.Println(v)&#125;func setPrefix(level Level) &#123; _, file, line, ok := runtime.Caller(DefaultCallerDepth) if ok &#123; logPrefix = fmt.Sprintf(&quot;[%s][%s:%d]&quot;, levelFlags[level], filepath.Base(file), line) &#125; else &#123; logPrefix = fmt.Sprintf(&quot;[%s]&quot;, levelFlags[level]) &#125; logger.SetPrefix(logPrefix)&#125; 4.3.2 日志格式12345678910111213141516171819202122232425262728func main() &#123; router := gin.New() // LoggerWithFormatter 中间件会将日志写入 gin.DefaultWriter // By default gin.DefaultWriter = os.Stdout router.Use(gin.LoggerWithFormatter(func(param gin.LogFormatterParams) string &#123; // 你的自定义格式 return fmt.Sprintf(&quot;%s - [%s] \\&quot;%s %s %s %d %s \\&quot;%s\\&quot; %s\\&quot;\\n&quot;, param.ClientIP, param.TimeStamp.Format(time.RFC1123), param.Method, param.Path, param.Request.Proto, param.StatusCode, param.Latency, param.Request.UserAgent(), param.ErrorMessage, ) &#125;)) router.Use(gin.Recovery()) router.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(200, &quot;pong&quot;) &#125;) router.Run(&quot;:8080&quot;)&#125; 4.4 模型绑定和验证Gin使用 go-playground/validator.v10 验证参数。 将请求主体绑定到结构体中，目前支持JSON、XML、YAML和标准表单值(foo=bar&amp;boo=baz)的绑定。 绑定方法： Must bind: Methods: Bind, BindJSON, BindXML, BindQuery, BindYAML Behavior: 底层使用MustBindWith，如果存在绑定错误，请求将被以下指令中止 c.AbortWithError(400, err).SetType(ErrorTypeBind) Should bind: Methods: ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML Behavior: 底层使用ShouldBindWith，如果存在绑定错误，则返回错误，开发人员可正确处理请求和错误 4.4.1 请求参数绑定1234567891011121314151617181920212223242526272829303132333435type User struct &#123; Username string `form:&quot;username&quot; json:&quot;username&quot; xml:&quot;username&quot; binding:&quot;required&quot;` Password string `form:&quot;password&quot; json:&quot;password&quot; xml:&quot;password&quot; binding:&quot;required&quot;`&#125;func main() &#123; r := gin.Default() r.POST(&quot;/login&quot;, func(c *gin.Context) &#123; var user User //if err := c.ShouldBind(&amp;user); err != nil &#123; if err := c.ShouldBindJSON(&amp;user); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; if user.Username != &quot;admin&quot; || user.Password != &quot;123&quot; &#123; c.JSON(http.StatusUnauthorized, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: &quot;unauthorized&quot;, &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.2 自定义校验器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport ( &quot;net/http&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;gopkg.in/go-playground/validator.v10&quot; &quot;github.com/gin-gonic/gin&quot;)type Booking struct &#123; // v8 // CheckIn time.Time `form:&quot;check_in&quot; binding:&quot;required,bookabledate&quot; time_format:&quot;2006-01-02&quot;` CheckIn time.Time `form:&quot;check_in&quot; binding:&quot;required&quot; validate:&quot;bookabledate&quot; time_format:&quot;2006-01-02&quot;` CheckOut time.Time `form:&quot;check_out&quot; binding:&quot;required,gtfield=CheckIn&quot; time_format:&quot;2006-01-02&quot;`&#125;func bookableDate(fl validator.FieldLevel) bool &#123; if date, ok := fl.Field().Interface().(time.Time); ok &#123; today := time.Now() if today.Before(date) &#123; return true &#125; &#125; return false&#125;func main() &#123; r := gin.Default() // v10 validate := validator.New() validate.RegisterValidation(&quot;bookabledate&quot;, bookableDate) r.GET(&quot;/book&quot;, func(c *gin.Context) &#123; var book Booking if err := c.ShouldBindWith(&amp;book, binding.Query); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; // v10: 绑定和校验分离 err := validate.Struct(book) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.3 绑定uri1234567891011121314151617181920212223242526type Person struct &#123; ID string `uri:&quot;id&quot; binding:&quot;required,uuid&quot;` Name string `uri:&quot;name&quot; binding:&quot;required&quot;`&#125;func main() &#123; r := gin.Default() r.GET(&quot;/:name/:id&quot;, func(c *gin.Context) &#123; var person Person if err := c.ShouldBindUri(&amp;person); err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123; &quot;code&quot;: -1, &quot;msg&quot;: err.Error(), &#125;) return &#125; c.JSON(http.StatusOK, gin.H&#123; &quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;, &#125;) &#125;) r.Run()&#125; 4.4.4 错误翻译器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 1. 定义翻译器 translator.gopackage translatorimport ( &quot;strings&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;github.com/go-playground/locales/zh&quot; ut &quot;github.com/go-playground/universal-translator&quot; &quot;github.com/go-playground/validator/v10&quot; zhTrans &quot;github.com/go-playground/validator/v10/translations/zh&quot;)var ( uni *ut.UniversalTranslator validate *validator.Validate trans ut.Translator)func InitTrans() &#123; // 翻译器 zh := zh.New() uni = ut.New(zh, zh) trans, _ = uni.GetTranslator(&quot;zh&quot;) // 获取gin的校验器 validate = binding.Validator.Engine().(*validator.Validate) // 注册翻译器 zhTrans.RegisterDefaultTranslations(validate, trans)&#125;func Translate(err error) string &#123; var result []string errors := err.(validator.ValidationErrors) for _, err := range errors &#123; result = append(result, err.Translate(trans)) &#125; return strings.Join(result, &quot;; &quot;)&#125;// 2. 初始化translator.InitTrans()// 3. 使用实例type addUserRequest struct &#123; Username string `json:&quot;username&quot; binding:&quot;required,min=3,max=20&quot;` Password string `json:&quot;password&quot; binding:&quot;required,min=6,max=8&quot;` Email string `json:&quot;email&quot; binding:&quot;omitempty,email&quot;`&#125;func AddUserHandler(c *gin.Context) (interface&#123;&#125;, error) &#123; var req addUserRequest err := c.ShouldBindJSON(&amp;req) fmt.Println(err) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; // 新增用户 srv := &amp;service.AddUserService&#123;&#125; err = srv.AddUser(req.Username, req.Password, req.Email) return srv, err&#125; 4.5 响应渲染4.5.1 常见格式123c.JSON(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;)c.XML(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;)c.YAML(http.StatusOK, gin.H&#123;&quot;code&quot;: 0, &quot;msg&quot;: &quot;ok&quot;&#125;) 4.5.2 ProtoBuf1234567891011121314151617func main() &#123; r := gin.Default() r.GET(&quot;/protobuf&quot;, func(c *gin.Context) &#123; reps := []int64&#123;int64(1), int64(2)&#125; label := &quot;test&quot; data := &amp;protoexample.Test&#123; Label: &amp;label, Reps: reps, &#125; c.ProtoBuf(http.StatusOK, data) &#125;) r.Run()&#125; 4.5.3 SecureJSONSecureJSON可以防止json劫持，如果返回的数据是数组，则会默认在返回值前加上”while(1)” JSON劫持，其实就是恶意网站，通过&lt;script&gt;标签获取你的JSON数据，因为JSON数组默认为是可执行的JS，所以通过这种方式，可以获得你的敏感数据。 1234567891011121314func main() &#123; r := gin.Default() // facebook r.SecureJsonPrefix(&quot;for(;;);&quot;) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; nums := []int&#123;1, 2, 3, 4, 5&#125; c.SecureJSON(http.StatusOK, nums) // while(1);[1,2,3,4,5] 默认Google &#125;) r.Run()&#125; 4.5.4 JSONPJSONP可以跨域传输，如果参数中存在回调参数，那么返回的参数将是回调函数的形式 123456789101112131415func main() &#123; r := gin.Default() data := make(map[string]interface&#123;&#125;) data[&quot;bar&quot;] = &quot;foo&quot; r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.JSONP(http.StatusOK, data) &#125;) // http://localhost:8080/test?callback=sayHello // sayHello(&#123;&quot;bar&quot;:&quot;foo&quot;&#125;); r.Run()&#125; 1234567&lt;script&gt; function sayHello(data) &#123; alert(JSON.stringify(data)) &#125;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:8080/jsonp?callback=sayHello&quot; &gt;&lt;/script&gt; 4.5.5 AsciiJSON编码中文、标签等特殊字符 12345678910111213141516func main() &#123; r := gin.Default() data := map[string]interface&#123;&#125;&#123; &quot;lang&quot;: &quot;中文&quot;, &quot;tag&quot;: &quot;&lt;xml&gt;&quot;, &#125; r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.AsciiJSON(http.StatusOK, data) &#125;) // &#123;&quot;lang&quot;:&quot;\\u4e2d\\u6587&quot;,&quot;tag&quot;:&quot;\\u003cxml\\u003e&quot;&#125; r.Run()&#125; 4.5.6 PureJSONJSON会将特殊的HTML字符替换为对应的unicode字符, 但PureJSON保留原有格式 12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.PureJSON(http.StatusOK, gin.H&#123; &quot;html&quot;: &quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot;, &#125;) &#125;) // &#123;&quot;html&quot;:&quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot;&#125; r.Run()&#125; 4.5.7 jsoniter高性能json工具 12345import jsoniter &quot;github.com/json-iterator/go&quot;var json = jsoniter.ConfigCompatibleWithStandardLibraryjson.Marshal(&amp;data)json.Unmarshal(input, &amp;data) Gin 默认使用 encoding/json，可以在编译中使用标签将其修改为 jsoniter 1go build -tags=jsoniter . 4.6 静态文件12345678910111213func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world&quot;) &#125;) r.Static(&quot;/assets&quot;, &quot;./assets&quot;) r.StaticFS(&quot;/disk&quot;, http.Dir(`E:\\Download`)) r.StaticFile(&quot;favicon.ico&quot;, &quot;./assets/favicon.ico&quot;) r.Run(&quot;:8080&quot;)&#125; 4.7 代理下载文件1234567891011121314151617181920func downloadFromUrl(c *gin.Context) &#123; url := c.Query(&quot;url&quot;) resp, err := http.Get(url) if err != nil || resp.StatusCode != http.StatusOK &#123; c.Status(http.StatusServiceUnavailable) return &#125; arr := strings.Split(url, &quot;/&quot;) filename := arr[len(arr)-1] reader := resp.Body contentLength := resp.ContentLength contentType := resp.Header.Get(&quot;Content-Type&quot;) extraHeaders := map[string]string&#123; &quot;Content-Disposition&quot;: fmt.Sprintf(&quot;attachment; filename=%s&quot;, filename), &#125; c.DataFromReader(http.StatusOK, contentLength, contentType, reader, extraHeaders) 4.8 HTML渲染1234567891011121314func main() &#123; r := gin.Default() //r.LoadHTMLFiles(&quot;templates/index.tmpl&quot;, &quot;templates/login.tmpl&quot;) r.LoadHTMLGlob(&quot;templates/*&quot;) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.HTML(http.StatusOK, &quot;index.tmpl&quot;, gin.H&#123; &quot;title&quot;: &quot;Home Page&quot;, &#125;) &#125;) r.Run()&#125; 12345&lt;html&gt; &lt;h1&gt; &#123;&#123; .title &#125;&#125; &lt;/h1&gt;&lt;/html&gt; 4.9 重定向1234567891011121314151617181920func main() &#123; r := gin.Default() // 外部重定向 r.GET(&quot;/test1&quot;, func(c *gin.Context) &#123; c.Redirect(http.StatusMovedPermanently, &quot;https://google.com&quot;) &#125;) // 路由重定向 HandleContext r.GET(&quot;/test2&quot;, func(c *gin.Context) &#123; c.Request.URL.Path = &quot;/test3&quot; r.HandleContext(c) &#125;) r.GET(&quot;/test3&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;hello world!&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125; 12345678910111213141516func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; c.Request.URL.Path = &quot;/test2&quot; r.HandleContext(c) &#125;) r.GET(&quot;/test2&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123; &quot;msg&quot;: &quot;hello world!&quot;, &#125;) &#125;) r.Run()&#125; 4.10 支持https123456789101112131415161718192021222324import ( &quot;log&quot; &quot;net/http&quot; &quot;golang.org/x/crypto/acme/autocert&quot; &quot;github.com/gin-gonic/autotls&quot; &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;pong&quot;) &#125;) m := autocert.Manager&#123; Prompt: autocert.AcceptTOS, HostPolicy: autocert.HostWhitelist(&quot;localhost:8080&quot;, &quot;example1.com&quot;, &quot;example2.com&quot;), Cache: autocert.DirCache(&quot;/var/www/.cache&quot;), &#125; log.Fatal(autotls.RunWithManager(r, &amp;m))&#125; 4.11 使用cookie123456789101112131415func main() &#123; r := gin.Default() r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; cookie, err := c.Cookie(&quot;gin_cookie&quot;) if err != nil &#123; cookie = &quot;NO_SET&quot; c.SetCookie(&quot;gin_cookie&quot;, &quot;test&quot;, 3600, &quot;/&quot;, &quot;localhost&quot;, false, true) &#125; c.String(http.StatusOK, &quot;cookie=%s&quot;, cookie) &#125;) r.Run()&#125; 4.13 服务配置123456789101112type Server struct &#123; Addr string Handler http.Handler TLSConfig *tls.Config ReadTimeout time.Duration ReadHeaderTime time.Duration WriteTimeout time.Duration IdleTimeout time.Duration MaxHeaderBytes int ConnState func(net.Conn, http.ConnState) ErrorLog *log.Logger&#125; 123456789101112func main() &#123; router := gin.Default() s := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; s.ListenAndServe()&#125; 4.14 使用 goroutine在中间件或处理程序中启动 Goroutine 时，需要使用只读副本 c.Copy() 123456789101112131415161718192021222324func main() &#123; r := gin.Default() r.GET(&quot;/sync&quot;, func(c *gin.Context) &#123; start := time.Now() time.Sleep(5 * time.Second) log.Println(c.Request.URL) latency := time.Now().Sub(start) c.String(http.StatusOK, latency.String()) &#125;) r.GET(&quot;/async&quot;, func(c *gin.Context) &#123; start := time.Now() // 协程中使用，必须先复制 cc := c.Copy() go func() &#123; time.Sleep(5 * time.Second) log.Println(cc.Request.URL) &#125;() latency := time.Now().Sub(start) c.String(http.StatusOK, latency.String()) &#125;)&#125; 5. 运行多个服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import ( &quot;log&quot; &quot;net/http&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin&quot; &quot;golang.org/x/sync/errgroup&quot;)var ( g errgroup.Group)func router01() http.Handler &#123; r := gin.New() r.Use(gin.Recovery()) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;welcome to server 01&quot;&#125;) &#125;) return r&#125;func router02() http.Handler &#123; r := gin.New() r.Use(gin.Recovery()) r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;welcome to server 02&quot;&#125;) &#125;) return r&#125;func main() &#123; server01 := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router01(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, &#125; server02 := &amp;http.Server&#123; Addr: &quot;:8081&quot;, Handler: router02(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, &#125; g.Go(func() error &#123; return server01.ListenAndServe() &#125;) g.Go(func() error &#123; return server02.ListenAndServe() &#125;) if err := g.Wait(); err != nil &#123; log.Fatal(err) &#125;&#125; 6. 集成JWT1go get github.com/dgrijalva/jwt-go 涉及方法： NewWithClaims(method SigningMethod, claims Claims), method对应着SigningMethodHMAC struct&#123;&#125;，其包含SigningMethodHS256, SigningMethodHS384, SigningMethodHS512三种crypt.Hash func (t *Token) SignedString(key interface&#123;&#125;) 内部生成签名字符串，再用于获取完整、已签名的token func (p *Parser) ParseWithClaims解析鉴权声明，方法内部主要是具体的解码和校验过程，最终返回*Token func (m MapClaims) Valid() 验证基于时间的声明exp, iat, nbf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import ( &quot;gin-blog/pkg/setting&quot; &quot;time&quot; jwt &quot;github.com/dgrijalva/jwt-go&quot;)var jwtSecret = []byte(setting.JwtSecret)type Claims struct &#123; Username string `json:&quot;username&quot;` Password string `json:&quot;password&quot;` jwt.StandardClaims&#125;func GenerateToken(username, password string) (string, error) &#123; nowTime := time.Now() expireTime := nowTime.Add(3 * time.Hour) claims := Claims&#123; username, password, jwt.StandardClaims&#123; ExpiresAt: expireTime.Unix(), Issuer: &quot;gin-blog&quot;, &#125;, &#125; tokenClaims := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) token, err := tokenClaims.SignedString(jwtSecret) return token, err&#125;func ParseToken(token string) (*Claims, error) &#123; tokenClaims, err := jwt.ParseWithClaims(token, &amp;Claims&#123;&#125;, func(token *jwt.Token) (interface&#123;&#125;, error) &#123; return jwtSecret, nil &#125;) if tokenClaims != nil &#123; if claims, ok := tokenClaims.Claims.(*Claims); ok &amp;&amp; tokenClaims.Valid &#123; return claims, nil &#125; &#125; return nil, err&#125; 7. 重启服务器要求： 不关闭现有连接 （正在运行中的程序） 新的进程启动并替代旧进程 新的进程结构新的连接 连接要随时响应用户的请求，当用户仍在请求旧进程时，要保持连接，新用户应请求新进程，不可出现拒绝请求的情况 7.1 endlessendless: Zero downtime restarts for golfing HTTP and HTTPS servers 每次更新发布、修改配置文件等，只要给该进行发送SIGTERM信号(kill )，而不需要强制结束应用 监听信号： syscall.SIGHUP: 触发fork子进程和重新启动 syscall.SIGUSR1/syscall.SIGTSTP: 被监听，但不触发任何动作 syscall.SIGUSR2: 触发hammerTime syscall.SIGINT/syscall.SIGTERM: 触发服务器关闭（会完成正在运行的请求） 123456789101112131415161718192021222324252627282930313233343536import ( &quot;fmt&quot; &quot;gin-blog/pkg/setting&quot; &quot;gin-blog/routers&quot; &quot;log&quot; &quot;syscall&quot; &quot;github.com/fvbock/endless&quot;)func main() &#123; //router := routers.InitRouter() // //server := &amp;http.Server&#123; // Addr: fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort), // Handler: router, // ReadTimeout: setting.ReadTimeout, // WriteTimeout: setting.WriteTimeout, // MaxHeaderBytes: 1 &lt;&lt; 20, //&#125; endless.DefaultReadTimeOut = setting.ReadTimeout endless.DefaultWriteTimeOut = setting.WriteTimeout endless.DefaultMaxHeaderBytes = 1 &lt;&lt; 20 endPoint := fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort) server := endless.NewServer(endPoint, routers.InitRouter()) server.BeforeBegin = func(add string) &#123; log.Printf(&quot;Actual pid is %d&quot;, syscall.Getpid()) &#125; err := server.ListenAndServe() if err != nil &#123; log.Printf(&quot;Server error: %v&quot;, err) &#125;&#125; 7.2 Shutdown使用 http.Server 内置的 Shutdown()方法优雅地关闭服务，它不会中断任何活动的连接，直到所有连接处理完毕 1234567891011121314151617181920212223242526272829303132func main() &#123; router := initRouter() server := &amp;http.Server&#123; Addr: fmt.Sprintf(&quot;:%d&quot;, setting.HTTPPort), Handler: router, ReadTimeout: setting.ReadTimeout, WriteTimeout: setting.WriteTimeout, MaxHeaderBytes: 1 &lt;&lt; 20, &#125; go func() &#123; if err := server.ListenAndServe(); err != nil &#123; log.Printf(&quot;Listen: %v\\n&quot;, err) &#125; &#125;() quit := make(chan os.Signal) signal.Notify(quit, os.Interrupt) &lt;-quit log.Printf(&quot;Shutdown Server ...&quot;) ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() if err := server.Shutdown(ctx); err != nil &#123; log.Fatal(&quot;Server Shutdown:&quot;, err) &#125; log.Println(&quot;Server exiting&quot;)&#125; 8. Swagger API123go get -u github.com/swaggo/swag/cmd/swaggo get -u github.com/swaggo/gin-swaggergo get -u github.com/swaggo/gin-swagger/swaggerFiles 8.1 API 接口注释1234567891011121314151617181920212223242526// LoginHandler godoc// @Summary 登录系统// @Tags 用户相关接口// @Accept json// @Produce json// @Param object body loginRequest true &quot;请求参数&quot;// @Success 200 &#123;object&#125; router.Response// @Failure 400 &#123;object&#125; e.ApiError// @Router /api/v1/login [post]func LoginHandler(c *gin.Context) (interface&#123;&#125;, error) &#123; var req loginRequest err := c.ShouldBindJSON(&amp;req) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; // 登录 srv := &amp;service.LoginService&#123;&#125; err = srv.Login(req.Username, req.Password) if err != nil &#123; return nil, e.ParameterError(translator.Translate(err)) &#125; return srv, nil&#125; 8.2 生成配置1swag init 8.3 引入配置12345678910// main.gofunc init() &#123; // swagger 相关信息 docs.SwaggerInfo.Title = &quot;XXX 项目接口文档&quot; docs.SwaggerInfo.Description = &quot;just a test&quot; docs.SwaggerInfo.Version = &quot;1.0&quot; docs.SwaggerInfo.Host = addr docs.SwaggerInfo.BasePath = &quot;/&quot; docs.SwaggerInfo.Schemes = []string&#123;&quot;http&quot;, &quot;https&quot;&#125;&#125; 9. 接口测试12345678910111213141516171819202122232425262728import ( &quot;net/http&quot; &quot;net/http/httptest&quot; &quot;testing&quot; &quot;github.com/stretchr/testify/assert&quot; &quot;github.com/gin-gonic/gin&quot;)func setRouter() *gin.Engine &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.String(http.StatusOK, &quot;pong&quot;) &#125;) return r&#125;func TestPingRoute(t *testing.T) &#123; router := setRouter() w := httptest.NewRecorder() req, _ := http.NewRequest(&quot;GET&quot;, &quot;/ping&quot;, nil) router.ServeHTTP(w, req) assert.Equal(t, http.StatusOK, w.Code) assert.Equal(t, &quot;pong&quot;, w.Body.String())&#125; 10. 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229// 获取一个gin框架实例gin.Default()// 具体的Default方法func Default() *Engine &#123; // 调试模式日志输出 debugPrintWARNINGDefault() // 创建一个gin框架实例 engine := New() // 注册中间件的方式一致 engine.Use(Logger(), Recovery()) return engine&#125;// 创建一个gin框架实例 具体方法func New() *Engine &#123; // 调试模式日志输出 debugPrintWARNINGNew() // 初始化一个Engine实例 engine := &amp;Engine&#123; // 给框架实例绑定上一个路由组 RouterGroup: RouterGroup&#123; Handlers: nil, // engine.Use 注册的中间方法到这里 basePath: &quot;/&quot;, root: true, // 是否是路由根节点 &#125;, FuncMap: template.FuncMap&#123;&#125;, RedirectTrailingSlash: true, RedirectFixedPath: false, HandleMethodNotAllowed: false, ForwardedByClientIP: true, AppEngine: defaultAppEngine, UseRawPath: false, UnescapePathValues: true, MaxMultipartMemory: defaultMultipartMemory, trees: make(methodTrees, 0, 9), // 路由树 delims: render.Delims&#123;Left: &quot;&#123;&#123;&quot;, Right: &quot;&#125;&#125;&quot;&#125;, secureJsonPrefix: &quot;while(1);&quot;, &#125; // RouterGroup绑定engine自身的实例 engine.RouterGroup.engine = engine // 绑定从实例池获取上下文的闭包方法 engine.pool.New = func() interface&#123;&#125; &#123; // 获取一个Context实例 return engine.allocateContext() &#125; // 返回框架实例 return engine&#125;// 注册日志&amp;goroutin panic捕获中间件engine.Use(Logger(), Recovery())// 具体的注册中间件的方法func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes &#123; engine.RouterGroup.Use(middleware...) engine.rebuild404Handlers() engine.rebuild405Handlers() return engine&#125;///////////////////////////////////////////// 注册GET请求路由func (group *RouterGroup) GET(relativePath string, handlers ...HandlerFunc) IRoutes &#123; // 往路由组内 注册GET请求路由 return group.handle(&quot;GET&quot;, relativePath, handlers)&#125;func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes &#123; absolutePath := group.calculateAbsolutePath(relativePath) // 把中间件的handle和该路由的handle合并 handlers = group.combineHandlers(handlers) // 注册一个GET集合的路由 group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj()&#125;func (engine *Engine) addRoute(method, path string, handlers HandlersChain) &#123; assert1(path[0] == &#x27;/&#x27;, &quot;path must begin with &#x27;/&#x27;&quot;) assert1(method != &quot;&quot;, &quot;HTTP method can not be empty&quot;) assert1(len(handlers) &gt; 0, &quot;there must be at least one handler&quot;) debugPrintRoute(method, path, handlers) // 检查有没有对应method集合的路由 root := engine.trees.get(method) if root == nil &#123; // 没有 创建一个新的路由节点 root = new(node) // 添加该method的路由tree到当前的路由到路由树里 engine.trees = append(engine.trees, methodTree&#123;method: method, root: root&#125;) &#125; // 添加路由 root.addRoute(path, handlers)&#125;// 路由树节点type node struct &#123; path string indices string children []*node handlers HandlersChain // 所有的handle 构成一个链 priority uint32 nType nodeType maxParams uint8 wildChild bool&#125;// 启动http serverfunc (engine *Engine) Run(addr ...string) (err error) &#123; defer func() &#123; debugPrintError(err) &#125;() address := resolveAddress(addr) debugPrint(&quot;Listening and serving HTTP on %s\\n&quot;, address) // 执行http包的ListenAndServe方法 启动路由 err = http.ListenAndServe(address, engine) return&#125;// engine自身就实现了Handler接口type Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125;// 监听IP+端口ln, err := net.Listen(&quot;tcp&quot;, addr)// 接着就是Servesrv.Serve(tcpKeepAliveListener&#123;ln.(*net.TCPListener)&#125;)// Accept请求rw, e := l.Accept()// 使用goroutine去处理一个请求，最终就执行的是engine的ServeHTTP方法go c.serve(ctx)// engine实现http.Handler接口ServeHTTP的具体方法func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; // 获取一个上下文实例，从实例池获取 性能高 c := engine.pool.Get().(*Context) // 重置获取到的上下文实例的http.ResponseWriter c.writermem.reset(w) // 重置获取到的上下文实例*http.Request c.Request = req // 重置获取到的上下文实例的其他属性 c.reset() // 实际处理请求的地方，传递当前的上下文 engine.handleHTTPRequest(c) //归还上下文实例 engine.pool.Put(c)&#125;// 具体执行路由的方法engine.handleHTTPRequest(c)t := engine.treesfor i, tl := 0, len(t); i &lt; tl; i++ &#123; // 遍历路由树，查找当前请求method if t[i].method != httpMethod &#123; continue &#125; // 找到节点 root := t[i].root // 寻找当前请求的路由 handlers, params, tsr := root.getValue(path, c.Params, unescape) if handlers != nil &#123; // 把找到的handles赋值给上下文 c.handlers = handlers // 把找到的入参赋值给上下文 c.Params = params // 执行handle c.Next() // 处理响应内容 c.writermem.WriteHeaderNow() return &#125; ...&#125;// 方法树结构体type methodTree struct &#123; // HTTP Method method string // 当前HTTP Method的路由节点 root *node&#125;// 方法树集合type methodTrees []methodTree// 执行handlefunc (c *Context) Next() &#123; // 上下文处理之后c.index被执为-1 c.index++ for s := int8(len(c.handlers)); c.index &lt; s; c.index++ &#123; // 遍历执行所有handle(其实就是中间件+路由handle) c.handlers[c.index](c) &#125;&#125;// Context的重置方法func (c *Context) reset() &#123; c.Writer = &amp;c.writermem c.Params = c.Params[0:0] c.handlers = nil // 很关键 注意这里是-1哦 c.index = -1 c.Keys = nil c.Errors = c.Errors[0:0] c.Accepted = nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go Beego框架","slug":"Go Beego框架","date":"2019-05-16T07:22:58.000Z","updated":"2021-06-30T08:25:52.165Z","comments":true,"path":"2019/05/16/Go Beego框架/","link":"","permalink":"https://elihe2011.github.io/2019/05/16/Go%20Beego%E6%A1%86%E6%9E%B6/","excerpt":"1. 实现HTTP服务1.1 最简单的实现123456789101112func main() &#123; http.HandleFunc(&quot;/&quot;, sayHello) err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatal(err) &#125;&#125;func sayHello(w http.ResponseWriter, r *http.Request) &#123; io.WriteString(w, &quot;Hello world, this is version 1&quot;)&#125;","text":"1. 实现HTTP服务1.1 最简单的实现123456789101112func main() &#123; http.HandleFunc(&quot;/&quot;, sayHello) err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatal(err) &#125;&#125;func sayHello(w http.ResponseWriter, r *http.Request) &#123; io.WriteString(w, &quot;Hello world, this is version 1&quot;)&#125; 1.2 使用Mux控制路由123456789101112131415161718192021222324252627282930func main() &#123; // 通过handler实现路由设定 mux := http.NewServeMux() mux.Handle(&quot;/&quot;, &amp;myHandler&#123;&#125;) mux.HandleFunc(&quot;/hello&quot;, sayHello) wd, err := os.Getwd() if err != nil &#123; log.Fatal(err) &#125; // 文件服务器 mux.Handle(&quot;/static/&quot;, http.StripPrefix(&quot;/static/&quot;, http.FileServer(http.Dir(wd)))) err = http.ListenAndServe(&quot;:8080&quot;, mux) if err != nil &#123; log.Fatal(err) &#125;&#125;type myHandler struct &#123;&#125;func (*myHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; io.WriteString(w, &quot;URL: &quot; + r.URL.String())&#125;func sayHello(w http.ResponseWriter, r *http.Request) &#123; io.WriteString(w, &quot;Hello world, this is version 2&quot;)&#125; 1.3 模拟mux1234567891011121314151617181920212223242526272829303132333435363738var mux map[string]func(w http.ResponseWriter, r *http.Request)func main() &#123; server := http.Server&#123; Addr: &quot;:8080&quot;, Handler: &amp;myHandler&#123;&#125;, ReadTimeout: 5 * time.Second, &#125; mux = make(map[string]func(w http.ResponseWriter, r *http.Request)) mux[&quot;/hello&quot;] = sayHello mux[&quot;/bye&quot;] = sayBye err := server.ListenAndServe() if err != nil &#123; log.Fatal(err) &#125;&#125;type myHandler struct &#123;&#125;func (*myHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; if h, ok := mux[r.URL.String()]; ok &#123; h(w, r) return &#125; io.WriteString(w, &quot;URL: &quot; + r.URL.String())&#125;func sayHello(w http.ResponseWriter, r *http.Request) &#123; io.WriteString(w, &quot;Hello world, this is version 3&quot;)&#125;func sayBye(w http.ResponseWriter, r *http.Request) &#123; io.WriteString(w, &quot;Bye bye, this is version 3&quot;)&#125; 2. 使用Beego2.1 安装支撑包12go get github.com/astaxie/beegogo get github.com/astaxie/bee 2.2 使用bee命令12345bee new myappbee run myapp # 无法直接使用，改为下面的命令cd myappbee run 2.3 打印配置和日志级别设置12345678910111213141516func (this *MainController) Get() &#123; msg := fmt.Sprintf(&quot;appname: %s\\nhttpport: %s\\nrunmode: %s\\n&quot;, beego.AppConfig.String(&quot;appname&quot;), beego.AppConfig.String(&quot;httpport&quot;), beego.AppConfig.String(&quot;runmode&quot;)) this.Ctx.WriteString(msg) logs.Trace(&quot;trace test1&quot;) logs.Info(&quot;info test1&quot;) logs.SetLevel(logs.LevelInfo) logs.Trace(&quot;trace test2&quot;) // 低于info级别，不打印 logs.Info(&quot;info test2&quot;)&#125; 3. 使用模板123456789101112131415161718192021222324252627func (c *MainController) Get() &#123; c.TplName = &quot;index.html&quot; c.Data[&quot;Condition&quot;] = true type User struct &#123; Name string Age int Sex string &#125; user := &amp;User&#123; Name: &quot;Jack&quot;, Age: 21, Sex: &quot;Male&quot;, &#125; c.Data[&quot;User&quot;] = user nums := []int&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125; c.Data[&quot;Nums&quot;] = nums c.Data[&quot;TpVar&quot;] = &quot;hey guys&quot; c.Data[&quot;Html&quot;] = &quot;&lt;div&gt;hello beego&lt;/div&gt;&quot; c.Data[&quot;Pipe&quot;] = &quot;&lt;div&gt;hello beego&lt;/div&gt;&quot;&#125; 1234567891011121314151617181920212223242526272829303132&lt;body&gt; &lt;div&gt; &#123;&#123; if .Condition &#125;&#125; true condition &#123;&#123; else &#125;&#125; false condition &#123;&#123; end &#125;&#125; &lt;/div&gt; &lt;div&gt; &#123;&#123; with .User&#125;&#125; &#123;&#123; .Name &#125;&#125;; &#123;&#123; .Age &#125;&#125;; &#123;&#123; .Sex &#125;&#125; &#123;&#123; end &#125;&#125; &lt;/div&gt; &lt;div&gt; &#123;&#123; range .Nums &#125;&#125; &#123;&#123; . &#125;&#125; &#123;&#123; end &#125;&#125; &lt;/div&gt; &lt;div&gt; &#123;&#123; $tplVar := .TpcVar &#125;&#125; &#123;&#123; $tplVar &#125;&#125; &lt;/div&gt; &#123;&#123;str2html .Html&#125;&#125; &lt;div&gt; &#123;&#123;.Pipe | htmlquote&#125;&#125; &lt;/div&gt;&lt;/body&gt;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 数据库 sqlx","slug":"Go 数据库 sqlx","date":"2019-05-01T08:30:58.000Z","updated":"2021-06-30T08:30:43.360Z","comments":true,"path":"2019/05/01/Go 数据库 sqlx/","link":"","permalink":"https://elihe2011.github.io/2019/05/01/Go%20%E6%95%B0%E6%8D%AE%E5%BA%93%20sqlx/","excerpt":"1. Getting Started12go get github.com/jmoiron/sqlxgithub.com/go-sql-driver/mysql 2. Handle Types4 handle types: sqlx database/sql sqlx.DB sql.DB sqlx.Tx sql.Tx sqlx.Stmt sql.Stmt sqlx.NamedStmt 2 cursor types: sqlx database/sql from sqlx.Rows sql.Rows Queryx sqlx.Row sql.Row QueryRowx","text":"1. Getting Started12go get github.com/jmoiron/sqlxgithub.com/go-sql-driver/mysql 2. Handle Types4 handle types: sqlx database/sql sqlx.DB sql.DB sqlx.Tx sql.Tx sqlx.Stmt sql.Stmt sqlx.NamedStmt 2 cursor types: sqlx database/sql from sqlx.Rows sql.Rows Queryx sqlx.Row sql.Row QueryRowx 3. Connecting to Database12345678910111213var dsn = &quot;root:123456@tcp(127.0.0.1:3306)/mydb?parseTime=true&amp;&amp;charset=utf8mb4&quot;var db *sqlx.DB// 1. same as sql.Open()db, err = sqlx.Open(&quot;mysql&quot;, dsn)err = db.Ping() // force a connection and test that is worked // 2. open and connect at the same timedb, err = sqlx.Connect(&quot;mysql&quot;, dsn)// 3. same as 2, but panic on errordb = sqlx.MustConnect(&quot;mysql&quot;, dsn) 4. Querying12345678910111213141516171819202122232425262728// 1. unchanged from database/sqlExec(query string, args ...interface&#123;&#125;) (sql.Result, error)Query(query string, args ...interface&#123;&#125;) (*sql.Rows, error)QueryRow(query string, args ...interface&#123;&#125;) *sql.Row// 2. extensionsMustExec(query string, args ...interface&#123;&#125;) sql.ResultQueryx(query string, args ...interface&#123;&#125;) (*sqlx.Rows, error)QueryRowx(query string, args ...interface&#123;&#125;) *sqlx.Row// 3. new semantics: 结构体struct与数据库schema绑定Select(dest interface&#123;&#125;, query string, args ...interface&#123;&#125;) errorGet(dest interface&#123;&#125;, query string, args ...interface&#123;&#125;) error // An error is returned if the result set is empty// 4. sqlx.Rowtype Rows struct &#123; *sql.Rows unsafe bool Mapper *reflectx.Mapper // these fields cache memory use for a rows during iteration w/ structScan started bool fields [][]int values []interface&#123;&#125;&#125;// 5. sql.ResultLastInsertId() (int64, error)RowsAffected() (int64, error) 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func querying(db *sqlx.DB) &#123; // 1. Exec &amp; MustExec schema := `CREATE TABLE IF NOT EXISTS person (id INT(10) AUTO_INCREMENT PRIMARY KEY,name VARCHAR(20) NOT NULL,age TINYINT,address VARCHAR(100))` db.MustExec(schema) sqlStr := &quot;insert into person(name, age) values(?, ?)&quot; db.MustExec(sqlStr, &quot;jack&quot;, 21) db.MustExec(sqlStr, &quot;maxin&quot;, 30) sqlStr = &quot;insert into person(name, age, address) values(?, ?, ?)&quot; result, err := db.Exec(sqlStr, &quot;lucy&quot;, 39, &quot;London, UK&quot;) if err != nil &#123; panic(err) &#125; id, _ := result.LastInsertId() fmt.Printf(&quot;last insert id is %d\\n&quot;, id) // 2. Query &amp; Queryx sqlStr = &quot;select * from person&quot; rows1, err := db.Query(sqlStr) if err != nil &#123; panic(err) &#125; for rows1.Next() &#123; var id int var name string var age uint8 var address sql.NullString err = rows1.Scan(&amp;id, &amp;name, &amp;age, &amp;address) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;id: %d, name: %s, age: %d, address: %v\\n&quot;, id, name, age, address) &#125; type person struct &#123; Id int Name string Age uint8 Address sql.NullString &#125; rows2, err := db.Queryx(sqlStr) if err != nil &#123; panic(err) &#125; for rows2.Next() &#123; var p person rows2.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p) &#125; // 3. Get &amp; Select var p person var pp []person err = db.Get(&amp;p, &quot;select * from person limit 1&quot;) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v\\n&quot;, p) err = db.Select(&amp;pp, &quot;select * from person where id &gt; 2&quot;) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%#v\\n&quot;, pp) var count int db.Get(&amp;count, &quot;select count(*) from person&quot;) fmt.Println(count) var names []string db.Select(&amp;names, &quot;select name from person&quot;) fmt.Println(names)&#125; 5. Transactions123456// 1. sql.TxBegin() (*sql.Tx, error)// 2. sqlx.TxBeginx() (*sqlx.Tx, error)MustBegin() (*sql.Tx) 示例： 123456789101112131415161718func transaction(db *sqlx.DB) &#123; tx := db.MustBegin() defer func() &#123; if err := recover(); err != nil &#123; tx.Rollback() &#125; &#125;() tx.MustExec(&quot;delete from person where id=4&quot;) tx.MustExec(&quot;insert into person values(2, &#x27;abc&#x27;, 22, &#x27;LA&#x27;)&quot;) tx.MustExec(&quot;insert into person values(100, &#x27;abc&#x27;, 22, &#x27;LA&#x27;)&quot;) err := tx.Commit() if err != nil &#123; panic(err) &#125;&#125; 6. Prepared Statements123456789101112131415161718func prepared(db *sqlx.DB) &#123; stmt, _ := db.Prepare(&quot;select * from person where id=?&quot;) row := stmt.QueryRow(5) var id int var name string var age uint8 var address sql.NullString row.Scan(&amp;id, &amp;name, &amp;age, &amp;address) fmt.Printf(&quot;id: %d, name: %s, age: %d, address: %v\\n&quot;, id, name, age, address) stmtx, _ := db.Preparex(&quot;select * from person where id=?&quot;) rowx := stmtx.QueryRowx(5) var p person rowx.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p)&#125; 7. Query Helpers7.1 “In” Queries123456789101112131415161718192021222324252627282930313233func inQuery(db *sqlx.DB) &#123; ids := []int&#123;1, 2, 3, 4, 5&#125; /* // converting argument $1 type: unsupported type []int, a slice of int rows, err := db.Query(&quot;select name from person where id in (?)&quot;, ids) if err != nil &#123; panic(err) &#125; for rows.Next() &#123; var name string rows.Scan(&amp;name) fmt.Println(name) &#125;*/ // convert to (?, ?, ...) query, args, err := sqlx.In(&quot;select name from person where id in (?)&quot;, ids) if err != nil &#123; panic(err) &#125; query = db.Rebind(query) fmt.Println(query) rows, err := db.Query(query, args...) if err != nil &#123; panic(err) &#125; for rows.Next() &#123; var name string rows.Scan(&amp;name) fmt.Println(name) &#125;&#125; 7.2 Named Queries123NamedQuery(query string, arg interface&#123;&#125;) (*sqlx.Rows, error)NamedExec(query string, arg interface&#123;&#125;) (sql.Result, error)PrepareNamed(query string) (*NamedStmt, error) 示例： 1234567891011121314151617func namedQuery(db *sqlx.DB) &#123; // named query with a struct p := person&#123;Name: &quot;jack&quot;&#125; rows, _ := db.NamedQuery(&quot;select count(*) from person where name=:name&quot;, p) for rows.Next() &#123; var count int rows.Scan(&amp;count) fmt.Println(count) &#125; // named query with a map m := map[string]interface&#123;&#125;&#123;&quot;address&quot;: &quot;LA&quot;&#125; stmt, _ := db.PrepareNamed(&quot;select * from person where address=:address limit 1&quot;) row := stmt.QueryRowx(m) row.Scan(&amp;p) fmt.Printf(&quot;%#v\\n&quot;, p)&#125; 8. Alternate Scan Types1234567891011121314func alternateScan(db *sqlx.DB) &#123; rows, _ := db.Queryx(&quot;select * from person&quot;) for rows.Next() &#123; cols, _ := rows.SliceScan() fmt.Println(cols) &#125; rows, _ = db.Queryx(&quot;select * from person&quot;) for rows.Next() &#123; cols := make(map[string]interface&#123;&#125;) rows.MapScan(cols) fmt.Println(cols) &#125;&#125; 9. Connection Pool12DB.SetMaxIdleConns(n int)DB.SetMaxOpenConns(n int)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"CentOS基础软件","slug":"CentOS基础软件","date":"2019-04-30T06:12:26.000Z","updated":"2021-06-22T10:50:49.738Z","comments":true,"path":"2019/04/30/CentOS基础软件/","link":"","permalink":"https://elihe2011.github.io/2019/04/30/CentOS%E5%9F%BA%E7%A1%80%E8%BD%AF%E4%BB%B6/","excerpt":"1. 换yum源123456mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -Oyum makecache 2. 编译器更新123yum upgrade gccyum upgrade make","text":"1. 换yum源123456mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -Oyum makecache 2. 编译器更新123yum upgrade gccyum upgrade make 3. 域名解决123456vi /etc/sysconfig/network-scripts/ifcfg-eth0DNS1=114.114.114.114DNS2=218.2.2.2 service network restart 4. 防火墙12345iptables -A INPUT -p tcp -s 0/0 --dport 80 -j ACCEPT iptables -A OUTPUT -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT service iptables save 5. 时区设置1234vi /etc/profileTZ=&#x27;Asia/Shanghai&#x27;export TZ 设置本地时间12345ls -l /etc/localtimerm -f /etc/localtimeln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtimels -l /etc/localtime 6. 系统设置设置同步12345date -s &quot;2019-06-04 11:06:30&quot; # 修改为一个正确的时间hwclock -wcrontab -e* */1 * * * ntpdate 0.asia.pool.ntp.org 7. 支持密码登录1234vi /etc/ssh/sshd_configPasswordAuthentication no =&gt; yessystemctl restart sshd","categories":[{"name":"CentOS","slug":"CentOS","permalink":"https://elihe2011.github.io/categories/CentOS/"}],"tags":[{"name":"yum","slug":"yum","permalink":"https://elihe2011.github.io/tags/yum/"},{"name":"timezone","slug":"timezone","permalink":"https://elihe2011.github.io/tags/timezone/"}]},{"title":"Nginx配置","slug":"Nginx","date":"2019-04-25T01:15:17.000Z","updated":"2021-06-22T10:50:49.734Z","comments":true,"path":"2019/04/25/Nginx/","link":"","permalink":"https://elihe2011.github.io/2019/04/25/Nginx/","excerpt":"1. 重定向1.1 proxy_pass302跳转，不能传递原来请求的header 12345678910111213server &#123; listen 80; server_name a.example.com; listen 443 ssl; location = /xx &#123; proxy_pass http://b.example.com/xx; proxy_set_header Host b.example.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; break; &#125;&#125;","text":"1. 重定向1.1 proxy_pass302跳转，不能传递原来请求的header 12345678910111213server &#123; listen 80; server_name a.example.com; listen 443 ssl; location = /xx &#123; proxy_pass http://b.example.com/xx; proxy_set_header Host b.example.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; break; &#125;&#125; 1.2 rewrite12345server &#123; listen 80; server_name test1.com; rewrite ^(.*) https://www.test1.com$1 permanent;&#125; 2. 负载均衡 upstream123456789101112131415upstream balanceServer &#123; ip_hash; server 192.168.1.10:8080 weight 2; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125;server &#123; server_name test.com; listen 80; location /api &#123; proxy_pass http://balanceServer; &#125;&#125; weight：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。与ip_hash不兼容 负载均衡策略： 轮询（默认） 缺点：如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。 12345upstream balanceServer &#123; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 最小连接数策略 将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求 123456upstream balanceServer &#123; least_conn; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 最快响应时间策略 依赖于 NGINX Plus，优先分配给响应时间最短的服务器。 123456upstream balanceServer &#123; fair; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; session共享 每个访问安访问ip的hash结果分配，可确保每个访客孤独访问一个后端服务器，可解决session保持问题。 123456upstream balanceServer &#123; ip_hash; server 192.168.1.10:8080; server 192.168.1.11:8080; server 192.168.1.12:8080;&#125; 3. Nginx内置全局变量 变量名 功能 $host 请求信息中的Host，没有则设置成服务器名 $request_method GET, POST $args $content_length $http_user_agent $http_cookie $remote_addr $remote_port $server_protocol HTTP/1.0 HTTP/1.1 $server_addr $server_port $server_name 4. 请求过滤4.1 按状态码过滤123456789101112server &#123; listen 80; server_name test.com; access_log /var/log/nginx/nginx-access.log main; error_log /var/log/nginx/nginx-error.log; error_page 404 = /404; error_page 403 = /403; error_page 500 501 502 503 504 506 /50x.html; location /50x.html &#123; root /data/www/static/html; &#125; 4.2 按URL过滤12345server &#123; #... rewrite ^.*$ /index.html;&#125; 4.3 按请求类型过滤12345server &#123; if ( $request_method !~ ^(GET|POST|HEAD)$ ) &#123; return 403; &#125;&#125; 5. 配置gzip1234567http &#123; gzip on; gzip_http_version 1.1; gzip_comp_level 5; gzip_min_length 1000; gzip_types text/csv text/xml text/css text/plain text/javascript application/javascript application/x-javascript application/json application/xml;&#125; 6. Nginx配置文件结构123456789101112131415161718192021222324252627events &#123; &#125;http &#123; upstream node &#123; &#125; server &#123; location path &#123; ... &#125; location path &#123; ... &#125; &#125; server &#123; ... &#125;&#125; 7. 静态资源配置123456location ~* \\.(png|gif|jpg|jpeg)$ &#123; root /root/static/; autoindex on; access_log off; expires 24h; # 过期时间为24小时 &#125; 8. 静态资源缓存1234567891011121314151617location /hhhh/ &#123; root /data/www/lp-web/; index index.html; try_files $uri index.html; if ($request_filename ~* .*\\.(?:htm|html)$) &#123; add_header Cache-Control &quot;private, no-store, no-cache, must-revalidate, proxy-revalidate&quot;; &#125; if ($request_filename ~* .*\\.(?:js|css)$) &#123; expires 7d; &#125; if ($request_filename ~* .*\\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm)$) &#123; expires 7d; &#125;&#125; 9. nginx日志request_time 和upstream_response_time区别 request_time: request processing time in seconds with a milliseconds resolution; time elapsed between the first bytes were read from the client and the log write after the last bytes were sent to the client. 指的就是从接受用户请求的第一个字节到发送完响应数据的时间，即包括接收请求数据时间、程序响应时间、输出响应数据时间。 upstream_response_time: keeps times of responses obtained from upstream servers; times are kept in seconds with a milliseconds resolution. Several response times are separated by commas and colons like addresses in the $upstream_addr variable. 指从Nginx向后端建立连接开始到接受完数据然后关闭连接为止的时间。 从上面的描述可以看出，$request_time肯定比$upstream_response_time值大，特别是使用POST方式传递参数时，因为Nginx会把request body缓存住，接受完毕后才会把数据一起发给后端。所以如果用户网络较差，或者传递数据较大时，$request_time会比$upstream_response_time大很多。 $request_time 包含了用户数据接收时间，而真正程序的响应时间应该用$upstream_response_time。 配置说明： 1234log_format timed_combined &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27; &#x27;$request_time $upstream_response_time&#x27;;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://elihe2011.github.io/categories/Nginx/"}],"tags":[]},{"title":"select、poll和epoll","slug":"IO多路复用和异步","date":"2019-04-12T03:22:17.000Z","updated":"2021-06-22T10:50:49.733Z","comments":true,"path":"2019/04/12/IO多路复用和异步/","link":"","permalink":"https://elihe2011.github.io/2019/04/12/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%BC%82%E6%AD%A5/","excerpt":"1. selectselect最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 1234567while true &#123; select(streams[]) for i in streams[] &#123; if i has data read until unavailable &#125;&#125;","text":"1. selectselect最早于1983年出现在4.2BSD中，它通过一个select()系统调用来监视多个文件描述符的数组，当select()返回后，该数组中就绪的文件描述符便会被内核修改标志位，使得进程可以获得这些文件描述符从而进行后续的读写操作。 1234567while true &#123; select(streams[]) for i in streams[] &#123; if i has data read until unavailable &#125;&#125; select的优点是支持目前几乎所有的平台，缺点主要有如下2个： 1）单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024(32位，64位默认2048，proc/sys/fs/file-max)，不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制。 2）select 所维护的存储大量文件描述符的数据结构，随着文件描述符数量的增大，其复制的开销也线性增长。同时，由于网络响应时间的延迟使得大量TCP连接处于非活跃状态，但调用select()会对所有socket进行一次线性扫描，所以这也浪费了一定的开销。 2. pollpoll则在1986年诞生于System V Release 3，它和select在本质上没有多大差别，但是poll没有最大文件描述符数量的限制。 3. epoll epoll是Linux 2.6 开始出现的为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 123456while true &#123; active_stream[] = epoll_wait(epollfd) for i in active_stream[] &#123; read or write till &#125;&#125; 1.3 epollepoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 epoll的优点： 1、没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数； 即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 3、 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 1.4 select、poll、epoll 区别总结1、支持一个进程所能打开的最大连接数 类型 特点 select 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 poll poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 epoll 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 2、FD剧增后带来的IO效率问题 类型 特点 select 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 poll 同上 epoll 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 3、 消息传递方式| 类型 | 特点 || —— | ———————————————————— || select | 内核需要将消息传递到用户空间，都需要内核拷贝动作 || poll | 同上 || epoll | epoll通过内核和用户空间共享一块内存来实现的。 | 总结： 综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。 1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 2. 异步与非阻塞的区别非阻塞是对于socket而言；异步是相对于应用程序而言，是一种编程模型 Epoll是非阻塞的，但不是异步。实现阻塞和简单，socket.setblocking(False)即可；实现异步很复杂。 Linux没有实现异步IO(效率并不高)，Epoll是一种I/O多路复用技术，用户程序需要主动去询问内核是否有事件发生，而不是事件发生时内核主动去调用回调函数，所以不是异步的。 Tornado框架之所以是异步的，它在epoll的基础上进行了一层封装，由框架去取事件，然后由框架去调用用户的回调函数，所以对于基于该框架的用户程序来说，是异步的。 Tornado使用Epoll实现了异步编程模型，使用异步的前提是socket是非阻塞的。 3. Python selectPython的select()方法直接调用操作系统的IO接口，它监控sockets,open files, and pipes(所有带fileno()方法的文件句柄)何时变成readable 和writeable, 或者通信错误，select()使得同时监控多个连接变的简单，并且这比写一个长循环来等待和监控多客户端连接要高效，因为select直接通过操作系统提供的C的网络接口进行操作，而不是通过Python的解释器。 select()方法接收并监控3个通信列表， 第一个是所有的输入的data,就是指外部发过来的数据，第2个是监控和接收所有要发出去的data(outgoing data),第3个监控错误信息，接下来我们需要创建2个列表来包含输入和输出信息来传给select(). select_echo_server.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import selectimport socketimport sysfrom queue import Queue, Emptyserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server.setblocking(False)server_address = (&#x27;localhost&#x27;, 5000)print(&#x27;starting up on %s port %s&#x27; % server_address, file=sys.stderr)server.bind(server_address)server.listen(5)# reading socketsinputs = [server, ]# writing socketsoutputs = []message_queues = &#123;&#125;while inputs: print(&#x27;\\nwaiting for the next event.&#x27;) readable, writable, exceptional = select.select(inputs, outputs, inputs) for s in readable: if s is server: # A readable server socket is ready to accept a connection connection, client_address = s.accept() print(&#x27;new connection from&#x27;, client_address) connection.setblocking(False) inputs.append(connection) # Give the connection a queue for data we want to send message_queues[connection] = Queue() else: data = s.recv(1024) if data: # A readable client socket has data print(&#x27;received &quot;%s&quot; from %s&#x27; % (data, s.getpeername())) message_queues[s].put(data) # Add output channel for response if s not in outputs: outputs.append(s) else: # Interpret empty result as closed connection print(&#x27;closing&#x27;, client_address, &#x27;after reading not data.&#x27;) # Stop listening for input on the connection if s in outputs: outputs.remove(s) inputs.remove(s) s.close() # Remove message queue del message_queues[s] for s in writable: try: next_msg = message_queues[s].get_nowait() except Empty: # No message waiting so stop checking for writability print(&#x27;output queue for&#x27;, s.getpeername(), &#x27;is empty&#x27;) outputs.remove(s) else: print(&#x27;sending &quot;%s&quot; to %s&#x27; % (next_msg, s.getpeername())) reply = &#x27;replied: &#x27; + next_msg.decode(&#x27;utf-8&#x27;) s.send(reply.encode(&#x27;utf-8&#x27;)) for s in exceptional: print(&#x27;handling exceptional condition for&#x27;, s.getpeername()) inputs.remove(s) if s in outputs: outputs.remove(s) s.close() del message_queues[s] select_echo_multiclient.py 12345678910111213141516171819202122232425import socketimport sysserver_address = (&#x27;localhost&#x27;, 5000)messages = [&#x27;message %s&#x27; % i for i in range(10)]socks = [socket.socket(socket.AF_INET, socket.SOCK_STREAM) for _ in range(3)]print(&#x27;connecting to %s port %s&#x27; % server_address, file=sys.stderr)for s in socks: s.connect(server_address)for message in messages: # send messages on both sockets for s in socks: print(&#x27;%s: sending &quot;%s&quot;&#x27; % (s.getsockname(), message), file=sys.stderr) s.send(message.encode(&#x27;utf-8&#x27;)) # read response on both sockets for s in socks: data = s.recv(1024) print(&#x27;%s: received &quot;%s&quot;&#x27; % (s.getsockname(), data), file=sys.stderr) if not data: print(&#x27;closing socket&#x27;, s.getsockname(), file=sys.stderr) s.close()","categories":[{"name":"Linux","slug":"Linux","permalink":"https://elihe2011.github.io/categories/Linux/"}],"tags":[]},{"title":"Python 并发编程","slug":"Python 并发编程","date":"2019-03-17T07:22:21.000Z","updated":"2021-06-22T10:50:49.728Z","comments":true,"path":"2019/03/17/Python 并发编程/","link":"","permalink":"https://elihe2011.github.io/2019/03/17/Python%20%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"1. 多线程1.1 创建线程123456789101112131415import timeimport threadingfrom threading import Threaddef test(x): print(&#x27;This is &#123;&#125;&#x27;.format(x)) time.sleep(2)thread_list = [Thread(target=test, args=(i,)) for i in range(5)]for thread in thread_list: thread.start() #thread.join()print(len(threading.enumerate())) # MainThread + 5-Thread","text":"1. 多线程1.1 创建线程123456789101112131415import timeimport threadingfrom threading import Threaddef test(x): print(&#x27;This is &#123;&#125;&#x27;.format(x)) time.sleep(2)thread_list = [Thread(target=test, args=(i,)) for i in range(5)]for thread in thread_list: thread.start() #thread.join()print(len(threading.enumerate())) # MainThread + 5-Thread 123456# Thread类实例化参数target 目标代码name Thread名args 参数kwargs 参数daemon=False 123456# 方法start() 启动子线程join(timeout=10) 主线程阻塞，直到子线程结束ident() 线程标识is_alive()daemon 1.2 锁123456789101112131415161718from threading import Thread, Lockcount = 0lock = Lock()class MyThread(Thread): def run(self): global count for i in range(1000000): if lock.acquire(): count += 1 lock.release() print(count)thread_list = (MyThread() for i in range(5))for thread in thread_list: thread.start() 12345678# 创建锁lock = threading.Lock()# 锁定lock.acquire(blocking=True) # blocking=False, 不等待# 释放锁lock.release() 死锁：不同线程持有不同的锁并相互等待的话，就会造成死锁 解决死锁的办法：尽量不使用多个锁，或设计程序时避免死锁，或为锁添加超时等待。 12345678910111213141516171819202122232425262728293031323334from threading import Thread, Lockcount = 0lock1 = Lock()lock2 = Lock()class MyThread1(Thread): def run(self): global count for i in range(1000000): if lock1.acquire(): count += 1 if lock2.acquire(): print(&#x27;this is lock 2&#x27;) lock2.release() lock1.release() print(count)class MyThread2(Thread): def run(self): global count for i in range(1000000): if lock2.acquire(): count += 1 if lock1.acquire(): print(&#x27;this is lock 1&#x27;) lock1.release() lock2.release() print(count)thread_list = (MyThread1(), MyThread2())for thread in thread_list: thread.start() 1.3 Condition1234567891011121314151617181920212223242526272829303132import timeimport threadingproduct = Nonecon = threading.Condition()def produce(): global product if con.acquire(): while True: if product is None: print &#x27;producing&#x27; product = &#x27;anything&#x27; con.notify() con.wait() time.sleep(2) def consume(): global product if con.acquire(): while True: if product is not None: print &#x27;consuming&#x27; product = None con.notify() con.wait() time.sleep(2) t1 = threading.Thread(target=produce)t2 = threading.Thread(target=consume)t1.start()t2.start() 1.4 GILGIL: 解释器全局锁 全局锁的存在是为了保护多线程对数据的安全访问； 对于任何Python程序，不管有多少的处理器内核，任何时候都总是只有一个线程在执行； 全局锁的存在使得一般情况下多线程比单线程的执行速度慢； python程序只有在io密集时多线程代码效率有所提高，所以不推荐使用多线程而是多进程；更好的替代方案为协程 2. 多进程2.1 os.fork()123456789101112131415import osimport timepid = os.fork()if pid == 0: print(&#x27;child process&#x27;) print(&#x27;PID: %s, PPID: %s&#x27; % (os.getpid(), os.getppid())) time.sleep(10)else: print(&#x27;parent process&#x27;) print(&#x27;PID: %s&#x27; % os.getpid()) time.sleep(5) os.wait() # 等待子进程结束释放资源 fork缺点: 兼容性差，只支持POSIX系统 扩展性差，多进程下，进程管理变得很复杂 会产生“孤儿”和“僵尸”进程 fork优点: 系统自带最接近底层的创建方式运行效率高 补充知识点: 123456789101112131415161718192021222324# os._exit() &amp; sys.exit()os._exit(): 不执行任何的清除工作(例如刷新缓冲区)。适用于退出子进程。参数必须是进程的退出状态，0正常终止。sys.exit(): 操作系统会回收父进程或其它子进程可能仍然需要的资源。传给os._exit()函数的。 # os.walk()os.walk(top, topdown=True, onerror=None, followlinks=False) 遍历目录树，对根目录top（包括根目录top本身）中的每个目录，它都会yield一个3元元组(dirpath, dirnames, filenames)。dirpath是一个字符串，为目录路径dirnames是dirpath中子目录的名称列表（不包括&#x27;.&#x27;和&#x27;..&#x27;)。filenames 是dirpath中非目录文件的名称列表。for dirpath, dirnames, filenames in os.walk(top_dir, False): for filename in filenames: file_path=os.path.join(dirpath, filename) os.remove(file_path) # os.path.walk(top, func, arg) 不适合对遍历的目录做修改操作，Python 3.x 已去除def find_file(arg, dirpath, filenames): for filename in filenames: file_path = os.path.join(dirpath, filename) if os.path.isfile(file_path): print(file_path)os.path.walk(&#x27;/Users/eli/utime&#x27;, find_file, ()) 2.2 创建进程12345678910111213import osimport timefrom multiprocessing import Process, Queuedef test(): time.sleep(2) print(&#x27;this is process &#123;&#125;&#x27;.format(os.getpid()))if __name__ == &#x27;__main__&#x27;: p = Process(target=test) p.start() p.join() # 等待子进程结束 print(&#x27;Done&#x27;) 说明： join() 主进程阻塞等待子进程结束 windows系统在子进程结束后立即自动清理子进程。Linux系统，如果没有join()，会在主进程结束后统一清理 Process分析: 123class Process(object): def __init__(self, group=None, target=None, name=None, args=(), kwargs=&#123;&#125;): pass 参数: target: 进程执行的目标函数 name: 进程名 args: 目标函数参数 kwargs: 目标函数参数 方法: start(): 启动子进程，每个Process实例只能执行一次，其会创建一个进程执行该类的run方法。 run(): 子进程需要执行的代码； join(): 主进程阻塞等待子进程直到子进程结束才继续执行，可以设置等待超时时间timeout. terminate(): 使活着的进程终止； is_alive(): 判断子进程是否还活着。 2.3 进程池Pool12345678910111213141516import osimport timefrom multiprocessing import Pooldef test(): time.sleep(2) print(&#x27;this is process &#123;&#125;&#x27;.format(os.getpid()))if __name__ == &#x27;__main__&#x27;: pool = Pool(5) # 设置进程池中进程数 for _ in range(10): pool.apply_async(test) pool.close() # 关闭进程池 pool.join() print(&#x27;Done&#x27;) Pool分析: 1234class Pool(object): def __init__(self, processes=None, initializer=None, initargs=(), maxtasksperchild=None, context=None): pass 参数: processes：进程池的大小，默认为CPU内核数量 initializer：创建进程执行的目标函数，其会按照进程池的大小创建相应个数的进程 initargs：目标函数的参数 context：代码的上下文 方法: apply(): 使用阻塞方式调用func apply_async(): 使用非阻塞方式条用func close()：关闭Pool，不再接受新的任务 terminate()：不管任务是否完成，立即终止 join()：主进程阻塞，等待子进程的退出，必须在close()后面使用 map(self, func, iterable, chunksize=None)：多进程执行一个函数，传入不同的参数 map_async(self, func, iterable, chunksize=None, callback=None,error_callback=None):异步方式的map starmap(self, func, iterable, chunksize=None)：和map类似，但iterable参数可解压缩 starmap_async(self, func, iterable, chunksize=None, callback=None, error_callback=None): 使用异步的方式的- starmap，callback为返回后的处理函数 2.4 进程锁进程不像线程一个共享内存，每个进程都有独立的内存空间。但进程可共享文件系统，例如磁盘，当同时操作文件时，需要锁来确保文件的一致性 multiprocess.Lock(): 由于进程不共享内存，Lock无法用来同步数据，唯一的用途：当多进程在同一个屏幕上打印数据时，需要它来控制打印顺序 12345678910111213141516171819202122232425262728import osfrom multiprocessing import Pool, Locklock = Lock()def test(): if lock.acquire(): with open(&#x27;./test.txt&#x27;, mode=&#x27;r+&#x27;) as f: x = f.read() if not x: f.write(&#x27;0&#x27;) else: f.seek(0) f.write(str(int(x) + 1)) f.flush() f.close() lock.release()if __name__ == &#x27;__main__&#x27;: pool = Pool(5) for _ in range(10): pool.apply_async(test) pool.close() pool.join() with open(&#x27;./test.txt&#x27;) as f: print(f.read()) 2.5 Queue1234567891011121314151617181920212223from multiprocessing import Queue, Processimport timedef task_write(queue): for i in range(50): print &#x27;Put %s to Queue&#x27; % i queue.put(i) time.sleep(1) def task_read(queue): while True: result = queue.get() print &#x27;Get %s from Queue&#x27; % result if __name__ == &#x27;__main__&#x27;: queue = Queue() pw = Process(target=task_write, args=(queue,)) pr = Process(target=task_read, args=(queue,)) pw.start() pr.start() pw.join() pr.terminate() # 死循环，只能把它terminate掉 2.6 多进程内存共享：1) multiprocess.Queue 2) Array, Value (Shared Memory) 3) Manager (slower than Array/Value) 123456manager = Manager()d = manager.dict()l = manager.list(range(10))p = Process(target=f, args=(d, l)) 3. asyncio协程协程实现了在单线程下的并发，每个协程共享线程的几乎所有的资源，除了协程自己私有的上下文栈；协程的切换属于程序级别的切换，对于操作系统来说是无感知的，因此切换速度更快、开销更小、效率更高，在有多IO操作的业务中能极大提高效率。 3.1 创建协程1234567891011121314import asyncioimport osasync def target_func(): print(&#x27;start the func&#x27;) print(os.getpid()) print(&#x27;end the func&#x27;)if __name__ == &#x27;__main__&#x27;: coroutine = target_func() loop = asyncio.get_event_loop() # 创建一个事件循环 loop.run_until_complete(coroutine) print(os.getpid()) loop.close() 123456789101112131415161718192021import asyncioimport osasync def func1(): print(&#x27;start func 1&#x27;) print(os.getpid()) await func2() # 当前协程挂起 print(&#x27;end func 1&#x27;)async def func2(): print(&#x27;start func 2&#x27;) print(os.getpid()) asyncio.sleep(2) print(&#x27;end func 2&#x27;)if __name__ == &#x27;__main__&#x27;: coroutine = func1() loop = asyncio.get_event_loop() loop.run_until_complete(coroutine) print(os.getpid()) loop.close() 主要方法： 123456789101112131415161718asyncio.get_event_loop(): 创建一个事件循环，所有异步函数都需要在事件循环中运行asyncio.ensure_future(): 创建一个任务asyncio.gather(*fs): 添加并行任务asyncio.wait(fs): 添加并行任务，可以是列表loop.run_until_complete(func): 添加协程函数同时启动阻塞直到结束loop.run_forever(): 运行事件无限循环，直到stop被调用loop.create_task(): 创建一个任务并添加到循环loop.close(): 关闭循环loop.time(): 循环开始后到当下的时间loop.stop(): 停止循环loop.is_closed(): 判断循环是否关闭loop.create_future(): 创建一个future对象，推荐使用这个函数而不要直接创建future实例loop.call_soon(): 设置回调函数，不能接受返回的参数，需要用到future对象，立即回调loop.call_soon_threadsafe(): 线程安全的对象loop.call_later(): 异步返回后开始算起，延迟回调loop.call_at(): 循环开始多少s回调loop.call_exception_handler(): 错误处理 主要的类： 12345678910111213141516# Future: 主要用来保存任务的状态future = Future()future.result() # 获取任务的结果future.remove_done_callback(fn) # 删除所有的回调函数并返回个数future.set_result(&#x27;result&#x27;) # 设置任务的结果，必须在result()之前执行，否则报错future.exception() # 获取任务的错误信息future.set_exception(&#x27;bad&#x27;) # 设置任务的错误信息future.add_done_callback(&#x27;fn&#x27;) # 添加回调函数# Task: Future的子类，扩展了Future的功能current_task() # 返回循环当前的任务，类方法all_tasks() # 返回事件循环所有的任务get_stack() # 获取其他协程的堆栈列表print_stack # 输出其他协程的堆栈列表cancel # 取消任务 3.2 多任务123456789101112import asyncioasync def target_func(name): await asyncio.sleep(1) print(name) return 0if __name__ == &#x27;__main__&#x27;: loop = asyncio.get_event_loop() x = loop.run_until_complete(asyncio.gather(*(target_func(i) for i in (&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;)))) loop.close() 3.3 使用Future类来作为第三方保存结果run_forever()不能直接得到异步函数的返回结果，需要使用Future类来作为第三方保存结果,同时设置回调函数 123456789101112131415161718192021222324import asynciofrom functools import partialasync def target_func(name, future): await asyncio.sleep(1) print(name) future.set_result(name)def get_result(loop, future): print(future.result()) loop.stop()if __name__ == &#x27;__main__&#x27;: loop = asyncio.get_event_loop() future = asyncio.Future(loop=loop) res = asyncio.ensure_future(target_func(&#x27;A&#x27;, future)) print(res) future.add_done_callback(partial(get_result, loop)) loop.run_forever() loop.close() 3.4 回调123456789101112131415161718192021222324252627import asynciofrom functools import partialasync def target_func(): print(&#x27;the func end&#x27;) return 1def get_result(loop): print(&#x27;xxxxx&#x27;) loop.stop()if __name__ == &#x27;__main__&#x27;: loop = asyncio.get_event_loop() loop.create_task(target_func()) # loop.call_soon(partial(get_result, loop)) # 设置回掉函数，不能接受返回的参数，需要用到future对象 # loop.call_soon_threadsafe(partial(get_result, loop)) # 线程安全 # loop.call_later(delay=5, callback=partial(get_result, loop)) # 延迟5s后回掉 # loop.call_at(when=8000, callback=partial(get_result, loop)) # 循环开始第8秒回调 loop.call_exception_handler() # 错误处理 loop.run_forever() loop.close() 3.5 异步网络IO123456789101112131415161718192021222324import asyncioimport timefrom aiohttp import ClientSessionasync def func(): print(&#x27;start func&#x27;) async with ClientSession() as session: async with session.get(url=&#x27;http://www.baidu.com&#x27;) as resp: data = await resp.read() print(&#x27;end func&#x27;) print(data)if __name__ == &#x27;__main__&#x27;: loop = asyncio.get_event_loop() tasks = [func() for _ in range(10)] ts = asyncio.gather(*tasks) t = time.time() loop.run_until_complete(ts) print(time.time() - t) loop.close() 3.6 协程Queueasyncio模块也有自己的queue实现生产消费模式，只要有三种队列：Queue(先进先出),PriorityQueue(优先级队列),LifoQueue(栈)，但是Queue不是线程安全的类，在多进程或多线程的情况下不要使用这个队列。 12345678910111213141516171819202122import asynciofrom asyncio import Queueasync def producer(q: Queue): for i in range(100): await q.put(i)async def consumer(q: Queue): for i in range(100): x = await q.get() print(x)if __name__ == &#x27;__main__&#x27;: loop = asyncio.get_event_loop() q = Queue(100) task = asyncio.gather(producer(q), consumer(q)) loop.run_until_complete(task) loop.close() 4. gevent协程4.1 greenlet协程greenlet模块，程序显性主动控制协程切换，但是对原生做了一定的封装使得切换变得简单一些。 1234567891011121314151617181920212223242526import timefrom greenlet import greenletdef func1(g1: greenlet, g2: greenlet): for i in range(20): print(&#x27;----A----&#x27;) g1.switch(g2, g1) time.sleep(0.5)def func2(g1: greenlet, g2: greenlet): for i in range(20): print(&#x27;----B----&#x27;) g1.switch(g2, g1) time.sleep(0.5)if __name__ == &#x27;__main__&#x27;: t = time.time() g1 = greenlet(func1) g2 = greenlet(func2) g1.switch(g2, g1) print(time.time() - t) greenlet类的主要方法： switch()：用来切换协程 throw()：用来抛出异常同时终止程序 4.2 gevent协程 gevent是对greenlet的封装，使其变得更加的易用 gevent采用了隐式启动事件循环，即在需要阻塞的时候开启一个专门的协程来启动事件循环 如果一个任务没有io操作，那么他会一直执行直到完成；其他协程没有执行的机会 自动识别io事件，放弃CPU控制时间 123456789101112131415161718from gevent import monkey; monkey.patch_all()import geventimport requestsdef func(n): print(&#x27;---start---&#123;&#125;&#x27;.format(n)) resp = requests.get(&#x27;http://www.baidu.com&#x27;) print(resp) return nif __name__ == &#x27;__main__&#x27;: jobs = [gevent.spawn(func, i) for i in range(1, 4)] gevent.joinall(jobs) print([job.value for job in jobs]) gevent模块分析 1) gevent顶层方法： 12345678910gevent.spawn():创建一个普通的Greenlet对象并切换；gevent.spawn_later(seconds=3) # 延时创建一个普通的Greenlet对象并切换gevent.spawn_raw() # 创建的协程对象属于一个组gevent.getcurrent() # 返回当前正在执行的greenletgevent.joinall(jobs)：将协程任务添加到事件循环，接收一个任务列表gevent.wait() # 可以替代join函数等待循环结束，也可以传入协程对象列表gevent.kill() # 杀死一个协程gevent.killall() # 杀死一个协程列表里的所有协程monkey.patch_all()：非常重要，会自动将python的一些标准模块替换成gevent框架 2) 设置强制切换时间 1234# 手动设置CPU密集型最大执行时间，如果是单线程的协程不需要关注这个sys.setcheckinterval(n):每n条执行尝试进行线程切换,n必须是intsys.getswitchinterval() # 默认5ms切换 3) greenlet对象 1234567891011121314151617181920212223242526272829303132333435363738# Greenlet对象from gevent import Greenlet# Greenlet对象创建job = Greenlet(target0, 3)Greenlet.spawn() # 创建一个协程并启动Greenlet.spawn_later(seconds=3) # 延时启动# 协程启动job.start() # 将协程加入循环并启动协程job.start_later(3) # 延时启动# 等待任务完成job.join() # 等待任务完成job.get() # 获取协程返回的值# 任务中断和判断任务状态job.dead() # 判断协程是否死亡job.kill() # 杀死正在运行的协程并唤醒其他的协程，这个协程将不会再执行，可以job.ready() # 任务完成返回一个真值job.successful() # 任务成功完成返回真值，否则抛出错误# 获取属性job.loop # 时间循环对象job.value # 获取返回的值# 捕捉异常job.exception # 如果运行有错误，获取它job.exc_info # 错误的详细信息# 设置回调函数job.rawlink(back) # 普通回调，将job对象作为回调函数的参数job.unlink() # 删除回调函数# 执行成功的回调函数job.link_value(back)# 执行失败的回调函数job.link_exception(back) 4.3 协程池Pool，限制并发123456789101112131415161718import requestsdef func(): print(&#x27;----start----&#x27;) resp = requests.get(&#x27;http://www.baidu.com&#x27;) print(resp) print(&#x27;----end----&#x27;) return 0if __name__ == &#x27;__main__&#x27;: from gevent.pool import Pool pool = Pool(5) for _ in range(10): pool.apply_async(func) pool.join() gevent.Pool的特殊方法： 12345678pool.wait_available():等待直到有一个协程有结果pool.dd(greenlet):向进程池添加一个方法并跟踪，非阻塞pool.discard(greenlet):停止跟踪某个协程pool.start(greenlet):加入并启动协程pool.join():阻塞等待结束pool.kill():杀死所有跟踪的协程pool.killone(greenlet):杀死一个协程 5. Queue单线程、多线程之间、进程之间、协程之间很多时候需要协同完成工作，这个时候它们需要进行通讯。或者说为了解耦，普遍采用Queue，生产消费模式。 5.1 dequedeque一般用在定长队列，多余的数据会被丢弃，这个队列是线程非安全的。 123456789101112131415161718192021222324252627282930313233343536373839from queue import dequeq = deque(iterable=[1, 2, 3, 4], maxlen=5)# 尾部添加和弹出q.append(3)q.pop()# 头部添加和弹出q.appendleft(5)q.popleft()# 扩展队列q.extend([6, 7, 8])q.extendleft([0, 9, 8])# 插入, 队列达到最大，抛出异常q.pop()q.insert(2, 3)# 删除元素，所有为3的元素q.remove(3)# 复制, q修改，q2不变q2 = q.copy()q.pop()# 变换q.reverse()q.rotate(2)# 统计n = q.count(0)x = q.index(0)# 清空队列q.clear() 5.2 QueueQueue提供更加完整成熟的队列操作，相对于deque来说偏重型，他是线程安全的队列。 方法和属性: 1234567891011121314151617181920212223242526from queue import Queue, dequeq = Queue(maxsize=5) #maxsize&lt;=0，队列长度没有限制，这个Queue是线程安全的，通过锁机制保证print(q.queue) # 一个deque队列print(q.mutex) # 队列的线程锁print(q.not_empty) # 非空通知，用在多线程print(q.not_full) # 非满通知，用在多线程print(q.all_tasks_done) # 完成的任务print(q.maxsize)print(q.unfinished_tasks) # 队列未完成的任务数量，即队列目前的数目# 数据存取q.put(3, block=True, timeout=3) # 向队列左边添加数据，block为True队列满了阻塞等待，block为false则直接抛出异常q.get(block=True, timeout=3) # 队列取出数据，超时抛出异常，block为false忽略timeout# q.get_nowait() # 立即获取，没有抛出异常q.put_nowait(4) # 立即插入，已满抛出异常# 判断q.full() # 判断当前队列是否已满，满了返回Trueq.empty() # 判断当前队列是否为空，空返回True# 统计q.task_done() # 用来通知队列任务完成q.qsize() # 当前队列的任务数量，不绝对可靠q.join() # 阻塞直到所有的任务完成，即q.unfinished_tasks降为0 5.2.1 线程间通信：123456789101112131415161718192021222324252627import timefrom queue import Queuefrom threading import Threaddef producer(queue: Queue): for i in range(100): if not queue.full(): queue.put_nowait(i) else: time.sleep(0.1)def consumer(queue: Queue): while True: if not queue.empty(): print(queue.get_nowait()) queue.task_done() # 完成任务if __name__ == &#x27;__main__&#x27;: q = Queue(5) t1 = Thread(target=consumer, args=(q,)) t2 = Thread(target=producer, args=(q,)) t1.start() t2.start() 5.2.2 进程间通信：123456789101112131415161718192021222324252627import timefrom multiprocessing import Process, Queuedef producer(queue: Queue): for i in range(100): if not queue.full(): queue.put_nowait(i) else: time.sleep(0.1)def consumer(queue: Queue): while True: if not queue.empty(): print(queue.get_nowait())if __name__ == &#x27;__main__&#x27;: q = Queue(5) t1 = Process(target=consumer, args=(q,)) t2 = Process(target=producer, args=(q,)) t1.start() t2.start() t1.join() t2.join() 5.2.3 gevent协程间通信12345678910111213141516171819202122232425262728293031323334import geventfrom gevent.queue import Queuedef producer(queue: Queue, n): i = 0 print(&#x27;start--put--&#123;&#125;&#x27;.format(n)) while True: queue.put(i) print(str(i) + &#x27; put &#x27; + str(n)) i += 1 if i == 100: breakdef consumer(queue: Queue, n): i = 0 print(&#x27;start--get--&#123;&#125;&#x27;.format(n)) while True: print(str(queue.get()) + &#x27; get &#x27; + str(n)) i += 1 if i == 100: breakif __name__ == &#x27;__main__&#x27;: q = Queue(5) job1 = [gevent.spawn(producer, q, i) for i in range(2)] job2 = [gevent.spawn(consumer, q, i) for i in range(2)] job1.extend(job2) print(len(job1)) gevent.joinall(job1) 6. 总结6.1 进程、线程和协程的资源比较1) 进程： 创建一个进程后，每个进程拥有自己独立的内存地址空间，代码段，数据段，BSS段，堆，栈等所有用户空间的信息； 多进程中，子进程复制主进程的几乎所有信息，除了pid等特殊信息； 2) 线程： 一个进程下多个线程，多个线程共享进程的进程代码段，进程的公有数据（堆），进程的所拥有其他辅助资源； 各个线程独立拥有的资源包括：线程id，程序计数器，一个栈，计数器寄存器和栈用来保存线程的执行历史和执行状态。 3) 协程： 协程可以看做轻量级的线程，即协程是在线程下开启，多协程在单线程下实现并发，而操作系统最多只能感知到线程，也就是说协程的切换对于操作系统来说是无感知的，属于程序级别的切换； 多个协程共享单线程的代码段、公有数据（堆）等； 每个协程拥有自己的栈来保存上下文状态，协程的切换开销更小，对操作系统来说，会认为一个开启了多协程的线程一直在计算； 协程的优势在于切换的代价更小，因此CPU的有效利用率得到了提高。 python的协程主流通过gevent和asyncio模块实现，它们的核心原理都是底层用代码创建事件循环来对多个协程的上下文进行调度； 6.2 进程、线程和协程的应用场景 python的代码尽量避免使用多线程； 如果上下文有一段代码可以分成相对独立的两个部分，如果独立的两个部分是CPU密集型，那么使用多进程；如果是IO密集型，那么使用协程；如果两者都涉及，可以考虑使用子进程中运行协程。 业务代码为了快速创建协程或进程，同时增强代码的可读性，推荐使用匿名函数。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Redis","slug":"Redis","date":"2019-01-29T03:12:17.000Z","updated":"2021-06-22T10:50:49.728Z","comments":true,"path":"2019/01/29/Redis/","link":"","permalink":"https://elihe2011.github.io/2019/01/29/Redis/","excerpt":"1. NoSQLNoSQL追求的目标： High performance 对数据库高并发读写的需求 Huge Storage 海量数据的高效率存储和访问需求 High Scalability &amp;&amp; High Availabiity 高可扩展性和高可用性需求","text":"1. NoSQLNoSQL追求的目标： High performance 对数据库高并发读写的需求 Huge Storage 海量数据的高效率存储和访问需求 High Scalability &amp;&amp; High Availabiity 高可扩展性和高可用性需求 2. Redis相关概念Redis：Remote Dictionary Server Redis的特点： key-value 存储 支持数据可靠性存储及落地 单进程但线程高性能服务器 crash safe &amp; recovery slow 单机qps可达10W 适合小数据量高速读写访问 Redis优点： 支持持久化 高性能，每秒读写频率超过10W 数据类型丰富。string, list, hash, set, sorted set等 所有操作原子性 还支持publish/subscribe、通知、key过期等 支持异机主从复制 Redis缺陷和陷阱： 内存管理开销大（低于物理内存的60%） buffer io造成系统OOM Redis持久化： Snapshot: 快照方式，将内存中的数据不断写入磁盘 save 900 1 save 300 10 save 60 10000 AOF: 类似MySQL的binlog日志方式，记录每次更新的日志(aof不用于主从同步) appendfsync always appendfsync everysec // 在性能和持久化方面折中 appendfsync no Snapshot性能更高，但可能会引起一定程度的数据丢失 建议： 更新频繁，一致性要求较高，AOF策略为主 更新不频繁，可以容忍少量数据丢失或错误，Snapshot为主 2.1 Redis应用场景： 计数 cache服务 展示最近、最热、点击率最高、活跃度最高等条件的top list 用户最近访问记录 Relation List/Message Queue 粉丝列表 2.2 Redis 使用经验： 进行master-slave主从同步配置，在出现服务故障时可切换 在master禁用数据持久化，在slave上配置数据持久化 Memory+swap不足。此时dump会挂死，最终会导致机器挡掉。64-128GB内存， SSD硬盘。 当使用的Memory超过60%，会使用swap，内存碎片大 当达到最大内存时，会清空带过期时间的key，即使该key未过期 redis和DB同步，先写DB，后写redis，内存写速度快 2.3 Redis部署：123456redis-serverredis-cliredis-benchmark # 测试Redis在当前系统、当前配置下的性能redis-check-aof # 检查更新日志appendonly.aofredis-check-dump # 检查本地数据库rdb文件 2.4 Redis启动：1234567redis-serverredis-server --port 6479redis-server --port 6479 --slaveof 127.0.0.1 6579redis-server /etc/redis/redis.confredis-server /etc/redis/redis.conf --loglevel verboseredis-server /etc/redis/redis.conf --sentinel 2.5 客户端操作：redis库(select 0~15)1234567891011telnet 192.168.1.100 6379echo &quot;set name abc&quot; | nc 127.0.0.1 6379redis-cli -h 192.168.1.100 -p 6379 -n 5&gt; help set&gt; help @string # 字符串操作相关的所有命令&gt; ping =&gt; pong&gt; keys *&gt; ttl KEY 2.6 Redis设置客户端连接密码：123456789101112vi /etc/redis/redis.confrequirepass New_Passredis-cli shutdownredis-server /etc/redis/redis.conf# 方法1：redis-cli&gt; auth New_Pass# 方法2：redis-cli -a New_Pass 不安全的命令改名： 12vi /etc/redis/redis.confrename-command keys &quot;&quot; 2.8 Redis配置文件说明：12345678910111213141516171819202122232425262728293031daemonize nopidfile /var/run/redis.pidport 6379bind 127.0.0.1timeout 0 # 0 client永不超时loglevel notice logfile &quot;/var/log/redis.log&quot;databases 16# snapchatsave 900 1save 300 10save 60 10000 # after 60 sec if at least 10000 keys changedsave &quot;&quot; # 读写频繁时，不使用Snapchatrdbchecksum yesdbfilename dump.rdbmaxmemory bytes?appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysec 2.9 Redis使用建议：1234567key: object-type:id:field length 10~20 value: string 不超过2K set, sortedset 元素个数不超过5000 各数据类型使用场景： List：实时聊天系统、不同进程间传递消息队列、列表类的东西 Set: 2.10 Redis主从同步：1) 主从同步特点 一个master可拥有多个slave slave还可连接到其他slave 主从复制不会阻塞master，数据同步时，master可继续处理client请求 2) 配置 salve: 12slaveof &lt;masterip&gt; &lt;masterport&gt;masterauth &lt;master-password&gt; 1234redis-cli&gt; info&gt; monitor&gt; info replication 2.11 Redis发布和订阅：1) Client 12redis-cli&gt; subscribe channel00 2) Server 12redis-cli&gt; publish channel00 hello 2.12 Redis设置过期时间：12345678910redis-cli&gt; flushdb&gt; keys *&gt; exists name&gt; set name tom&gt; ttl name # -1, 永不过期&gt; expire name 5 # 5s后过期&gt; set age 20&gt; expireat age 1555506769 ​ 过期机制：redis采用lazy expriation方式，即在访问key时判断是否过期，如果过期，则进行过期处理。其次，每秒对volation keys进行抽样测试，如果有过期键，那对所有过期key处理。 3. Redis持久化3.1 支持数据持久化 两种存储方式： snapshot: 快照，定时将内存快照持久化到磁盘，crash会丢失数据 aof(append only mode): 写数据的同时，将操作命令保存日志，不会丢失数据，但维护成本高 redis是单线程的，memcached多线程 redis修改libevent库实现小的epoll，memcached完全依赖libevent，影响性能 redis支持事务 3.2 持久化类型 RDB: 在指定的时间间隔内，将内存中的数据快照写入磁盘 AOF: 以日志形式记录服务器每个写操作。服务器启动时，根据日志文件重构数据库，保证数据库的完整性 无持久化：只在内存中存储，加强版的memcached RDB&amp;AOF: 3.3 RDBsnapshot: 默认方式，将内存中的数据以快照方式写入二进制文件中(dump.rdb) 123save 900 1save 300 10save 60 10000 快照保存过程： redis调用fork，产生一个子进程 父进程继续处理client请求，子进程负责将fork时刻整个内存数据库快照写入临时文件。 子进程完成写入临时文件后，用临时文件替换原来的快照文件，然后子进程退出。 问题：每次快照持久化都是将内存数据完整写入到磁盘，如果数据量较大，读写操作较多，必然会引起磁盘IO问题。 优点： 1) 整个数据库只有一个文件，备份简单 2) 性能最大化，在持久化时，fork出子进程，由子进程完成持久化操作 3) 大数据量时，RDB启动效率更高 缺点： 1) 宕机时，来不及持久化的数据丢失 2) 大数据量时，持久化fork的子进程，可能导致服务器暂停服务100ms甚至更长 3.4 AOF (append only file)12345appendonly yesappendfsync alwaysappendfsync everysecappendfsync no # 完全依赖操作系统，性能最好，但持久化可能丢数据 aof的问题：持久化文件会越来越大。为了压缩aof的持久化文件，redis提供命令bgrewriteaof命令。收到此命令，将使用和快照类似的处理方式，将内存以命令的方式保存到临时文件，最后替换原来的文件。 123# 自动bgrewriteaofauto-aof-rewrite-percentage 100auto-aof-rewrite-size 64mb 优点： 1) 更高的数据安全性 2) 对日志文件采取append写入，即使宕机，也不会破坏日志文件已存在的内容，出现数据不一致问题时，使用redis-check-aof修复 3) 日志文件过大时，启用rewrite机制，保证日志文件切换不丢失 4) 日志文件清晰，有助数据库重建 缺点： 1) 数据文件比RDB大 2) 根据同步策略的不同，AOF运行效率比RDB差 4. 其他常用命令：12345678910redis-cli&gt; auth PASS&gt; config get appendonly&gt; config set appendonly yes # 临时改参数&gt; config get *&gt; config reset&gt; info&gt; flushall&gt; monitor&gt; shutdown Redis-benchmark: 服务器性能测试 12# 100个并发，100000次redis-benchmark -h localhost -p 6379 -c 100 -n 100000 5. Redis优化：1) 内存管理 1234567# HashMap成员数量，小于配置，按紧凑格式存储，内存开销少，任意一个超过，就使用真实的HashMap存储，内存占用大hash-max-zipmap-entries 64 # 成员数量少hash-max-zipmap-value 512 # 成员长度小# Listlist-max-ziplist-value 64list-max-ziplist-entries 512 2) 持久化 选择aof，每个实例不要超过2G 6. 哈希槽redis 在数据和节点之间又加入了一层，把这层称为槽（slot），因该槽主要和哈希有关，又叫哈希槽。最后变成了，节点上放的是槽，槽里放的是数据。槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。哈希解决的是映射问题，使用 key 的哈希值来计算所在的槽，便于数据分配。","categories":[{"name":"NoSQL","slug":"NoSQL","permalink":"https://elihe2011.github.io/categories/NoSQL/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://elihe2011.github.io/tags/redis/"}]},{"title":"HTTP和WebSocket","slug":"HTTP和WebSocket","date":"2019-01-03T03:12:17.000Z","updated":"2021-06-22T10:50:49.728Z","comments":true,"path":"2019/01/03/HTTP和WebSocket/","link":"","permalink":"https://elihe2011.github.io/2019/01/03/HTTP%E5%92%8CWebSocket/","excerpt":"1. 协议 HTTP 1.0: 在一次 TCP 连接中只能完成一个 HTTP 请求 HTTP 1.1: keep-alive，在一次 TCP 连接中完成多个 HTTP 请求 Websocket: 借用HTTP协议来完成握手 12345Connection: UpgradeSec-WebSocket-Extensions: permessage-deflate; client_max_window_bitsSec-WebSocket-Key: km9iqxp+3H2ndD5zXkAczA==Sec-WebSocket-Version: 13Upgrade: websocket","text":"1. 协议 HTTP 1.0: 在一次 TCP 连接中只能完成一个 HTTP 请求 HTTP 1.1: keep-alive，在一次 TCP 连接中完成多个 HTTP 请求 Websocket: 借用HTTP协议来完成握手 12345Connection: UpgradeSec-WebSocket-Extensions: permessage-deflate; client_max_window_bitsSec-WebSocket-Key: km9iqxp+3H2ndD5zXkAczA==Sec-WebSocket-Version: 13Upgrade: websocket 2. 通信方式比较： ajax轮询：浏览器隔几秒向服务器发起一个请求，询问服务器是否有新信息。需要服务器有很快的处理速度和资源。（速度） long poll：采用阻塞模式，客户端发起连接后，如果没消息，就一直不返回Response给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。需要有很高的并发，也就是说同时接待客户的能力。（场地大小） WebSocket：一次HTTP握手后，整个通讯过程是建立在该连接状态中。服务器可主动推送消息给客户端。 WebSocket和HTTP最大不同是： WebSocket是一种双向通信协议。在建立连接后，WebSocket服务器端和客户端都能主动向对方发送或接收数据，就像Socket一样； WebSocket需要像TCP一样，先建立连接，连接成功后才能相互通信。","categories":[{"name":"Network","slug":"Network","permalink":"https://elihe2011.github.io/categories/Network/"}],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://elihe2011.github.io/tags/websocket/"},{"name":"http","slug":"http","permalink":"https://elihe2011.github.io/tags/http/"}]},{"title":"Python 类继承的MRO","slug":"Python 类继承的MRO","date":"2018-12-11T05:40:35.000Z","updated":"2021-06-22T10:50:49.727Z","comments":true,"path":"2018/12/11/Python 类继承的MRO/","link":"","permalink":"https://elihe2011.github.io/2018/12/11/Python%20%E7%B1%BB%E7%BB%A7%E6%89%BF%E7%9A%84MRO/","excerpt":"1. super的TypeError问题1super: TypeError: must be type, not classobj , 原因: 经典类，不支持super","text":"1. super的TypeError问题1super: TypeError: must be type, not classobj , 原因: 经典类，不支持super 2. mro1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class A(object): def __init__(self): self.n = 1 def add(self, m): print(&#x27;self is &#123;0&#125; @A.add&#x27;.format(self)) self.n += mclass B(A): def __init__(self): self.n = 2 def add(self, m): print(&#x27;self is &#123;0&#125; @B.add&#x27;.format(self)) super(B, self).add(m) self.n += 2class C(A): def __init__(self): self.n = 3 def add(self, m): print(&#x27;self is &#123;0&#125; @C.add&#x27;.format(self)) super(C, self).add(m) self.n += 3class D(B, C): def __init__(self): self.n = 4 def add(self, m): print(&#x27;self is &#123;0&#125; @D.add&#x27;.format(self)) super(D, self).add(m) self.n += 4if __name__ == &#x27;__main__&#x27;: d = D() d.add(7) print(d.n) print(D.__mro__) In [10]: D.mro()Out[10]: [__main__.D, __main__.B, __main__.C, __main__.A, object]","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python Review","slug":"Python Review","date":"2018-12-01T02:22:31.000Z","updated":"2021-06-22T10:50:49.727Z","comments":true,"path":"2018/12/01/Python Review/","link":"","permalink":"https://elihe2011.github.io/2018/12/01/Python%20Review/","excerpt":"1. 基础1.1 函数参数 If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart’s delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you’re done, the outer reference will still point at the original object. If you pass an immutable object to a method, you still can’t rebind the outer reference, and you can’t even mutate the object.","text":"1. 基础1.1 函数参数 If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart’s delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you’re done, the outer reference will still point at the original object. If you pass an immutable object to a method, you still can’t rebind the outer reference, and you can’t even mutate the object. 1.2 元类A metaclass is the class of a class. Like a class defines how an instance of the class behaves, a metaclass defines how a class behaves. A class is an instance of a metaclass. type is the usual metaclass in Python. To create your own metaclass in Python you really just want to subclass type. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do ‘extra things’ when creating a class, like registering the new class with some registry, or even replace the class with something else entirely. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475def make_hook(f): f.is_hook = 1 return fclass MyType(type): def __new__(cls, name, bases, attrs): if name.startswith(&#x27;None&#x27;): return None newattrs = &#123;&#125; for attrname, attrvalue in attrs.iteritems(): if getattr(attrvalue, &#x27;is_hook&#x27;, 0): newattrs[&#x27;__%s__&#x27; % attrname] = attrvalue else: newattrs[attrname] = attrvalue return super(MyType, cls).__new__(cls, name, bases, newattrs) def __init__(self, name, bases, attrs): super(MyType, self).__init__(name, bases, attrs) # classregistry.registry(self, self.interfaces) print &quot;Would register class %s now.&quot; % self def __add__(self, other): # Alternatively, to autogenerate the classname as well as the class: # return type(self.__name__ + other.__name__, (self, other), &#123;&#125;) class AutoClass(self, other): pass return AutoClass def unregister(self): # classregistry.unregister(self) print &quot;Would unregister class %s now.&quot; % selfclass MyObject: __metaclass__ = MyTypeclass NoneSample(MyObject): pass# Will print &quot;NoneType None&quot;print type(NoneSample), repr(NoneSample)class Example(MyObject): def __init__(self, value): self.value = value @make_hook def add(self, other): return self.__class__(self.value + other.value)# Will unregister ExampleExample.unregister()inst = Example(1)print inst + instclass Sibling(MyObject): passExampleSibling = Example + Sibling# ExampleSibling is now a subclass of both Example and Sibling (with no# content of its own) although it will believe it&#x27;s called &#x27;AutoClass&#x27;print ExampleSiblingprint ExampleSibling.__mro__ SQLAlchemy Model: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class DeclarativeMeta(type): def __init__(cls, classname, bases, dict_): if &#x27;_decl_class_registry&#x27; not in cls.__dict__: _as_declarative(cls, classname, cls.__dict__) type.__init__(cls, classname, bases, dict_) def __setattr__(cls, key, value): _add_attribute(cls, key, value)class _BoundDeclarativeMeta(DeclarativeMeta): def __new__(cls, name, bases, d): # if tablename is set explicitly, move it to the cache attribute so # that future subclasses still have auto behavior if &#x27;__tablename__&#x27; in d: d[&#x27;_cached_tablename&#x27;] = d.pop(&#x27;__tablename__&#x27;) return DeclarativeMeta.__new__(cls, name, bases, d) def __init__(self, name, bases, d): bind_key = d.pop(&#x27;__bind_key__&#x27;, None) or getattr(self, &#x27;__bind_key__&#x27;, None) DeclarativeMeta.__init__(self, name, bases, d) if bind_key is not None and hasattr(self, &#x27;__table__&#x27;): self.__table__.info[&#x27;bind_key&#x27;] = bind_keydef _declarative_constructor(self, **kwargs): cls_ = type(self) for k in kwargs: if not hasattr(cls_, k): raise TypeError( &quot;%r is an invalid keyword argument for %s&quot; % (k, cls_.__name__)) setattr(self, k, kwargs[k])_declarative_constructor.__name__ = &#x27;__init__&#x27;def declarative_base(bind=None, metadata=None, mapper=None, cls=object, name=&#x27;Base&#x27;, constructor=_declarative_constructor, class_registry=None, metaclass=DeclarativeMeta): lcl_metadata = metadata or MetaData() if bind: lcl_metadata.bind = bind if class_registry is None: class_registry = weakref.WeakValueDictionary() bases = not isinstance(cls, tuple) and (cls,) or cls class_dict = dict(_decl_class_registry=class_registry, metadata=lcl_metadata) if isinstance(cls, type): class_dict[&#x27;__doc__&#x27;] = cls.__doc__ if constructor: class_dict[&#x27;__init__&#x27;] = constructor if mapper: class_dict[&#x27;__mapper_cls__&#x27;] = mapper return metaclass(name, bases, class_dict)def make_declarative_base(self, model, metadata=None): &quot;&quot;&quot;Creates the declarative base.&quot;&quot;&quot; base = declarative_base(cls=model, name=&#x27;Model&#x27;, metadata=metadata, metaclass=_BoundDeclarativeMeta) if not getattr(base, &#x27;query_class&#x27;, None): base.query_class = self.Query base.query = _QueryProperty(self) return base 1.3 Instance, Class, and Static MethodsStatic methods can neither access the object instance state nor the class state. They work like regular functions but belong to the class’s (and every instance’s) namespace. 1.4 类变量和实例变量123456789101112131415161718192021222324class A(object): x = 1 def __init__(self, y): self.y = y A.__dict__&gt;&gt; mappingproxy(&#123;&#x27;__module__&#x27;: &#x27;__main__&#x27;, &#x27;x&#x27;: 1, &#x27;__init__&#x27;: &lt;function __main__.A.__init__(self, y)&gt;, &#x27;__dict__&#x27;: &lt;attribute &#x27;__dict__&#x27; of &#x27;A&#x27; objects&gt;, &#x27;__weakref__&#x27;: &lt;attribute &#x27;__weakref__&#x27; of &#x27;A&#x27; objects&gt;, &#x27;__doc__&#x27;: None&#125;)a = A(2)a.__dict__&gt;&gt; &#123;&#x27;y&#x27;: 2&#125;a.x&gt;&gt; 1a.x = 3a.__dict__&gt;&gt; &#123;&#x27;y&#x27;: 2, &#x27;x&#x27;: 3&#125; 1.5 自省12345type(obj)dir(obj)isinstance(obj, cls)hasattr(obj, attr)getattr(obj, attr) 1.6 字典推导1234m = [(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2)]&#123;x: y for x, y in m&#125;&gt;&gt; &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: 2&#125; 1.7 私有属性12345678910111213class Foo: def __init__(self): self._semiprivate = 1 self.__superprivate = 2foo = Foo()foo._semiprivate # 1foo.__superprivate # AttributeErrorfoo._Foo__superprivate # 2# _foo: weak &quot;internal use&quot;, not work when from M import *# __spam, name mangling, is textually replaced with _classname__spam 1.8 字符串格式化:%和.format12print &#x27;%s&#x27; % &#x27;hello&#x27;print &#x27;&#123;&#125;&#x27;.format(&#x27;hello&#x27;) 1.9 迭代器和生成器Iterables: Everything you can use “for... in...“ on is an iterable; lists, strings, files… Generators: Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly 1.10 *args and **kwargs *args = list of arguments - as positional arguments **kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments. 1.11 面向切面编程AOP和装饰器装饰器是一个很著名的设计模式，经常被用于有切面需求的场景，较为经典的有插入日志、性能测试、事务处理等。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量函数中与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 1.12 鸭子类型“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 我们并不关心对象是什么类型，到底是不是鸭子，只关心行为。 比如在python中，有很多file-like的东西，比如StringIO,GzipFile,socket。它们有很多相同的方法，我们把它们当作文件使用。 又比如list.extend()方法中,我们并不关心它的参数是不是list,只要它是可迭代的,所以它的参数可以是list/tuple/dict/字符串/生成器等. 鸭子类型在动态语言中经常使用，非常灵活，使得python不想java那样专门去弄一大堆的设计模式。 1234567891011class Writer: @staticmethod def write(output, content): output.write(content) output = StringIO.StringIO()Writer.write(output, &#x27;Hello&#x27;)output = open(&#x27;a.txt&#x27;, &#x27;w&#x27;)Writer.write(output, &#x27;Hello&#x27;) 1. 13 Python中重载函数重载主要是为了解决两个问题。 可变参数类型。 可变参数个数。 另外，一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字不同的函数。 好吧，那么对于情况 1 ，函数功能相同，但是参数类型不同，python 如何处理？答案是根本不需要处理，因为 python 可以接受任何类型的参数，如果函数的功能相同，那么不同的参数类型在 python 中很可能是相同的代码，没有必要做成两个不同函数。 那么对于情况 2 ，函数功能相同，但参数个数不同，python 如何处理？大家知道，答案就是缺省参数。对那些缺少的参数设定为缺省参数即可解决问题。因为你假设函数功能相同，那么那些缺少的参数终归是需要用的。 好了，鉴于情况 1 跟 情况 2 都有了解决方案，python 自然就不需要函数重载了。 1.14 新式类和旧式类Important behavior changes between old and new style classes super added MRO changed (explained below) descriptors added new style class objects cannot be raised unless derived from Exception (example below) __slots__ added Classic classes do a depth first search from left to right. Stop on first match. They do not have the __mro__ attribute. 123456789101112131415class C: i = 0class C1(C): passclass C2(C): i = 2class C12(C1, C2): passclass C21(C2, C1): passassert C12().i == 0assert C21().i == 2try: C12.__mro__except AttributeError: passelse: assert False New-style classes MRO is more complicated to synthesize in a single English sentence. It is explained in detail here. One of its properties is that a Base class is only searched for once all its Derived classes have been. They have the __mro__ attribute which shows the search order. 1234567891011class C(object): i = 0class C1(C): passclass C2(C): i = 2class C12(C1, C2): passclass C21(C2, C1): passassert C12().i == 2assert C21().i == 2assert C12.__mro__ == (C12, C1, C2, C, object)assert C21.__mro__ == (C21, C2, C1, C, object) New style class objects cannot be raised unless derived from Exception 12345678910111213141516171819202122232425262728293031323334# OK, old:class Old: passtry: raise Old()except Old: passelse: assert False# TypeError, new not derived from `Exception`.class New(object): passtry: raise New()except TypeError: passelse: assert False# OK, derived from `Exception`.class New(Exception): passtry: raise New()except New: passelse: assert False# `&#x27;str&#x27;` is a new style object, so you can&#x27;t raise it:try: raise &#x27;str&#x27;except TypeError: passelse: assert False 1.15 __new__和__init__的区别 __new__是一个类方法,而__init__是一个实例方法. __new__方法会返回一个创建的实例,而__init__什么都不返回. 只有在__new__返回一个cls的实例时后面的__init__才能被调用. 当创建一个新实例时调用__new__,初始化一个实例时用__init__. 1234567891011121314151617181920class A(object): _dict = dict() def __new__(cls): if &#x27;key&#x27; in A._dict: print &quot;EXISTS&quot; return A._dict[&#x27;key&#x27;] else: print &quot;NEW&quot; return super(A, cls).__new__(cls) def __init__(self): print &quot;INIT&quot; A._dict[&#x27;key&#x27;] = self print &quot;&quot;a1 = A()a2 = A()a3 = A() I’m just trying to streamline one of my classes and have introduced some functionality in the same style as the flyweight design pattern. However, I’m a bit confused as to why init is always called after new. I wasn’t expecting this. Can anyone tell me why this is happening and how I can implement this functionality otherwise? (Apart from putting the implementation into the new which feels quite hacky.) Here’s an example: 1234567891011121314151617181920212223242526272829class A(object): _dict = dict() def __new__(cls): if &#x27;key&#x27; in A._dict: print &quot;EXISTS&quot; return A._dict[&#x27;key&#x27;] else: print &quot;NEW&quot; return super(A, cls).__new__(cls) def __init__(self): print &quot;INIT&quot; A._dict[&#x27;key&#x27;] = self print &quot;&quot;a1 = A()a2 = A()a3 = A()## Outputs:NEWINITEXISTSINITEXISTSINIT __metaclass__是创建类时起作用.所以我们可以分别使用__metaclass__,__new__和__init__来分别在类创建,实例创建和实例初始化的时候做一些小手脚. 1.16 单例模式 ​ 单例模式是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例类的特殊类。通过单例模式可以保证系统中一个类只有一个实例而且该实例易于外界访问，从而方便对实例个数的控制并节约系统资源。如果希望在系统中某个类的对象只能存在一个，单例模式是最好的解决方案。 __new__()在__init__()之前被调用，用于生成实例对象。利用这个方法和类的属性的特点可以实现设计模式的单例模式。单例模式是指创建唯一对象，单例模式设计的类只能实例 这个绝对常考啊.绝对要记住1~2个方法,当时面试官是让手写的. 1.16.1 使用__new__方法12345678class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, &#x27;_instance&#x27;): cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls._instanceclass MyClass(Singleton): a = 1 1.16.2 共享属性创建实例时把所有实例的__dict__指向同一个字典,这样它们具有相同的属性和方法. 123456789class Borg(object): _state = &#123;&#125; def __new__(cls, *args, **kwargs): ob = super(Borg, cls).__new__(cls, *args, **kwargs) ob.__dict__ = cls._state return obclass MyClass2(Borg): a = 1 1.16.3 装饰器版本1234567891011def singleton(cls): instances = &#123;&#125; def getinstance(*args, **kwargs): if cls not in instances: instances[cls] = cls(*args, **kwargs) return instances[cls] return getinstance@singletonclass MyClass: ... 1.16.4 import方法作为python的模块是天然的单例模式 1234567891011# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonmy_singleton.foo() 1.17 Python中的作用域Python 中，一个变量的作用域总是由在代码中被赋值的地方所决定的。 当 Python 遇到一个变量的话他会按照这样的顺序进行搜索： 本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） 1.18 GIL线程全局锁线程全局锁(Global Interpreter Lock),即Python为了保证线程安全而采取的独立线程运行的限制,说白了就是一个核只能在同一时间运行一个线程.对于io密集型任务，python的多线程起到作用，但对于cpu密集型任务，python的多线程几乎占不到任何优势，还有可能因为争夺资源而变慢。 解决办法就是多进程和下面的协程(协程也只是单CPU,但是能减小切换代价提升性能). 1.19 协程简单点说协程是进程和线程的升级版,进程和线程都面临着内核态和用户态的切换问题而耗费许多切换时间,而协程就是用户自己控制切换的时机,不再需要陷入系统的内核态. Python里最常见的yield就是协程的思想! 1.20 闭包闭包(closure)是函数式编程的重要的语法结构。闭包也是一种组织代码的结构，它同样提高了代码的可重复使用性。 当一个内嵌函数引用其外部作作用域的变量,我们就会得到一个闭包. 总结一下,创建一个闭包必须满足以下几点: 必须有一个内嵌函数 内嵌函数必须引用外部函数中的变量 外部函数的返回值必须是内嵌函数 感觉闭包还是有难度的,几句话是说不明白的,还是查查相关资料. 重点是函数运行后并不会被撤销,就像16题的instance字典一样,当函数运行完后,instance并不被销毁,而是继续留在内存空间里.这个功能类似类里的类变量,只不过迁移到了函数上. 闭包就像个空心球一样,你知道外面和里面,但你不知道中间是什么样. 12345def func(n): return lambda x: x + nadd_2 = func(2)add_2(4) 1.21 lambda函数其实就是一个匿名函数,为什么叫lambda?因为和后面的函数式编程有关. 1.22 Python函数式编程不依赖于外部的数据，而且也不改变外部数据的值，而是返回一个新的值给你。 python中函数式编程支持: filter 函数的功能相当于过滤器。调用一个布尔函数bool_func来迭代遍历每个seq中的元素；返回一个使bool_seq返回值为true的元素的序列。 1234&gt;&gt;&gt;a = [1,2,3,4,5,6,7]&gt;&gt;&gt;b = filter(lambda x: x &gt; 5, a)&gt;&gt;&gt;print b&gt;&gt;&gt;[6,7] map函数是对一个序列的每个项依次执行函数，下面是对一个序列每个项都乘以2： 123&gt;&gt;&gt; a = map(lambda x:x*2,[1,2,3])&gt;&gt;&gt; list(a)[2, 4, 6] reduce函数是对一个序列的每个项迭代调用函数，下面是求3的阶乘： 12&gt;&gt;&gt; reduce(lambda x,y:x*y,range(1,4))6 1.23 Python里的拷贝引用和copy(),deepcopy()的区别 1234567891011121314151617181920import copya = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;]] #原始对象b = a #赋值，传对象的引用c = copy.copy(a) #对象拷贝，浅拷贝d = copy.deepcopy(a) #对象拷贝，深拷贝a.append(5) #修改对象aa[4].append(&#x27;c&#x27;) #修改对象a中的[&#x27;a&#x27;, &#x27;b&#x27;]数组对象print &#x27;a = &#x27;, aprint &#x27;b = &#x27;, bprint &#x27;c = &#x27;, cprint &#x27;d = &#x27;, d输出结果：a = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 5]b = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], 5]c = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]]d = [1, 2, 3, 4, [&#x27;a&#x27;, &#x27;b&#x27;]] 1.24 Python垃圾回收机制Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。 1.24.1 引用计数PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。 优点: 简单 实时性 缺点: 维护引用计数消耗资源 循环引用 1.24.2 标记-清除机制基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。 1.24.3 分代技术分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 举例： 当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 1.25 Python的List推荐: http://www.jianshu.com/p/J4U6rR 1.26 Python的isis是对比地址,==是对比值 1.27 read,readline和readlines read 读取整个文件 readline 读取下一行,使用生成器方法 readlines 读取整个文件到一个迭代器以供我们遍历 1.28 Python2和3的区别1.28.1 __future__模块Py2.x导入3.x中侧特性 123from __future__ import divisionfrom __future__ import absolute_importfrom __future__ import print_function 1.28.2 print函数Py2.x中，print为声明，不是函数 12print &#x27;Hello&#x27;,; print &#x27;World!&#x27;print(&#x27;Hello&#x27;, end=&#x27; &#x27;); print(&#x27;World!&#x27;) 1.28.3 整除1234567# 2.xassert 3 / 2 == 1assert 3 // 2 == 1# 3.xassert 3 / 2 == 1.5assert 3 // 2 == 1 1.28.4 Unicode2.x: string is byte 3.x: string is unicode 1.28.5 xrange2.x: range(列表), xrange(惰性求值) 3.x: range(惰性求值), xrange(取消)，特别地，支持range.__contains__, in 操作较快 1.28.6 Exceptions1234567# 2.xraise IOError, &#x27;file error&#x27;catch IOError, e# 2.x, 3.xraise IOError(&#x27;file error&#x27;)catch IOError as e 1.28.6 next()函数和.next()方法1234567891011121314# 2.xclass A(object): def next(self): passa = A()a.next()# 3.xclass A: def __next__(self): pass a = A()next(a) 1.28.7 For循环变量和全局命名空间泄漏123456789101112131415# 2.x[... for var in item1, item2, ...]# 2.x, 3.x[... for var in (item1, item2, ...)]# 2.xi = 1[i for i in range(5)]assert i == 4# 3.xi = 1[i for i in range(5)]assert i == 1 1.29 super initsuper() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven’t already. Note that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer. 1.30 访问私有属性123456class Student(Person): def __init__(self): self.__gender = &#x27;male&#x27; stu = Student()print(stu._Student__gender) 1.31 unicode12unicode.encode() --&gt; bytesbytes.decode() --&gt; unicode 2. 系统相关2.1 selec,poll和epoll区别总结基本上select有3个缺点: 连接数受限 查找配对速度慢 数据由内核拷贝到用户态 poll改善了第一个缺点 epoll改了三个缺点. epoll是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集 合来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符 集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。epoll除了提供select/poll那种IO事件的电平触发 （Level Triggered）外，还提供了边沿触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。Linux2.6内核中对/dev/epoll设备的访问的封装（system epoll）。 2.2 Redis数据库 ​ 通常局限点来说，Redis也以消息队列的形式存在，作为内嵌的List存在，满足实时的高并发需求。在使用缓存的时候，redis比memcached具有更多的优势，并且支持更多的数据类型，把redis当作一个中间存储系统，用来处理高并发的数据库操作 速度快：使用标准C写，所有数据都在内存中完成，读写速度分别达到10万/20万 持久化：对数据的更新采用Copy-on-write技术，可以异步地保存到磁盘上，主要有两种策略，一是根据时间，更新次数的快照（save 300 10 ）二是基于语句追加方式(Append-only file，aof) 自动操作：对不同数据类型的操作都是自动的，很安全 快速的主–从复制，官方提供了一个数据，Slave在21秒即完成了对Amazon网站10G key set的复制。 Sharding技术： 很容易将数据分布到多个Redis实例中，数据库的扩展是个永恒的话题，在关系型数据库中，主要是以添加硬件、以分区为主要技术形式的纵向扩展解决了很多的应用场景，但随着web2.0、移动互联网、云计算等应用的兴起，这种扩展模式已经不太适合了，所以近年来，像采用主从配置、数据库复制形式的，Sharding这种技术把负载分布到多个特理节点上去的横向扩展方式用处越来越多。 Redis缺点 是数据库容量受到物理内存的限制,不能用作海量数据的高性能读写,因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 2.3 MyISAM和InnoDBMyISAM：大量写性能差，大量读性能高；不支持事务。 InnoDB： 支持“行锁” ，于是在写操作比较多的时候，会更优秀。还支持事务。 2.4 网络2.4.1 三次握手 SYN SYN+ACK ACK SYN_SENT –syn–&gt; SYN_RECV –syn+ack–&gt; ESTABLISHED –ack–&gt; ESTABLISHED a 2.4.2 四次挥手 FIN+ACK ACK FIN ACK FIN_WAIT_1 –fin+ack–&gt; CLOSE_WAIT –ack–&gt; FIN_WAIT_2 ​ LAST_ACK –fin–&gt; TIME_WAIT –ack–&gt; CLOSED 2.5 urllib和urllib2urllib2: 可以接受一个Request对象，可以用来设置Headers urllib：提供urlencode方法，用来生成GET查询字符串 12345678910111213141516171819202122232425262728resp = urllib2.urlopen(&#x27;http://python.org&#x27;)html = resp.read()req = urllib2.Request(&#x27;http://python.org&#x27;)resp = urllib2.urlopen(req)html = resp.read()form = &#123;&#x27;name&#x27;: &#x27;alex&#x27;, &#x27;age&#x27;: 21&#125;data = urllib.urlencode(form)headers = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&#x27;&#125;req = urllib2.Request(url, data, headers)resp = urllib2.urlopen(req)html = resp.read()req = urllib2.Request(&#x27;http://python.org&#x27;)req.add_header(&#x27;User-Agent&#x27;, &#x27;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&#x27;)resp = urllib2.urlopen(req)html = resp.read()opener = urllib2.build_opener()opener.addheaders([(&#x27;User-Agent&#x27;, &#x27;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&#x27;)])opener.open(url)s = &#x27;id=1&amp;title=test&#x27;data = urllib.quote(s)form = &#123;&#x27;name&#x27;: &#x27;alex&#x27;, &#x27;age&#x27;: 12&#125;data = urllib.urlencode(form) 2.6 XSRF和XSS CSRF(Cross-site request forgery)跨站请求伪造 XSS(Cross Site Scripting)跨站脚本攻击 CSRF重点在请求,XSS重点在脚本 CSRF攻击：攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账……造成的问题包括：个人隐私泄露以及财产安全。 CSRF防御: 客户端页面增加伪随机数 XSS: 跨站脚本的重点不在‘跨站’上，而在于‘脚本’上。大多数XSS攻击的主要方式是嵌入一段远程或者第三方域上的JS代码。实际上是在目标网站的作用域下执行了这段js代码。 2.7 CGI和WSGICGI是通用网关接口，是连接web服务器和应用程序的接口，用户通过CGI来获取动态数据或文件等。 CGI程序是一个独立的程序，它可以用几乎所有语言来写，包括perl，c，lua，python等等。 WSGI, Web Server Gateway Interface，是Python应用程序或框架和Web服务器之间的一种接口，WSGI的其中一个目的就是让用户可以用统一的语言(Python)编写前后端。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 内存管理和垃圾回收","slug":"Python 内存管理和垃圾回收","date":"2018-09-20T08:25:29.000Z","updated":"2021-06-22T10:50:49.726Z","comments":true,"path":"2018/09/20/Python 内存管理和垃圾回收/","link":"","permalink":"https://elihe2011.github.io/2018/09/20/Python%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"1. python的内存管理机制有三种 引用计数 垃圾回收 内存池 1.1 引用计数引用计数是一种非常高效的内存管理手段，当一个pyhton对象被引用时其引用计数增加1，当其不再被引用时引用计数减1，当引用计数等于0的时候，对象就被删除了。","text":"1. python的内存管理机制有三种 引用计数 垃圾回收 内存池 1.1 引用计数引用计数是一种非常高效的内存管理手段，当一个pyhton对象被引用时其引用计数增加1，当其不再被引用时引用计数减1，当引用计数等于0的时候，对象就被删除了。 1.2 垃圾回收1) 引用计数引用计数也是一种垃圾回收机制，而且是一种最直观，最简单的垃圾回收技术。在Python中每一个对象的核心就是一个结构体PyObject，它的内部有一个引用计数 ob_refcnt，当python的某个对象引用计数为0。就说明没有任何引用指向该对象，该对象就成为要被回收的垃圾了。 2) 标记清除标记清除用来解决循环引用产生的问题，循环引用只有在容器对象才会产生，比如字典，元祖，列表等。首先为了追踪对象，需要每个容器对象维护两个额外的指针，用来将容器对象组成一个链表，指针分别指向前后两个容器对象，这样可以将对象的循环引用摘除，就可以得出两个对象的有效计数。 3) 分代回收了解分类回收，首先要了解一下，GC的阈值，所谓阈值就是一个临界点的值。随着你的程序运行，Python解释器保持对新创建的对象，以及因为引用计数为零而被释放掉的对象的追踪。从理论上说，创建==释放数量应该是这样子。但是如果存在循环引用的话，肯定是创建&gt;释放数量，当创建数与释放数量的差值达到规定的阈值的时候，当当当当~分代回收机制就登场啦。 分代回收思想将对象分为三代（generation 0,1,2） 0代表幼年对象， 1代表青年对象， 2代表老年对象。 根据弱代假说（越年轻的对象越容易死掉，老的对象通常会存活更久。）新生的对象被放入0代，如果该对象在第0代的一次gc垃圾回收中活了下来，那么它就被放到第1代里面（它就升级了）。如果第1代里面的对象在第1代的一次gc垃圾回收中活了下来，它就被放到第2代里面。 从上一次第0代gc后，如果分配对象的个数减去释放对象的个数大于threshold0，那么就会对第0代中的对象进行gc垃圾回收检查。 从上一次第1代gc后，如果第0代被gc垃圾回收的次数大于threshold1，那么就会对第1代中的对象进行gc垃圾回收检查。 从上一次第2代gc后，如果第1代被gc垃圾回收的次数大于threshold2，那么就会对第2代中的对象进行gc垃圾回收检查。 gc每一代垃圾回收所触发的阈值可以自己设置。 1.3 内存池Python的内存机制呈现金字塔形状，-1，-2层主要有操作系统进行操作第0层是C中的malloc，free等内存分配和释放函数进行操作第1层和第2层是内存池，有python接口函数，PyMem_Malloc函数实现，当对象小于256k的时由该层直接分配内存第3层是最上层，也就是我们对python对象的直接操作Python在运行期间会大量地执行malloc和free的操作，频繁地在用户态和核心态之间进行切换，这将严重影响Python的执行效率。为了加速Python的执行效 率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。 2. 调优手段 手动垃圾回收 避免循环引用（手动解循环引用和使用弱引用） 调高垃圾回收阈值","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 调度器","slug":"Python 调度器","date":"2018-09-15T09:01:07.000Z","updated":"2021-06-22T10:50:49.725Z","comments":true,"path":"2018/09/15/Python 调度器/","link":"","permalink":"https://elihe2011.github.io/2018/09/15/Python%20%E8%B0%83%E5%BA%A6%E5%99%A8/","excerpt":"1. sched任务调度器1.1 构造函数：sched.scheduler(timefunc=time.monotonic, delayfunc=time.sleep) 参数： timefunc：生成时间戳的时间函数 delayfunc：阻塞程序的函数 1.2 scheduler调度器常用属性和方法enterabs(time, priority, action, argument=(), kwargs=&#123;&#125;)：定时执行任务 time: 执行时间点 priority: 值越小代表优先级越高 action: 需要执行的函数 enter(delay, priority, action, argument=(),kwargs=&#123;&#125;)：延时执行任务 cancel(event)：取消任务 empty()：判断当前该调度器的调度队列是否为空。 run(blocking=True)：运行所有需要调度的任务。如果调用该方法的 blocking 参数为 True，该方法将会阻塞线程，直到所有被调度的任务都执行完成。 queue：该只读属性返回该调度器的调度队列。","text":"1. sched任务调度器1.1 构造函数：sched.scheduler(timefunc=time.monotonic, delayfunc=time.sleep) 参数： timefunc：生成时间戳的时间函数 delayfunc：阻塞程序的函数 1.2 scheduler调度器常用属性和方法enterabs(time, priority, action, argument=(), kwargs=&#123;&#125;)：定时执行任务 time: 执行时间点 priority: 值越小代表优先级越高 action: 需要执行的函数 enter(delay, priority, action, argument=(),kwargs=&#123;&#125;)：延时执行任务 cancel(event)：取消任务 empty()：判断当前该调度器的调度队列是否为空。 run(blocking=True)：运行所有需要调度的任务。如果调用该方法的 blocking 参数为 True，该方法将会阻塞线程，直到所有被调度的任务都执行完成。 queue：该只读属性返回该调度器的调度队列。 1.3 实例12345678910111213141516171819202122232425262728import schedimport timescheduler = sched.scheduler()def print_time(name=&#x27;default&#x27;): print(&#x27;%s 的时间: %s&#x27; % (name, time.ctime()))print(&#x27;主线程: &#x27;, time.ctime())event1 = scheduler.enter(10, 1, print_time)event2 = scheduler.enter(5, 2, print_time, argument=(&#x27;位置参数&#x27;,))event3 = scheduler.enter(5, 1, print_time, kwargs=&#123;&#x27;name&#x27;: &#x27;关键字参数&#x27;&#125;)scheduler.cancel(event2)scheduler.run(blocking=False)print(event1)print(event2)print(event3)print(&#x27;主线程: &#x27;, time.ctime())","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 多进程","slug":"Python 多进程","date":"2018-09-14T12:19:51.000Z","updated":"2021-06-22T10:50:49.723Z","comments":true,"path":"2018/09/14/Python 多进程/","link":"","permalink":"https://elihe2011.github.io/2018/09/14/Python%20%E5%A4%9A%E8%BF%9B%E7%A8%8B/","excerpt":"1. os.fork()创建新进程fork() 方法的作用在于，程序会启动两个进程（一个是父进程，一个是 fork 出来的子进程）来执行从 os.fork() 开始的所有代码。 1234567891011121314151617181920import osprint(&#x27;启动进程 %s&#x27; % os.getpid())pid = os.fork()# pid=0, 表明是 fork 出来的子进程在执行if pid == 0: print(&#x27;启动子进程 %s, 父进程 %d&#x27; % (os.getpid(), os.getppid()))else: print(&#x27;父进程 %s, 创建子进程 %s&#x27; % (os.getpid(), pid))print(&#x27;进程 %s 结束&#x27; % os.getpid())启动进程 71215父进程 71215, 创建子进程 71216进程 71215 结束启动子进程 71216, 父进程 71215进程 71216 结束","text":"1. os.fork()创建新进程fork() 方法的作用在于，程序会启动两个进程（一个是父进程，一个是 fork 出来的子进程）来执行从 os.fork() 开始的所有代码。 1234567891011121314151617181920import osprint(&#x27;启动进程 %s&#x27; % os.getpid())pid = os.fork()# pid=0, 表明是 fork 出来的子进程在执行if pid == 0: print(&#x27;启动子进程 %s, 父进程 %d&#x27; % (os.getpid(), os.getppid()))else: print(&#x27;父进程 %s, 创建子进程 %s&#x27; % (os.getpid(), pid))print(&#x27;进程 %s 结束&#x27; % os.getpid())启动进程 71215父进程 71215, 创建子进程 71216进程 71215 结束启动子进程 71216, 父进程 71215进程 71216 结束 2. Process创建子进程Process 类的方法和属性： run()：实现进程的执行体 start()：启动进程。 join([timeout])：当前进程必须等待被 join 的进程执行完成才能向下执行 name：进程的名字 is_alive()：是否还活着 daemon：是否后台进程 pid：进程ID authkey：进程的授权key terminate()：中断该进程 12345678910111213141516171819import multiprocessingimport osdef foo(n): for i in range(n): print(&#x27;子进程[%s], 父进程[%s], %s&#x27; % (os.getpid(), os.getppid(), i))if __name__ == &#x27;__main__&#x27;: print(&#x27;主进程[%s]&#x27; % os.getpid()) p1 = multiprocessing.Process(target=foo, args=(100,)) p2 = multiprocessing.Process(target=foo, args=(100,)) p1.start() # p1.join() p2.start() # p2.join() print(&#x27;进程[%s]结束&#x27; % os.getpid()) 3. 启动进程的3种方式1) spawn父进程会启动一个全新的 Python 解释器进程。在这种方式下，子进程只能继承那些处理 run() 方法所必需的资源。典型的，那些不必要的文件描述器和 handle 都不会被继承。使用这种方式来启动进程，其效率比使用 fork 或 forkserver 方式要低得多。 Windows 只支持 spawn 方式来启动进程，因此在 Windows 平台上默认使用这种方式来启动进程。 2) fork父进程使用 os.fork() 来启动一个 Python 解释器进程。在这种方式下，子进程会继承父进程的所有资源，因此子进程基本等效于父进程。这种方式只在 UNIX 平台上有效，UNIX 平台默认使用这种方式来启动进程。 3) forkserver如果使用这种方式来启动进程，程序将会启动一个服务器进程。在以后的时间内，当程序再次请求启动新进程时，父进程都会连接到该服务器进程，请求由服务器进程来 fork 新进程。通过这种方式启动的进程不需要从父进程继承资源。这种方式只在 UNIX 平台上有效。 3.1 set_start_method()multiprocessing 模块提供了一个set_start_method()函数，该函数可用于设置启动进程的方式 1234567891011121314151617181920import multiprocessingimport osdef foo(q): print(&#x27;启动子进程 %s&#x27; % os.getpid()) q.put(&#x27;haha&#x27;)if __name__ == &#x27;__main__&#x27;: # 设置进程启动方式 multiprocessing.set_start_method(&#x27;spawn&#x27;) queue = multiprocessing.Queue() p = multiprocessing.Process(target=foo, args=(queue,)) p.start() p.join() print(queue.get()) 3.2 get_context()利用 get_context() 方法来获取 Context 对象，调用该方法时可传入 spawn、fork 或 forkserver 字符串。Context 拥有和 multiprocessing 相同的 API，因此程序可通过 Context 来创建并启动进程。 123456789101112131415161718import multiprocessingimport osdef foo(q): print(&#x27;启动子进程 %s&#x27; % os.getpid()) q.put(&#x27;haha&#x27;)if __name__ == &#x27;__main__&#x27;: # 设置进程启动方式 ctx = multiprocessing.get_context(&#x27;fork&#x27;) queue = ctx.Queue() p = ctx.Process(target=foo, args=(queue,)) p.start() p.join() print(queue.get()) 4. 多进程编程和多线程编程优缺点多进程编程和多钱程编程，都可以使用并行机制来提升系统的运行效率。二者的区别在于运行时所占的内存分布不同，多钱程是共用一套内存的代码块区间；而多进程是各用一套独立的内存区间。 多进程的优点是稳定性好，一个子进程崩溃了，不会影响主进程以及其余进程。基于这个特性，常常会用多进程来实现守护服务器的功能。 多进程编程也有不足，即创建进程的代价非常大，因为操作系统要给每个进程分配固定的资源，并且操作系统对进程的总数会有一定的限制，若进程过多，操作系统调度都会存在问题，会造成假死状态。 多线程编程的优点是效率较高一些，适用于批处理任务等功能；不足之处在于，任何一个线程崩溃都可能造成整个进程的崩溃，因为它们共享了进程的内存资源池。 既然多线程编程和多进程编程各有优缺点，因此它们分别适用于不同的场景。比如说，对于计算密集型的任务，多进程效率会更高一下；而对于IO密集型的任务（比如文件操作，网络爬虫），采用多线程编程效率更高。为什么是这样呢？ 其实也不难理解。对于 IO 密集型操作，大部分消耗时间其实是等待时间，在等待时间中，Python会释放GIL供新的线程使用，实现了线程间的切换；相反对于 CPU 密集型代码，2 个 CPU 干活肯定比一个 CPU 快很多。 在大型的计算机集群系统中，通常都会将多进程程序分布运行在不同的计算机上协同工作。而每一台计算机上的进程内部，又会由多个线程来并行工作。 注意，对于任务数来说，无论是多进程编程或者多线程编程，其进程数或线程数都不能太多：对于多进程编程来说，操作系统在切换任务时，会有一系列的保护现场措施，这要花费相当多的系统资源，若任务过多，则大部分资源都被用做干这些了，结果就是所有任务都做不好； 线程数 = (线程等待时间 + CPU时间) / CPU时间 * CPU数量 5. 进程池multiprocessing.Pool() 5.1 进程池常用方法： apply(func[, args[, kwds]])：提交给进程池处理 apply_async(func[, args[, kwds[, callback[, error_callback]]]])：apply() 方法的异步版本 map(func, iterable[, chunksize])：使用新进程对 iterable 的每一个元素执行 func 函数。 map_async(func, iterable[, chunksize[, callback[, error_callback]]])：map() 方法的异步版本 imap(func, iterable[, chunksize])：map() 方法的延迟版本 imap_unordered(func, iterable[, chunksize])：类似于 imap() 方法，但该方法不能保证所生成的结果（包含多个元素）与原 iterable 中的元素顺序一致。 starmap(func, iterable[,chunksize])：类似于 map() 方法，但该方法要求 iterable 的元素也是 iterable 对象，程序会将每一个元素解包之后作为 func 函数的参数。 close()：关闭进程池。在调用该方法之后，该进程池不能再接收新任务，它会把当前进程池中的所有任务执行完成后再关闭自己。 terminate()：立即中止进程池。 join()：等待所有进程完成。 5.2 apply_async()123456789101112131415161718192021import multiprocessingimport osimport timedef foo(name=&#x27;default&#x27;): print(&#x27;进程 %s 正在执行，参数为&quot;%s&quot;&#x27; % (os.getpid(), name)) time.sleep(3)if __name__ == &#x27;__main__&#x27;: pool = multiprocessing.Pool(4) pool.apply(foo) pool.apply_async(foo) pool.apply_async(foo, args=(&#x27;位置参数&#x27;,)) pool.apply_async(foo, kwds=&#123;&#x27;name&#x27;: &#x27;关键字参数&#x27;&#125;) pool.close() pool.join() 5.3 map()123456789101112131415161718import multiprocessingimport osdef foo(n): total = 0 for i in range(n): print(&#x27;进程 %s 正在执行： %d&#x27; % (os.getpid(), i)) total += i return totalif __name__ == &#x27;__main__&#x27;: with multiprocessing.Pool(processes=4) as pool: results = pool.map(foo, (50, 100, 150)) for result in results: print(result) 6. 进程间通信6.1 Queuemultiprocessing.Queue: 为进程服务 queue.Queue: 为线程提供服务 他们都提供了 qsize()、empty()、full()、put()、put_nowait()、get()、get_nowait() 等方法。 12345678910111213141516import multiprocessingdef foo(q): print(&#x27;进程 %s 存入数据&#x27; % multiprocessing.current_process().pid) q.put(&#x27;haha&#x27;)if __name__ == &#x27;__main__&#x27;: queue = multiprocessing.Queue() p = multiprocessing.Process(target=foo, args=(queue,)) p.start() p.join() print(&#x27;进程 %s 取出数据&#x27; % multiprocessing.current_process().pid) print(queue.get()) 6.2 Pipemultiprocessing.Pipe(): 创建一个管道，该函数会返回两个 PipeConnection 对象，代表管道的两个连接端（一个管道有两个连接端，分别用于连接通信的两个进程）。 PipeConnection 对象常用方法： send(obj)：发送一个 obj 给管道的另一端。obj 必须是可 picklable, 对象序列化不能超过 32MB，否则可能会引发 ValueError 异常。 recv()：接收另一端通过 send() 方法发送过来的数据。 fileno()：关于连接所使用的文件描述器。 close()：关闭连接。 poll([timeout])：返回连接中是否还有数据可以读取。 send_bytes(buffer[, offset[, size]])：发送字节数据。 recv_bytes([maxlength])：接收通过 send_bytes() 方法发迭的数据， recv_bytes_into(buffer[, offset])：功能与 recv_bytes() 方法类似，只是该方法将接收到的数据放在 buffer 中。 1234567891011121314151617import multiprocessingdef foo(conn): print(&#x27;进程 %s 发送数据&#x27; % multiprocessing.current_process().pid) conn.send(&#x27;haha&#x27;)if __name__ == &#x27;__main__&#x27;: parent_conn, child_conn = multiprocessing.Pipe() p = multiprocessing.Process(target=foo, args=(child_conn,)) p.start() p.join() print(&#x27;进程 %s 接收数据&#x27; % multiprocessing.current_process().pid) print(parent_conn.recv())","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 协程","slug":"Python 协程","date":"2018-09-14T03:25:23.000Z","updated":"2021-06-22T10:50:49.725Z","comments":true,"path":"2018/09/14/Python 协程/","link":"","permalink":"https://elihe2011.github.io/2018/09/14/Python%20%E5%8D%8F%E7%A8%8B/","excerpt":"1. 协程1.1 什么是协程协程，又称微线程，Coroutine。协程的作用，是在执行函数A时，可以随时中断，去执行函数B，然后中断继续执行函数A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。 1.2 协程的优势 执行效率极高，因为子程序切换（函数）不是线程切换，由程序自身控制，没有切换线程的开销。所以与多线程相比，线程的数量越多，协程性能的优势越明显。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在控制共享资源时也不需要加锁，因此执行效率高很多。 说明：协程可以处理IO密集型程序的效率问题，但是处理CPU密集型不是它的长处，如要充分发挥CPU利用率可以结合多进程+协程。","text":"1. 协程1.1 什么是协程协程，又称微线程，Coroutine。协程的作用，是在执行函数A时，可以随时中断，去执行函数B，然后中断继续执行函数A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。 1.2 协程的优势 执行效率极高，因为子程序切换（函数）不是线程切换，由程序自身控制，没有切换线程的开销。所以与多线程相比，线程的数量越多，协程性能的优势越明显。 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在控制共享资源时也不需要加锁，因此执行效率高很多。 说明：协程可以处理IO密集型程序的效率问题，但是处理CPU密集型不是它的长处，如要充分发挥CPU利用率可以结合多进程+协程。 1.3 线程、进程、协程比较1)多进程: 能够利用多核优势,但是进程间通信比较麻烦,另外,进程数目的增加会使性能下降,进程切换的成本较高。程序流程复杂度相对I/O多路复用要低。 2)I/O多路复用: 在一个进程内部处理多个逻辑流程,不用进行进程切换,性能较高,另外流程间共享信息简单。但是无法利用多核优势,另外,程序流程被事件处理切割成一个个小块,程序比较复杂,难于理解。 3)线程: 运行在一个进程内部,由操作系统调度,切换成本较低,另外,他们共享进程的虚拟地址空间,线程间共享信息简单。但是线程安全问题导致线程学习曲线陡峭,而且易出错。 4)协程: 有编程语言提供,由程序员控制进行切换,所以没有线程安全问题,可以用来处理状态机,并发请求等。但是无法利用多核优势。 2. gevent2.1 基本说明gevent基于greenlet实现协程，其基本思想： 当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。 12345678910111213import geventfrom gevent import monkeymonkey.patch_all()from urllib import requestdef get_body(i): print(&#x27;start&#x27;, i) request.urlopen(&#x27;http://www.iamtxt.com&#x27;) print(&#x27;end&#x27;, i)tasks = [gevent.spawn(get_body, i) for i in range(5)]gevent.joinall(tasks) 2.2 使用说明 monkey可以使一些阻塞的模块变得不阻塞，机制：遇到IO操作则自动切换，手动切换可以用gevent.sleep(0)（将爬虫代码换成这个，效果一样可以达到切换上下文） gevent.spawn 启动协程，参数为函数名称，参数名称 gevent.joinall 停止协程 3. asyncio (Python 3.x)3.1 基本说明asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。asyncio的异步操作，需要在coroutine中通过yield from完成。 12345678910111213141516171819import asyncio# 3.4@asyncio.coroutinedef test1(i): print(&#x27;start&#x27;, i) yield from asyncio.sleep(1) print(&#x27;end&#x27;, i)# 3.5+async def test(i): print(&#x27;start&#x27;, i) await asyncio.sleep(1) print(&#x27;end&#x27;, i)loop = asyncio.get_event_loop()tasks = [test(i) for i in range(5)]loop.run_until_complete(asyncio.wait(tasks))loop.close() 3.2 使用说明 @asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。 test()会首先执行print，然后，yield from语法可以让我们方便地调用另一个generator。由于asyncio.sleep()也是一个coroutine，所以线程不会等待asyncio.sleep()，而是直接中断并执行下一个消息循环。当asyncio.sleep()返回时，线程就可以从yield from拿到返回值（此处是None），然后接着执行下一行语句。 把asyncio.sleep(1)看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。 4. asyncio与gevent的区别4.1 控制权限 asycio 需要自己在代码中让出CPU，控制权在自己手上 gevent 用会替换标准库，你以为调用的是标准库的方法实际已经被替换成gevent自己的实现，遇到阻塞调用，gevent会自动让出CPU 4.2 库来源不同gevent是第三方库，通过greenlet实现协程，其基本思路是：当一个greenlet遇到IO操作时，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。 asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持，不需要第三方的支持，asyncio的编程模型就是一个消息循环。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python GIL","slug":"Python GIL","date":"2018-09-10T08:29:14.000Z","updated":"2021-06-22T10:50:49.724Z","comments":true,"path":"2018/09/10/Python GIL/","link":"","permalink":"https://elihe2011.github.io/2018/09/10/Python%20GIL/","excerpt":"1. GIL是什么？GIL全称Global Interpreter Lock，即全局解释器锁。 作用就是，限制多线程同时执行，保证同一时间内只有一个线程在执行。 GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。python 与 python解释器是两个概念，切不可混为一谈，也就是说，GIL只存在于使用C语言编写的解释器CPython中。 通俗地说，就是如果你不用Python官方推荐的CPython解释器，而使用其他语言编写的Python解释器（比如 JPython: 运行在Java上的解释器，直接把python代码编译成Java字节码执行 ），就不会有GIL问题。然而因为CPython是大部分环境下默认的Python执行环境。所以在很多人的概念里CPython就是Python，也就想当然的把GIL归结为Python语言的缺陷。所以这里要先明确一点：GIL并不是Python的特性，Python完全可以不依赖于GIL。 虽然python支持多线程，但是由于GIL的限制，在实际运行时，程序运行后开启多个线程，但在通过GIL后同时也只能有一个线程被CPU执行。","text":"1. GIL是什么？GIL全称Global Interpreter Lock，即全局解释器锁。 作用就是，限制多线程同时执行，保证同一时间内只有一个线程在执行。 GIL并不是Python的特性，它是在实现Python解析器(CPython)时所引入的一个概念。python 与 python解释器是两个概念，切不可混为一谈，也就是说，GIL只存在于使用C语言编写的解释器CPython中。 通俗地说，就是如果你不用Python官方推荐的CPython解释器，而使用其他语言编写的Python解释器（比如 JPython: 运行在Java上的解释器，直接把python代码编译成Java字节码执行 ），就不会有GIL问题。然而因为CPython是大部分环境下默认的Python执行环境。所以在很多人的概念里CPython就是Python，也就想当然的把GIL归结为Python语言的缺陷。所以这里要先明确一点：GIL并不是Python的特性，Python完全可以不依赖于GIL。 虽然python支持多线程，但是由于GIL的限制，在实际运行时，程序运行后开启多个线程，但在通过GIL后同时也只能有一个线程被CPU执行。 2. GIL有什么作用？为了更有效的利用多核处理器的性能，就出现了多线程的编程方式，而随之带来的就是线程间数据的一致性和状态同步的完整性。 python为了利用多核，开始支持多线程，但线程是非独立的，所以同一进程里线程是数据共享，当各个线程访问数据资源时会出现竞状态，即数据可能会同时被多个线程占用，造成数据混乱，这就是线程的不安全。而解决多线程之间数据完整性和状态同步最简单的方式就是加锁。GIL能限制多线程同时执行，保证同一时间内只有一个线程在执行。 GIL并不是Python的特性，他是CPython引入的概念，是一个全局排他锁。 解释执行python代码时，会限制线程对共享资源的访问，直到解释器遇到I/O操作或者操作次数达到一定数目时才会释放GIL。所以，虽然CPython的线程库直接封装了系统的原生线程，但CPython整体作为一个进程，同一时间只会有一个获得GIL的线程在跑，其他线程则处于等待状态。这就造成了即使在多核CPU中，多线程也只是做着分时切换而已，所以多线程比较适合IO密集型，不太适合CPU密集型的任务。同一时刻一个解释进程只有一行bytecode 在执行 3. GIL有什么影响？GIL无疑就是一把全局排他锁。毫无疑问全局锁的存在会对多线程的效率有不小影响。甚至就几乎等于Python是个单线程的程序。 4. 如何避免GIL带来的影响？1) 用进程+协程 代替 多线程的方式 在多进程中，由于每个进程都是独立的存在，所以每个进程内的线程都拥有独立的GIL锁，互不影响。但是，由于进程之间是独立的存在，所以进程间通信就需要通过队列的方式来实现。 2) 更换解释器 像JPython和IronPython这样的解析器由于实现语言的特性，他们不需要GIL的帮助。然而由于用了Java/C#用于解析器实现，他们也失去了利用社区众多C语言模块有用特性的机会。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python Asyncio并发编程","slug":"Python Asyncio并发编程","date":"2018-09-07T06:07:49.000Z","updated":"2021-06-22T10:50:49.724Z","comments":true,"path":"2018/09/07/Python Asyncio并发编程/","link":"","permalink":"https://elihe2011.github.io/2018/09/07/Python%20Asyncio%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"1. 基本概念1.1 什么是 Asyncioasyncio 是python3.4 引入的一个新的并发模块，主要通过使用coroutines 和 futures 来让我们更容易的去实现异步的功能，并且几乎和写同步代码一样的写代码，还没有烦人的回调。 asyncio 是单线程的，它只有一个主线程，但可以进行多个不同的任务。这里的任务，指的就是特殊的 future 对象，我们可以把它类比成多线程版本里的多个线程。 asyncio 用来干什么？ 异步网络操作 并发 协程 asyncio 缺陷：目前asyncio相关的异步库并不完善，在github上有一些常用的库如：aiomysql, aiopika, aioredis等。 想要用asyncio异步的功能，那么你整个代码中其他的库也要是异步的而不能是阻塞的，要用aiomysql取代pymysql，aiohttp取代requests等","text":"1. 基本概念1.1 什么是 Asyncioasyncio 是python3.4 引入的一个新的并发模块，主要通过使用coroutines 和 futures 来让我们更容易的去实现异步的功能，并且几乎和写同步代码一样的写代码，还没有烦人的回调。 asyncio 是单线程的，它只有一个主线程，但可以进行多个不同的任务。这里的任务，指的就是特殊的 future 对象，我们可以把它类比成多线程版本里的多个线程。 asyncio 用来干什么？ 异步网络操作 并发 协程 asyncio 缺陷：目前asyncio相关的异步库并不完善，在github上有一些常用的库如：aiomysql, aiopika, aioredis等。 想要用asyncio异步的功能，那么你整个代码中其他的库也要是异步的而不能是阻塞的，要用aiomysql取代pymysql，aiohttp取代requests等 1.2 关于asyncio的一些关键字的说明event_loop 事件循环：程序开启一个无限循环，把一些函数注册到事件循环上，当满足事件发生的时候，调用相应的协程函数. coroutine 协程：协程对象，指一个使用async关键字定义的函数，它的调用不会立即执行函数，而是会返回一个协程对象。协程对象需要注册到事件循环，由事件循环调用。在这个函数中通常会有一个关键字await, 当coroutine执行到await的时候，就会将控制权释放给event_loop. 如果一个coroutine被包装成一个Future类型的Task中，那么这个coroutine就需要被event_loop 去调度执行 task 任务：一个协程对象就是一个原生可以挂起的函数，任务则是对协程进一步封装，其中包含了任务的各种状态 future: 代表将来执行或没有执行的任务的结果。它和task上没有本质上的区别 async/await 关键字：python3.5用于定义协程的关键字，async定义一个协程，将其变为awaitable对象；await用于挂起阻塞的异步调用接口，await 后面必须跟一个 awaitable 类型或者具有 __await__ 属性的对象. 1) 常见的 awaitable 对象: 12await asyncio.sleep(3) # asyncio.sleep() 机制与 time.sleep() 不同, 前者是 &quot;假性睡眠&quot;, 后者是会导致线程阻塞的 &quot;真性睡眠&quot;await an_async_func() # 一个异步的函数, 也是可等待的对象 2) 不可等待的对象: 12345await time.sleep(3) # unwaitablex = await &#x27;hello&#x27; # &lt;class &#x27;str&#x27;&gt; doesn&#x27;t define &#x27;__await__&#x27;x = await 3 + 2 # &lt;class &#x27;int&#x27;&gt; dosen&#x27;t define &#x27;__await__&#x27;x = await None # ...x = await a_sync_func() # 普通的函数, 是不可等待的 1.3 调用步骤1）定义协程: 给一个函数添加async关键字，或使用asyncio.coroutine装饰器，就会把它变成一个协程 2）创建事件循环: 每个线程有一个事件循环，主线程调用asyncio.get_event_loop时会创建事件循环 3) 将协程加入到事件循环: 将任务封装为集合asyncio.gather(*tasks), 之后一起传入事件循环中 4) 将协程注册到事件循环: 使用run_until_complete方法，注册循环事，并启动 123456789101112131415# 1. 创建一个事件循环loop = asyncio.get_event_loop() # 2. 将异步函数加入事件队列tasks = [ task1(), task2(), task3(),] # 3. 执行事件队列, 直到最晚的一个事件被处理完毕后结束loop.run_until_complete(asyncio.wait(tasks))# 4. 如果不再使用 loop, 建议养成良好关闭的习惯loop.close() 2. 使用asyncio2.1 定义一个协程协程不能直接运行，需要将协程加入到事件循环loop中 123456789101112131415161718192021222324import asyncioimport timeasync def bar(): print(&#x27;waiting 2 seconds&#x27;) await asyncio.sleep(2) print(&#x27;done&#x27;)def main(): start = time.time() # 创建协程 coroutine = bar() print(coroutine) # 创建一个事件循环 loop = asyncio.get_event_loop() # 将协程注册到事件循环，并启动事件循环 loop.run_until_complete(coroutine) print(&#x27;it took &#123;:.6f&#125; seconds&#x27;.format(time.time() - start)) 2.2 创建一个task协程对象不能直接运行，在注册事件循环的时候，其实是run_until_complete方法将协程包装成为了一个任务（task）对象. task对象是Future类的子类，保存了协程运行后的状态，用于未来获取协程的结果 1234567891011121314151617181920212223242526272829import asyncioimport timeasync def bar(): print(&#x27;waiting 2 seconds&#x27;) await asyncio.sleep(2) print(&#x27;done&#x27;)def main(): start = time.time() # 创建协程 coroutine = bar() print(coroutine) # 循环事件 loop = asyncio.get_event_loop() # 创建任务 task = loop.create_task(coroutine) print(task) # pending # 将任务加入循环事件 loop.run_until_complete(task) print(task) # finished print(&#x27;it took &#123;:.6f&#125; seconds&#x27;.format(time.time() - start)) 创建task: AbstractEventLoop.create_task(coro): 在确定参数是 coroutine 的情况下可以使用 asyncio.ensure_future(coro_or_future, *, loop=None): 参数为coroutine或者Future，为Future时，直接返回。最高层的函数，推荐使用 2.3 绑定回调在task执行完成的时候可以获取执行的结果，回调的最后一个参数是future对象，通过该对象可以获取协程返回值。 通过add_done_callback方法给task任务添加回调函数 12345678910111213141516171819202122232425262728293031323334353637import asyncioimport timeasync def bar(x): print(&#x27;waiting for &#123;&#125; seconds&#x27;.format(x)) await asyncio.sleep(x) return &#x27;done after &#123;&#125; seconds&#x27;.format(x)def callback(future): print(&#x27;callback: &#x27; + future.result())def main(): start = time.time() # 创建协程 coroutine = bar(3) print(coroutine) # 循环事件 loop = asyncio.get_event_loop() # 创建任务 task = asyncio.ensure_future(coroutine) print(task) task.add_done_callback(callback) print(task) # 将任务加入循环事件 loop.run_until_complete(task) print(task) # finished print(&#x27;it took &#123;:.6f&#125; seconds&#x27;.format(time.time() - start)) 回调函数带参数 1234567891011121314151617181920212223242526272829303132import asyncioimport timefrom functools import partial # 偏函数, 以函数名作为传入参数, 但无法再传入传入函数的参数的问题async def get_html(url): print(&#x27;start get url&#x27;) await asyncio.sleep(2) # asyncio.sleep(2)的一个子线程，不可用time.sleep(), await不支持 print(&#x27;end get url&#x27;) return &#x27;Done&#x27;def callback(url, future): print(url)def main(): # 开始时间循环 loop = asyncio.get_event_loop() coroutine = get_html(&#x27;http://baidu.com&#x27;) # 运行协程得到的future # future = asyncio.ensure_future(coroutine)) future = loop.create_task(coroutine) # 执行完毕回调 future.add_done_callback(partial(callback, &#x27;www.baidu.com&#x27;)) loop.run_until_complete(future) print(future.result()) 2.4 阻塞和await使用async定义协程对象，使用await可以针对耗时的操作进行挂起，就像生成器里的yield一样，函数让出控制权。协程遇到await，事件循环将会挂起该协程，执行别的协程，直到其他的协程也挂起或者执行完毕，再进行下一个协程的执行 await asyncio.sleep(x)，因为这里sleep了，模拟了阻塞或者耗时操作，这个时候就会让出控制权。 即当遇到阻塞调用的函数的时候，使用await方法将协程的控制权让出,以便loop调用其他的协程。 2.5 实现并发: 多个协程一起执行1234567891011121314151617181920212223242526272829303132333435import asyncioimport timeasync def bar(x): print(&#x27;waiting for &#123;&#125; seconds&#x27;.format(x)) await asyncio.sleep(x) return &#x27;done after &#123;&#125; seconds&#x27;.format(x)def callback(future): print(&#x27;callback: &#x27; + future.result())def main(): start = time.time() coroutine1 = bar(3) coroutine2 = bar(1) coroutine3 = bar(2) tasks = [ asyncio.ensure_future(coroutine1), asyncio.ensure_future(coroutine2), asyncio.ensure_future(coroutine3), ] loop = asyncio.get_event_loop() loop.run_until_complete(asyncio.wait(tasks)) for task in tasks: print(&#x27;Task result: &#x27; + task.result()) print(&#x27;it took &#123;:.6f&#125; seconds&#x27;.format(time.time() - start)) 实现并发： asyncio.wait(tasks): Wait for the Futures and coroutine objects given by the sequence futures to complete. Coroutines will be wrapped in Tasks. Returns two sets of Future: (done, pending). asyncio.gather(*tasks): Return a future aggregating results from the given coroutine objects or futures. asyncio.as_completed(tasks): Return an iterator whose values are coroutines gather与wait的区别: gather更加high-level高层， gather除了多任务外，还可以对任务进行分组。优先使用gather 123456789101112131415161718192021222324252627282930import asyncioimport timeasync def get_html(url): print(&#x27;start get url&#x27;) await asyncio.sleep(2) # asyncio.sleep(2)的一个子线程，不可用time.sleep(), await不支持 print(&#x27;end get url&#x27;) return &#x27;Done&#x27;def callback(url, future): print(url)def main(): start = time.time() # 开始时间循环 loop = asyncio.get_event_loop() tasks1 = [get_html(&#x27;https://www.baidu.com&#x27;) for _ in range(2)] tasks2 = [get_html(&#x27;https://www.qq.com&#x27;) for _ in range(3)] group1 = asyncio.gather(*tasks1) group2 = asyncio.gather(*tasks2) loop.run_until_complete(asyncio.gather(group1, group2)) print(time.time() - start) 2.6 协程嵌套123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import asyncioimport timeasync def bar(x): print(&#x27;waiting for &#123;&#125; seconds&#x27;.format(x)) await asyncio.sleep(x) return &#x27;done after &#123;&#125; seconds&#x27;.format(x)def callback(future): print(&#x27;callback: &#x27; + future.result())async def main(): coroutine1 = bar(3) coroutine2 = bar(1) coroutine3 = bar(2) tasks = [ asyncio.ensure_future(coroutine1), asyncio.ensure_future(coroutine2), asyncio.ensure_future(coroutine3), ] # dones, pendings = await asyncio.wait(tasks) # for task in dones: # print(&#x27;Task result: &#x27; + task.result()) # asyncio.gather 结果收集 # results = await asyncio.gather(*tasks) # for result in results: # print(&#x27;Task result: &#x27; + result) # asyncio.as_completed for task in asyncio.as_completed(tasks): result = await task print(&#x27;Task result: &#x27; + result)if __name__ == &#x27;__main__&#x27;: start = time.time() loop = asyncio.get_event_loop() loop.run_until_complete(main()) print(&#x27;it took &#123;:.6f&#125; seconds&#x27;.format(time.time() - start)) 获取结果 123456789101112131415161718192021222324252627282930313233343536373839404142import asyncioimport randomimport timeimport aiohttpURL = &#x27;https://baidu.com&#x27;MAX_CLIENTS = 3async def aiohttp_get(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return responseasync def fetch_async(pid): start = time.time() sleep_time = random.randint(2, 5) print(&#x27;fetch corountine &#123;&#125; started, sleeping for &#123;&#125; seconds&#x27;.format(pid, sleep_time)) response = await aiohttp_get(URL) date = response.headers.get(&#x27;Date&#x27;) await asyncio.sleep(sleep_time) response.close() return &#x27;corountine &#123;&#125;: &#123;&#125;, took &#123;:.2f&#125; seconds&#x27;.format(pid, date, time.time() - start)async def main(): start = time.time() futures = [fetch_async(i) for i in range(1, MAX_CLIENTS + 1)] done, pending = await asyncio.wait(futures) print(done) for future in done: print(future.result()) print(&#x27;it took: &#123;:.2f&#125; seconds&#x27;.format(time.time() - start))asyncio.run(main()) 2.7 协程的停止future对象有几个状态： Pending Running Done Cacelled 1) 取消任务 1234567891011121314151617181920212223242526272829import asyncioasync def bar(t): print(&#x27;waiting&#x27;) await asyncio.sleep(t) print(&#x27;done after &#123;&#125;s&#x27;.format(t))def main(): task1 = bar(1) task2 = bar(2) task3 = bar(3) tasks = [task1, task2, task3] loop = asyncio.get_event_loop() try: loop.run_until_complete(asyncio.wait(tasks)) except KeyboardInterrupt as e: all_tasks = asyncio.Task.all_tasks() for task in all_tasks: print(&#x27;cancel task&#x27;) print(task.cancel()) # 成功返回True loop.stop() loop.run_forever() # stop之后必须调用run_forever,否则会报错 finally: loop.close() 2）任务返回状态 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import asyncioimport randomimport timefrom asyncio import FIRST_COMPLETEDimport aiohttpURL = &#x27;https://baidu.com&#x27;MAX_CLIENTS = 3async def aiohttp_get(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return responseasync def fetch_async(pid): start = time.time() sleep_time = random.randint(2, 5) print(&#x27;fetch corountine &#123;&#125; started, sleeping for &#123;&#125; seconds&#x27;.format(pid, sleep_time)) response = await aiohttp_get(URL) date = response.headers.get(&#x27;Date&#x27;) await asyncio.sleep(sleep_time) response.close() return &#x27;corountine &#123;&#125;: &#123;&#125;, took &#123;:.2f&#125; seconds&#x27;.format(pid, date, time.time() - start)# # 全部执行完成才返回# async def main():# start = time.time()# futures = [fetch_async(i) for i in range(1, MAX_CLIENTS + 1)]# for i, future in enumerate(asyncio.as_completed(futures)):# result = await future# print(&#x27;&#123;&#125; &#123;&#125;&#x27;.format(&#x27;&gt;&gt;&#x27; * (i + 1), result))## print(&#x27;all took: &#123;:.2f&#125; seconds&#x27;.format(time.time() - start))### asyncio.run(main()) # Python3.7新增方法# 只关注最快返回的任务, return_whenasync def main(): start = time.time() futures = [fetch_async(i) for i in range(1, MAX_CLIENTS + 1)] done, pending = await asyncio.wait(futures, return_when=FIRST_COMPLETED) print(done.pop().result()) print(&#x27;it took: &#123;:.2f&#125; seconds&#x27;.format(time.time() - start))# # 告警 Task was destroyed but it is pending!# loop = asyncio.get_event_loop()# loop.run_until_complete(main())# loop.close()# 自动cancel未执行完毕的任务asyncio.run(main()) 2.8 使用call_soon, call_at, ccall_later, call_soon_threadsafe123456789101112131415161718192021222324252627282930313233import asynciodef callback(t): print(&#x27;sleep &#123;&#125;s success&#x27;.format(t))def callback2(loop): print(&#x27;loop time: &#123;&#125; &#x27;.format(loop.time()))def stop_loop(loop): loop.stop()def main(): loop = asyncio.get_event_loop() loop.call_later(1, callback, 1) loop.call_later(2, callback, 2) loop.call_later(3, callback, 3) # loop.call_later(4, stop_loop, loop) # 停止loop, 否则程序不会停止 now = loop.time() loop.call_at(now + 1, callback2, loop) loop.call_at(now + 2, callback2, loop) loop.call_at(now + 3, callback2, loop) loop.call_later(now + 4, stop_loop, loop) # 停止loop, 否则程序不会停止 loop.call_soon(callback, 4) # 最先执行 loop.run_forever() # 保证程序运行 3. 其他示例3.1 使用aiohttp12345678910111213141516171819202122232425262728293031323334353637import asyncioimport timeimport aiohttpasync def download_one(url): async with aiohttp.ClientSession() as session: async with session.get(url) as resp: print(&#x27;Read &#123;&#125; from &#123;&#125;&#x27;.format(resp.content_length, url))async def download_many(urls): # tasks = [asyncio.ensure_future(download_one(url)) for url in urls] tasks = [asyncio.create_task(download_one(url)) for url in urls] # 3.7+ await asyncio.gather(*tasks)def main(): urls = [&#x27;https://www.sina.com&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.bing.com&#x27;] start_at = time.perf_counter() # loop = asyncio.get_event_loop() # try: # loop.run_until_complete(download_many(urls)) # finally: # loop.close() asyncio.run(download_many(urls)) # 3.7+ end_at = time.perf_counter() print(&#x27;Download &#123;&#125; sites in &#123;&#125; seconds&#x27;.format(len(urls), end_at - start_at))if __name__ == &#x27;__main__&#x27;: main() 3.2 ThreadPoolExecutor 和 asycio完成阻塞io请求12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import asyncioimport socketimport timefrom concurrent.futures.thread import ThreadPoolExecutorfrom urllib.parse import urlparsedef get_url(url): url = urlparse(url) host = url.netloc path = url.path if path == &#x27;&#x27;: path = &#x27;/&#x27; client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect((host, 80)) client.send(&#x27;GET &#123;&#125; HTTP/1.1\\r\\nHost:&#123;&#125;\\r\\nConnection:close\\r\\n\\r\\n&#x27;.format(path, host).encode(&#x27;utf8&#x27;)) data = b&#x27;&#x27; while True: d = client.recv(1024) if d: data += d else: break data = data.decode(&#x27;utf8&#x27;) html_data = data.split(&#x27;\\r\\n\\r\\n&#x27;)[1] # 去除请求信息头 print(html_data) client.close()def main(): start = time.time() loop = asyncio.get_event_loop() executor = ThreadPoolExecutor(3) tasks = [] for i in range(1, 21): url = &#x27;http://shop.projectsedu.com/goods/&#123;&#125;/&#x27;.format(i) task = loop.run_in_executor(executor, get_url, url) # 阻塞的代码放到线程池 tasks.append(task) loop.run_until_complete(asyncio.wait(tasks)) print(&#x27;last time: &#123;&#125;&#x27;.format(time.time() - start)) 3.3 asyncio模拟http请求 (协程完成http请求)1234567891011121314151617181920212223242526272829303132333435363738394041424344import asyncioimport timefrom urllib.parse import urlparseasync def get_url(url): url = urlparse(url) host = url.netloc path = url.path if path == &#x27;&#x27;: path = &#x27;/&#x27; # 建立socket连接 reader, writer = await asyncio.open_connection(host, 80) writer.write(&#x27;GET &#123;&#125; HTTP/1.1\\r\\nHost:&#123;&#125;\\r\\nConnection:close\\r\\n\\r\\n&#x27;.format(path, host).encode(&#x27;utf8&#x27;)) lines = [] async for line in reader: # __aiter__, __anext__ lines.append(line.decode(&#x27;utf8&#x27;)) html = &#x27;&#x27;.join(lines).split(&#x27;\\r\\n\\r\\n&#x27;)[1] return htmlasync def get_tasks(): tasks = [] for i in range(1, 21): url = &#x27;http://shop.projectsedu.com/goods/&#123;&#125;/&#x27;.format(i) tasks.append(asyncio.ensure_future(get_url(url))) for task in asyncio.as_completed(tasks): result = await task print(result)def main(): start = time.time() loop = asyncio.get_event_loop() loop.run_until_complete(get_tasks()) print(&#x27;last time: &#123;&#125;&#x27;.format(time.time() - start))","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python Futures并发编程","slug":"Python Futures并发编程","date":"2018-09-05T02:54:05.000Z","updated":"2021-06-22T10:50:49.723Z","comments":true,"path":"2018/09/05/Python Futures并发编程/","link":"","permalink":"https://elihe2011.github.io/2018/09/05/Python%20Futures%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"1. concurrent.futures模块 Python标准库为我们提供了threading和multiprocessing模块编写相应的多线程/多进程代码，但是当项目达到一定的规模，频繁创建/销毁进程或者线程是非常消耗资源的，这个时候我们就要编写自己的线程池/进程池，以空间换时间。但从Python3.2开始，标准库为我们提供了concurrent.futures模块，它提供了ThreadPoolExecutor和ProcessPoolExecutor两个类，实现了对threading和multiprocessing的进一步抽象，对编写线程池/进程池提供了直接的支持。","text":"1. concurrent.futures模块 Python标准库为我们提供了threading和multiprocessing模块编写相应的多线程/多进程代码，但是当项目达到一定的规模，频繁创建/销毁进程或者线程是非常消耗资源的，这个时候我们就要编写自己的线程池/进程池，以空间换时间。但从Python3.2开始，标准库为我们提供了concurrent.futures模块，它提供了ThreadPoolExecutor和ProcessPoolExecutor两个类，实现了对threading和multiprocessing的进一步抽象，对编写线程池/进程池提供了直接的支持。 1.1 Executor concurrent.futures模块的基础是Exectuor，Executor是一个抽象类，它不能被直接使用。但是它提供的两个子类ThreadPoolExecutor和ProcessPoolExecutor却是非常有用，顾名思义两者分别被用来创建线程池和进程池的代码。我们可以将相应的tasks直接放入线程池/进程池，不需要维护Queue来操心死锁的问题，线程池/进程池会自动帮我们调度。 1.2 Future Future你可以把它理解为一个在未来完成的操作，这是异步编程的基础，传统编程模式下比如我们操作queue.get的时候，在等待返回结果之前会产生阻塞，cpu不能让出来做其他事情，而Future的引入帮助我们在等待的这段时间可以完成其他的操作。 1.3 Python2.x需要独立安装1pip install futures 2. 操作线程池2.1 submit12345678910111213141516171819from concurrent.futures.thread import ThreadPoolExecutorfrom urllib import requestdef download(url): with request.urlopen(url, timeout=60) as conn: print(&#x27;%r page is %d bytes&#x27; % (url, len(conn.read())))if __name__ == &#x27;__main__&#x27;: urls = [&#x27;https://www.163.com&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.csdn.net&#x27;] executor = ThreadPoolExecutor(max_workers=3) for _url in urls: future = executor.submit(download, _url) print(future.done()) print(&#x27;Done&#x27;) 2.2 map1234567891011121314151617from concurrent.futures.thread import ThreadPoolExecutorfrom urllib import requestdef download(url): with request.urlopen(url, timeout=60) as conn: print(&#x27;%r page is %d bytes&#x27; % (url, len(conn.read())))if __name__ == &#x27;__main__&#x27;: urls = [&#x27;https://www.163.com&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.csdn.net&#x27;] executor = ThreadPoolExecutor(max_workers=3) executor.map(download, urls) print(&#x27;Done&#x27;) 2.3 wait wait方法接会返回一个tuple(元组)，tuple中包含两个set(集合)，一个是completed(已完成的)另外一个是uncompleted(未完成的)。使用wait方法的一个优势就是获得更大的自由度，它接收三个参数FIRST_COMPLETED, FIRST_EXCEPTION 和ALL_COMPLETE，默认设置为ALL_COMPLETED。 2.3.1 采用默认的ALL_COMPLETED，程序会阻塞直到线程池里面的所有任务都完成，再执行主线程1234567891011121314151617181920212223from concurrent.futures import waitfrom concurrent.futures.thread import ThreadPoolExecutorfrom urllib import requestdef download(url): with request.urlopen(url, timeout=60) as conn: print(&#x27;%r page is %d bytes&#x27; % (url, len(conn.read())))if __name__ == &#x27;__main__&#x27;: urls = [&#x27;https://www.163.com&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.csdn.net&#x27;] executor = ThreadPoolExecutor(max_workers=3) f_list = [] for _url in urls: future = executor.submit(download, _url) f_list.append(future) wait(f_list) print(&#x27;Done&#x27;) 2.3.2 采用FIRST_COMPLETED参数，程序并不会等到线程池里面所有的任务都完成1234567891011121314151617181920212223from concurrent.futures import waitfrom concurrent.futures.thread import ThreadPoolExecutorfrom urllib import requestdef download(url): with request.urlopen(url, timeout=60) as conn: print(&#x27;%r page is %d bytes&#x27; % (url, len(conn.read())))if __name__ == &#x27;__main__&#x27;: urls = [&#x27;https://www.163.com&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.csdn.net&#x27;] executor = ThreadPoolExecutor(max_workers=3) f_list = [] for _url in urls: future = executor.submit(download, _url) f_list.append(future) wait(f_list, return_when=&#x27;FIRST_COMPLETED&#x27;) print(&#x27;Done&#x27;) 3. 应用线程池12345678910111213141516171819202122232425262728import osimport requestsfrom concurrent.futures.thread import ThreadPoolExecutordef get_page(url): print(&#x27;&lt;%s&gt; is getting [%s]&#x27; % (os.getpid(), url)) response = requests.get(url) if response.status_code == 200: return &#123;&#x27;url&#x27;: url, &#x27;text&#x27;: response.text&#125;def parse_page(res): res = res.result() print(&#x27;&lt;%s&gt; is parsing [%s]&#x27; % (os.getpid(), res[&#x27;url&#x27;])) with open(&#x27;test.txt&#x27;, &#x27;a&#x27;) as f: data = &#x27;url: %s, size: %s\\n&#x27; % (res[&#x27;url&#x27;], len(res[&#x27;text&#x27;])) f.write(data)if __name__ == &#x27;__main__&#x27;: urls = [&#x27;https://www.163.com&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.csdn.net&#x27;] with ThreadPoolExecutor(max_workers=3) as executor: for _url in urls: executor.submit(get_page, _url).add_done_callback(parse_page) print(&#x27;Done&#x27;) 4. 进一步理解FutureFuture可以理解为一个在未来完成的操作，这是异步编程的基础。通常情况下，我们执行io操作，访问url时（如下）在等待结果返回之前会产生阻塞，cpu不能做其他事情，而Future的引入帮助我们在等待的这段时间可以完成其他的操作。 1234567891011future = executor.submit()future.cancel()future.cancelled()future.running()future.done()future.result(timeout=None)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 线程池和进程池","slug":"Python 线程池和进程池","date":"2018-09-02T09:03:06.000Z","updated":"2021-06-22T10:50:49.723Z","comments":true,"path":"2018/09/02/Python 线程池和进程池/","link":"","permalink":"https://elihe2011.github.io/2018/09/02/Python%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%92%8C%E8%BF%9B%E7%A8%8B%E6%B1%A0/","excerpt":"1. 为何使用线程池系统启动一个新线程的成本是比较高的，因为它涉及与操作系统的交互。在这种情形下，使用线程池可以很好地提升性能，尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。 线程池在系统启动时即创建大量空闲的线程，程序只要将一个函数提交给线程池，线程池就会启动一个空闲的线程来执行它。当该函数执行结束后，该线程并不会死亡，而是再次返回到线程池中变成空闲状态，等待执行下一个函数。 此外，使用线程池可以有效地控制系统中并发线程的数量。当系统中包含有大量的并发线程时，会导致系统性能急剧下降，甚至导致 Python 解释器崩溃，而线程池的最大线程数参数可以控制系统中并发线程的数量不超过此数。","text":"1. 为何使用线程池系统启动一个新线程的成本是比较高的，因为它涉及与操作系统的交互。在这种情形下，使用线程池可以很好地提升性能，尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。 线程池在系统启动时即创建大量空闲的线程，程序只要将一个函数提交给线程池，线程池就会启动一个空闲的线程来执行它。当该函数执行结束后，该线程并不会死亡，而是再次返回到线程池中变成空闲状态，等待执行下一个函数。 此外，使用线程池可以有效地控制系统中并发线程的数量。当系统中包含有大量的并发线程时，会导致系统性能急剧下降，甚至导致 Python 解释器崩溃，而线程池的最大线程数参数可以控制系统中并发线程的数量不超过此数。 2. 线程池的使用线程池的基类是 concurrent.futures 模块中的 Executor，Executor 提供了两个子类，即 ThreadPoolExecutor 和 ProcessPoolExecutor，其中 ThreadPoolExecutor 用于创建线程池，而 ProcessPoolExecutor 用于创建进程池。 如果使用线程池/进程池来管理并发编程，那么只要将相应的 task 函数提交给线程池/进程池，剩下的事情就由线程池/进程池来搞定。 2.1 Exectuor的常用方法： submit(fn, *args, **kwargs)：将 fn 函数提交给线程池。args 代表传给 fn 函数的参数，kwargs 代表以关键字参数的形式为 fn 函数传入参数。 map(func, *iterables, timeout=None, chunksize=1)：该函数类似于全局函数 map(func, *iterables)，只是该函数将会启动多个线程，以异步方式立即对 iterables 执行 map 处理。 shutdown(wait=True)：关闭线程池。(执行了join操作，同步等待) 程序将 task 函数提交（submit）给线程池后，submit 方法会返回一个 Future 对象，Future 类主要用于获取线程任务函数的返回值。 2.2 Future 提供了如下方法： cancel()：取消该 Future 代表的线程任务。如果该任务正在执行，不可取消，则该方法返回 False；否则，程序会取消该任务，并返回 True。 cancelled()：返回 Future 代表的线程任务是否被成功取消。 running()：如果该 Future 代表的线程任务正在执行、不可被取消，该方法返回 True。 done()：如果该 Funture 代表的线程任务被成功取消或执行完成，则该方法返回 True。 result(timeout=None)：获取该 Future 代表的线程任务最后返回的结果。如果 Future 代表的线程任务还未完成，该方法将会阻塞当前线程，其中 timeout 参数指定最多阻塞多少秒。 exception(timeout=None)：获取该 Future 代表的线程任务所引发的异常。如果该任务成功完成，没有异常，则该方法返回 None。 add_done_callback(fn)：为该 Future 代表的线程任务注册一个“回调函数”，当该任务成功完成时，程序会自动触发该 fn 函数。 在用完一个线程池后，应该调用该线程池的 shutdown() 方法，该方法将启动线程池的关闭序列。调用 shutdown() 方法后的线程池不再接收新任务，但会将以前所有的已提交任务执行完成。当线程池中的所有任务都执行完成后，该线程池中的所有线程都会死亡。 12345678910111213141516171819202122232425262728import threadingimport timefrom concurrent.futures.thread import ThreadPoolExecutordef foo(n): total = 0 for i in range(n): print(&#x27;%s: %s&#x27; % (threading.current_thread().getName(), i)) total += i return totalif __name__ == &#x27;__main__&#x27;: pool = ThreadPoolExecutor(max_workers=2) future1 = pool.submit(foo, 50) future2 = pool.submit(foo, 100) time.sleep(2) print(future1.done()) print(future2.done()) print(future1.result()) print(future2.result()) pool.shutdown() 2.4 获取执行结果123456789101112131415161718192021222324import threadingimport timefrom concurrent.futures.thread import ThreadPoolExecutordef foo(n): total = 0 for i in range(n): print(&#x27;%s: %s&#x27; % (threading.current_thread().getName(), i)) total += i return totaldef get_result(future): print(future.result())if __name__ == &#x27;__main__&#x27;: with ThreadPoolExecutor(max_workers=2) as pool: future1 = pool.submit(foo, 50) future2 = pool.submit(foo, 100) future1.add_done_callback(get_result) future2.add_done_callback(get_result) map(func, *iterables, timeout=None, chunksize=1) 1234567891011121314151617import threadingfrom concurrent.futures.thread import ThreadPoolExecutordef foo(n): total = 0 for i in range(n): print(&#x27;%s: %s&#x27; % (threading.current_thread().getName(), i)) total += i return totalif __name__ == &#x27;__main__&#x27;: with ThreadPoolExecutor(max_workers=4) as pool: results = pool.map(foo, (50, 100, 200)) for result in results: print(result)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 多线程","slug":"Python 多线程","date":"2018-09-01T03:00:01.000Z","updated":"2021-06-22T10:50:49.722Z","comments":true,"path":"2018/09/01/Python 多线程/","link":"","permalink":"https://elihe2011.github.io/2018/09/01/Python%20%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"1. 线程和进程每个线程必须有自己的父进程，且它可以拥有自己的堆栈、程序计数器和局部变量，但不拥有系统资源，因为它和父进程的其他线程共享该进程所拥有的全部资源。线程可以完成一定的任务，可以与其他线程共享父进程中的共享变量及部分环境，相互之间协同完成进程所要完成的任务。 多个线程共享父进程里的全部资源，会使得编程更加方便，需要注意的是，要确保线程不会妨碍同一进程中的其他线程。","text":"1. 线程和进程每个线程必须有自己的父进程，且它可以拥有自己的堆栈、程序计数器和局部变量，但不拥有系统资源，因为它和父进程的其他线程共享该进程所拥有的全部资源。线程可以完成一定的任务，可以与其他线程共享父进程中的共享变量及部分环境，相互之间协同完成进程所要完成的任务。 多个线程共享父进程里的全部资源，会使得编程更加方便，需要注意的是，要确保线程不会妨碍同一进程中的其他线程。 2. 创建线程2.1 调用 Thread 类的构造器创建线程__init__(self, group=None, target=None, name=None, args=(), kwargs=None, *,daemon=None) 123456789101112131415161718import threadingdef foo(n): for i in range(n): print(threading.current_thread().getName() + &#x27; &#x27; + str(i))if __name__ == &#x27;__main__&#x27;: print(threading.current_thread().getName()) t1 = threading.Thread(target=foo, args=(100,)) t1.start() t2 = threading.Thread(target=foo, args=(100,)) t2.start() print(&#x27;done&#x27;) 2.2 继承 Thread 类创建线程类12345678910111213141516171819import threadingclass MyThread(threading.Thread): def run(self): for i in range(100): print(threading.current_thread().getName() + &#x27; &#x27; + str(i))if __name__ == &#x27;__main__&#x27;: print(threading.current_thread().getName()) t1 = MyThread() t1.start() t2 = MyThread() t2.start() print(&#x27;done&#x27;) 3. 线程生命周期当线程被创建并启动后，并不会直接进入执行状态，也不会一直处于执行状态，线程的生命周期中，它会经历新建（new）、就绪（Ready）、运行（Running）、阻塞（Blocked）和死亡（Dead）5 种状态。 3.1 线程的新建和就绪状态12start() -&gt; 线程就绪，解释器会为其创建方法调用栈和程序计数器，未运行，等待线程调度器的调度run() -&gt; 立即执行，并阻塞其他线程并发执行。直接调用线程对象的 run() 方法，则系统会把线程对象当成一个普通对象，并不真正创建线程对象 3.2 线程的运行和阻塞状态当发生如下情况时，线程将会进入阻塞状态： 调用 sleep() 方法，主动放弃其所占用的处理器资源。 调用了一个阻塞式 I/O 方法，在该方法返回之前，该线程被阻塞。 试图获得一个锁对象，但该锁对象正被其他线程所持有。 等待某个通知（Notify） 3.3 线程死亡线程会以如下方式结束，结束后就处于死亡状态： run() 方法或代表线程执行体的 target 函数执行完成，线程正常结束。 线程抛出一个未捕获的 Exception 或 Error。 is_alive(): 检查线程是否已经死亡。当线程处于就绪、运行、阻塞三种状态时，该方法将返回 True；当线程处于新建、死亡两种状态时，该方法将返回 False。 4. join()方法join(timeout=None)阻塞其他线程执行，直到调用join()方法的线程执行完毕或超时 5. 守护线程 (Daemon Thread)作用：在后台运行，为其他线程提供服务。垃圾回收线程就是典型的后台线程。 特征：如果所有的前台线程都死亡了，那么后台线程会自动死亡。 1234567891011121314151617import threadingclass MyThread(threading.Thread): def run(self): for i in range(100): print(threading.current_thread().getName() + &#x27; &#x27; + str(i))if __name__ == &#x27;__main__&#x27;: print(threading.current_thread().getName()) t1 = MyThread() t1.daemon = True # 提前死亡，循环不可能到达100 t1.start() print(&#x27;done&#x27;) 创建后台线程有两种方式： 主动将线程的 daemon 属性设置为 True。 后台线程启动的线程默认是后台线程。 6. 互斥锁同步12345mutex = threading.Lock()mutex.acquire(timeout=None)mutex.release() 123456789101112131415161718192021222324252627282930313233343536import threadingimport timemutex = threading.Lock()g_num = 0def foo(n): global g_num if mutex.acquire(): for i in range(n): g_num += i mutex.release() print(&#x27;foo:g_num=%d&#x27; % g_num)def bar(n): global g_num if mutex.acquire(): for i in range(n): g_num += i mutex.release() print(&#x27;bar:g_num=%d&#x27; % g_num)if __name__ == &#x27;__main__&#x27;: t1 = threading.Thread(target=foo, args=(1000000,)) t2 = threading.Thread(target=bar, args=(2000000,)) t1.start() t2.start() time.sleep(2) print(&#x27;main:g_num=%d&#x27; % g_num) 7. 死锁死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。 死锁产生的原因 系统资源的竞争导致系统资源不足，以及资源分配不当，导致死锁。 进程在运行过程中，请求和释放资源的顺序不当，会导致死锁。 产生死锁的四个必要条件： 互斥条件：一个资源每次只能被一个进程使用，即在一段时间内某 资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。 请求与保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 不可剥夺条件:进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。 循环等待条件: 若干进程间形成首尾相接循环等待资源的关系 8. Condition线程通信notify()和wait()相互交替执行 1234567891011121314151617181920212223242526272829303132import threadingimport timecond = threading.Condition()def foo(): if cond.acquire(): print(&#x27;foo:1&#x27;) cond.notify() cond.wait() print(&#x27;foo:2&#x27;) cond.notify() cond.release()def bar(): if cond.acquire(): print(&#x27;bar:1&#x27;) cond.notify() cond.wait() print(&#x27;bar:2&#x27;) cond.notify() cond.release()if __name__ == &#x27;__main__&#x27;: t1 = threading.Thread(target=foo) t2 = threading.Thread(target=bar) t1.start() t2.start() 9. Queue线程通信利用Queue的自动同步机制 1234567891011121314151617181920212223242526272829import threadingfrom queue import Queuecond = threading.Condition()def foo(q): for _ in range(100): tmp = q.get() q.put(tmp + 1)def bar(q): for _ in range(100): tmp = q.get() q.put(tmp + 1)if __name__ == &#x27;__main__&#x27;: queue = Queue(32) queue.put(0) # 非常关键，否则引起死锁 t1 = threading.Thread(target=foo, args=(queue,)) t2 = threading.Thread(target=bar, args=(queue,)) t1.start() t2.start() print(queue.get()) 10. Event线程通信一个线程发出一个 Event，另一个线程可通过该 Event 被触发。 is_set()：返回 Event 的内部旗标是否为True。set()：将会把 Event 的内部旗标设置为 True，并唤醒所有处于等待状态的线程。clear()：该方法将 Event 的内部旗标设置为 False，通常接下来会调用 wait() 方法来阻塞当前线程。wait(timeout=None)：该方法会阻塞当前线程。 12345678910111213141516171819202122232425import threadingimport timeevent = threading.Event()def calc(name): print(&#x27;%s starting ...&#x27; % threading.current_thread().getName()) print(&#x27;%s prepare to calculating&#x27; % name) event.wait() print(&#x27;%s receive event notify&#x27; % threading.current_thread().getName()) print(&#x27;%s calculated&#x27; % name)if __name__ == &#x27;__main__&#x27;: threading.Thread(target=calc, args=(&#x27;A&#x27;,)).start() threading.Thread(target=calc, args=(&#x27;B&#x27;,)).start() time.sleep(2) print(&#x27;-&#x27; * 20) print(&#x27;main thread send notify&#x27;) event.set() Event 实际上优点类似于 Condition 和旗标的结合体，但 Event 本身并不带 Lock 对象，因此如果要实现线程同步，还需要额外的 Lock 对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import threadingimport timeclass BankAccount: def __init__(self, account, balance=0): self.account = account self._balance = balance self.lock = threading.Lock() self.event = threading.Event() @property def balance(self): return self._balance def deposit(self, amount): if self.lock.acquire(): # 未存过钱 if not self.event.is_set(): print(&#x27;%s deposit [%s].&#x27; % (threading.current_thread().getName(), amount)) self._balance += amount print(&#x27;balance: %s&#x27; % self.balance) # 存钱 self.event.set() self.lock.release() self.event.wait() def withdraw(self, amount): if self.lock.acquire(): # 存过钱 if self.event.is_set(): print(&#x27;%s withdraw [%s].&#x27; % (threading.current_thread().getName(), amount)) self._balance -= amount print(&#x27;balance: %s&#x27; % self.balance) # 取钱 self.event.clear() self.lock.release() self.event.wait()if __name__ == &#x27;__main__&#x27;: bc = BankAccount(&#x27;21871282112&#x27;) threading.Thread(target=bc.deposit, args=(100,)).start() threading.Thread(target=bc.withdraw, args=(20,)).start() print(bc.balance) 11. local()线程上下文线程局部变量（Thread Local Variable）的功用其实非常简单，就是为每一个使用该变量的线程都提供一个变量的副本，使每一个线程都可以独立地改变自己的副本，而不会和其他线程的副本冲突。 1234567891011121314151617181920212223import threadingmeta = threading.local()def foo(n): for i in range(n): try: meta.x += i except: meta.x = i print(&#x27;%s: %s&#x27; % (threading.current_thread().getName(), meta.x))if __name__ == &#x27;__main__&#x27;: ts = [] for i in range(20): t = threading.Thread(target=foo, args=(10,)) ts.append(t) for t in ts: t.start() 12. Timer()定时器1234567891011121314151617import threadingimport timecount = 0def foo(): global count print(time.ctime()) count += 1 if count &lt; 10: threading.Timer(5, foo).start()if __name__ == &#x27;__main__&#x27;: threading.Timer(5, foo).start()","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Kubernetes Helm","slug":"Kubernetes Helm","date":"2018-07-09T12:34:25.000Z","updated":"2021-06-22T10:50:49.721Z","comments":true,"path":"2018/07/09/Kubernetes Helm/","link":"","permalink":"https://elihe2011.github.io/2018/07/09/Kubernetes%20Helm/","excerpt":"1. HelmHelm：让应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成的k8s资源清单文件 (deployment.yaml, service.yaml)，然后调用kubectl自动执行k8s资源部署。 Helm 包管理工具，是部署环境的流程封装 Helm 两个重要概念： chart: 创建一个应用的信息集合，包含各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元，即yum中的安装包 release: chart的运行实例。当chart被安装到kubernetes中，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个realease helm 包含两个组件：Helm 客户端 和 Tiller 服务器 Helm客户端: 负责chart和release的创建和管理、和Tiller的交互 Tiller服务器：运行在kubernetes集群节点中，处理Helm客户端请求，与API Server交互","text":"1. HelmHelm：让应用管理（Deployment、Service等）可配置，能动态生成。通过动态生成的k8s资源清单文件 (deployment.yaml, service.yaml)，然后调用kubectl自动执行k8s资源部署。 Helm 包管理工具，是部署环境的流程封装 Helm 两个重要概念： chart: 创建一个应用的信息集合，包含各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元，即yum中的安装包 release: chart的运行实例。当chart被安装到kubernetes中，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个realease helm 包含两个组件：Helm 客户端 和 Tiller 服务器 Helm客户端: 负责chart和release的创建和管理、和Tiller的交互 Tiller服务器：运行在kubernetes集群节点中，处理Helm客户端请求，与API Server交互 1.1 Helm 部署安装包下载地址：https://github.com/helm/helm/releases 123wget https://get.helm.sh/helm-v2.16.10-linux-amd64.tar.gztar zxvf helm-v2.16.10-linux-amd64.tar.gzcp linux-amd64/helm /usr/local/bin 安装Tiller: k8s APIServer开启了RBAC访问控制，在创建Tiller需要使用service account: tiller，并分配合适的角色给它 1234567891011121314151617181920# tiller-rbac-config.yamlapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system ---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: tiller namespace: kube-system 1234567891011121314# 创建RBAC$ kubectl create -f tiller-rbac-config.yaml# 部署 tiller 服务器$ helm init --service-account tiller --skip-refresh# tiller 服务器，namespace 为 kube-system$ kubectl get pod -n kube-system | grep tillerNAME READY STATUS RESTARTS AGEtiller-deploy-6845b7d56c-2wk2x 1/1 Running 0 31s$ helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.16.10&quot;, GitCommit:&quot;bceca24a91639f045f22ab0f41e47589a932cf5e&quot;, GitTreeState:&quot;clean&quot;&#125;Server: &amp;version.Version&#123;SemVer:&quot;v2.16.10&quot;, GitCommit:&quot;bceca24a91639f045f22ab0f41e47589a932cf5e&quot;, GitTreeState:&quot;clean&quot;&#125; 部署 helm v3.3: 1234567$ wget https://get.helm.sh/helm-v3.3.1-linux-amd64.tar.gz$ tar zxvf helm-v3.3.1-linux-amd64.tar.gz$ cp linux-amd64/helm /usr/local/bin/helm$ helm repo add stable https://kubernetes-charts.storage.googleapis.com/$ helm repo update 命令汇总： 命令 说明 helm search hub xxx 在Helm Hub上搜索Chart helm search repo repo_name 在本地配置的Repo中搜索Chart helm install release_name chart_reference chart一共有5种reference helm list 查看已部署的release helm status release_name 查看release信息 helm upgrade release_name chart_reference 修改chart信息后升级release helm history release_name 查看release的更新历史记录 helm rollback release_name revision 回滚操作 helm uninstall release_name 卸载release 1.2 Helm 自定义模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263$ mkdir helm-demo &amp;&amp; cd helm-demo# 创建自描述文件$ cat &gt; Chart.yaml &lt;&lt;EOFname: helloversion: 1.0.0EOF# 创建目标文件，用于生成 kubernetes 资源清单 manifests$ mkdir templates$ cat &gt; ./templates/deployment.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 3 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: hub.elihe.io/library/nginx:v1 ports: - containerPort: 80 protocol: TCPEOF# 创建 svc$ cat &gt; ./templates/service.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: hello-worldspec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP selector: app: hello-worldEOF# 安装#$ helm install . --name hello$ helm install hello . NAME: helloLAST DEPLOYED: Thu Oct 15 10:35:57 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None# 查询$ helm listNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONhello default 1 2020-10-15 10:35:57.015330177 +0800 CST deployed hello-1.0.1 通过动态配置项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 动态配置$ cat &gt; values.yaml &lt;&lt;EOFimage: repository: hub.elihe.io/test/nginx tag: v2EOF# 动态模板$ cat &gt; ./templates/deployment.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 1 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: &#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125; ports: - containerPort: 80 protocol: TCPEOF# 升级版本$ helm upgrade hello -f values.yaml .# 指定版本升级$ helm upgrade --set image.tag=&#x27;v3&#x27; hello . # 历史$ helm history helloREVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Thu Oct 15 10:35:57 2020 superseded hello-1.0.1 Install complete2 Thu Oct 15 10:40:11 2020 superseded hello-1.0.1 Upgrade complete3 Thu Oct 15 10:40:33 2020 deployed hello-1.0.1 Upgrade complete# 回滚$ helm rollback hello 2Rollback was a success.# 卸载$ helm uninstall --keep-history hello# 还原$ helm rollback hello 1# 彻底删除$ helm uninstall hello debug： 12# 配置检查和预生成配置清单$ helm install . --dry-run --debug --set image.tag=v2 2. 部署 Dashboard12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061$ mkdir dashboard &amp;&amp; cd dashboard$ helm repo update$ helm repo listNAME URL stable https://kubernetes-charts.storage.googleapis.comlocal http://127.0.0.1:8879/charts $ helm fetch stable/kubernetes-dashboard$ tar zxvf kubernetes-dashboard-1.11.1.tgz $ cd kubernetes-dashboard# 参数设置$ cat &gt; kubernetes-dashboard.yaml &lt;&lt;EOFimage: repository: k8s.gcr.io/kubernetes-dashboard-amd64 tag: v1.8.3ingress: enable: true hosts: - k8s.frognew.com annotations: nginx.ingress.kubernetes.io/ssl-redirect: true nginx.ingress.kubernetes.io/backend-protocol: HTTPS tls: - secretName: frognew-com-tls-secret hosts: - k8s.frognew.comrbac: clusterAdminRole: trueEOF# 安装$ helm install kubernetes-dashboard . \\--namespace kube-system \\-f kubernetes-dashboard.yaml # 容器已运行$ kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkubernetes-dashboard-7cfd66fc8b-8t79v 1/1 Running 0 37s# 查看访问$ kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard ClusterIP 10.98.142.181 &lt;none&gt; 443/TCP 66s# 改为NodePort访问$ kubectl edit svc kubernetes-dashboard -n kube-systemtype: NodePort$ kubectl get svc -n kube-systemkubernetes-dashboard NodePort 10.101.30.189 &lt;none&gt; 443:31667/TCP 3m11s# 获取令牌访问 token$ kubectl get secret -n kube-system | grep kubernetes-dashboard-tokenkubernetes-dashboard-token-bbt69 kubernetes.io/service-account-token 3 3m12s$ kubectl describe secret kubernetes-dashboard-token-bbt69 -n kube-systemtoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IlduNEdhTUJxOWtXbFhwdlhRSzhEMGFRemdJR0duQl9FNm9Rc2d0ekREQkEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi1iYnQ2OSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBlMTZlZjcyLWM5YjgtNDViMC05OTEzLThhNzY2NmY2ZDQzNyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.4FxXZN-Gc6mpd50sl7Wrm_ZjO5T53LrMa30MYMAHubIxOSgIh5HBvpdq5SxgQg2-XGTWZy8yZvxdmC53XOl5zqq-7RMKKjTv-Qa3O_KcHRPpnAOjj9aXvRbGdSlc5Y4D2nkysRKjWca8NjSrTXOzNHMFK0CHEIqVP-GFrKUMWmZRGYiwIoaBBKgTaS-KM3vF2Be94U2f1-ybFloOsAgEijqhUWrxpBgvXYfAmWjH4tdjCgo_1YEFPYUuUS9hq_VifdvWma9ZQthKbWplik9nuG2g-9o_xS0en5rnbxJQFfoAl5iypEi6zJiKgFoGwJsl5ScLFhpDaYN3QNhOnHhJrA 部署Dashboard2.0: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# 卸载V1.8.3$ helm uninstall kubernetes-dashboard --namespace kube-system# 使用kubectl安装$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml# 安装$ kubectl apply -f recommended.yaml$ kubectl get pod -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-6b4884c9d5-8j778 1/1 Running 0 38skubernetes-dashboard-7d8574ffd9-wff2g 1/1 Running 0 38s$ kubectl get svc -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.99.116.101 &lt;none&gt; 8000/TCP 115skubernetes-dashboard ClusterIP 10.111.190.197 &lt;none&gt; 443/TCP 116s# 改为NodePort$ kubectl edit svc kubernetes-dashboard -n kubernetes-dashboardtype: NodePort$ kubectl get svc -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdashboard-metrics-scraper ClusterIP 10.99.116.101 &lt;none&gt; 8000/TCP 2m40skubernetes-dashboard NodePort 10.111.190.197 &lt;none&gt; 443:32202/TCP 2m41s# 开放账号权限cat &gt; dashboard-admin.yaml &lt;&lt;EOF# Creating a Service AccountapiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard ---# Creating a ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboardEOF# 开放管理员权限$ kubectl apply -f dashboard-admin.yaml# 访问token$ kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#x27;&#123;print $1&#125;&#x27;)Name: admin-user-token-zjkxsNamespace: kubernetes-dashboardLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: af11f2f3-613e-4bc5-959b-4591e3ada6dfType: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 20 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IlduNEdhTUJxOWtXbFhwdlhRSzhEMGFRemdJR0duQl9FNm9Rc2d0ekREQkEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXpqa3hzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJhZjExZjJmMy02MTNlLTRiYzUtOTU5Yi00NTkxZTNhZGE2ZGYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.NRMwYGUtsf0v8rL3aZQDmi1lTAFMp1m2xEvAO6zavtFFo6HJzbpF_ReSssgWeK5LLk6sbOXVUx19O0wnASSPKg7JXiXBBGyb_qHkMdD5p2yc5ggGJu_MjE_0kXS-0OvSMS20Dtv1BiZiWB-eNEy3xxTorivG2Zah8-ART5J1HtqHauxxyQr21pHfQ9XlmOlby3MQVelIbQ1e7-EZemOSggcQI0rlpWlU_OPiakksoJGEcwr0xK7kypLnxG4AjM9x9fgjIBft30c4tfwMDXzYiB5ZwwDP2cHRiYN6fnE9XdJmrGBVAL4SgTabXFz2DOfOFpsbWkcDNdOBBWsZHzvUww# 卸载$ kubectl delete -f dashboard-admin.yaml $ kubectl delete -f recommended.yaml 3. Prometheus3.1 组件说明 MetricServer: k8s 集群资源使用情况的集合器，收集数据给 k8s 集群内使用，如kubectl, hpa, scheduler等 （支持kubectl top node等操作） PrometheusOperator: 系统监控和警报工具箱，用来存储监控数据 NodeExporter: 各个node的关键度量指标状态数据 KubeStateMetrics: 收集k8s集群内资源对象数据，制定告警规则 Prometheus: 采用pull方式收集apiserver, scheduler, controller-manager, kubelet组件数据，通过http协议传输 Grafana: 可视化数据统计和监控平台 3.2 构建记录1234567$ mkdir prometheus &amp;&amp; cd promethues$ git clone https://github.com/coreos/kube-prometheus.git$ cd kube-prometheus/manifests# 当前k8s版本为 v1.18.6, 切换分支 release-0.6$ git checkout release-0.6 修改 grafana-service.yaml, 开启NodePort方式: 12345678910111213141516apiVersion: v1kind: Servicemetadata: labels: app: grafana name: grafana namespace: monitoringspec: type: NodePort # add ports: - name: http port: 3000 targetPort: http nodePort: 30100 # add selector: app: grafana 修改 prometheus-service.yaml, 开启NodePort方式: 123456789101112131415161718apiVersion: v1kind: Servicemetadata: labels: prometheus: k8s name: prometheus-k8s namespace: monitoringspec: type: NodePort # add ports: - name: web port: 9090 targetPort: web nodePort: 30200 # add selector: app: prometheus prometheus: k8s sessionAffinity: ClientIP 修改 alertmanager-service.yaml, 开启NodePort方式: 123456789101112131415161718apiVersion: v1kind: Servicemetadata: labels: alertmanager: main name: alertmanager-main namespace: monitoringspec: type: NodePort # add ports: - name: web port: 9093 targetPort: web nodePort: 30300 # add selector: alertmanager: main app: alertmanager sessionAffinity: ClientIP 获取需要的镜像: 1234567891011121314151617$ find . -type f | xargs grep &#x27;image:&#x27; | awk &#x27;&#123;print $3&#125;&#x27; | sed &#x27;/^[ ]*$/d&#x27; | sort | uniqdirectxman12/k8s-prometheus-adapter:v0.7.0grafana/grafana:7.1.0quay.io/coreos/kube-rbac-proxy:v0.4.1quay.io/coreos/kube-state-metrics:v1.9.5quay.io/coreos/prometheus-operator:v0.40.0quay.io/prometheus/alertmanager:v0.21.0quay.io/prometheus/node-exporter:v0.18.1quay.io/prometheus/prometheus:v2.20.0# 先手动拉取镜像docker pull quay.io/coreos/kube-rbac-proxy:v0.4.1docker pull quay.io/coreos/kube-state-metrics:v1.9.5docker pull quay.io/coreos/prometheus-operator:v0.40.0docker pull quay.io/prometheus/alertmanager:v0.21.0docker pull quay.io/prometheus/node-exporter:v0.18.1docker pull quay.io/prometheus/prometheus:v2.20.0 执行安装： 1234567# Create the namespace and CRDs, and then wait for them to be availble before creating the remaining resources$ kubectl create -f manifests/setup$ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo &quot;&quot;; done$ kubectl create -f manifests/# teardown the stack$ kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup 安装后检查： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647$ kubectl get pod -n monitoringNAME READY STATUS RESTARTS AGEalertmanager-main-0 2/2 Running 0 6m17salertmanager-main-1 2/2 Running 0 6m16salertmanager-main-2 2/2 Running 0 6m16sgrafana-67dfc5f687-vqfbh 1/1 Running 0 6m7skube-state-metrics-69d4c7c69d-2lmfl 3/3 Running 0 6m6snode-exporter-j9nzx 2/2 Running 0 6m4snode-exporter-lwmkw 2/2 Running 0 6m3snode-exporter-p5sl8 2/2 Running 0 6m3sprometheus-adapter-66b855f564-qvs8x 1/1 Running 0 5m53sprometheus-k8s-0 3/3 Running 1 5m46sprometheus-k8s-1 3/3 Running 1 5m46sprometheus-operator-75c98bcfd7-smmwd 2/2 Running 0 8m22s$ kubectl top nodeNAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master 321m 16% 1329Mi 70% k8s-node01 190m 9% 1062Mi 56% k8s-node02 961m 48% 1011Mi 53% $ kubectl top pod -n monitoringNAME CPU(cores) MEMORY(bytes) alertmanager-main-0 7m 22Mi alertmanager-main-1 11m 23Mi alertmanager-main-2 9m 24Mi grafana-67dfc5f687-vqfbh 25m 25Mi kube-state-metrics-69d4c7c69d-2lmfl 2m 33Mi node-exporter-j9nzx 58m 19Mi node-exporter-lwmkw 5m 18Mi node-exporter-p5sl8 5m 13Mi prometheus-adapter-66b855f564-qvs8x 4m 18Mi prometheus-k8s-0 31m 235Mi prometheus-k8s-1 26m 195Mi prometheus-operator-75c98bcfd7-smmwd 1m 34Mi $ kubectl get svc -n monitoringNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEalertmanager-main NodePort 10.105.101.126 &lt;none&gt; 9093:30300/TCP 9m37salertmanager-operated ClusterIP None &lt;none&gt; 9093/TCP,9094/TCP,9094/UDP 9m37sgrafana NodePort 10.100.132.19 &lt;none&gt; 3000:30100/TCP 9m26skube-state-metrics ClusterIP None &lt;none&gt; 8443/TCP,9443/TCP 9m25snode-exporter ClusterIP None &lt;none&gt; 9100/TCP 9m25sprometheus-adapter ClusterIP 10.101.16.41 &lt;none&gt; 443/TCP 9m12sprometheus-k8s NodePort 10.101.33.228 &lt;none&gt; 9090:30200/TCP 9m10sprometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 9m4sprometheus-operator ClusterIP None &lt;none&gt; 8443/TCP 11m 访问 promethues：http://192.168.31.40:30200 1sum by (pod_name)(rate(container_cpu_usage_seconds_total&#123;image!=&quot;&quot;&#125;[1m] )) 访问 Grafana: http://192.168.31.40:30100 1admin/admin 3. Horizontal Pod AutoscalingHPA 可以根据CPU利用率自动伸缩一个 Replication Controller、Deployment或者 ReplicaSet中的Pod数量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104cat &gt; hpa.yaml &lt;&lt;EOFapiVersion: apps/v1kind: Deploymentmetadata: name: php-apachespec: replicas: 1 selector: matchLabels: app: apache template: # Pod metadata: labels: app: apache spec: containers: - name: php-apache image: gcr.io/google_containers/hpa-example ports: - containerPort: 80 resources: requests: cpu: 0.1 memory: 32Mi---apiVersion: v1kind: Servicemetadata: name: php-apachespec: type: ClusterIP selector: app: apache ports: - name: http port: 80 targetPort: 80EOF# 启动$ kubectl apply -f hpa.yaml$ kubectl top podNAME CPU(cores) MEMORY(bytes) php-apache-86d4bcdcd9-wlvs5 1/1 Running 0 29m # 创建HPA控制器$ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10# 查看数据释放统计到了$ kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 0%/50% 1 10 1 5m# 增加负载，查看负载数量 （新开一个窗口）$ kubectl run -i --tty load-generator --image=busybox /bin/sh$ while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done# 监控 kubectl get hpa -wNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache &lt;unknown&gt;/50% 1 10 0 7sphp-apache Deployment/php-apache &lt;unknown&gt;/50% 1 10 1 15sphp-apache Deployment/php-apache 0%/50% 1 10 1 4m3sphp-apache Deployment/php-apache 0%/50% 1 10 1 5m19sphp-apache Deployment/php-apache 1%/50% 1 10 1 19mphp-apache Deployment/php-apache 0%/50% 1 10 1 20mphp-apache Deployment/php-apache 0%/50% 1 10 1 25mphp-apache Deployment/php-apache 378%/50% 1 10 1 28mphp-apache Deployment/php-apache 378%/50% 1 10 4 28mphp-apache Deployment/php-apache 467%/50% 1 10 8 28m# 尝试新作 Pod$ kubectl get pod -wNAME READY STATUS RESTARTS AGEload-generator 1/1 Running 0 45mphp-apache-86d4bcdcd9-wlvs5 1/1 Running 0 29mphp-apache-86d4bcdcd9-7cjmm 0/1 Pending 0 0sphp-apache-86d4bcdcd9-7cjmm 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 Pending 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 Pending 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 Pending 0 0sphp-apache-86d4bcdcd9-dr2rg 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-9srl5 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-7cjmm 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-hzf8h 0/1 Pending 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 Pending 0 0sphp-apache-86d4bcdcd9-hzf8h 0/1 Pending 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 Pending 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 Pending 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 Pending 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 Pending 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 Pending 0 0sphp-apache-86d4bcdcd9-hzf8h 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-m4tp6 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-5bfp8 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-8scwl 0/1 ContainerCreating 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 Pending 0 0sphp-apache-86d4bcdcd9-z6qkt 0/1 Pending 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 Pending 0 0sphp-apache-86d4bcdcd9-z6qkt 0/1 Pending 0 0sphp-apache-86d4bcdcd9-rsg9f 0/1 ContainerCreating 0 1sphp-apache-86d4bcdcd9-z6qkt 0/1 ContainerCreating 0 3s 4. 资源限制4.1 Pod12345678910111213spec: containers: - name: php-apache image: gcr.io/google_containers/hpa-example ports: - containerPort: 80 resources: requests: cpu: 0.1 memory: 32Mi limits: cpu: 200m memory: 100Mi 4.2 名称空间 计算姿态配额 123456789101112apiVersion: v1kind: ResourceQuotametadata: name: compute-resource namespace: spark-clusterspec: hard: pods: 20 requests.cpu: 20 requests.memory: 100Gi limits.cpu: 40 limits.memory: 200Gi 配置对象数量配额限制 12345678910111213apiVersion: v1kind: ResourceQuotametadata: name: object-counts namespace: spark-clusterspec: hard: configmaps: 10 persistentvolumeclaims: 4 replicationcontrollers: 20 secrets: 10 services: 10 services.loadbalancer: 2 配置CPU 和 内存的 LimitRange 12345678910111213apiVersion: v1kind: LimitRangemetadata: name: mem-limit-rangespec: limits: - default: memory: 50Gi cpu: 5 defaulyRequest: memory: 1Gi cpu: 1 type: Container 5. EFK 日志EFK: Elasticsearch + Fluentd + Kibana ELFK: Elasticsearch + Logstash + Filebeat + Kibana 安装参考：https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes 5.1 创建 Namespace12345678910111213$ mkdir efk &amp;&amp; cd efk$ cat &gt; kube-logging.yaml &lt;&lt;EOFkind: NamespaceapiVersion: v1metadata: name: kube-loggingEOF$ kubectl create -f kube-logging.yaml$ kubectl get ns | grep kube-loggingkube-logging Active 6s 5.2 ElasticSearch5.2.1 创建无头服务123456789101112131415161718192021222324$ cat &gt; elasticsearch_svc.yaml &lt;&lt;EOFkind: ServiceapiVersion: v1metadata: name: elasticsearch namespace: kube-logging labels: app: elasticsearchspec: selector: app: elasticsearch clusterIP: None ports: - port: 9200 name: rest - port: 9300 name: inter-nodeEOF$ kubectl create -f elasticsearch_svc.yaml$ kubectl get services --namespace=kube-loggingNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 13s 5.2.2 创建PV1234567891011121314151617181920212223$ cat &gt; elasticsearch_pv.ymal &lt;&lt;EOFapiVersion: v1kind: PersistentVolumemetadata: name: nfspv1 namespace: kube-loggingspec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs server: 192.168.31.200EOF$ kubectl create -f elasticsearch_pv.ymal$ kubectl get pv -n kube-loggingNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Available nfs 18s 5.2.3 安装ES123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101$ cat &gt; elasticsearch_statefulset.yaml &lt;&lt;EOFapiVersion: apps/v1kind: StatefulSetmetadata: name: es-cluster namespace: kube-loggingspec: serviceName: elasticsearch #replicas: 3 replicas: 1 selector: matchLabels: app: elasticsearch template: metadata: labels: app: elasticsearch spec: containers: - name: elasticsearch image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0 resources: limits: #cpu: 1000m cpu: 400m requests: cpu: 100m ports: - containerPort: 9200 name: rest protocol: TCP - containerPort: 9300 name: inter-node protocol: TCP volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data env: - name: cluster.name value: k8s-logs - name: node.name valueFrom: fieldRef: fieldPath: metadata.name - name: discovery.type # test-bed value: single-node #- name: discovery.seed_hosts #value: &quot;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&quot; #- name: cluster.initial_master_nodes #value: &quot;es-cluster-0,es-cluster-1,es-cluster-2&quot; - name: ES_JAVA_OPTS #value: &quot;-Xms512m -Xmx512m&quot; value: &quot;-Xms256m -Xmx256m&quot; initContainers: - name: fix-permissions image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 1000:1000 /usr/share/elasticsearch/data&quot;] securityContext: privileged: true volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data - name: increase-vm-max-map image: busybox command: [&quot;sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;] securityContext: privileged: true - name: increase-fd-ulimit image: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;] securityContext: privileged: true volumeClaimTemplates: - metadata: name: data labels: app: elasticsearch spec: accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: nfs resources: requests: storage: 1GiEOF$ kubectl create -f elasticsearch_statefulset.yaml# 监控创建进度$ kubectl rollout status sts/es-cluster --namespace=kube-logging$ kubectl get pod -n kube-loggingNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 59s# 监控日志$ kubectl logs -f es-cluster-0 -n kube-logging # 开启本地端口，测试服务$ kubectl port-forward es-cluster-0 9200:9200 --namespace=kube-logging$ curl http://localhost:9200/_cluster/state?pretty 5.3 Kibana1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162$ cat &gt; kibana.yaml &lt;&lt;EOFapiVersion: v1kind: Servicemetadata: name: kibana namespace: kube-logging labels: app: kibanaspec: type: NodePort ports: - port: 5601 selector: app: kibana---apiVersion: apps/v1kind: Deploymentmetadata: name: kibana namespace: kube-logging labels: app: kibanaspec: replicas: 1 selector: matchLabels: app: kibana template: metadata: labels: app: kibana spec: containers: - name: kibana image: docker.elastic.co/kibana/kibana:7.2.0 resources: limits: cpu: 1000m requests: cpu: 100m env: - name: ELASTICSEARCH_URL value: http://elasticsearch:9200 ports: - containerPort: 5601EOF$ kubectl create -f kibana.yaml$ kubectl rollout status deployment/kibana --namespace=kube-logging$ kubectl get pod -n kube-loggingNAME READY STATUS RESTARTS AGEes-cluster-0 1/1 Running 0 13mkibana-5749b5778b-zvtwn 1/1 Running 0 4m33s$ kubectl get svc -n kube-loggingNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEelasticsearch ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 89mkibana NodePort 10.106.103.244 &lt;none&gt; 5601:30750/TCP 8s$ curl http://192.168.1.40:30750 5.4 Fluentd123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100$ cat &gt; fluentd.yaml &lt;&lt;EOFapiVersion: v1kind: ServiceAccountmetadata: name: fluentd namespace: kube-logging labels: app: fluentd---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: fluentd labels: app: fluentdrules:- apiGroups: - &quot;&quot; resources: - pods - namespaces verbs: - get - list - watch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: fluentdroleRef: kind: ClusterRole name: fluentd apiGroup: rbac.authorization.k8s.iosubjects:- kind: ServiceAccount name: fluentd namespace: kube-logging---apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd namespace: kube-logging labels: app: fluentdspec: selector: matchLabels: app: fluentd template: metadata: labels: app: fluentd spec: serviceAccount: fluentd serviceAccountName: fluentd tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd image: fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1 env: - name: FLUENT_ELASTICSEARCH_HOST value: &quot;elasticsearch.kube-logging.svc.cluster.local&quot; - name: FLUENT_ELASTICSEARCH_PORT value: &quot;9200&quot; - name: FLUENT_ELASTICSEARCH_SCHEME value: &quot;http&quot; - name: FLUENTD_SYSTEMD_CONF value: disable resources: limits: #memory: 512Mi memory: 256Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containersEOF$ kubectl create -f fluentd.yaml$ kubectl get ds -n kube-loggingNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEfluentd 2 2 2 2 2 &lt;none&gt; 27s 5.5 Kibana 页面 5.6 测试创建一个 Pod： 1234567891011121314$ cat &gt; counter.yaml &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: [/bin/sh, -c, &#x27;i=0; while true; do echo &quot;$i: $(date)&quot;; i=$((i+1)); sleep 1; done&#x27;]EOF$ kubectl create -f counter.yaml 6. 补充：Port说明：Pod Template中的ports: containerPort: 容器对外开发的端口 Service 中的 ports: port: 监听请求，接收端口，绑定在ClusterIP上 targetPort: 指定Pod的接收端口，与containerPort绑定 nodePort: 类型为NodeType时，绑定在NodeIP上，未指定则随机给一个","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 安全机制","slug":"Kubernetes 安全机制","date":"2018-07-08T07:44:26.000Z","updated":"2021-06-22T10:50:49.721Z","comments":true,"path":"2018/07/08/Kubernetes 安全机制/","link":"","permalink":"https://elihe2011.github.io/2018/07/08/Kubernetes%20%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/","excerpt":"1. 机制说明API Server 是集群内部各个组件通讯的中介，也是外部控制的入口。k8s 使用认证(Authentication)、鉴权(Authorization)、准入控制(Admission Control) 三步来确保API Server的安全。 2. 认证 (Authentication) HTTP Token：HTTP Request Header 的 Token字段 HTTP Base: 客户端通过base64 USERNAME:PASSWORD, 填充 HTTP Request Header 的 Authorization字段，服务端收到后解码获取用户名和密码 HTTPS: 基于CA根证书签名的客户端身份认证方式。（推荐）","text":"1. 机制说明API Server 是集群内部各个组件通讯的中介，也是外部控制的入口。k8s 使用认证(Authentication)、鉴权(Authorization)、准入控制(Admission Control) 三步来确保API Server的安全。 2. 认证 (Authentication) HTTP Token：HTTP Request Header 的 Token字段 HTTP Base: 客户端通过base64 USERNAME:PASSWORD, 填充 HTTP Request Header 的 Authorization字段，服务端收到后解码获取用户名和密码 HTTPS: 基于CA根证书签名的客户端身份认证方式。（推荐） 2.1 HTTPS 证书认证 2.2 需要认证的节点 两种类型： Kubernetes组件对API Server的访问：kubectl、Controller Manager、Scheduler、kubelet、kube-proxy Kubernetes管理的Pod对容器的访问：Pod（dashborad也是以Pod形式运行） 安全性说明： Controller Manager、Scheduler与API Server在同一台机器，所以直接使用API Server的非安全端口访问--insecure-bind-address=127.0.0.1 kubectl、kubelet、kube-proxy访问API Server都需要证书进行HTTPS双向认证 证书颁发： 手动签发：通过k8s集群的根 ca 进行签发 HTTPS 证书 自动签发：kubelet 首次访问 API Server 时，使用 token 认证，通过后，Controller Manager 会为kubelet生成一个证书，以后的访问均使用该证书 2.3 kubeconfigkubeconfig 文件包含集群参数（CA证书、API Server地址），客户端参数，集群context信息（集群名称、用户名）。k8s 组件通过启动时指定不同的 kubeconfig 文件可以切换到不同的集群 cat ~/.kube/config 2.4 ServiceAccountPod 中的容器访问API Server。因为Pod的创建和销毁是动态的，所以要为它手动生成证书是不可行的，k8s 使用 Service Account解决Pod访问API Server的认证问题 2.5 Secret 与 SA 的关系Secret 分两类： 用于ServiceAccount的 service-account-token 用于保存用户自定义的保密信息的 Opaque SA 中包含三个部分： token：使用API Server私钥签名的 JWT ca.crt: 根证书，用于Client端验证API Server发送的证书 namespace: 标识该service-account-token的作用域名空间 1234567891011121314151617181920212223242526272829303132$ kubectl get secret --all-namespacesNAMESPACE NAME TYPE DATA AGEdefault default-token-rhw7k kubernetes.io/service-account-token 3 5d16hingress-nginx default-token-ftjf6 kubernetes.io/service-account-token 3 2d3hkube-system kube-proxy-token-kcgcp kubernetes.io/service-account-token 3 5d16h$ kubectl describe secret default-token-rhw7kName: default-token-rhw7kNamespace: defaultLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: default kubernetes.io/service-account.uid: 3fdb2906-e8c4-4bb1-9dc0-ac8aa15167b6Type: kubernetes.io/service-account-tokenData====ca.crt: 1025 bytesnamespace: 7 bytestoken: eyJhbGciOiJSUzI1NiIsImtpZCI6Ikx5ZjJCcWJPandjZzl5czlkRHpZZWp0d2NtT2dSU0w3c2M5dXY2ZUQ0QkUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tcmh3N2siLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjNmZGIyOTA2LWU4YzQtNGJiMS05ZGMwLWFjOGFhMTUxNjdiNiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.FkcID8mWCOXDQbZAZPJLWSSWngvt9R-69AEDVV_QQvyvP_BW1MwiANOM2cXkS-qDo4-hcDcRKGOZ-q7BxQC96YUsj41iiLBbsXyVI1_ovEgp58dwROJe-MTxkSlk8sic40QmW2y1CwREf-5EIxwLy1iGekbbMZb4W0m4oXa-BN7qzNzMwu4Bb6ScJbxljHpO33K80oKtWYN-fpow31FjMjZMEebUvf-pGw6O2FPLvzwC7A7_U-WRNrFWd2wZIRQf8GfQgUf5-phAnmyawcJ4gpQooRvHoyGyW366dEY-qAk4D-1xSj598X0Q_pq7PdT1WQkO3nozHL-w4mbSlb3Ytw$ kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEkube-proxy-c5t62 1/1 Running 13 5d16hkube-proxy-q7m2t 1/1 Running 13 5d16hkube-proxy-t2tgb 1/1 Running 13 5d16h$ kubectl exec kube-proxy-c5t62 -n kube-system -it -- ls -l /run/secrets/kubernetes.io/serviceaccounttotal 0lrwxrwxrwx 1 root root 13 Sep 13 06:40 ca.crt -&gt; ..data/ca.crtlrwxrwxrwx 1 root root 16 Sep 13 06:40 namespace -&gt; ..data/namespacelrwxrwxrwx 1 root root 12 Sep 13 06:40 token -&gt; ..data/token 2.6 总结 3. 鉴权 (Authorization)认证 和鉴权： 认证(authencation): 通过只代表通讯双方是可信的 鉴权(authorization): 确定请求方有哪些资源权限 API Server的授权策略，启动参数--authorization-mode AlwaysDeny: 拒绝所有请求，一般用于测试 AlwaysAllow: 接收所有请求。如果集群不需要授权流程，采用该策略 ABAC (Attribute-Based Access Control): 基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webbook: 通过调用外部REST服务对用户进行授权 RBAC (Role-Based Access Control): 基于角色的访问控制，默认规则 RBAC优势： 对集群中的资源和非资源均拥有完整的覆盖 整个RBAC完全由几个API对象完成，同其他API对象一样，可以用kubectl或API进行操作 可在运行时调整，无需重启API Server 3.1 RBAC 的 API资源对象 Role ClusterRole RoleBinding ClusterRoleBinding k8s 不会提供用户管理，User, Group, ServiceAccount指定的用户，需要通过证书请求文件指定： 1234567891011121314151617&#123; &quot;CN&quot;: &quot;admin&quot;, // User &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;HangZhou&quot;, &quot;L&quot;: &quot;XS&quot;, &quot;O&quot;: &quot;system:master&quot;, // Group &quot;OU&quot;: &quot;Sytem&quot; &#125; ]&#125; 3.2 Role &amp; ClusterRole3.2.1 RoleRole 表示一组规则权限，权限只会增加（累加权限），不存在一开始就开通很多权限而通过RBAC对其减少的操作。Role 必须定义在一个namespace中，跨namespace可以使用ClusterRole 123456789apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: pod-reader namespace: defaultrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ pods ] verbs: [get, watch, list] 3.2.2 ClusterRoleClusterRole 是集群级别的，可用于： 集群级别资源控制，例如node访问权限 非资源型 endpoints，例如/healthz 访问 所有命名空间资源控制，例如pod 12345678apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: secret-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ secrets ] verbs: [get, watch, list] 3.3 RoleBinding &amp; ClusterRoleBinding3.3.1 RoleBindingRoleBinding 可以将角色中定义的权限赋予用户或组，它包含了一种权限列表(subjects)，权限列表包含不同形式的待授予权限资源类型（users，groups，service accounts），同时它也包含被Bind的Role引用 12345678910111213apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: read-pods namespace: defaultsubjects:- kind: User name: jane apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io RoleBinding引用ClusterRole： 1234567891011121314# This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespaceapiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: read-secrets namespace: developmentsubjects:- kind: User name: dave apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 3.3.2 ClusterRoleBindingClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权 12345678910111213# This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in any namespace.apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: read-secrets-globalsubjects:- kind: Group name: manager apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 3.4 Resources访问子资源: 1GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log 12345678apiVersion: rbac.authorization.k8s.io/v1beta1kind: Rolemetadata: name: pod-and-pod-logs-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [ pods, &quot;pods/log&quot; ] verbs: [get, list] 3.5 to SubjectsRoleBinding &amp; ClusterRoleBinding 可以将Role绑定到Subjects, Subjects 可以是groups, users, 或SA 3.6 示例3.6.1 创建Linux账号123456useradd devuserpasswd devusersu - devuser$ kubectl get pod # 无权限The connection to the server localhost:8080 was refused - did you specify the right host or port? 3.6.2 安装证书工具12345678# 下载证书生成工具$ wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64$ wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 $ wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 $ chmod +x cfssl*$ mv cfssl_linux-amd64 /usr/local/bin/cfssl $ mv cfssljson_linux-amd64 /usr/local/bin/cfssljson$ mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo 3.6.3 生成证书1234567891011121314151617181920212223242526$ mkdir -p ~/cert/devuser# 证书请求文件$ cat &gt; ~/cert/devuser/user-csr.json &lt;&lt;EOF&#123; &quot;CN&quot;: &quot;devuser&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;JS&quot;, &quot;L&quot;: &quot;NJ&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;Sytem&quot; &#125; ]&#125;EOF# 生成证书$ cd /etc/kubernetes/pki$ cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes ~/cert/devuser/user-csr.json | cfssljson -bare devuser 3.6.4 设置集群参数1234567891011121314151617181920212223# 设置集群参数cd ~/cert/devuserexport KUBE_APISERVER=&quot;https://192.168.31.40:6443&quot;kubectl config set-cluster kubernetes \\--certificate-authority=/etc/kubernetes/pki/ca.crt \\--embed-certs=true \\--server=$&#123;KUBE_APISERVER&#125; \\--kubeconfig=devuser.kubeconfig# 设置客户端认证参数kubectl config set-credentials devuser \\--client-certificate=/etc/kubernetes/pki/devuser.pem \\--client-key=/etc/kubernetes/pki/devuser-key.pem \\--embed-certs=true \\--kubeconfig=devuser.kubeconfig# 设置上下文kubectl config set-context kubernetes \\--cluster=kubernetes \\--user=devuser \\--namespace=dev \\--kubeconfig=devuser.kubeconfig 3.6.5 角色绑定123# rolebindingkubectl create ns devkubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev 3.6.6 用户管理配置123mkdir -p /home/devuser/.kubecp devuser.kubeconfig /home/devuser/.kube/configchown -R devuser:devuser /home/devuser/.kube 3.6.7 设置默认上下 和 验证123456789101112131415161718# 设置默认上下文su - devuser$ kubectl config use-context kubernetes --kubeconfig=.kube/configSwitched to context &quot;kubernetes&quot;.# devuser 用户下创建 pod$ kubectl get podNo resources found in dev namespace.$ kubectl run nginx --image=hub.elihe.io/test/nginx:v1pod/nginx created$ kubectl get podNAME READY STATUS RESTARTS AGEnginx 1/1 Running 0 4s$ kubectl get pod -n defaultError from server (Forbidden): pods is forbidden: User &quot;devuser&quot; cannot list resource &quot;pods&quot; in API group &quot;&quot; in the namespace &quot;default&quot; 4. 准入控制准入控制是 API Server 的插件集合，通过添加不同的插件，实现额外的准入控制规则 常见准入控制插件： NamespaceLifecycle: 防止在不存在的namespace上创建对象；防止删除系统预置的namespace；删除namespace时，连带删除它下面的所有资源 LimitRanger: 确保请求的资源不会超过资源所在Namespace的LimitRange的限制 ServiceAccount: 实现自动化添加SA ResourceQuota: 确保请求的资源不会超过资源的ResourceQuota限制","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 集群调度","slug":"Kubernetes 集群调度","date":"2018-07-07T03:52:25.000Z","updated":"2021-06-22T10:50:49.720Z","comments":true,"path":"2018/07/07/Kubernetes 集群调度/","link":"","permalink":"https://elihe2011.github.io/2018/07/07/Kubernetes%20%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6/","excerpt":"1. 调度说明1.1 简介Scheduler 是 K8S 的调度器，主要任务是把定义的 pod 分配到集群节点上。它主要考虑如下问题： 公平： 如何确保每个节点都被分配资源 资源高利用率：集群所有资源最大化被使用 效率：调度性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Scheduler 作为独立的进程允许，启动后会一直监听API Server，获取 PodSpec.NodeName 为空的pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上","text":"1. 调度说明1.1 简介Scheduler 是 K8S 的调度器，主要任务是把定义的 pod 分配到集群节点上。它主要考虑如下问题： 公平： 如何确保每个节点都被分配资源 资源高利用率：集群所有资源最大化被使用 效率：调度性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Scheduler 作为独立的进程允许，启动后会一直监听API Server，获取 PodSpec.NodeName 为空的pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上 1.2 调度过程 首先，过滤掉不满足条件的节点，这个过程称为 predicate 其次，对通过的节点按优先级排序，这个是 priority 最后，从中选择优先级最高的节点。 总结：预选 + 优选 Predicate 算法： PodFitsResources: 节点上剩余资源是否大于 pod 请求资源 PodFitsHost: 如果 pod 指定了NodeName，检查当前节点名称是否与之匹配 PodFitsHostPorts: pod 申请的port 是否已被占用 PodSelectorMatches: 过滤掉和 pod 指定的 label 不匹配的节点 NoDiskConflict: 已经 mount 的 volume和pod指定的 volume 不冲突，除非它们都是只读的 如果在 predicate 过程中没有合适的节点，pod 会一直在 pending 状态，不断重试调度，直到有节点满足条件。多个节点同时满足条件，继续按 priorities 过程，按优先级大小排序 优先级选项： LeastRequestedPriority: 计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高 BalancedResourceAllocation: CPU 和 Memory 的使用率接近，权重越高。通常和上一个一起使用 ImageLocalityPriority: 本地已下载镜像，镜像总大小越大，权重越高 1.3 自定义调度器spec.schedulername 指定调度器名称 1234567891011apiVersion: v1kind: Podmetadata: name: annotation-second-scheduler labels: name: multischeduler-examplespec: schedulername: my-scheduler conatiners: - name: pod-with-second-annotation-container image: gcr.io/google_containers/pause:2.0 2. 调度亲和性2.1 节点亲和性pod.spec.nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: 软策略 requiredDuringSchedulingIgnoredDuringExecution: 硬策略 12345678910111213141516171819202122232425262728apiVersion: v1kind: Podmetadata: name: node-affinity labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn values: - k8s-node02 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: source operator: In values: - k8s-node01 2.2 Pod 亲和性pod.spec.affinity.podAffinity/PodAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: 软策略 requiredDuringSchedulingIgnoredDuringExecution: 硬策略 1234567891011121314151617181920212223242526272829303132apiVersion: v1kind: Podmetadata: name: pod-affinity labels: app: pod-3spec: containers: - name: pod-3 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - pod-1 topologyKey: kubernetes.io/hostname podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - pod-2 topologyKey: kubernetes.io/hostname 12345678910111213$ kubectl get podNAME READY STATUS RESTARTS AGEnode-affinity 1/1 Running 0 9m22spod-affinity 0/1 Pending 0 10s# 注意node-affinity必须是running的，否则即使修改了的label满足条件，pod-3也不会创建$ kubectl label pod node-affinity app=pod-1 --overwrite=truepod/node-affinity labeled$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSnode-affinity 1/1 Running 1 10m app=pod-1pod-affinity 1/1 Running 0 95s app=pod-3 2.3 亲和性/反亲和性策略对比 调度策略 匹配标签 操作符 拓扑域支持 调度目标 nodeAffinity Node In, NotIn, Exists, DoesNotExist, Gt, Lt No 指定主机 podAffinity Pod In, NotIn, Exists, DoesNotExist Yes 指定Pod在同一个拓扑域 podAntiAffinity Pod In, NotIn, Exists, DoesNotExist Yes 指定Pod不在同一个拓扑域 3. 污点 和 容忍 亲和性：Pod的一种偏好或硬性要求，它使 Pod 能被吸引到一类特定的节点 污点：与亲和性相反，它使节点能够排斥一类特定的Pod Taint：用来避免pod节点被分配到不合适的节点上 Toleration：表示pod可以(容忍)被分配到Taint节点上 3.1 Taint3.1.1 污点的组成1key=value:effect 其中value可以为空，effect描述污点的作用，当前支持如下三个选项： NoSchedule: 不会将Pod调度到具有该污点的Node上 PreferNoSchedule: 尽量避免将Pod调度到具有该污点的Node上 NoExecute: 不会将Pod调度到具有该污点的Node上，同时会将已存在的Pod驱逐出该Node 3.1.2 污点的设置，查看和去除123456789# 设置污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule# 查看污点$ kubectl describe node k8s-node01 | grep -i taintTaints: kickoff=test:NoSchedule# 去除污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule- 3.2 Tolerationpod.spec.tolerations 12345678910111213tolerations:- key: key1 operator: Equal value: value1 effect: NoSchedule tolerationSeconds: 3600 # 驱离前保留时间- key: key2 operator: Equal value: value2 effect: NoExecute- key: key3 operator: Exists effect: NoSchedule key, value, effect 要与 Node 上设置的taint一致 operator等于 Exists 时，忽略 value值 tolerationSeconds Pod被驱离前的保留时间 当不指定key时，容忍所有的污点key 12tolerations:- operator: Exists 当不指定effect时，容忍所有的污点作用 123tolerations:- key: key operator: Exists 多个master节点，可去除默认污点 12345# 主节点默认设置污点$ kubectl describe node k8s-master | grep -i taintTaints: node-role.kubernetes.io/master:NoSchedule$ kubectl taint nodes k8s-master node-role.kubernetes.io/master=:PreferNoSchedule 3.2.1 示例1234567891011121314151617181920212223242526# taint-toleration.yamlapiVersion: v1kind: Podmetadata: name: pod-1spec: containers: - name: pod-1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;]---apiVersion: v1kind: Podmetadata: name: pod-2spec: containers: - name: pod-2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] tolerations: - key: kickoff operator: Equal value: test effect: NoSchedule 12345678910111213141516171819# 节点都打上污点标识$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule$ kubectl taint nodes k8s-node02 kickoff=test:NoSchedule$ kubectl create -f taint-toleration.yaml$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod-1 0/1 Pending 0 58s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;pod-2 1/1 Running 0 58s 10.244.2.55 k8s-node02 &lt;none&gt; &lt;none&gt;# 去除污点$ kubectl taint nodes k8s-node01 kickoff=test:NoSchedule-# 不再Pending$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod-1 1/1 Running 0 2m 10.244.1.40 k8s-node01 &lt;none&gt; &lt;none&gt;pod-2 1/1 Running 0 2m 10.244.2.55 k8s-node02 &lt;none&gt; &lt;none&gt; 4. 固定节点4.1 指定节点名称pod.spec.nodeName 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: test-1spec: replicas: 3 selector: matchLabels: app: tools template: metadata: labels: app: tools spec: nodeName: k8s-node01 # 指定节点名称 containers: - name: pod-1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] 12345$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-1-5c889d444f-pp9td 1/1 Running 0 48s 10.244.1.41 k8s-node01 &lt;none&gt; &lt;none&gt;test-1-5c889d444f-rtk25 1/1 Running 0 48s 10.244.1.43 k8s-node01 &lt;none&gt; &lt;none&gt;test-1-5c889d444f-rv2fc 1/1 Running 0 48s 10.244.1.42 k8s-node01 &lt;none&gt; &lt;none&gt; 4.2 指定节点选择器pod.spec.nodeSelector, 通过label-selector机制选择节点，由调度器调度策略匹配label，然后调度到目标节点 1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: test-2spec: replicas: 2 selector: matchLabels: app: web template: metadata: labels: app: web spec: nodeSelector: # 指定标签 type: backendNode1 containers: - name: web image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] 12345678910111213$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGEtest-2-564fd7c7df-4jftd 0/1 Pending 0 3s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;test-2-564fd7c7df-tdwj7 0/1 Pending 0 3s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;# 给node打标签$ kubectl label node k8s-node02 type=backendNode1node/k8s-node02 labeled$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEStest-2-564fd7c7df-4jftd 1/1 Running 0 3m24s 10.244.2.56 k8s-node02 &lt;none&gt; &lt;none&gt;test-2-564fd7c7df-tdwj7 1/1 Running 0 3m24s 10.244.2.57 k8s-node02 &lt;none&gt; &lt;none&gt;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 存储","slug":"Kubernetes 存储","date":"2018-07-05T23:12:05.000Z","updated":"2021-06-22T10:50:49.720Z","comments":true,"path":"2018/07/06/Kubernetes 存储/","link":"","permalink":"https://elihe2011.github.io/2018/07/06/Kubernetes%20%E5%AD%98%E5%82%A8/","excerpt":"1. ConfigMap提供向容器注入配置信息的机制，可以用来保存单个属性，也可以用来保存整个配置文化或 JSON 二进制大对象 1.1 创建 ConfigMap1.1.1 文件--from-file：指定文件或目录 12345678910111213141516$ cat &gt; ./ui.properties &lt;&lt;EOFcolor=redbackground=cyanEOF$ kubectl create configmap ui-config --from-file=./ui.properties $ kubectl get cm ui-config -o yamlapiVersion: v1data: ui.properties: | # key 为文件名称 color=red background=cyankind: ConfigMapmetadata: ...","text":"1. ConfigMap提供向容器注入配置信息的机制，可以用来保存单个属性，也可以用来保存整个配置文化或 JSON 二进制大对象 1.1 创建 ConfigMap1.1.1 文件--from-file：指定文件或目录 12345678910111213141516$ cat &gt; ./ui.properties &lt;&lt;EOFcolor=redbackground=cyanEOF$ kubectl create configmap ui-config --from-file=./ui.properties $ kubectl get cm ui-config -o yamlapiVersion: v1data: ui.properties: | # key 为文件名称 color=red background=cyankind: ConfigMapmetadata: ... 1.1.2 字面值--from-literal 123456789101112$ kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm$ kubectl describe cm special-config$ kubectl get cm special-config -o yamlapiVersion: v1data: special.how: very special.type: charmkind: ConfigMapmetadata: ... 1.2 使用 ConfigMap1.2.1 使用 ConfigMap 代替环境变量spec.containers[].env[] spec.containers[].envFrom[] 123456789101112131415161718192021222324252627282930313233343536373839404142434445# configmap-injection.yamlapiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: very special.type: charm---apiVersion: v1kind: ConfigMapmetadata: name: env-config namespace: defaultdata: log_level: INFO---apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot;] env: # 按key导入 - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: # 全部导入 - configMapRef: name: env-config restartPolicy: Never 1234567891011121314$ kubectl create -f configmap-injection.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEconfigmap-pod 0/1 Completed 0 2m35s$ kubectl logs configmap-pod ...SPECIAL_TYPE_KEY=charm # targetSPECIAL_LEVEL_KEY=very # targetlog_level=INFO # targetKUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_SERVICE_HOST=10.96.0.1 1.2.2 用 ConfigMap 设置命令行参数12345678910111213141516171819202122apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $&#123;SPECIAL_LEVEL_KEY&#125; $&#123;SPECIAL_TYPE_KEY&#125; &quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never 1.2.3 通过数据插件使用 ConfigMap123456789101112131415161718apiVersion: v1kind: Podmetadata: name: configmap-podspec: containers: - name: cm-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 300&quot;] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never 12$ kubectl exec configmap-pod -it -- cat /etc/config/special.howvery 1.2.4 ConfigMap 热更新12345678910111213141516171819202122232425262728293031323334353637# configmap-hot-update.yamlapiVersion: v1kind: ConfigMapmetadata: name: log-config namespace: defaultdata: log_level: INFO---apiVersion: apps/v1kind: Deploymentmetadata: name: nginxspec: replicas: 1 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: log-config 12345678910111213141516171819202122$ kubectl apply -f configmap-hot-update.yaml$ kubectl get podNAME READY STATUS RESTARTS AGEnginx-df47dc9cd-9mjnx 1/1 Running 0 82s$ kubectl exec nginx-df47dc9cd-9mjnx -it -- cat /etc/config/log_levelINFO# 修改 ConfigMap$ kubectl edit configmap log-configapiVersion: v1data: log_level: DEBUGkind: ConfigMap# 30s 后再次查询$ kubectl exec nginx-df47dc9cd-9mjnx -it -- cat /etc/config/log_levelDEBUG# 触发热更新, 会重新启动, 配置生效$ kubectl patch deployment nginx --patch &#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;version.config&quot;: &quot;20201014&quot;&#125;&#125;&#125;&#125;&#125;&#x27; 2. SecretSecret 解决密码、token、密钥等敏感数据的配置问题，可以以Volume 或环境变量方式导入 Pod 中使用 Secret 类型有三种： Service Account: 用来访问 k8s api。由 k8s 自动创建，自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录下 Opaque: base64 编码格式的 Secret，用来存储密码、密钥等 kubernetes.io/dockerconfigjson: 用来存储私有 docker registry 的认证信息 2.1 Service Account (SA)12$ kubectl exec nginx-596675fccc-v8gfw -it -- ls /run/secrets/kubernetes.io/serviceaccountca.crt namespace token 2.2 Opaque2.2.1 创建12345$ echo -n &quot;admin&quot; | base64YWRtaW4=$ echo -n &quot;pass123&quot; | base64cGFzczEyMw== 123456789# secret.yamlapiVersion: v1kind: Secretmetadata: name: my-secrettype: Opaquedata: username: YWRtaW4= password: cGFzczEyMw== 2.2.2 使用 Secret 将 Secret 挂载到 Volume 1234567891011121314151617181920# secret-volume.yamlapiVersion: v1kind: Podmetadata: labels: name: secret-volume name: secret-volumespec: volumes: - name: secrets secret: secretName: my-secret containers: - name: db image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent volumeMounts: - name: secrets mountPath: &quot;/etc/secrets&quot; readOnly: true 123456789101112$ kubectl create -f secret-volume.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEsecret-volume 1/1 Running 0 8s$ kubectl exec secret-volume -it -- ls /etc/secretspassword username# 容器内自动解密$ kubectl exec secret-volume -it -- cat /etc/secrets/passwordpass123 将 Secret 导入环境变量 1234567891011121314151617181920212223242526272829303132# secret-env.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: secret-envspec: replicas: 2 selector: matchLabels: app: secret-pod template: metadata: labels: app: secret-pod spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 env: - name: TEST_USER valueFrom: secretKeyRef: name: my-secret key: username - name: TEST_PASSWORD valueFrom: secretKeyRef: name: my-secret key: password 12345678910$ kubectl apply -f secret-env.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEsecret-env-6f5785997f-2w7dj 1/1 Running 0 8ssecret-env-6f5785997f-khzjz 1/1 Running 0 8s$ kubectl exec secret-env-6f5785997f-2w7dj -it -- env | grep TESTTEST_USER=adminTEST_PASSWORD=pass123 2.3 kubernetes.io/dockerconfigjson创建 docker register 认证 1$ kubectl create secret docker-register myregisterkey --docker-server=hub.elihe.io --docker-username=admin --docker-password=Harbor12345 --docker-email=eli.he@live.cn 创建 Pod 时，用 imagePullSecrets 来引用刚创建的 myregisterkey 12345678910apiVersion: v1kind: Podmetadata: name: nginxspec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullSecrets: - name: myregisterkey 3. Volumevolume 解决问题： 容器磁盘上的新增文件，容器重启后将消失，无法持久化 Pod中运行的多个容器需求共享文件 当 Pod 中的容器重启时，volume 数据还在。但是当 Pod 不存在时，volume 也将不复存在。 Volume 支持的类型： awsElasticBlockStore, azureDisk, azureFile, cephfs, csi, downwardAPI, emptyDir fc, flocker, gcePersistentDisk, gitRepo, glusterfs, hostPath, iscsi, local, nfs persistentVolumeClaim, projected, portworxVolume, quobyte, rbd, scaleIO, secret storageos vsphereVolume 3.1 emptyDir创建 Pod 时，会自动创建 emptyDir 卷，它最初是空的，Pod 中的容器可以读取和写入 emptyDir 卷中的文件。当删除 Pod 时，emptyDir 中的数据将被永久删。容器崩溃不会导致 Pod 被删除，因此 emptyDir 卷中的数据在容器崩溃时是安全的。 emptyDir 用法： 暂存空间，例如用于基于磁盘的合并排序 用于长时间计算崩溃恢复时的检查点 Web服务器容器提供数据时，保存内容管理容器提取的文件 123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: vol-emptydirspec: containers: - name: c1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /cache name: cache-volume - name: c2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; 1234$ kubectl exec vol-emptydir -c c1 -it -- touch /cache/now.txt$ kubectl exec vol-emptydir -c c2 -it -- ls -l /cache/now.txt-rw-r--r-- 1 root root 0 Oct 14 01:34 /cache/now.txt 3.2 hostPath将主机节点的文件系统中的文件和目录挂载到集群中 hostPath 用途： 运行需要访问 Docker 内部的容器，使用 /var/lib/docker 的 hostPath 在容器中运行 cAdvisor(猫头鹰，Google提供的一个服务)，使用 /dev/cgroups 的 hostPath hostPath 卷指定 type检查： 值 行为 空字符串(默认)，向后兼容，在挂载hostPath 卷之前不会执行任何检查 DirectoryOrCreate 目录不存在自动创建，权限0755，与kubectl具有相同组和所有权 Directory 目录必须存在 FileOrCreate 文件不存在自动创建，权限0644，与kubectl具有相同组和所有权 File 文件必须存在 Socket Unix 套接字必须存在 CharDevice 字符设备必须存在 BlockDevice 块设备必须存在 1234567891011121314151617181920212223apiVersion: v1kind: Podmetadata: name: vol-hostpathspec: containers: - name: c1 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /data name: data-volume - name: c2 image: busybox command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 600&quot;] volumeMounts: - mountPath: /data name: data-volume volumes: - name: data-volume hostPath: path: /data type: Directory 1234567891011$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESvol-hostpath 0/2 ContainerCreating 0 44s &lt;none&gt; k8s-node02 &lt;none&gt; &lt;none&gt;# k8s-node02 上创建目录 /data$ mkdir /data$ date &gt; /data/abc.txt# 查看文件内容$ kubectl exec vol-hostpath -c c1 -it -- cat /data/abc.txtSat Sep 12 11:10:53 CST 2020 4. PV &amp; PVCPV 作用：屏蔽后端不同存储类型之间，挂载方式不一致等特性差异 PVC: 寻找一个合适的PV进行绑定 4.1 概念 PV: Persistent Volume。由管理员设置的存储，它是集群的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期之外。 静态 PV：集群管理员创建一些 PV。它们带有可供集群用户使用的实际存储的细节。它们存储在 k8s api 中，可用于消费 动态 PV：当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim时，集群可能会尝试动态地为 PVC创建卷。此配置基于StorageClasses: PVC必须请求（存储类），并且管理员必须创建并配置该类才能够尽兴动态创建。声明该类为 “” 可有效地禁用其动态配置 PVC: PersistentVolumeClaim。是用户存储的请求。它与Pod 类似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源(CPU &amp; Memory)。PVC 可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载) 4.1.1 绑定mater 中的控制环路监视新的 PVC，寻找匹配的PV（如果可能），并将它们绑定在一起。如果为新的PVC动态调配PV，则该环路将始终将该PV绑定到PVC。否则，用户总会得到他们所请求的存储，但容器可能会超出要求的数量。一旦PV和PVC绑定后，PVC绑定是排他性的，不管它们是如何绑定的，PVC和PV绑定是一一映射的 4.1.2 持久化卷声明的保护PVC 保护的目的是确保 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话，可能导致数据丢失。 当 Pod 状态为 Pending 或 Running 时，PVC 处于活动状态 当启用 PVC 保护 alpha 功能时，如果用户删除一个 pod 正在使用的 PVC，该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 Pod 使用 4.1.3 持久化卷类型 GCEPersistentDisk, AWSElasticBlockStore, AsureFile, AzureDisk, FC(Fibre Channel) FlexVolume, Flocker, NFS, iSCSI, RBD(Ceph Block Device), CephFS Cinder (OpenStack block storage), Glusterfs, VsphereVolume, QuoByte Volumes HostPath, VMware Photon, Portworx Volumes, ScaleIO Volumes, StorageOS 4.1.4 PV 访问模式PV 可以以资源提供者支持的任何方式挂载在主机上。 ReadWriteOnce: 单节点读写模式，RWO ReadOnlyMany: 多节点只读模式，ROX ReadWriteMany: 多节点读写模式， RWX 4.1.5 回收策略 Retain: 保留，需手动回收 Recycle: 基本擦除 （rm -rf /thevolume/*），新版k8s已不支持 Delete: 关联的存储资产将被删除 只有 NFS和HostPath 支持 Recycle 策略 AWS EBS、GCE PD、Azure Disk 和 Cinder 卷 支持 Delete 策略 4.1.6 状态 Available: 空闲资源，还未被绑定 Bound: 已绑定 Released: 解除绑定，但未被集群重新声明 Failed: 自动回收失败 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv-1spec: capacity: storage: 2Gi volumeMode: Filesystem accessModes: - ReadWriteOnce # 同时只允许一个用户读写操作 persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsserevr=4.1 nfs: path: /tmp server: 192.168.31.200 4.2 持久化演示 NFS4.2.1 安装 NFS 服务器123456789101112131415yum install -y nfs-common nfs-utils rpcbindmkdir /nfschmod 666 /nfschown nfsnobody /nfsecho &#x27;/nfs *(rw, no_root_squash,no_all_squash,sync)&#x27; &gt; /etc/exportssystemctl start rpcbindsystemctl start nfsexportfs -rv# 客户端安装yum install -y nfs-utils rpcbindshowmount -e 192.168.31.200mkdir /testmount -t nfs 192.168.31.200:/nfs /test 4.2.2 部署 PV1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: nfspv1spec: capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs server: 192.168.31.200---apiVersion: v1kind: PersistentVolumemetadata: name: nfspv2spec: capacity: storage: 2Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs2 server: 192.168.31.200---apiVersion: v1kind: PersistentVolumemetadata: name: nfspv3spec: capacity: storage: 3Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: nfs nfs: path: /nfs3 server: 192.168.31.200 4.2.3 创建服务并使用 PVCStatefulSet 控制器，必须先要有一个无头服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# app.yamlapiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx ---apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: selector: matchLabels: app: nginx serviceName: nginx # service 必须为无头服务 replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: # 选择条件 accessModes: [ &quot;ReadWriteOnce&quot; ] storageClassName: nfs resources: requests: storage: 1Gi 1234567891011121314151617181920212223242526272829$ kubectl apply -f pv.yaml$ kubectl apply -f app.yaml$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Bound default/www-web-0 nfs 5m23snfspv2 2Gi RWO Retain Bound default/www-web-1 nfs 5m23snfspv3 3Gi RWO Retain Bound default/www-web-2 nfs 5m23s$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound nfspv1 1Gi RWO nfs 2m53swww-web-1 Bound nfspv2 2Gi RWO nfs 2m50swww-web-2 Bound nfspv3 3Gi RWO nfs 2m45s$ kubectl get sts # statefulsetNAME READY AGEweb 3/3 3m11s$ kubectl get podNAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 3m29sweb-1 1/1 Running 0 3m26sweb-2 1/1 Running 0 3m21s$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 4d17hnginx ClusterIP None &lt;none&gt; 80/TCP 49m StatefulSet 相关总结： Pod Name(网络标识)：$(statefulset name)-(order)。例如：web-0 DNS 域名：$(podname).(headless server name) Pod 重建，IP改变，但域名不变。例如：web-0.nginx 域名FQDN：$(service name).$(namespace).svc.cluster.local, 其中”cluster.local”为集群的域名。例如：nginx.default.svc.cluster.local 123456789$ kubectl get pod -n kube-system -o wide | grep corednscoredns-66bff467f8-8lb4m 1/1 Running 4 21d 10.244.0.10 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 4 21d 10.244.0.11 k8s-master &lt;none&gt; &lt;none&gt;$ dig -t A nginx.default.svc.cluster.local. @10.244.0.10;; ANSWER SECTION:nginx.default.svc.cluster.local. 30 IN A 10.244.2.53nginx.default.svc.cluster.local. 30 IN A 10.244.1.36nginx.default.svc.cluster.local. 30 IN A 10.244.2.54 FQDN：(Fully Qualified Domain Name)全限定域名：同时带有主机名和域名的名称。（通过符号“.”）例如：主机名是bigserver,域名是mycompany.com,那么FQDN就是bigserver.mycompany.com StatefulSet 启停顺序： 有序部署：如果有多个Pod副本，它们会按顺序创建 0～N-1，并且只有当Pod处于Running和Ready状态，才会创建下一个Pod 有序删除：Pod被删除时，删除顺序从N-1～ 0 有序扩展：扩展时，也必须按顺序进行 StatefulSet 使用场景： 稳定的持久存储 稳定的网络标识，即Pod重新调度后，PodName 和 Hostname 不变 有序部署，有序扩展，具有 init containers 来实现 有序收缩 pv资源释放： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647$ kubectl delete svc nginx$ kubectl delete sts --all$ kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound nfspv1 1Gi RWO nfs 39mwww-web-1 Bound nfspv2 2Gi RWO nfs 39mwww-web-2 Bound nfspv3 3Gi RWO nfs 39m$ kubectl delete pvc --allpersistentvolumeclaim &quot;www-web-0&quot; deletedpersistentvolumeclaim &quot;www-web-1&quot; deletedpersistentvolumeclaim &quot;www-web-2&quot; deleted$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Released default/www-web-0 nfs 41mnfspv2 2Gi RWO Retain Released default/www-web-1 nfs 41mnfspv3 3Gi RWO Retain Released default/www-web-2 nfs 41m$ kubectl edit pv nfspv1...spec: accessModes: - ReadWriteOnce capacity: storage: 1Gi claimRef: # 删除 apiVersion: v1 kind: PersistentVolumeClaim name: www-web-0 namespace: default resourceVersion: &quot;104634&quot; uid: 57597e18-963d-4ce1-b1d9-880ac0ef3da0 nfs: path: /nfs server: 192.168.31.200 persistentVolumeReclaimPolicy: Retain storageClassName: nfs ...$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnfspv1 1Gi RWO Retain Available nfs 46mnfspv2 2Gi RWO Retain Released default/www-web-1 nfs 46mnfspv3 3Gi RWO Retain Released default/www-web-2 nfs 46m","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes Service","slug":"Kubernetes Service","date":"2018-07-05T08:07:23.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/05/Kubernetes Service/","link":"","permalink":"https://elihe2011.github.io/2018/07/05/Kubernetes%20Service/","excerpt":"1. Service 的概念SVC：服务发现 Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 – 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector Service 能够提供负载均衡能力，但只提供了 4 层，而没有 7 层。当需要更多的匹配规则来转发请求时，不支持。","text":"1. Service 的概念SVC：服务发现 Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 – 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector Service 能够提供负载均衡能力，但只提供了 4 层，而没有 7 层。当需要更多的匹配规则来转发请求时，不支持。 2. Service 代理模式分类2.1 VIP 和 Service 代理kube-proxy 进程：负责为 Service 实现一种 VIP（虚拟IP）的形式，代理模式有如下三种： userspace：k8s v1.0 iptables: v1.1 加入，v1.2 默认 ipvs: v1.8 加入，v1.14 默认 Ingress API: v1.1 新增，支持 7 层服务 为什么不使用 round-robin DNS? dns 存在缓存，当有Pod节点故障时，无法自动处理 2.1.1 userspace 2.1.2 iptables 2.1.3 ipvs kube-proxy 监控 Service 和 Endpoints，调用 netlink 接口以相应地创建 ipvs 规则，并定期与 Service 和 Endpoints 对象同步 ipvs 规则，以确保 ipvs 状态与期望一致。访问服务时，流量将被重定向到其中一个后端 Pod 与 iptables 类似，ipvs 于 netfilter 的 hook 功能，但使用hash表作为底层数据结构并在内核空间中工作。这意味着 ipvs 可以快速地重定向流量，并且在同步代理规则时具有更好的性能。 ipvs 为负载均衡算法提供了更多选项： rr: 轮训调度 lc: 最小连接数 dh: 目标hash sh: 源hash sed: 最短期望延迟 nq: 不排队调度 3. Service 的类型 ClusterIp: 默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟IP NodePort: 在ClusterIp 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 &lt;NodeIp&gt;:&lt;NodePort&gt; 来访问服务 LoadBalancer: 在 NodePort 基础上，借助 Cloud Provider 创建一个外部负载均衡器，并将请求转发到 &lt;NodeIp&gt;:&lt;NodePort&gt; ExternalName: 把集群外部的服务引入集群内部，在集群内部直接使用。 3.1 ClusterIpClusterIP 主要在每个 node 节点使用 iptables，将发向 ClusterIp 的流量转发至 kube-proxy，然后 kube-proxy 自己内部实现负载均衡算法，查询到该 Service 下对应 Pod 的地址和端口，进而将数据转发给对应的 Pod 工作原理： apiserver: 用户通过 kubectl 向 apiserver 下发创建 service 的命令，apiserver 接收到请求后，将数据存储到 etcd 中 kube-proxy: 该进程负载监控 Service 和 Pod 的变化 (etcd)，并将变化信息更新到本地 iptables中 iptables: 使用NAT 等技术，将 VIP 的流量转发至 Endpoint 中 12345678910111213141516171819202122232425# myapp-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deployspec: replicas: 3 selector: matchLabels: app: myapp release: stable template: metadata: labels: app: myapp release: stable env: test spec: containers: - name: myapp image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 1234567891011121314# myapp-service-clusterip.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: ClusterIP selector: # 绑定Pod app: myapp release: stable ports: - name: http port: 80 targetPort: 80 操作： 123456789101112131415161718192021222324252627$ kubectl apply -f myapp-deploy.yaml$ kubectl apply -f myapp-service-clusterip.yaml$ kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyapp-deploy-7779c7f4bb-dv7zh 1/1 Running 0 24s 10.244.2.31 k8s-node02 &lt;none&gt; &lt;none&gt;myapp-deploy-7779c7f4bb-jc8dp 1/1 Running 0 24s 10.244.2.32 k8s-node02 &lt;none&gt; &lt;none&gt;myapp-deploy-7779c7f4bb-lx4kl 1/1 Running 0 24s 10.244.1.25 k8s-node01 &lt;none&gt; &lt;none&gt;$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20dmyapp ClusterIP 10.96.155.51 &lt;none&gt; 80/TCP 42s# 通过 ClusterIp 访问$ curl 10.96.155.51Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;# ipvs转发$ ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 10.96.155.51:80 rr -&gt; 10.244.1.25:80 Masq 1 0 0 -&gt; 10.244.2.31:80 Masq 1 0 0 -&gt; 10.244.2.32:80 Masq 1 0 0 Headless Service: 当不需要负载均衡和独立Service Ip时，可以指定 spec.clusterIP 为 None来创建 Headless Service。这类 Service 并不会分配 Cluster IP，kube-proxy 也不会处理它们，而且平台也不会其对进行负载均衡和路由 123456789101112131415# myapp-service-clusterip-headless.yamlapiVersion: v1kind: Servicemetadata: name: myapp-headlessspec: type: ClusterIP selector: app: myapp release: stable clusterIP: None ports: - name: http port: 80 targetPort: 80 操作： 12345678910111213141516171819202122$ kubectl apply -f myapp-service-clusterip-headless.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp-headless ClusterIP None &lt;none&gt; 80/TCP 31s# 获取 DNS 地址信息$ kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66bff467f8-8lb4m 1/1 Running 2 20d 10.244.0.6 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 2 20d 10.244.0.7 k8s-master &lt;none&gt; &lt;none&gt;# 安装 dig 命令$ yum install -y bind-utils# 解析域名 i 记录$ dig -t A myapp-headless.default.svc.cluster.local. @10.244.0.6;; ANSWER SECTION:myapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.32myapp-headless.default.svc.cluster.local. 30 IN A 10.244.2.31myapp-headless.default.svc.cluster.local. 30 IN A 10.244.1.25 虽然没有svc，但依旧可以通过访问域名，路由到不同Pod上 3.2 NodePort原理：在当前Node的物理机上暴露一个端口，外部可以通过IP:PORT 方式访问集群服务 1234567891011121314# myapp-service-nodeport.yamlapiVersion: v1kind: Servicemetadata: name: myappspec: type: NodePort selector: app: myapp release: stable ports: - name: http port: 80 targetPort: 80 操作： 1234567891011121314$ kubectl apply -f myapp-service-nodeport.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmyapp NodePort 10.106.31.155 &lt;none&gt; 80:31205/TCP 6s$ curl 192.168.31.40:31205# 访问流程$ ipvsadm -LnTCP 192.168.31.40:31205 rr -&gt; 10.244.1.26:80 Masq 1 0 0 -&gt; 10.244.2.33:80 Masq 1 0 0 -&gt; 10.244.2.34:80 Masq 1 0 3.3 ExternalName该类型的 Service 通过返回 CNAME 和 它的值，可将服务映射到 externalName 字段的内容。ExternalName没有 selector，也未指定任何端口和 Endpoint。相反，它为集群提供访问外部服务方式 12345678# myapp-service-external-name.yamlapiVersion: v1kind: Servicemetadata: name: my-servicespec: type: ExternalName externalName: hub.elihe.io 123456789101112131415$ kubectl apply -f myapp-service-external-name.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmy-service ExternalName &lt;none&gt; hub.elihe.io &lt;none&gt; 21s$ kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-66bff467f8-8lb4m 1/1 Running 3 20d 10.244.0.8 k8s-master &lt;none&gt; &lt;none&gt;coredns-66bff467f8-nbzmn 1/1 Running 3 20d 10.244.0.9 k8s-master &lt;none&gt; &lt;none&gt;$ dig -t A my-service.default.svc.cluster.local. @10.244.0.8;; ANSWER SECTION:my-service.default.svc.cluster.local. 30 IN CNAME hub.elihe.io. 4. Service Ingressingress: 进入、入境 4.1 Ingress-Nginx 部署 部署： 12345678910111213141516171819202122232425262728293031323334353637$ wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml$ wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml# 手动下载包$ grep image mandatory.yaml image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0$ docker pull quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0# 导出$ docker save -o nginx-ingress.tar quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0$ gzip nginx-ingress.tar# 上次到每个节点，然后导入镜像$ gunzip nginx-ingress.tar.gz $ docker load -i nginx-ingress.tar # 部署$ kubectl apply -f mandatory.yaml$ kubectl apply -f service-nodeport.yaml$ kubectl get deploy -n ingress-nginxNAME READY UP-TO-DATE AVAILABLE AGEnginx-ingress-controller 1/1 1 1 5m26s$ kubectl get rs -n ingress-nginxNAME DESIRED CURRENT READY AGEnginx-ingress-controller-5bb8fb4bb6 1 1 1 6m10s$ kubectl get pod -n ingress-nginxNAME READY STATUS RESTARTS AGEnginx-ingress-controller-5bb8fb4bb6-6lnb4 1/1 Running 0 6m13s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 5m36s 4.2 Ingress HTTP 代理访问123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ingress-http-1.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-1spec: replicas: 2 selector: matchLabels: app: nginx-1 template: metadata: labels: app: nginx-1 name: nginx-1 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-1spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-1---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-1spec: rules: - host: www1.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-1 servicePort: 80 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# ingress-http-2.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-2spec: replicas: 2 selector: matchLabels: app: nginx-2 template: metadata: labels: app: nginx-2 name: nginx-2 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v2 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-2spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-2---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-2spec: rules: - host: www2.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-2 servicePort: 80 操作： 123456789101112131415161718192021222324252627282930313233343536$ kubectl apply -f ingress-http-1.yaml$ kubectl apply -f ingress-http-2.yaml $ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx-svc-1 ClusterIP 10.109.205.227 &lt;none&gt; 80/TCP 32snginx-svc-2 ClusterIP 10.108.96.68 &lt;none&gt; 80/TCP 29s$ curl 10.109.205.227Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ curl 10.108.96.68Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-1 &lt;none&gt; www1.elihe.io 10.107.51.68 80 5m46snginx-2 &lt;none&gt; www2.elihe.io 10.107.51.68 80 116s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 37m$ kubectl get pod -n ingress-nginxNAME READY STATUS RESTARTS AGEnginx-ingress-controller-5bb8fb4bb6-6lnb4 1/1 Running 0 42m# 进入 nginx-ingress-controller 容器, 查询 nginx 配置$ kubectl exec nginx-ingress-controller-5bb8fb4bb6-6lnb4 -n ingress-nginx -it -- /bin/sh/etc/nginx $ cat nginx.conf$ curl http://www1.elihe.io:31319Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;$ curl http://www2.elihe.io:31319Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt; 4.3 Ingress HTTPS 代理访问创建证书，以及cert存储方式 123$ openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=nginxsvc/O=nginxsvc&quot;$ kubectl create secret tls tls-secret --key tls.key --cert tls.crt 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# ingress-https.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-app-3spec: replicas: 2 selector: matchLabels: app: nginx-3 template: metadata: labels: app: nginx-3 name: nginx-3 spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v3 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1kind: Servicemetadata: name: nginx-svc-3spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx-3---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-httpsspec: tls: - hosts: - www3.elihe.io secretName: tls-secret rules: - host: www3.elihe.io http: paths: - path: / backend: serviceName: nginx-svc-3 servicePort: 80 1234567891011$ kubectl apply -f ingress-https.yaml$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-https &lt;none&gt; www3.elihe.io 10.107.51.68 80, 443 51s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 56mhttps://www.elihe.io:32750/ 4.4 Nginx 进行 BasicAuth1234# 安装apacheyum install -y httpdhtpasswd -c auth elikubectl create secret generic basic-auth --from-file=auth 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# ingress-http-basicauth.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-basicauthspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx name: nginx spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: nginx-svcspec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: nginx---apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-basicauth annotations: nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: basic-auth nginx.ingress.kubernetes.io/auth-realm: &#x27;Authentication Required - eli&#x27;spec: rules: - host: auth.elihe.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 1234567891011$ kubectl apply -f ingress-http-basicauth.yaml $ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-basicauth &lt;none&gt; auth.elihe.io 80 15s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 71mhttp://auth.elihe.io:31319 # 弹出验证窗口 4.5 Nginx 重写 名称 类型 描述 nginx.ingress.kubernetes.io/rewrite-target String 重定向的目标URI nginx.ingress.kubernetes.io/ssl-redirect Boolean 仅支持https nginx.ingress.kubernetes.io/force-ssl-redirect Boolean 强制重定向至https nginx.ingress.kubernetes.io/app-root String 上下文 “/” nginx.ingress.kubernetes.io/use-regex Boolean 使用正则表达式 12345678910111213141516# ingress-http-rewrite.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-rewrite annotations: nginx.ingress.kubernetes.io/rewrite-target: http://baidu.comspec: rules: - host: www1.elihe.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 1234567891011$ kubectl apply -f ingress-http-rewrite.yaml$ kubectl get ingressNAME CLASS HOSTS ADDRESS PORTS AGEnginx-rewrite &lt;none&gt; www1.elihe.io 10.107.51.68 80 14s$ kubectl get svc -n ingress-nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEingress-nginx NodePort 10.107.51.68 &lt;none&gt; 80:31319/TCP,443:32750/TCP 75mhttp://www1.elihe.io:31319 # 重定向到百度","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 资源控制器","slug":"Kubernetes 资源控制器","date":"2018-07-04T06:30:31.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/04/Kubernetes 资源控制器/","link":"","permalink":"https://elihe2011.github.io/2018/07/04/Kubernetes%20%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/","excerpt":"1. Pod分类 自主式Pod：Pod退出，不会被再次创建，因为无管理者（资源控制器）。 控制器管理的Pod： 在控制器的生命周期里，始终要维持 Pod 的副本数目 2. 什么是控制器K8S 中内建了很多 controller (控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为","text":"1. Pod分类 自主式Pod：Pod退出，不会被再次创建，因为无管理者（资源控制器）。 控制器管理的Pod： 在控制器的生命周期里，始终要维持 Pod 的副本数目 2. 什么是控制器K8S 中内建了很多 controller (控制器)，这些相当于一个状态机，用来控制Pod的具体状态和行为 3. 控制器类型 ReplicationController 和 ReplicaSet Deployment DaemonSet StatefulSet Job/CronJob Horizontal Pod Autoscalling 3.1 ReplicationController 和 ReplicaSet作用：维持Pod的副本数 RC: 用来确保容器应用的副本数量始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收 RS: RC的的替代者，支持集合式的selector ReplicaSet 123456789101112131415161718192021222324# nginx-rs.yaml#apiVersion: extension/v1beta1 # 统一迁移到apps/v1apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: # Pod metadata: labels: tier: frontend spec: containers: - name: my-nginx image: hub.elihe.io/test/nginx:v1 env: - name: GET_HOST_FROM value: dns ports: - containerPort: 80 123456789101112131415161718192021$ kubectl create -f nginx-rs.yaml$ kubectl get rsNAME DESIRED CURRENT READY AGEfrontend 3 3 2 21s$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSfrontend-cdxws 1/1 Running 0 51s tier=frontendfrontend-fqx6q 1/1 Running 0 51s tier=frontendfrontend-s255j 1/1 Running 0 51s tier=frontend$ kubectl label pod frontend-s255j tier=frontend1 --overwrite=truepod/frontend-s255j labeled$ kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSfrontend-cdxws 1/1 Running 0 3m25s tier=frontendfrontend-fqx6q 1/1 Running 0 3m25s tier=frontendfrontend-pb5c4 1/1 Running 0 5s tier=frontendfrontend-s255j 1/1 Running 0 3m25s tier=frontend1 # 不再受rs管理 3.2 DeploymentDeployment 为 Pod 和 ReplicaSet 提供一个声明式 (declarative) 方法，用来替代以前的 RC 来方便的管理应用，典型的应用场景包括： 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 (创建一个新的RS，新RS中Pod增1，旧RS的Pod减1) 扩容和缩容 暂停和继续 Deployment 补充：命令式编程和声明式编程 命令式编程：它侧重于如何实现程序，需要把程序的实现结果按照逻辑一步一步写下来 声明式编程：它侧重于定义想要什么，然后告诉计算机 / 引擎，让它帮你去实现。（SQL） 声明式（Deployment）：apply优先 命令式（RS）：create优先 RS 与 Deployment的关联： 部署一个简单的 Nginx 应用 123456789101112131415161718192021# nginx-deploy.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployspec: replicas: 3 selector: matchLabels: tier: frontend template: # Pod metadata: labels: app: nginx tier: frontend spec: containers: - name: nginx image: hub.elihe.io/test/nginx:v1 ports: - containerPort: 80 123456789101112131415$ kubectl apply -f nginx-deploy.yaml --record # record 更新时，记录每一步的状态$ kubectl get deployNAME READY UP-TO-DATE AVAILABLE AGEnginx-deploy 3/3 3 3 22s$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deploy-7775dd49df 3 3 3 72s$ kubectl get podNAME READY STATUS RESTARTS AGEnginx-deploy-7775dd49df-8jlh9 1/1 Running 0 76snginx-deploy-7775dd49df-gjkbj 1/1 Running 0 77snginx-deploy-7775dd49df-ksj9t 1/1 Running 0 76s 1234567891011121314151617181920# 扩容$ kubectl scale deployment nginx-deploy --replicas=5# 更新镜像, 会自动创建rs$ kubectl set image deployment/nginx-deploy nginx=hub.elihe.io/test/nginx:v2# 回滚$ kubectl rollout undo deployment/nginx-deploy# 查询回滚状态$ kubectl rollout status deployment/nginx-deploy# 查看历史版本 (创建时，加--record，会显示描述)$ kubectl rollout history deployment/nginx-deploy# 回滚到某个历史版本$ kubectl rollout undo deployment/nginx-deploy --to-revision=2# 暂停更新$ kubectl rollout pause deployment/nginx-deploy 版本更新策略：默认25%替换 清理历史版本：可以通过设置 .spec.revisionHistoryLimit 来指定 Deployment 最多保留多少个 revision 历史记录。默认保留所有的revision，如果该项设置为0，Deployment将不能被回退 3.3 DaemonSetDaemonSet 确保全部（或一些）Node上运行一个Pod副本。当有Node加入集群时，也会为它们新增一个Pod。当Node从集群移除时，这些Pod也会被回收。删除DaemonSet 将会删除它创建的所有 Pod。 使用DaemonSet 的一些典型场景： 运行集群存储 daemon，例如在每个Node上运行 glusterd, ceph 在每个Node上运行日志收集 daemon，例如 fluentd, logstash 在每个Node上运行监控 daemon, 例如 Promethesus Node Exporter, collectd, Datalog代理，New Replic代理，Ganglia, gmond 123456789101112131415161718apiVersion: apps/v1kind: DaemonSetmetadata: name: daemonset labels: app: daemonsetspec: selector: matchLabels: tier: daemonset-example template: metadata: labels: tier: daemonset-example spec: containers: - name: daemonset-example image: hub.elihe.io/test/nginx:v1 12345678910$ kubectl create -f nginx-daemonset.yaml$ kubectl get dsNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEdaemonset 2 2 2 2 2 &lt;none&gt; 23s$ kubectl get podNAME READY STATUS RESTARTS AGEdaemonset-msnrn 1/1 Running 0 86sdaemonset-nw5t9 1/1 Running 0 86s 3.4 JobJob 仅执行一次的任务，它确保批处理任务的一个或多个 Pod 成功结束。 特殊说明： spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个Pod时，默认Pod成功运行后 Job 结束 .spec.completions 标志 Job 结束需要运行的Pod个数，默认为1 .spec.parallelism 标志并行运行的 Pod 个数，默认为1 .spec.activeDeadlineSeconds 标志失败 Pod的重试最大时间，超过这个时间将不会再重试 1234567891011121314apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [&quot;perl&quot;, &quot;-Mbignum-bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] restartPolicy: Never 123456789101112$ kubectl create -f job.yaml job.batch/pi created$ kubectl get jobNAME COMPLETIONS DURATION AGEpi 0/1 10s 10s$ kubectl get podNAME READY STATUS RESTARTS AGEpi-779v9 0/1 ContainerCreating 0 14s$ kubectl describe pod pi-779v9 3.5 CronJobCornJob 管理基于时间的 Job，即： 在给定时间点只执行一次 周期性地在给定时间点运行 特殊说明： .spec.schedule: 调度，必选字段，格式同Cron spec.jobTemplate: 格式同 Pod .spec.startingDeadlineSeconds: 启动Job的期限，可选字段。如果因为任何原因而错过了被调度的时间，那么错过了执行时间的Job被认为是失败的 .spec.concurrencyPolicy: 并发策略，可选字段 Allow: 默认，允许并发运行 Job Forbid: 禁止并发Job，只能顺序执行 Replace: 用新的Job替换当前正在运行的 Job .spec.suspend: 挂起，可选字段，如果设置为true，后续所有执行都会被挂起。默认为fasle .spec.successfulJobsHistoryLimit 和 .spec.failedJobsHistoryLimit: 历史限制，可选字段。它们指定了可以保留多少完成和失败的Job。默认值为3和1。如果设置为0，相关类型的Job完成后，将不会保留 123456789101112131415161718apiVersion: batch/v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure 1234567891011121314$ kubectl create -f cronjob.yaml cronjob.batch/hello created$ kubectl get cjNAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGEhello */1 * * * * False 0 52s 2m24s$ kubectl get jobNAME COMPLETIONS DURATION AGEhello-1602576000 1/1 17s 49s$ kubectl get podNAME READY STATUS RESTARTS AGEhello-1602576000-r6mgh 0/1 Completed 0 52 3.6 StatefulSet （有状态服务）StatefulSet 作为 Controller 为 Pod 提供的唯一标识，它可以确保部署和 scale 的顺序 StatefulSet 解决了有状态服务的问题，其应用场景包括： 稳定的持久化存储，即 Pod 重新调度后，还能够访问到相同的持久化数据，基于PVC来实现 稳定的网络标识，即 Pod 重新调度后其 PodName 和 HostName 不变，基于 Headless Service （即没有Cluster IP的Service）来实现 有序部署、有序扩展，即Pod是有序的，在部署和扩展时，要按照定义的顺序依次进行 (即从 0 到N - 1, 在下一个Pod 运行前，所有 Pod 必须是 Running 和 Ready 状态)，基于 Init Containers 来实现 有序收缩、有序删除（即从 N-1 到 0） 3.7 Horizontal Pod AutoScalling应用的资源使用率通常有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，HPA 提供了 Pod 的水平自动缩放功能 通过控制RS，Deployment 来实现自动缩放","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 资源清单","slug":"Kubernetes 资源清单","date":"2018-07-03T12:37:13.000Z","updated":"2021-06-22T10:50:49.719Z","comments":true,"path":"2018/07/03/Kubernetes 资源清单/","link":"","permalink":"https://elihe2011.github.io/2018/07/03/Kubernetes%20%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95/","excerpt":"1. K8S 资源k8s中，所有的内容都被抽象为资源，资源实例化后，称为对象 集群资源分类： 名称空间级别: 只在本名称空间下可见 集群级别: role, 不管在什么名称空间小，均可见 元数据级别: HPA(可以CPU利用率平滑扩展)","text":"1. K8S 资源k8s中，所有的内容都被抽象为资源，资源实例化后，称为对象 集群资源分类： 名称空间级别: 只在本名称空间下可见 集群级别: role, 不管在什么名称空间小，均可见 元数据级别: HPA(可以CPU利用率平滑扩展) 1.1 名称空间级别资源仅在此名称空间下有效：kubeadm k8s kube-system, kubectl get pod -n default 1.1.1 工作负载型资源 (workload) Pod: 最小资源，共享网络栈、存储卷等 ReplicaSet：调度器，管理Pod的创建，通过标签的选择去控制Pod的副本数 Deployment: 控制器，通过控制RS的创建，去创建Pod StatefulSet：有状态服务管理器 DaemonSet：可在每个节点都运行一个Pod组件 Job: 批量工作 CronJob: 定时或轮训工作 ReplicationController：v1.11后被废弃 1.1.2 服务发现及负载均衡资源 (ServiceDiscovery, LoadBalance) Service: svc Ingress: 1.1.3 配置与存储型资源 Volume: 存储卷 CSI: 容器存储接口，可扩展第三方存储设备 1.1.4 特殊类型的存储卷 ConfigMap: 配置中心 Secret: 敏感数据保存 DownwardAPI: 外部环境中的信息输出给容器 1.2 集群级别资源不指定名称空间，所有节点均能访问：role Namespace Node Role ClusterRole RoleBinding ClusterRoleBinding 1.3 元数据型资源通过指标进行操作：HPA HPA PodTemplate LimitRange 2. 资源清单2.1 必须存储的属性 参数名 字段类型 说明 apiVersion String k8s API版本，可用kubectl api-versions查询 kind String yaml文件定义的资源类型和角色，比如：Pod metadata Object 元数据对象 metadata.name String metadata.namespace String 默认为default spec Object 详细定义对象 spec.containers[] List spec.containers[].name String spec.containers[].image String spec.containers[].imagePullPolicy String 1. Always: 默认，每次都尝试重新拉取镜像; 2. Never: 仅使用本地镜像; 3. IfNotPresent: 优先本地镜像 spec.containers[].command[] List 容器启动命令。不指定则使用镜像打包时使用的启动命令 spec.containers[].args[] List 容器启动命令参数 spec.containers[].workingDir String spec.containers[].volumeMounts[] List spec.containers[].volumeMounts[].name String spec.containers[].volumeMounts[].mountPath String spec.containers[].volumeMounts[].readOnly String 默认false，可读写 spec.containers[].ports[] List spec.containers[].ports[].name String spec.containers[].ports[].containerPort String spec.containers[].ports[].hostPort String 主机上需要监听的端口号，默认与containerPort相同 spec.containers[].ports[].protocol String 默认TCP spec.containers[].env[] List spec.containers[].env[].name String spec.containers[].env[].value String spec.containers[].resources Object 资源 spec.containers[].resources.limits Object 容器运行时的资源上限 spec.containers[].resources.limits.cpu String 单位core数，将用于docker run --cpu-shares spec.containers[].resources.limits.memory String 单位MIB、GiB spec.containers[].resources.requests Object 容器启动和调度时的资源上限 spec.containers[].resources.requests.cpu String spec.containers[].resources.request.memory String 2.2 额外的参数项 参数名 字段类型 说明 spec.restartPolicy String 1. Always: 默认，Pod一旦停止，无论容器是否已终止，kubelet服务都将重启它; 2. OnFailure: 只有Pod以非0退出码终止时，kubelet将重启它; 3. Never: Pod终止后，kubelet将推出码上报Master，但不会重启Pod spec.nodeSelector Object 定义Node的Label过滤标签，以key: value格式指定 spec.imagePullSecrets Object 定义pull镜像时使用secret名称，以name: secretKey格式指定 spec.hostNetwork Boolean 使用使用主机网络。默认false。为true时，将不使用docker网桥，直接使用宿主机网络，但同时，也无法启动第二个副本 2.3 使用命令查询参数123kubectl explain podkubectl explain pod.spec 2.4 示例：Pod模板123456789101112apiVersion: v1kind: Podmetadata: name: myapp namespace: default labels: app: myapp version: v1spec: containers: - name: app1 image: hub.elihe.io/test/nginx:v1 1234567891011121314151617181920212223242526272829303132333435363738394041$ kubectl apply -f pod.yaml$ kubectl get podNAME READY STATUS RESTARTS AGEmyapp 1/1 Running 0 6s$ kubectl describe pod myappName: myappNamespace: defaultPriority: 0Node: k8s-node02/192.168.31.42Start Time: Mon, 28 Sep 2020 21:41:25 +0800Labels: app=myapp version=v1Annotations: &lt;none&gt;Status: RunningIP: 10.244.2.5IPs: IP: 10.244.2.5Containers: app1: Container ID: docker://dad5e86a4d90a7275e7a15833801d57c87356e1c7ce723fde113b18ef960213c Image: hub.elihe.io/test/nginx:v1...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 61s default-scheduler Successfully assigned default/myapp to k8s-node02 Normal Pulled 60s kubelet, k8s-node02 Container image &quot;hub.elihe.io/test/nginx:v1&quot; already present on machine Normal Created 60s kubelet, k8s-node02 Created container app1 Normal Started 60s kubelet, k8s-node02 Started container app1$ kubectl logs myapp -c app1/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: error: IPv6 listen already enabled/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Configuration complete; ready for start up$ kubectl exec myapp -it -- /bin/bash 3. 容器的生命周期 1）kubectl –&gt; apiserver –&gt; CRI –&gt; kubelet 环境初始化 2）启动Pause容器: 初始化网络和数据卷 3）init C初始化。多个initC时，必须串行执行，且每个必须执行成功才向下走 4）Main C，开始运行时，启动Start命令/脚本；结束时，执行Stop命令(做哪些清理操作等) 5）Readiness 就绪检测：若干秒后，进行是否就绪的探测。只有当Readiness成功后，Pod才会显示Running状态 6）Liveness 生存检测：探测Main C中的进程是否正常，不正常则执行重启、删除等命令 3.1 Init C 容器应用容器启动的容器，称为Init C容器 Init 容器与普通容器非常像，除下列两点： 每个 Init 容器必须在下一个 Init 容器启动前成功完成 Init 容器总是在运行成功后自动销毁 如果Init容器启动失败，k8s 会不停重启Pod，直到Init 容器成功为止。然而如果Pod的restartPolicy为Never，它则不会重启 Init 容器的作用： 可以包含并运行实用工具。但出于安全考虑，不建议在应用程序容器镜像中包含这些工具。（主容器启动前，文件创建、数据初始化等） 可以包含使用工具和定制化代码来安装，但不能出现在应用程序镜像中。例如，创建镜像没必要FROM另一个镜像，只需在安装过程中使用sed, awk, python等命令 应用程序镜像可以分离出创建和部署角色，而没有必要联合它们构建一个单独的镜像 Init容器使用Linux Namespace，所以相对应用程序来说具有不同的文件系统视图。因此它能够具有访问Secret的权限，而应用程序容器则不能。简言之，InitC可以把MainC无法取得的Secret权限，先取得，以便MainC使用。 Init容器必须在运用程序启动之前完成，而应用程序是并行运行的，所以Init容器能够提供一种简单的阻塞或延迟应用程序启动的方法，直到满足一组先决条件。 init 模板： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# init-pod.yamlapiVersion: v1kind: Podmetadata: name: init-pod labels: app: init-podspec: containers: - name: app image: hub.elihe.io/test/busybox:v1 imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo &#x27;The app is running!&#x27; &amp;&amp; sleep 3600&quot;] initContainers: - name: init-myservice image: hub.elihe.io/test/busybox:v1 imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;until nslookup myservice; do echo waiting for myservice; sleep 2; done&quot;] - name: init-mydb image: hub.elihe.io/test/busybox:v1 imagePullPolicy: IfNotPresent command: [&quot;sh&quot;, &quot;-c&quot;, &quot;until nslookup mydb; do echo waiting for mydb; sleep 2; done&quot;] # myservice.yamlapiVersion: v1kind: Servicemetadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9001 # mydb.yamlapiVersion: v1kind: Servicemetadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9002 12345678910111213141516$ kubectl create -f init-pod.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEinit-pod 0/1 Init:0/2 0 26s# 创建svc$ kubectl create -f myservice.yaml $ kubectl create -f mydb.yaml$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEmydb ClusterIP 10.100.88.255 &lt;none&gt; 80/TCP 3m58smyservice ClusterIP 10.110.141.175 &lt;none&gt; 80/TCP 6m20s$ kubectl get podNAME READY STATUS RESTARTS AGEinit-pod 1/1 Running 0 6m42s 4. 容器探针4.1 什么是探针探针：是由kubelet对容器执行的定期诊断。要执行诊断，kubelet调用有容器实现的Handler，有三种类型的处理程序： ExecAction: 在容器内执行指定命令，返回码为0表示成功 TCPSocketAction: 在指定IP进行TCP检查，如果端口打开，则诊断成功 HTTPGetAction: 对指定的http://ip:port/path地址执行HTTP Get操作，如果响应的状态码大于等于200且小于400，则诊断成功 每次探测都获得以下三种结果： 成功：诊断通过 失败：诊断未通过 未知：诊断失败，但不采取任何行动 4.2 探测方式 livenessProbe: 指示容器是否正在运行。如果存活探测失败，kubelet会杀死容器，并且容器将受其“restartPolicy”的影响。如果容器不提供存活探针，则默认状态为Success readinessProbe: 指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针，则默认状态为Success 4.2.1 就绪检测检测失败，状态非Ready，但不会重启容器 spec.containers[].readinessProbe.httpGet 12345678910111213141516# readiness-probe-httpget.yaml apiVersion: v1kind: Podmetadata: name: readiness-httpget-podspec: containers: - name: readiness-httpget-container image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent readinessProbe: httpGet: port: 80 path: /index1.html initialDelaySeconds: 1 periodSeconds: 3 123456789101112131415161718192021222324$ kubectl create -f readiness-probe-httpget.yaml $ kubectl get podNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 0/1 Running 0 9s$ kubectl describe pod readiness-httpget-podWarning Unhealthy 1s (x3 over 7s) kubelet, k8s-node01 Readiness probe failed: HTTP probe failed with statuscode: 404# 进入容器$ kubectl exec readiness-httpget-pod -it -- /bin/sh# cd /usr/share/nginx/html# ls -altotal 8drwxr-xr-x 2 root root 40 Aug 14 00:36 .drwxr-xr-x 3 root root 18 Aug 14 00:36 ..-rw-r--r-- 1 root root 494 Aug 11 14:50 50x.html-rw-r--r-- 1 root root 612 Aug 11 14:50 index.html# echo &quot;hello, i&#x27;am index1.html&quot; &gt; index1.html# logout$ kubectl get podNAME READY STATUS RESTARTS AGEreadiness-httpget-pod 1/1 Running 0 2m57s 4.2.2 存活检测检测失败，直接重启Pod spec.containers[].livenessProbe.exec 12345678910111213141516# liveness-prob-exec.yaml apiVersion: v1kind: Podmetadata: name: liveness-exec-podspec: containers: - name: liveness-exec-container image: busybox imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;touch /tmp/abc.txt; sleep 60; rm -f /tmp/abc.txt; sleep 3600&quot;] livenessProbe: exec: command: [&quot;test&quot;, &quot;-e&quot;, &quot;/tmp/abc.txt&quot;] initialDelaySeconds: 1 periodSeconds: 3 123456789$ kubectl create -f liveness-prob-exec.yaml # 失败，重启自动重启$ kubectl get pod -wNAME READY STATUS RESTARTS AGEliveness-exec-pod 1/1 Running 0 26sliveness-exec-pod 1/1 Running 1 2m58sliveness-exec-pod 1/1 Running 2 3m35sliveness-exec-pod 1/1 Running 3 5m15s spec.containers[].livenessProbe.httpGet 12345678910111213141516apiVersion: v1kind: Podmetadata: name: liveness-httpget-podspec: containers: - name: liveness-httpget image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent livenessProbe: httpGet: port: 80 path: /index.html initialDelaySeconds: 1 periodSeconds: 3 timeoutSeconds: 10 # 超时处理 spec.containers[].livenessProbe.tcpSocket 123456789101112131415apiVersion: v1kind: Podmetadata: name: liveness-tcp-podspec: containers: - name: liveness-tcp image: hub.elihe.io/test/nginx:v1 imagePullPolicy: IfNotPresent livenessProbe: tcpSocket: port: 80 initialDelaySeconds: 5 periodSeconds: 3 timeoutSeconds: 10 # 超时处理 4.3 启动 &amp; 退出spec.containers[].lifecycle.postStart|preStop 123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello form the postStart handler &gt; /usr/share/mesage&quot;] preStop: exec: command: [&quot;/usr/sbin/nginx&quot;, &quot;-s&quot;, &quot;quit&quot;] 5. Pod 状态值 Pending：Pod已被k8s系统接受，但有一个或多个镜像容器尚未创建。等待时间包括调度Pod的时间和通过网络下载镜像的时间。 Running: Pod已经绑定到一个节点上了，Pod中的所有容器已被创建 Succeeded: Pod中的所有容器都被成功终止，且不会再重启 Failed: Pod中的所有容器都已终止，但至少有一个容器以非0返回值退出 Unknown: 未知原因无法获取Pod状态，通常是因为与Pod所在主机的通信失败","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 集群安装","slug":"Kubernetes 集群安装","date":"2018-07-02T13:44:16.000Z","updated":"2021-06-22T10:50:49.718Z","comments":true,"path":"2018/07/02/Kubernetes 集群安装/","link":"","permalink":"https://elihe2011.github.io/2018/07/02/Kubernetes%20%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"1. 安装准备1.1 设置主机名123456# masterhostnamectl set-hostname k8s-master# nodehostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02","text":"1. 安装准备1.1 设置主机名123456# masterhostnamectl set-hostname k8s-master# nodehostnamectl set-hostname k8s-node01hostnamectl set-hostname k8s-node02 1.2 hostname相互解析1234vi /etc/hosts192.168.31.40 k8s-master192.168.31.41 k8s-node01192.168.31.42 k8s-node02 1.3 关闭虚拟内存 swap1swapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab 1.4 调整内核参数1234567891011121314151617181920cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_tw_recycle=0vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它vm.overcommit_memory=1 # 不检查物理内存是否够用fs.inotify.max_user_instances=8192 # 开启 OOMvm.panic_on_oom=0 fs.inotify.max_user_watches=1048576fs.file-max=52706963fs.nr_open=52706963net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max=2310720EOFsysctl -p /etc/sysctl.d/kubernetes.conf# 问题 sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directorymodprobe br_netfilter 1.5 升级内核123456789101112131415161718uname -r3.10.0-1127.el7.x86_64# 内核reporpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm# 安装新内核yum --enablerepo=elrepo-kernel install -y kernel-lt# 检查启动menu是否已加入新内核版本cat /boot/grub2/grub.cfg | grep elrepo | grep menuentrymenuentry &#x27;CentOS Linux (4.4.236-1.el7.elrepo.x86_64) 7 (Core)&#x27; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &#x27;gnulinux-3.10.0-1127.el7.x86_64-advanced-3ec6d414-2b79-482d-9643-b7baeb42cb3d&#x27; &#123;# 开机从新内核启动grub2-set-default &#x27;CentOS Linux (4.4.236-1.el7.elrepo.x86_64) 7 (Core)&#x27;# 重启系统reboot 1.6 开启 ipvs (kube-proxy需要)1234567891011121314modprobe br_netfiltercat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.moduleslsmod | grep -e ip_vs -e nf_conntrack_ipv4 2. Kubeadm 部署安装2.1 安装kubeadm12345678910111213141516cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 查询版本yum list kubelet --showduplicatesyum install -y kubeadm-1.18.6 kubelet-1.18.6 kubectl-1.18.6systemctl enable kubelet kubelet: 运行在集群的所有节点上，用于启动Pod和容器对象的工具 kubeadm: 初始化集群，启动集群的命令工具 kubectl: 和集群通信的命令行工具。可以部署和管理应用，查看各种资源，创建、删除和更新各种组建 2.2 下载k8s镜像默认镜像放google服务器上，国内使用aliyun服务器 123456789101112$ vi load_kube_images.sh#!/bin/bashurl=registry.aliyuncs.com/google_containersversion=v1.18.6images=(`kubeadm config images list --kubernetes-version=$version|awk -F &#x27;/&#x27; &#x27;&#123;print $2&#125;&#x27;`)for imagename in $&#123;images[@]&#125; ; do docker pull $url/$imagename docker tag $url/$imagename k8s.gcr.io/$imagename docker rmi -f $url/$imagenamedone$ chmod u+x load_kube_images.sh &amp;&amp; bash load_kube_images.sh 2.3 初始化主节点 (k8s-master)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 默认配置$ kubeadm config print init-defaults &gt; kubeadm-config.yaml$ vi kubeadm-config.yaml...localAPIEndpoint: advertiseAddress: 192.168.31.40 # 修改为本机IP bindPort: 6443...kubernetesVersion: v1.18.6 # 版本必须匹配networking: dnsDomain: cluster.local podSubnet: 10.244.0.0/16 # 新增 serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;# 新增如下，修改kube-proxy协议为ipvs---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs# 执行初始化$ kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log...[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.31.40:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1c02156e6d3d6b85938e20f0473af2dffff7a22a6c67387aba97da38f0952386 # 如果发生错误，重置后重新init$ kubeadm reset# 执行初始化后的提示步骤$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config# 获取节点$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master NotReady master 3m31s v1.18.6 2.4 部署网络 (k8s-master)1234567891011121314151617181920212223# 解决DNS污染问题 (不推荐)$ echo &quot;199.232.68.133 raw.githubusercontent.com&quot; &gt;&gt; /etc/hosts # 尽量用nsloop查询，将dns配对$ yum install -y bind-utils$ nslookup raw.githubusercontent.com$ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml$ kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds created$ kubectl get pod -n kube-systemkube-flannel-ds-4dlvt 1/1 Running 0 54s$ kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-master Ready master 22m v1.18.6 2.5 工作节点加入集群 (k8s-node1, k8s-node2)123# k8s-master节点下 kubeadm init 的运行日志最后行$ kubeadm join 192.168.31.40:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1c02156e6d3d6b85938e20f0473af2dffff7a22a6c67387aba97da38f0952386 如果未找到，主节点(k8s-master) 执行下列操作获取令牌 1234567891011$ kubeadm token listTOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS7114t2.imdu2ivf56cbjk38 1h 2020-09-22T22:31:42+08:00 &lt;none&gt; Proxy for managing TTL for the kubeadm-certs secret &lt;none&gt;abcdef.0123456789abcdef 23h 2020-09-23T20:31:43+08:00 authentication,signing &lt;none&gt; system:bootstrappers:kubeadm:default-node-token# 令牌过期$ kubeadm token create# 生成密钥$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;0daca31a7b9820fc60eaa28cacc25ee3a16c7af5c6e8104d91bf709bf2e741bc 2.6 查看所有节点12345678910111213# kubectl 命令补齐yum install -y bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profilekubectl get nodekubectl get pod -n kube-system# 当前各个节点的详细情况kubectl get pod -n kube-system -o wide 2.7 问题：组件controller-manager 和scheduler状态 Unhealthy1234567$ kubectl get csNAME STATUS MESSAGE ERRORscheduler Unhealthy Get http://127.0.0.1:10251/healthz: dial tcp 127.0.0.1:10251: connect: connection refused controller-manager Unhealthy Get http://127.0.0.1:10252/healthz: dial tcp 127.0.0.1:10252: connect: connection refused etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; $ netstat -an | grep -e 10251 -e 10252 解决方法: 检查kube-scheduler和kube-controller-manager组件配置是否禁用了非安全端口 123456789101112131415161718192021222324252627282930$ vi /etc/kubernetes/manifests/kube-scheduler.yaml ...spec: containers: - command: - kube-scheduler - --kubeconfig=/etc/kubernetes/scheduler.conf - --leader-elect=true #- --port=0 # 注释掉 image: k8s.gcr.io/kube-scheduler:v1.18.6$ vi /etc/kubernetes/manifests/kube-controller-manager.yaml...spec: containers: - command: - kube-controller-manager - --node-cidr-mask-size=24 #- --port=0 # 注释掉 - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt# 重启kubelet$ systemctl restart kubelet# 再次查询状态$ kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 6. k8s主节点测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788vi nginx.yml# API 版本号apiVersion: apps/v1# 类型，如：Pod/ReplicationController/Deployment/Service/Ingresskind: Deploymentmetadata: # Kind 的名称 name: nginx-appspec: selector: matchLabels: # 容器标签的名字，发布 Service 时，selector 需要和这里对应 app: nginx # 部署的实例数量 replicas: 2 template: metadata: labels: app: nginx spec: # 配置容器，数组类型，说明可以配置多个容器 containers: # 容器名称 - name: nginx # 容器镜像 image: hub.elihe.io/library/nginx:v1 # 只有镜像不存在时，才会进行镜像拉取 imagePullPolicy: IfNotPresent ports: # Pod 端口 - containerPort: 80 kubectl apply -f nginx.ymlkubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-app-76b8bd9478-z74zq 1/1 Running 0 93s 10.244.1.2 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-z8zt6 1/1 Running 0 93s 10.244.2.5 k8s-node01 &lt;none&gt; &lt;none&gt;kubectl delete pod nginx-app-76b8bd9478-z74zqkubectl get pod -o wide# 变更数量kubectl scale --replicas=3 deployment/nginx-appkubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-app-76b8bd9478-6gkq6 1/1 Running 0 4m25s 10.244.1.3 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-d7p6r 1/1 Running 0 13s 10.244.1.4 k8s-node02 &lt;none&gt; &lt;none&gt;nginx-app-76b8bd9478-z8zt6 1/1 Running 0 6m37s 10.244.2.5 k8s-node01 &lt;none&gt; &lt;none&gt;kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEnginx-app 3/3 3 3 12mkubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16h# 开放访问端口kubectl expose deployment nginx-app --port=3000 --target-port=80kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16hnginx-app ClusterIP 10.104.89.46 &lt;none&gt; 3000/TCP 9s# 测试端口转发curl -i 10.104.89.46:3000ipvsadm -LnTCP 10.104.89.46:3000 rr -&gt; 10.244.1.3:80 Masq 1 0 1 -&gt; 10.244.1.4:80 Masq 1 0 1 -&gt; 10.244.2.5:80 Masq 1 0 1 # 开放外部访问nginxkubectl edit svc nginx-apptype: NodePort #ClusterIPkubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 16hnginx-app NodePort 10.104.89.46 &lt;none&gt; 3000:31057/TCP 8m44shttp://192.168.31.40:31057/http://192.168.31.41:31057/http://192.168.31.42:31057/","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes 基础概念","slug":"Kubernetes 基础概念","date":"2018-07-01T08:27:43.000Z","updated":"2021-06-22T10:50:49.718Z","comments":true,"path":"2018/07/01/Kubernetes 基础概念/","link":"","permalink":"https://elihe2011.github.io/2018/07/01/Kubernetes%20%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","excerpt":"1. 架构Kubernetes特点： 轻量级：消耗资源小 开源 弹性伸缩 负载均衡：IPVS 1.1 核心组件 etcd: 保存整个集群的状态 apiserver: 资源操作的唯一入口，提供了认证、授权、访问控制、API注册和发现等机制 controller manager: 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler: 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet: 负责维护容器的生命周期、Volume(CVI) 和网络(CNI)的管理 container runtime: 负责镜像管理以及Pod和容器的真正运行 (CRI) kube-proxy: 负责为Service提供cluster内部的服务发现和负载均衡 （四层） iptables ipvs etcd: 可信赖的分布式键值对存储服务，为整个分布式集群存储关键数据，协助分布式集群的正常运转。","text":"1. 架构Kubernetes特点： 轻量级：消耗资源小 开源 弹性伸缩 负载均衡：IPVS 1.1 核心组件 etcd: 保存整个集群的状态 apiserver: 资源操作的唯一入口，提供了认证、授权、访问控制、API注册和发现等机制 controller manager: 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler: 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上 kubelet: 负责维护容器的生命周期、Volume(CVI) 和网络(CNI)的管理 container runtime: 负责镜像管理以及Pod和容器的真正运行 (CRI) kube-proxy: 负责为Service提供cluster内部的服务发现和负载均衡 （四层） iptables ipvs etcd: 可信赖的分布式键值对存储服务，为整个分布式集群存储关键数据，协助分布式集群的正常运转。 1.2 Add-ons: kube-dns: 负责为整个集群提供DNS服务（CoreDNS, 可以为集群中的SVC创建一个域名IP对应关系解析，即A记录) Ingress Controller: 为服务提供外网入口 （七层代理） Dashboard: 提供GUI Federation: 提供跨可用区的集群 Prometheus：监控 ELK：集群日志统一分析接入平台 2. Pod 共享存储 共享网络 2.1 Pod 控制器类型 RelicationController &amp; ReplicaSet &amp; Deployment 2.1.1 ReplicationController &amp; ReplicaSet &amp; Deployment ReplicationController: 用来确保容器的应用副本数始终是用户定义的副本数。即如果有容器异常退出，会创建新的Pod来代替；如果多出来，自动回收。 ReplicaSet: 新版k8s中建议使用ReplicaSet取代RelocationController，它支持集合式selector Deployment: 用来自动管理ReplicaSet。ReplicaSet不支持rolling-update，但Deployment支持。 2.1.2 HPA （HorizontalPodAutoScale)HPA仅适用于Deployment和ReplicaSet，在v1版本中仅支持根据Pod的CPU利用率扩/缩容，在v1alpha中，支持根据内存和用户自定义的metric扩/缩容 2.1.3 StatefulSet解决有状态服务的问题（Deployment和ReplicaSet只支持无状态服务），应用场景： 稳定的持久化存储，即Pod重新调度后还是能够访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后，其PodName和HostName不变，基于Headless Service (即没有Cluster IP的Service)来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或扩展的时候，要依据定义的顺序依次进程（即从0到N-1，在下一个Pod运行之前，所有之前的Pod必须是Running和Ready状态)，基于init containers来实现 有序收缩，有序删除（即从N-1到0） 2.1.4 DaemonSet确保全部（或部分）Node上运行一个Pod副本。当有Node加入集群时，也会为它们新增一个Pod；当有Node从集群移除时，这些Pod会被回收。删除DaemonSet，将会删除它创建的所有Pod。 一些典型的DaemonSet用法： 运行集群存储daemon，例如每个Node上运行glusterd、ceph 在每个Node上进行日志收集daemon，例如fluentd、logstash 在每个Node上运行监控daemon，例如Prometheus Node Exporter 2.1.5 Job &amp; CronJob Job: 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束 CronJob：定时Job 在给定时间点运行一次 周期性地在给定时间点运行 2.2 服务发现Service 通过标签选择到Pod 3. 网络通讯模式k8s 的网络模型假定了所有Pod都在一个可以直接连通的扁平化网络空间中。在GCE(Google Compute Engine) 里面是现成的网络模型。但在私有云中搭建k8s集群，一般需要我们自己去实现这个扁平化网络模型。 扁平化网络：所有的Pod可以通过IP“直接到达” 3.1 通讯模式 同一个Pod内的多个容器之间：lo 各Pod之间的通信: Overlay Network Pod与Service之间的通讯：各节点的iptables规则 3.2 FlannelFlannel是CoreOS团队针对k8s设计的一种网络规划服务。它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址，而且它还能在这些IP地址之间建立一个覆盖网络(Overlay Network)，通过这个网络，将数据包原封不动地传递到模板容器内。 etcd为Flannel提供服务： 存储Flannel可分配的IP地址段资源 监控etcd中每个Pod的实际地址，并在内存中创建和维护Pod节点路由表 3.3 总结：不同情况下网络的通信方式 同一个Pod内部通信：共享同一个网络命名空间，共享同一个Linux协议栈。lo网卡 Pod1至Pod2: 同一台主机：由Docker0网桥转发，不需要经过Flannel 不同主机：将Pod的IP和Node的IP关联起来，通过这个关联让Pod可以相互访问。涉及网络封包和拆包，较消耗资源。 Pod至Service网络：基于性能考虑，全部为iptables/LVS维护和转发 Pod到外网：Pod向外网发送请求，查找路由表，转发数据包到宿主机的网卡，宿主机网卡完成路由选择后，iptables执行Masquerade，把源IP更改为宿主网卡的IP，然后向外网服务器发送请求 外网访问Pod：Service 3.4 组件通讯示意图 节点网络：物理的网络 Pod网络：虚拟网络 Service网络：虚拟网络","categories":[{"name":"k8s","slug":"k8s","permalink":"https://elihe2011.github.io/categories/k8s/"}],"tags":[]},{"title":"Docker 私有仓库","slug":"Docker 私有仓库","date":"2018-06-17T08:41:09.000Z","updated":"2021-06-22T10:50:49.717Z","comments":true,"path":"2018/06/17/Docker 私有仓库/","link":"","permalink":"https://elihe2011.github.io/2018/06/17/Docker%20%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93/","excerpt":"1. 安装Docker详见 Docker 安装 2. 安装Docker Compose123curl -L &quot;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose","text":"1. 安装Docker详见 Docker 安装 2. 安装Docker Compose123curl -L &quot;https://github.com/docker/compose/releases/download/1.27.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose 3. 安装Harbor下载地址：https://github.com/goharbor/harbor/releases 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152wget https://github.com/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgztar zxvf harbor-offline-installer-v2.0.2.tgzmv harbor /usr/local/cd /usr/local/harborcp harbor.yml.tmpl harbor.ymlvi harbor.ymlhostname: hub.elihe.iohttps: port: 443 # The path of cert and key files for nginx certificate: /data/cert/server.crt private_key: /data/cert/server.keymkdir -p /data/cert &amp;&amp; cd /data/cert# 私钥openssl genrsa -des3 -out server.key 2048# 证书请求openssl req -new -key server.key -out server.csr# 备份私钥cp server.key server.key.org# 转换成证书 （去除设置的密码）openssl rsa -in server.key.org -out server.key# 签名openssl x509 -req -days 3650 -in server.csr -signkey server.key -out server.crt# 证书赋予执行权限chmod a+x *# 安装harborcd /usr/local/harbor./install.sh# 启动 docker-composedocker-compose start# 开机启动 docker-compose# 启动不一定成功，废弃vi /etc/rc.d/rc.local/usr/local/bin/docker-compose -f /usr/local/harbor/docker-compose.yml up -d# 按这种方式crontab -e@reboot sleep 60 &amp;&amp; /usr/local/bin/docker-compose -f /usr/local/harbor/docker-compose.yml up -d 4. Harbor服务器和客户端配置1234567891011# 添加域名解析echo &quot;192.168.31.200 hub.elihe.io&quot; &gt;&gt; /etc/hosts# 配置daemon.jsonvi /etc/docker/daemon.json&#123; &quot;insecure-registries&quot;: [&quot;https://hub.elihe.io&quot;]&#125;# 重启dockersystemctl daemon-reload &amp;&amp; systemctl restart docker 5. 访问Harbor1234567891011121314151617181920https://hub.elihe.io admin/Harbor12345docker login https://hub.elihe.io docker pull nginxdocker tag nginx hub.elihe.io/library/nginx:v1 cat index.html echo &#x27;Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;&#x27; &gt; index.htmlcat &gt; hostname.html &lt;&lt;EOF&lt;script type=&quot;text/javascript&quot;&gt;document.write(location.hostname);&lt;/script&gt;EOFdocker commit 7e7553b2204f hub.elihe.io/library/nginx:v1docker push hub.elihe.io/library/nginx:v1","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 网络","slug":"Docker 网络","date":"2018-06-16T07:22:58.000Z","updated":"2021-06-22T10:50:49.717Z","comments":true,"path":"2018/06/16/Docker 网络/","link":"","permalink":"https://elihe2011.github.io/2018/06/16/Docker%20%E7%BD%91%E7%BB%9C/","excerpt":"","text":"1. 通过Linux路由机制打通网络1.1 修改主机名12hostnamectl set-hostname centos7-ahostnamectl set-hostname centos7-b 1.2 centos7-a的docker0默认绑定的ip地址1234567891011121314ip addr2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:a3:00:96 brd ff:ff:ff:ff:ff:ff inet 192.168.31.30/24 brd 192.168.31.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::a05d:dcec:e694:2cfc/64 scope link noprefixroute valid_lft forever preferred_lft forever3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:a5:d2:db:31 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:a5ff:fed2:db31/64 scope link valid_lft forever preferred_lft forever 1.3 修改主机centos7-b的docker0网卡的ip地址123456789101112131415161718192021vi /etc/docker/daemon.json &#123; &quot;bip&quot;:&quot;172.18.0.1/16&quot;&#125;systemctl restart dockerip addr2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:49:57:44 brd ff:ff:ff:ff:ff:ff inet 192.168.31.31/24 brd 192.168.31.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::a05d:dcec:e694:2cfc/64 scope link tentative noprefixroute dadfailed valid_lft forever preferred_lft forever inet6 fe80::4298:eebd:9094:f36e/64 scope link noprefixroute valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:92:1b:3b:17 brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 brd 172.18.255.255 scope global docker0 valid_lft forever preferred_lft forever 1.4 增加网关路由123456789101112131415# centos7-a[root@centos7-a ~]# route add -net 172.18.0.0/16 gw 192.168.31.31[root@centos7-a ~]# ip routedefault via 192.168.31.1 dev ens33 proto static metric 100 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 via 192.168.31.31 dev ens33 192.168.31.0/24 dev ens33 proto kernel scope link src 192.168.31.30 metric 100 # centos7-b[root@centos7-a ~]# route add -net 172.17.0.0/16 gw 192.168.31.30[root@centos7-a ~]# ip routedefault via 192.168.31.1 dev ens33 proto static metric 100 172.18.0.0/16 dev docker0 proto kernel scope link src 172.18.0.1 172.17.0.0/16 via 192.168.31.30 dev ens33 192.168.31.0/24 dev ens33 proto kernel scope link src 192.168.31.30 metric 100 1.5 测试网络是否联通1234567891011[root@centos7-a ~]# ping 172.18.0.1PING 172.18.0.1 (172.18.0.1) 56(84) bytes of data.64 bytes from 172.18.0.1: icmp_seq=1 ttl=64 time=1.61 ms64 bytes from 172.18.0.1: icmp_seq=2 ttl=64 time=0.979 ms64 bytes from 172.18.0.1: icmp_seq=3 ttl=64 time=0.614 ms[root@centos7-b ~]# ping 172.17.0.1PING 172.17.0.1 (172.17.0.1) 56(84) bytes of data.64 bytes from 172.17.0.1: icmp_seq=1 ttl=64 time=2.13 ms64 bytes from 172.17.0.1: icmp_seq=2 ttl=64 time=0.521 ms64 bytes from 172.17.0.1: icmp_seq=3 ttl=64 time=0.659 ms 3. Overlay网络 4. NamespaceVeth pair：用于不同network namespace间进行通信，点对点通信。 Linux Bridge： 实现类似交换机的工作模式，将多个不同Namespace上的网卡连通 使用网桥工具 123456789101112131415yum install bridge-utils -y[root@centos7-a ~]# brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242a5d2db31 no veth463224b veth95cd878[root@centos7-a ~]# ip addr 29: veth95cd878@if28: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 56:19:de:43:e7:e4 brd ff:ff:ff:ff:ff:ff link-netnsid 1 inet6 fe80::5419:deff:fe43:e7e4/64 scope link valid_lft forever preferred_lft forever55: veth463224b@if54: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether fa:89:aa:75:57:a1 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::f889:aaff:fe75:57a1/64 scope link valid_lft forever preferred_lft forever 1234567891011121314151617181920212223242526# 获取容器运行的PID[root@centos7-a ~]# docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; 0f9fa4e71fb718607# 建立链接，方便ip netns标准命令查询mkdir -p /var/run/netnsln -s /proc/18607/ns/net /var/run/netns/18607# 查询net namespace[root@centos7-a ~]# ip netns ls18607 (id: 0)[root@centos7-a ~]# ip netns exec 18607 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever54: eth0@if55: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever # 查询veth网卡序号[root@centos7-a ~]# ip netns exec 18607 ethtool -S eth0NIC statistics: peer_ifindex: 55","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 数据卷","slug":"Docker 数据卷","date":"2018-06-15T01:45:21.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/15/Docker 数据卷/","link":"","permalink":"https://elihe2011.github.io/2018/06/15/Docker%20%E6%95%B0%E6%8D%AE%E5%8D%B7/","excerpt":"1. 数据卷设计的目的 经过特殊设计的目录，可以绕过联合文件系统(UFS)，为一个或多个容器提供访问。 在于数据的永久化，它完全独立于容器的生命周期。因此，Docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾回收机制，对容器引用的数据卷进行处理","text":"1. 数据卷设计的目的 经过特殊设计的目录，可以绕过联合文件系统(UFS)，为一个或多个容器提供访问。 在于数据的永久化，它完全独立于容器的生命周期。因此，Docker不会在容器删除时删除其挂载的数据卷，也不会存在类似的垃圾回收机制，对容器引用的数据卷进行处理 2. 添加数据卷12docker run -it -v ~/datavolume:/data ubuntu /bin/bashdocker run -it -v ~/datavolume:/data:ro ubuntu /bin/bash 123FROM ubuntuVOLUME [&#x27;/datavolume1&#x27;, &#x27;/datavolume2&#x27;]CMD /bin/bash 3. 共享数据卷12345docker run --rm --name dvt1 -v /docker_data:/data -it ubuntu# 共享数据卷docker run --rm --name dvt2 --volumes-from dvt1 -it ubuntudocker run --rm --name dvt3 --volumes-from dvt1 -it ubuntu 4. 实例：安装 MySQL 主从数据库4.1 创建配置文件1234567891011121314151617181920212223242526272829303132333435363738mkdir -p /mysql_data/confmkdir -p /mysql_data/mastermkdir -p /mysql_data/slave# 主节点配置cat &gt; /mysql_data/conf/master.conf &lt;&lt;EOF[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]log_bin = log # 开启二进制日志，用于从节点的历史复制回放collation-server = utf8_unicode_ciinit-connect = &#x27;SET NAMES utf8&#x27;character-set-server = utf8server_id = 1 # 需保证主库和从库的server_id不同replicate-do-db=fileserver # 需要复制的数据库名，复制多个数据库时，重复设置即可EOF# 从节点配置cat &gt; /mysql_data/conf/slave.conf &lt;&lt;EOF[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]log_bin = log # 开启二进制日志，用于从节点的历史复制回放collation-server = utf8_unicode_ciinit-connect = &#x27;SET NAMES utf8&#x27;character-set-server = utf8server_id = 2 # 需保证主库和从库的server_id不同replicate-do-db=fileserver # 需要复制的数据库名，复制多个数据库时，重复设置即可EOF 4.2 启动MYSQL容器1234567891011# 主节点docker run -d --name mysql-master -p 13306:3306 \\-v /mysql_data/conf/master.conf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-v /mysql_data/master:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 mysql:5.7# 从节点docker run -d --name mysql-slave -p 13307:3306 \\-v /mysql_data/conf/slave.conf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-v /mysql_data/slave:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 4.3 宿主机安装 MYSQL 客户端123456789101112# 卸载 mariadb 组件$ yum list installed | grep -i mariadbmariadb-libs.x86_64 1:5.5.65-1.el7 @anaconda $ yum remove -y mariadb-libs# 安装 mysql repoyum -y install http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm# 安装客户端yum search mysql-communityyum install -y mysql-community-client 4.4 配置同步信息4.4.1 主节点1234567891011121314151617# 不要使用localhost，使用本机公网IPmysql -uroot -h 192.168.31.60 -P13306 -p# 授权slave节点登录mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#x27;slave&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;slave&#x27;;mysql&gt; flush privileges;mysql&gt; create database utime default character set utf8mb4;mysql&gt; show master status\\G*************************** 1. row *************************** File: log.000001 Position: 582 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 4.4.2 从节点12345678mysql -uroot -h 192.168.31.60 -P13307 -p # 不要使用localhost，使用本机公网IPmysql&gt; stop slave;mysql&gt; create database utime default character set utf8mb4;mysql&gt; CHANGE MASTER TO MASTER_HOST=&#x27;192.168.31.60&#x27;, MASTER_PORT=13306, MASTER_USER=&#x27;slave&#x27;, MASTER_PASSWORD=&#x27;slave&#x27;, MASTER_LOG_FILE=&#x27;log.000001&#x27;, MASTER_LOG_POS=627;mysql&gt; start slave;mysql&gt; show slave status\\G","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 容器互联","slug":"Docker 容器互联","date":"2018-06-14T05:35:53.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/14/Docker 容器互联/","link":"","permalink":"https://elihe2011.github.io/2018/06/14/Docker%20%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94/","excerpt":"1. 基于 Volume 的互联 Graph的架构图","text":"1. 基于 Volume 的互联 Graph的架构图 graphdriver架构图 Aufs: Docker最早支持的driver，但它只是Linux内核的一个补丁集。 Device Mapper： Linux2.6 内核提供的一种从逻辑设备到物理设备的映射框架机制，时LVM2的核心，支持块级别的copy on write特性。支持block到block复制 VFS: 虚拟文件系统最大的缺陷是不支持copy on write特性，每层都是一个单独的目录，如果新增一个child层，则需要将父级层镜像文件一并复制到新目录） Btrfs: 速度快，采用btrfs的文件系统的快照能力来实现layer分层功能。缺点是还不够成熟。 Overlay: 当前最新的文件驱动 1.1 不指定volume挂载目录，默认放在容器_data目录下123456789101112131415161718192021222324252627282930313233343536373839404142434445docker run --rm -it -v /data ubuntu /bin/bashroot@83139b884b25:/# dfFilesystem 1K-blocks Used Available Use% Mounted onoverlay 28289540 3451104 24838436 13% /tmpfs 65536 0 65536 0% /devtmpfs 499104 0 499104 0% /sys/fs/cgroupshm 65536 0 65536 0% /dev/shm/dev/mapper/centos-root 28289540 3451104 24838436 13% /datatmpfs 499104 0 499104 0% /proc/asoundtmpfs 499104 0 499104 0% /proc/acpitmpfs 499104 0 499104 0% /proc/scsitmpfs 499104 0 499104 0% /sys/firmwaredocker inspect 83139b884b25 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;3fd2650cc22d735d6674c721cedd34ace7be5cfd3f35852abc98cf4ee8dbd50b&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/3fd2650cc22d735d6674c721cedd34ace7be5cfd3f35852abc98cf4ee8dbd50b/_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ],# 共享 --volumes-fromdocker run --rm -it --privileged=true --volumes-from=83139b884b25 busybox /bin/sh/ # dfFilesystem 1K-blocks Used Available Use% Mounted onoverlay 28289540 3451180 24838360 12% /tmpfs 65536 0 65536 0% /devtmpfs 499104 0 499104 0% /sys/fs/cgroupshm 65536 0 65536 0% /dev/shm/dev/mapper/centos-root 28289540 3451204 24838336 12% /data/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/resolv.conf/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/hostname/dev/mapper/centos-root 28289540 3451204 24838336 12% /etc/hosts 1.2 指定挂载目录123456789101112131415mkdir -p /docker_data # 宿主机上创建目录 (SRC:DEST)docker run --rm -it -v /docker_data:/data ubuntu /bin/bashdocker inspect f15e04881ea5 &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/docker_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 1.3 基于数据容器的单主机互联数据容器：只提供数据的容器，业务容器连接到该数据容器，实现数据共享 12345678910111213docker run --rm --volumes-from=f15e04881ea5 -it ubuntu /bin/bashdocker inspect 19f9a3ffc9ea &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/docker_data&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 2. 基于 Link 的互联2.1 默认允许 Container 互通12345678910111213docker run --rm --name=mysql-srv -P -e MYSQL_ROOT_PASSWORD=123456 -it mysql:5.7 /bin/shroot@64faae051d97:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.5 64faae051d97docker run --rm -it ubuntu curl 172.17.0.5:3306curl: (1) Received HTTP/0.9 when not allowed 2.2 关闭 Container 互通关闭互通: /usr/bin/dockerd -H unix:///var/run/docker.sock --icc=false --link name:alias: 关闭互通的container，连接指定的 container。它会在/etc/hosts中生成对应的ip映射 123456789101112131415161718192021222324252627282930313233docker run --rm --name=java1 -it java /bin/bashroot@090a30f3504e:/# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever88: eth0@if89: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# link 网络docker run --rm --link=java1:java2 -it java /bin/bashroot@51a3a3e91351:/# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever92: eth0@if93: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft foreverroot@51a3a3e91351:/# cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.2 java2 090a30f3504e java1172.17.0.3 51a3a3e91351 3. 基于网络的互联3.1 端口映射1234docker run --rm -p 8306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7ps -ef | grep docker-proxyroot 71225 55463 0 14:26 ? 00:00:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8306 -container-ip 172.17.0.3 -container-port 3306 3.2 直接使用宿主机网络1docker run --rm --net=host -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 3.3 容器共用一个IP网络1234docker run --rm --name=mysqlserver -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7# 与 mysql 共用网络docker run --rm --name javasrv --net=container:mysqlserver -it java /bin/bash 3.4 网络知识补充 docker0: nat 网桥 网桥：把物理网卡当交换机，能接收mac不是自己的报文，然后转发到正确的mac上 1234567891011121314151617181920212223242526272829303132333435$ yum install -y bridge-utils$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242d81a56c3 no veth6445d40$ ip link show1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:ff:1c:29 brd ff:ff:ff:ff:ff:ff3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:d8:1a:56:c3 brd ff:ff:ff:ff:ff:ff99: veth6445d40@if98: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether 1e:cd:1b:e4:1d:fc brd ff:ff:ff:ff:ff:ff link-netnsid 0$ docker network lsNETWORK ID NAME DRIVER SCOPE5edf46553116 bridge bridge local3f0e974cff7d host host local016c2058322a none null local$ docker network inspect bridge# closed container，未分配IP地址$ docker run --rm --network none -it busybox /bin/sh# default$ docker run --rm --network default -it busybox /bin/sh# joined, 共享IP$ docker run --rm --network container:c1 -it busybox /bin/sh# host, 使用宿主机IP$ docker run --rm --network host -it busybox /bin/sh docker 网络模型：","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 自定义镜像","slug":"Docker 自定义镜像","date":"2018-06-13T03:32:47.000Z","updated":"2021-06-22T10:50:49.716Z","comments":true,"path":"2018/06/13/Docker 自定义镜像/","link":"","permalink":"https://elihe2011.github.io/2018/06/13/Docker%20%E8%87%AA%E5%AE%9A%E4%B9%89%E9%95%9C%E5%83%8F/","excerpt":"1. Dockerfile 指令 FROM: 指定基础镜像 服务类镜像： nginx、redis、mongo、mysql、httpd、php、tomcat 语言类镜像: node、openjdk、python、ruby、golang 操作系统镜像: ubuntu、debian、centos、fedora、alpine 空白镜像：scratch 适用于静态编译的程序，不需要操作系统支撑。 COPY: 复制文件 ADD: 支持添加URL，自动解压文件等 WORKDIR: 指定默认目录工作","text":"1. Dockerfile 指令 FROM: 指定基础镜像 服务类镜像： nginx、redis、mongo、mysql、httpd、php、tomcat 语言类镜像: node、openjdk、python、ruby、golang 操作系统镜像: ubuntu、debian、centos、fedora、alpine 空白镜像：scratch 适用于静态编译的程序，不需要操作系统支撑。 COPY: 复制文件 ADD: 支持添加URL，自动解压文件等 WORKDIR: 指定默认目录工作 RUN: 构建镜像时执行, 用于安装应用和软件包，创建用户等操作 CMD: 运行容器的启动命令，可被替换 ENTRYPOINT: 同CMD, 但支持额外参数 ENV: 设置环境变量 VOLUME: 定义匿名卷 EXPOSE: 曝露端口 USER:指定当前用户 HEALTHCHECK 2. 使用scratch镜像2.1 直接使用编译好的C程序 （依赖外部库，直接报错）12345#include &lt;stdio.h&gt;void main() &#123; printf(&quot;hello world\\n&quot;);&#125; 1234FROM scratchCOPY hello /CMD [&quot;/hello&quot;] 123456gcc hello.c -o hellodocker build -t hello .docker run --rm hellostandard_init_linux.go:190: exec user process caused &quot;no such file or directory&quot; 2.2 改用golang程序1234567package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(&quot;hello world&quot;)&#125; 12345678FROM golang as builderWORKDIR /go/src/appCOPY hello.go .RUN go build -ldflags=&quot;-w -s&quot; hello.goFROM scratchCOPY --from=builder /go/src/app/hello /CMD [&quot;/hello&quot;] 12docker build -t hello .docker run --rm hello # hello world 2.3 不使用标准库的C版本12345678910111213#include &lt;sys/syscall.h&gt;#ifndef DOCKER_GREETING #define DOCKER_GREETING &quot;Hello from Docker&quot;#endifconst char message[] = DOCKER_GREETING &quot;\\n&quot;;void _start() &#123; syscall(SYS_write, 1, message, sizeof(message)-1); syscall(SYS_exit, 0);&#125; 1234FROM scratchCOPY hello /CMD [&quot;/hello&quot;] 12345# 静态编译 yum install glibc-staticgcc -static -Os -nostartfiles -fno-asynchronous-unwind-tables -o hello hello.cdocker build -t hello .docker run --rm hello # Hello from Docker 3. 错误的文件系统操作在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt # 文件并不在/app目录下 4. RUN &amp; CMD &amp; ENTRYPOINT4.1 docker中的进程，必须以前台方式启动对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 123456789CMD echo $HOMECMD [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;] # 实际执行命令# 错误的示范CMD service nginx startCMD [&quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;] # 实际执行命令# 正确的nginx启动命令, 必须以前台形式运行CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off&quot;] 4.2 支持额外参数12345678FROM ubuntuRUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lob/apt/lists/*#CMD [&quot;curl&quot;, &quot;-s&quot;, &quot;https://cip.cc&quot;] # 不主持额外参数ENTRYPOINT [&quot;curl&quot;, &quot;-s&quot;, &quot;https://cip.cc&quot;] # 支持额外参数，比如 curl -i 1234docker build -t myip .docker run --rm myipdocker run --rm myip -i # -i, 获取HTTP请求头，但这里报错，无法将该参数传入 4.3 应用运行前的准备工作某些应用，需要在运行主进程钱，做一些准备工作。mysql需要提前进行数据库配置、初始化工作 123456789FROM alpine:3.4...RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis...ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] USER redis EXPOSE 6379CMD [ &quot;redis-server&quot; ] 123456789#!/bin/sh...# allow the container to be started with `--user`if [ &quot;$1&quot; = &#x27;redis-server&#x27; -a &quot;$(id -u)&quot; = &#x27;0&#x27; ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot;fi exec &quot;$@&quot; 12345# id 命令将替换默认的 CMD [&quot;redis-server&quot;] 命令docker run -it redis id# 正确的启动方式docker run --name redis-srv -d redis 5. 其他示例5.1 命令细节说明12345678910111213141516171819202122232425262728293031323334FROM busyboxMAINTAINER &quot;eli.he@live.cn&quot;# LABEL maintainer=&quot;eli.he@live.cn&quot;ENV WEB_ROOT=&quot;/data/www/html/&quot;WORKDIR $&#123;WEB_ROOT&#125;COPY index.html .COPY app ./app # 拷贝目录时，目录不会自动创建，需要指定ADD http://nginx.org/download/nginx-1.19.2.tar.gz /usr/local/src/ # 只下载，不解压ADD nginx-1.19.2.tar.gz /usr/local/src/ # 自动解压VOLUME /data/www/mysqlEXPOSE 80/tcp 443/tcp # 容器运行时，-P 自动暴露# RUN 打包镜像时运行RUN cd /usr/local/src/ &amp;&amp; tar xf nginx-1.19.2.tar.gz# CMD 容器启动时运行，可被docker run中指定的命令替换CMD /bin/httpd -f -h $WEB_ROOT # okCMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;] # 无法解析变量CMD [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;] # 能解析，但执行完shell立即退出# ENTRYPOINT 指定容器的默认运行程序，docker run中指定的命令，无法替换它，只能被当初参数传递给该默认程序ENTRYPOINT /bin/httpd -f -h $WEB_ROOT# 注意： CMD &amp; ENTRYPOINT 同时存在时，CMD 中的数据被当成参数传递给 ENTRYPOINTCMD [&quot;/bin/httpd&quot;, &quot;-f&quot;, &quot;-h $WEB_ROOT&quot;]ENTRYPOINT [&quot;/bin/sh&quot;, &quot;-c&quot;]HEALTHCHECK --interval=5m --timeout=3s \\ CMD curl -f http://localhost/ || exit 1 5.2 自定义nginx镜像1234567891011121314151617FROM nginx:1.19.2-alpineLABEL maintainer=&quot;eli.he@live.cn&quot;ENV WEB_ROOT=&quot;/data/www/html/&quot;WORKDIR $WEB_ROOTADD index.html ./ADD entrypoint.sh /bin/RUN chmod +x /bin/entrypoint.shEXPOSE 80/tcpHEALTHCHECK --start-period=3s CMD curl -o - -q http://$&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;CMD [&quot;/usr/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]ENTRYPOINT [&quot;/bin/entrypoint.sh&quot;] 123456789101112#!/bin/sh# entrypoint.shcat &gt; /etc/nginx/conf.d/http.conf &lt;&lt;EOFserver &#123; server_name $HOSTNAME; listen $&#123;IP:-0.0.0.0&#125;:$&#123;PORT:-80&#125;; root $&#123;WEB_ROOT:-/usr/share/nginx/html&#125;;&#125;EOFexec &quot;$@&quot; 123docker build -t myweb:v0.1 .docker run --name web1 -P -d myweb:v0.1","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 命令","slug":"Docker 命令","date":"2018-06-12T00:32:27.000Z","updated":"2021-06-22T10:50:49.715Z","comments":true,"path":"2018/06/12/Docker 命令/","link":"","permalink":"https://elihe2011.github.io/2018/06/12/Docker%20%E5%91%BD%E4%BB%A4/","excerpt":"1. 基本命令12345678docker infodocker versiondocker system df # 存储统计docker login https://hub.elihe.iodocker logout","text":"1. 基本命令12345678docker infodocker versiondocker system df # 存储统计docker login https://hub.elihe.iodocker logout 2. 镜像123456789101112131415161718192021222324docker imagesdocker image lsdocker search nginxdocker pull nginxdocker tag nginx hub.elihe.io/mylib/nginx:v0.1docker push hub.elihe.io/mylib/nginx:v0.1docker run --name myweb -p 80:80 -d nginxdocker commit -p myweb hub.elihe.io/mylib/nginx:v0.2docker history hub.elihe.io/mylib/nginx:v0.2docker save -o myweb0.2.tar hub.elihe.io/mylib/nginx:v0.2docker load -i myweb0.2.tardocker export myweb | gzip &gt; myweb.tar.gzdocker import myweb.tar.gz hub.elihe.io/mylib/nginx:v0.3 # to imagedocker rmi -f hub.elihe.io/mylib/nginx:v0.3 docker image prune # 清理 dangling 镜像docker image prune -a # 清理所有没有关联容器的镜像 2.1 特殊镜像2.1.1 虚悬镜像(dangling image)仓库名、标签均为 的镜像 （docker pull/build 时，原有的镜像名被占用，会导致此种情况) 12345$ docker image ls -f dangling=trueREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago $ docker image prune # 删除虚悬镜像 2.1.2 中间层镜像为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像 1$ docker image ls -a 3. 容器12345678910111213141516171819202122232425262728docker create --name myweb -p 80:80 --cpu-shares=1024 nginx # cpu 占用100%docker start mywebdocker stop mywebdocker pause mywebdocker unpause mywebdocker psdocker kill mywebdocker rm myweb# Ctrl+P Ctrl+Q 切换到后台运行, 变成守护式容器docker run --name test -it alpine /bin/shdocker attach test # Attach local standard input, output, and error streams to a running container, exit后，容器自动停止# 守护式容器, 适合有常驻进程的镜像docker run --name myweb2 -p 8080:80 -d nginxdocker exec -it myweb2 /bin/shdocker logs -tf --tail=10 myweb2 # 查看容器日志. -f --follows, -t --timestampsdocker inspect myweb2docker port myweb2docker top myweb2 # 容器进程docker stats myweb2 # 实时监控，相当于进入容器执行 top# 宿主机与容器的文件拷贝docker cp myweb2:/usr/share/nginx/html/50x.html .docker cp index.html myweb2:/usr/share/nginx/html/ 3.1 什么是守护式容器？ 能够长期运行 没有交互式会话 适合运行应用程序和服务 3.2 CPU 限制 -c, --cpu-shares: 1024 means 100% of the CPU --cpuset-cpus: 使用那些 CPU 12docker run --cpu-shares=512 # 50% CPUdocker run --cpuset-cpus=0,2,4 # 使用0,2,4三个 CPU 3.3 内存限制 -m, --memory: 限制内存使用 1docker run -it -m 300M ubuntu /bin/sh 3.4 访问宿主机设备限制12345678# Mount a FUSE based fsdocker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs# give access to a single devicedocker run -it --device=/dev/ttyUSB0 ubuntu /bin/sh# give access to all devicesdocker run -it --privileged -v /dev/bus/usb:/dev/bus/usb ubuntu /bin/sh 4. 网络12345678910111213docker network createdocker network rmdocker network connectdocker network disconnectdocker network lsNETWORK ID NAME DRIVER SCOPE5edf46553116 bridge bridge local3f0e974cff7d host host local016c2058322a none null localdocker network inspect bridge 5. Volumes12345docker volume createdocker volume rmdocker volume lsdocker volume inspect 6. 常用命令总结 7. 简单示例7.1 MySQL12345docker pull mysql:5.7docker run --name mysqlsrv -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 -d mysql:5.7 docker exec -it mysqlsrv /bin/bash 7.2 容器中部署静态网站Nginx部署流程 创建映射80端口的交互式容器 安装Nginx 安装文本编辑器vim 创建静态页面 修改Nginx配置文件 运行Ngix 验证网站访问 123456789101112131415161718192021222324252627docker run --name web -p 8080:80 -it ubuntu /bin/bashroot@ecd4887cf28d:/#apt-get updateapt-get install -y nginx vimmkdir -p /var/www/htmlecho &#x27;&lt;h1&gt;Nginx in Docker&lt;/h1&gt;&#x27; &gt; /var/www/html/index.htmlvi /etc/nginx/sites-enabled/defaultserver &#123; root /var/www/html;&#125;nginxps -efCTRL-P, CTRL-Q # 退出容器，容器转后台运行docker port web # 查看端口curl http://127.0.0.1:8080 # 访问网页docker stop web # 停止容器docker start -i web # 运行容器docker exec web nginx # 启动nginx","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 安装","slug":"Docker 安装","date":"2018-06-10T23:35:11.000Z","updated":"2021-06-22T10:50:49.714Z","comments":true,"path":"2018/06/11/Docker 安装/","link":"","permalink":"https://elihe2011.github.io/2018/06/11/Docker%20%E5%AE%89%E8%A3%85/","excerpt":"1. CentOS1.1 安装依赖包12345678# 更换yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repoyum makecacheyum install -y conntrack ntpdate ntp ipvsadm ipset iptables sysstat wget vim net-tools git","text":"1. CentOS1.1 安装依赖包12345678# 更换yum源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupcurl http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repoyum makecacheyum install -y conntrack ntpdate ntp ipvsadm ipset iptables sysstat wget vim net-tools git 1.2 设置防火墙规则1234567systemctl stop firewalld &amp;&amp; systemctl disable firewalldyum install -y iptables-servicessystemctl start iptables &amp;&amp; systemctl enable iptablesiptables -F &amp;&amp; service iptables save 1.3 关闭SELINUX1setenforce 0 &amp;&amp; sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/config 1.4 调整时区1234567891011121314timedatectl set-timezone Asia/Shanghaidate -s 10:52:50hwclock -wtimedatectl set-local-rtc 0 # 硬件时钟设置为协调UTC (操作)timedatectl set-local-rtc 1 # 硬件时钟设置为协调本地时间# 重启依赖时间的服务systemctl restart rsyslog systemctl restart crond# 开启时间同步crontab -e*/30 * * * * /usr/sbin/ntpdate ntp1.aliyun.com 1.5 关闭系统冗余服务1systemctl stop postfix &amp;&amp; systemctl disable postfix 1.6 设置rsyslogd 和 systemd journald1234567891011121314151617181920212223242526272829303132# 持久化保存日志目录mkdir -p /var/log/journal# 持久化日志配置mkdir -p /etc/systemd/journald.conf.dcat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF[Journal]# 持久化保存到磁盘Storage-persistent# 压缩日志Compress=yesSyncIntervalSec=5mRateLimitInterval=30sRateLimitBurst=1000# 最大占用空间SystemMaxUser=10G# 单个日志文件最大SystemMaxFileSize=200M# 日志保存时间MaxRetentionSec=2week# 不将日志转发到 syslogForwardToSyslog=noEOFsystemctl restart systemd-journald 1.7 安装Docker1234567891011121314151617181920212223242526yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 选取合适的docker版本, 默认安装最新版yum list docker-ce --showduplicates | sort -r yum update -y &amp;&amp; yum install -y docker-ce# 启动dockersystemctl start docker &amp;&amp; systemctl enable docker# 配置dockermkdir -p /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;, &quot;registry-mirrors&quot;: [&quot;https://pvjhx571.mirror.aliyuncs.com&quot;]&#125;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker 1.8 支持代理123456789mkdir -p /etc/systemd/system/docker.service.dcat &gt; /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt;EOF [Service] Environment=&quot;ALL_PROXY=socks5://192.168.31.20:1080/&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,docker.io,hub.elihe.io,pvjhx571.mirror.aliyuncs.com&quot;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker 1.9 开启远程访问1234567vi /etc/docker/daemon.json&#123; &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2357&quot;, &quot;unix:///var/run/docker.sock&quot;]&#125;# -H, --hostdocker -H 192.168.31.41 network show 2. Ubuntu1234567891011121314151617sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;sudo add-apt-repository --remove &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;sudo add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;sudo apt-get updatesudo apt-get install docker-ce# 避免执行docker命令使用sudo, 不使用sudo usermod -aG docker $USER 3. MacOS修改容器配置 1234567891011121314151617181920212223242526272829303132333435363738# 停止容器docker stop mysql-master# 获取容器Iddocker inspect mysql-master | grep -w &quot;Id&quot;# 进入docker虚拟镜像 (MacOS)cd ~/Library/Containers/com.docker.docker/Data/vms/0screen tty# 编辑配置文件cd /var/lib/docker/containers/2d8790feefd411d081791eef1b07b8499d72cd7a8d0f8af7b2e306f85305da52-rw------- 1 root root 3262 Jun 17 13:38 config.v2.json-rw-r--r-- 1 root root 1633 Jun 17 13:39 hostconfig.json# 退出docker镜像Ctrl-A-D# 查询screen进程，并彻底退出 （非常重要）screen -lsThere is a screen on: 47007.ttys007.MacPro (Detached)1 Socket in /var/folders/td/m3fv0wrd27d4ydwl5hdmqyjm0000gn/T/.screen.kill -9 47007screen -wipeThere is a screen on: 47007.ttys007.MacPro (Removed)1 socket wiped out.# 重启docker进程 (必须，否则修改的配置不生效)# 检查容器的配置是否已更新docker inspect mysql-master# 启动容器docker start mysql-master 4. 图形化管理工具12345docker volume create portainer_datadocker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainerhttp://192.168.31.30:9000 eli@1234","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Docker 简介","slug":"2018-06-10-Docker-简介","date":"2018-06-09T23:32:02.000Z","updated":"2021-06-22T10:50:49.714Z","comments":true,"path":"2018/06/10/2018-06-10-Docker-简介/","link":"","permalink":"https://elihe2011.github.io/2018/06/10/2018-06-10-Docker-%E7%AE%80%E4%BB%8B/","excerpt":"1. 什么是容器 一种虚拟化的方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖Linux内核特性：Namespace和Cgroups(Control Group) 2. 什么是Docker将应用程序自动部署到容器 Boot2Docker: 本质是一个Linux轻量级VM，用于Windows/macOS系统上使用Docker （开发、测试使用)","text":"1. 什么是容器 一种虚拟化的方案 操作系统级别的虚拟化 只能运行相同或相似内核的操作系统 依赖Linux内核特性：Namespace和Cgroups(Control Group) 2. 什么是Docker将应用程序自动部署到容器 Boot2Docker: 本质是一个Linux轻量级VM，用于Windows/macOS系统上使用Docker （开发、测试使用) 3. Docker的使用场景 使用Docker容器开发、测试、部署服务 创建隔离的运行环境 搭建测试环境 构建多用户的平台即服务(PaaS)基础设施 提供软件即服务(SaaS)应用程序 高性能、超大规模的宿主机部署 4. Docker的基本组成 Docker Client Docker Daemon Docker Image Docker Container Docker Registry Docker的三要素：仓库、镜像、容器 4.1 客户端/守护进程 C/S架构 本地/远端 4.2 Docker Image镜像 容器的基石 层叠的只读文件系统 联合加载(union mount) 镜像：多个镜像层 (Image Layer) 叠加而成的只读文件系统 (UnionFile System) bootfs: 最底层的文件系统，用于系统引导，包含bootloader和kernel，容器启动后会被卸载以节约内存资源 rootfs： 位于bootfs之上，为容器的根文件系统 传统模式：系统启动时，内核以“只读”模式挂载rootfs，完整性自检后，再重新挂载为“读写”模式 docker：rootfs由内核挂载为“只读”模式，而后通过“联合挂载”技术额外挂载一个“可写”层 4.3 Docker Container 容器 通过镜像启动 启动和执行阶段 写时复制(copy on write) 容器：在镜像的基础上，增加了一个读写层 (Top Layer)。运行状态下的容器，由一个可读写的文件系统、隔离的进程空间和进程构成。 4.4 Docker Registry 仓库 公有 私有 Docker Hub 5. Docker容器相关技术简介5.1 依赖的Linux内核特性 Namespaces 命名空间 Cgroups(Control Group) 控制组 5.1.1 Namespaces 容器的独立资源 Mount PID Net IPC UTS: Unix Time-Sharing, allow a single system to appear to have different host and domain names to different processes. User 5.1.2 CGroups 控制组 资源限制：对进程组使用的资源总额进行限制。如设定应用运行时使用内存的上限，一旦超过这个配额就发出OOM（Out of Memory） 优先级分配：通过分配cpu时间片数量及硬盘io，带宽大小来控制进程的优先级 资源统计：统计系统的资源使用量，如CPU使用量，内存用量等 进程控制：可以对进程组执行挂起、恢复等操作 5.2 Docker容器的能力 文件系统隔离 进程隔离 网络隔离 资源隔离和分组：使用cgroups将CPU和内存之类的资源，独立分配给每个Docker容器 5.3 LXC (Linux Containers)基于容器的操作系统级别的虚拟化技术，借助于namesapce的隔离机制和cgroups限额功能，LXC提供了一套统一的API和工具来建立和管理container。 LXC提供一个共享kernel的OS级虚拟化方法，在执行时不用重复加载kernel，且conatiner的kernel与host共享，因此大大加快了container的启动过程，并显著减少了内存消耗。 5.4 分成文件系统层状文件系统，当进程需要修改文件时，AUFS创建该文件的一个副本。 aufs: ubuntu, 未合入内核 devicemapper (dm): centos, 性能差 overlay: 合入内核，当前主流","categories":[{"name":"Docker","slug":"Docker","permalink":"https://elihe2011.github.io/categories/Docker/"}],"tags":[]},{"title":"Python urllib","slug":"Python urllib","date":"2018-06-01T03:12:17.000Z","updated":"2021-06-22T10:50:49.713Z","comments":true,"path":"2018/06/01/Python urllib/","link":"","permalink":"https://elihe2011.github.io/2018/06/01/Python%20urllib/","excerpt":"1. urllib.request1.1 urlopen直接打开url 123456response = request.urlopen(&#x27;http://www.baidu.com&#x27;)print(response.getcode()) # HTTP状态码print(response.info()) # META信息html = response.read()print(html) 对获取的内容进行解码 123response = request.urlopen(&#x27;http://www.baidu.com&#x27;)html = response.read().decode(&#x27;utf-8&#x27;)print(html) # 内容可读性增强","text":"1. urllib.request1.1 urlopen直接打开url 123456response = request.urlopen(&#x27;http://www.baidu.com&#x27;)print(response.getcode()) # HTTP状态码print(response.info()) # META信息html = response.read()print(html) 对获取的内容进行解码 123response = request.urlopen(&#x27;http://www.baidu.com&#x27;)html = response.read().decode(&#x27;utf-8&#x27;)print(html) # 内容可读性增强 自动获取网页编码 1234response = request.urlopen(&#x27;http://www.baidu.com&#x27;)html = response.read()charset = chardet.detect(html)print(charset) # &#123;&#x27;encoding&#x27;: &#x27;utf-8&#x27;, &#x27;confidence&#x27;: 0.99, &#x27;language&#x27;: &#x27;&#x27;&#125; 1.2 支持https全局取消证书验证 12345from urllib import requestimport ssl# 全局取消证书验证ssl._create_default_https_context = ssl._create_unverified_context 创建为验证的上下文，并在请求时传入 123456789101112from urllib import requestimport sslcontext = ssl._create_unverified_context()if __name__ == &#x27;__main__&#x27;: url = &#x27;https://www.csdn.net&#x27; req = request.Request(url) response = request.urlopen(req, context=context) html = response.read().decode(&#x27;utf8&#x27;) print(html) 1.3 伪造User-Agent12345678910111213141516from urllib import requestimport sslcontext = ssl._create_unverified_context()if __name__ == &#x27;__main__&#x27;: url = &#x27;https://www.csdn.net&#x27; req = request.Request(url) req.add_header(&#x27;User-Agent&#x27;, &#x27;Mozilla/5.0 (Linux; Android 4.1.1; Nexus 7 Build/JRO03D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.166 Safari/535.19&#x27;) print(req.header_items()) response = request.urlopen(req, context=context) html = response.read().decode(&#x27;utf8&#x27;) print(html) 1.4 使用代理创建代理 1234proxy_handler = request.ProxyHandler(proxies)opener = request.build_opener(proxy_handler)opener.addheaders = [(&#x27;User-Agent&#x27;, &#x27;xxx&#x27;), ]request.install_opener(opener) 1234567891011121314151617181920212223242526from urllib import requestimport chardetimport reimport sslssl._create_default_https_context = ssl._create_unverified_contextif __name__ == &#x27;__main__&#x27;: url = &#x27;https://ip.cn&#x27; proxies = &#123;&#x27;https&#x27;: &#x27;127.0.0.1:1087&#x27;&#125; proxy_handler = request.ProxyHandler(proxies) opener = request.build_opener(proxy_handler) opener.addheaders = [(&#x27;User-Agent&#x27;, &#x27;Mozilla/5.0 (Android; Mobile; rv:14.0) Gecko/14.0 Firefox/14.0&#x27;)] request.install_opener(opener) response = request.urlopen(url) data = response.read() encoding = chardet.detect(data)[&#x27;encoding&#x27;] print(encoding) html = data.decode(encoding) #print(html) regex = r&#x27;&lt;code&gt;(.*?)&lt;/code&gt;&#x27; result = re.findall(regex, html) print(result) 1.5 urlretrieve下载文件1234567891011121314151617181920212223from urllib import requestimport sslimport osssl._create_default_https_context = ssl._create_unverified_contextdef callback(blocks, block_size, total_size): percent = 100.0 * blocks * block_size / total_size if percent &gt; 100: percent = 100 print(&#x27;%.2f%%&#x27; % percent)if __name__ == &#x27;__main__&#x27;: url = &#x27;https://www.python.org/ftp/python/3.7.0/python-3.7.0-amd64-webinstall.exe&#x27; filename = os.path.join(os.path.dirname(__file__), &#x27;python3.7.exe&#x27;) # filename必须传入，否则是临时文件 filename_origin, headers = request.urlretrieve(url, filename=filename, reporthook=callback) print(headers) print(filename_origin) 1.6 cookie获取cookie信息 123456789101112131415161718192021222324from urllib import requestfrom http import cookiejarif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.baidu.com&#x27; cookie = cookiejar.CookieJar() handler = request.HTTPCookieProcessor(cookie) opener = request.build_opener(handler) request.install_opener(opener) response = request.urlopen(url) for item in cookie: print(item) # output&lt;Cookie BAIDUID=0AA570FEE28BD692F7FBEE143E909A11:FG=1 for .baidu.com/&gt;&lt;Cookie BIDUPSID=0AA570FEE28BD692F7FBEE143E909A11 for .baidu.com/&gt;&lt;Cookie H_PS_PSSID=1430_21081_26350_20927 for .baidu.com/&gt;&lt;Cookie PSTM=1538101592 for .baidu.com/&gt;&lt;Cookie delPer=0 for .baidu.com/&gt;&lt;Cookie BDSVRTM=0 for www.baidu.com/&gt;&lt;Cookie BD_HOME=0 for www.baidu.com/&gt; 保存cookie到文件 12345678910111213141516from urllib import requestfrom http import cookiejarif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.baidu.com&#x27; filename = &#x27;cookie.txt&#x27; cookie = cookiejar.MozillaCookieJar(filename) handler = request.HTTPCookieProcessor(cookie) opener = request.build_opener(handler) request.install_opener(opener) response = request.urlopen(url) cookie.save(ignore_discard=True, ignore_expires=True) 读取cookie文件 12345678910111213141516from urllib import requestfrom http import cookiejarif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.baidu.com&#x27; filename = &#x27;cookie.txt&#x27; cookie = cookiejar.MozillaCookieJar() cookie.load(filename, ignore_discard=True, ignore_expires=True) handler = request.HTTPCookieProcessor(cookie) opener = request.build_opener(handler) request.install_opener(opener) response = request.urlopen(url) print(response.read().decode(&#x27;utf8&#x27;)) 重点: CookieJar的继承关系：CookieJar -&gt; FileCookieJar -&gt; MozillaCookieJar request使用Cookie：handler = request.HTTPCookieProcessor(cookie) 2. urllib.parse请求参数编码 12form_data = &#123;&#x27;name&#x27;: &#x27;admin&#x27;, &#x27;passwd&#x27;: &#x27;123&#x27;&#125;data = parse.urlencode(form_data) 3. urllib.errorOSError –&gt; URLError –&gt; HTTPError 3.1 URLError访问不存在的链接 12345678910from urllib import request, errorif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.asssaa.com&#x27; req = request.Request(url) try: response = request.urlopen(req) except error.URLError as e: print(e.reason) 3.2 HTTPError访问不存在的页面 12345678910from urllib import request, errorif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.imac.ly/haha.html&#x27; req = request.Request(url) try: response = request.urlopen(req) except error.HTTPError as e: print(e.reason) 3.3 混用遵循原则：先捕获子错误（HTTPError)，在捕获父错误(URLError) 123456789101112from urllib import request, errorif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.imac.ly/haha.html&#x27; req = request.Request(url) try: response = request.urlopen(req) except error.HTTPError as e: print(e.code) except error.URLError as e: print(e.reason) 优化写法： 1234567891011121314from urllib import request, errorif __name__ == &#x27;__main__&#x27;: url = &#x27;http://www.imac.ly/haha.html&#x27; req = request.Request(url) try: response = request.urlopen(req) except error.URLError as e: if hasattr(e, &#x27;code&#x27;): print(e.code) # HTTPError if hasattr(e, &#x27;reason&#x27;): print(e.reason) # URLError 5. 实例使用youdao翻译。先分析有道翻译的URL和提交参数，然后构造相关请求 123456789101112131415161718192021222324252627282930313233from urllib import request, parseimport jsonif __name__ == &#x27;__main__&#x27;: #url = &#x27;http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule&#x27; url = &#x27;http://fanyi.youdao.com/translate&#x27; form_data = &#123; &#x27;i&#x27;: &#x27;jack&#x27;, &#x27;from&#x27;: &#x27;AUTO&#x27;, &#x27;to&#x27;: &#x27;AUTO&#x27;, &#x27;client&#x27;: &#x27;fanyideskweb&#x27;, &#x27;salt&#x27;: &#x27;1538030802893&#x27;, &#x27;sign&#x27;: &#x27;e15c78d65fedec11ae2e91c1d5b332dd&#x27;, &#x27;doctype&#x27;: &#x27;json&#x27;, &#x27;version&#x27;: &#x27;2.1&#x27;, &#x27;keyfrom&#x27;: &#x27;fanyi.web&#x27;, &#x27;action&#x27;: &#x27;FY_BY_REALTIME&#x27;, &#x27;typoResult&#x27;: &#x27;false&#x27;, &#125; form_data = &#123; &#x27;i&#x27;: &quot;C&#x27;est la vie&quot;, &#x27;doctype&#x27;: &#x27;json&#x27; &#125; data = parse.urlencode(form_data).encode(&#x27;utf8&#x27;) print(data) response = request.urlopen(url, data) html = response.read().decode(&#x27;utf8&#x27;) result = json.loads(html) print(result) 123456requests.post(&#x27;http://fanyi.youdao.com/translate&#x27;, data=&#123;&#x27;i&#x27;: &quot;C&#x27;est la vie&quot;, &#x27;doctype&#x27;: &#x27;json&#x27;&#125;).json()&#123;&#x27;type&#x27;: &#x27;FR2ZH_CN&#x27;, &#x27;errorCode&#x27;: 0, &#x27;elapsedTime&#x27;: 1, &#x27;translateResult&#x27;: [[&#123;&#x27;src&#x27;: &quot;C&#x27;est la vie&quot;, &#x27;tgt&#x27;: &#x27;这就是生活&#x27;&#125;]]&#125;","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"jQuery","slug":"jQuery","date":"2018-04-03T03:32:22.000Z","updated":"2021-06-22T10:50:49.713Z","comments":true,"path":"2018/04/03/jQuery/","link":"","permalink":"https://elihe2011.github.io/2018/04/03/jQuery/","excerpt":"$符号：jQuery的别名 1234window.jQuery; // jQuery(selector, context)window.$; // jQuery(selector, context)$ === jQuery; // truetypeof($); // &#x27;function&#x27;","text":"$符号：jQuery的别名 1234window.jQuery; // jQuery(selector, context)window.$; // jQuery(selector, context)$ === jQuery; // truetypeof($); // &#x27;function&#x27; 选择器： 基本选择器： 1) ID选择器 123var obj = $(&#x27;#id&#x27;); // jQuery对象var dom = obj.get(0); // 获取第一个DOM元素var obj2 = $(dom); // 将DOM包装成jQuery对象 2) 标签选择器 12var obj = $(&#x27;p&#x27;); // 所有&lt;p&gt;节点obj.length; 3) 类选择器 12var obj = $(&#x27;.red&#x27;); // class=&quot;red&quot;, class=&quot;red green&quot;var obj = $(&#x27;.red.green&#x27;) // class=&quot;red green&quot; 4) 属性选择器 123var obj = $(&#x27;[name=email]&#x27;); // &lt;? name=&quot;email&quot; ?&gt;var obj = $(&#x27;[name^=icon]&#x27;); // name=&quot;icon-1&quot;, name=&quot;icon-2&quot;var obj = $(&#x27;[name$=with]&#x27;); // name=&quot;startswith&quot;, name=&quot;endswith&quot; 5) 组合选择器 12var obj = $(&#x27;input[name=email]&#x27;); // &lt;input name=&quot;email&quot; /&gt;var obj = $(&#x27;tr.red&#x27;); // &lt;tr class=&quot;red&quot; ...&gt; 6) 多项选择器 12$(&#x27;p,div&#x27;);$(&#x27;p.red,p.green&#x27;); 层级选择器(Descendant Selector): 123$(&#x27;ul.lang li.lang-javascript&#x27;);$(&#x27;form[name=upload] input&#x27;);$(&#x27;form.test p input&#x27;); 子选择器(Child Selector): $(&#39;parent&gt;child&#39;) 1$(&#x27;ul.lang&gt;li.lang-javascript&#x27;); 过滤器(Filter): 12345678910$(&#x27;ul.lang li&#x27;);$(&#x27;ul.lang li:first-child&#x27;);$(&#x27;ul.lang li:last-child&#x27;);$(&#x27;ul.lang li:nth-child(2)&#x27;); // 第N个元素， start from 1$(&#x27;ul.lang li:nth-child(even)&#x27;);$(&#x27;ul.lang li:nth-child(odd)&#x27;);$(&#x27;div:visible&#x27;);$(&#x27;div.hiden&#x27;); 表单相关过滤器: 12345678:input &lt;input&gt;, &lt;textarea&gt;, &lt;select&gt;, &lt;button&gt;:file &lt;input type=&quot;file&quot; ..&gt;:checkbox:radio:focus 光标聚焦:checked $(&#x27;input[type=radio]:checked&#x27;):enabled:disabled 查找：find() 1234567891011var ul = $(&#x27;ul.lang&#x27;);var swift = ul.find(&#x27;#swift&#x27;);var parent = swift.parent();var li = swift.parent(&#x27;.red&#x27;);swift.next();swift.next(&#x27;[name=haskell]&#x27;);swift.prev();swift.prev(&#x27;.red&#x27;); 过滤：filter(), map() 1234567891011121314var langes = $(&#x27;ul.lang li&#x27;);var a = langes.filter(&#x27;.red&#x27;);var b - langes.filter(function () &#123; return this.innerHTML.indexOf(&#x27;S&#x27;) === 0; // 以S开头&#125;);var arr = langs.map(function() &#123; return this.innerHTML;&#125;).get();var js = langes.first();var haskell = langs.last();var sub = langs.slice(2, 4); form表单数据json化： 12345678910111213141516171819202122232425262728293031323334&lt;script src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;form id=&quot;test-form&quot; action=&quot;#0&quot; onsubmit=&quot;return false;&quot;&gt; &lt;p&gt;&lt;label&gt;Name: &lt;input name=&quot;name&quot;&gt;&lt;/label&gt;&lt;/p&gt; &lt;p&gt;&lt;label&gt;Email: &lt;input name=&quot;email&quot;&gt;&lt;/label&gt;&lt;/p&gt; &lt;p&gt;&lt;label&gt;Password: &lt;input name=&quot;password&quot; type=&quot;password&quot;&gt;&lt;/label&gt;&lt;/p&gt; &lt;p&gt;Gender: &lt;label&gt;&lt;input name=&quot;gender&quot; type=&quot;radio&quot; value=&quot;m&quot; checked&gt; Male&lt;/label&gt; &lt;label&gt;&lt;input name=&quot;gender&quot; type=&quot;radio&quot; value=&quot;f&quot;&gt; Female&lt;/label&gt;&lt;/p&gt; &lt;p&gt;&lt;label&gt;City: &lt;select name=&quot;city&quot;&gt; &lt;option value=&quot;BJ&quot; selected&gt;Beijing&lt;/option&gt; &lt;option value=&quot;SH&quot;&gt;Shanghai&lt;/option&gt; &lt;option value=&quot;CD&quot;&gt;Chengdu&lt;/option&gt; &lt;option value=&quot;XM&quot;&gt;Xiamen&lt;/option&gt; &lt;/select&gt;&lt;/label&gt;&lt;/p&gt; &lt;p&gt;&lt;button type=&quot;submit&quot; onclick=&quot;verify();&quot;&gt;Submit&lt;/button&gt;&lt;/p&gt;&lt;/form&gt;&lt;script&gt;function verify() &#123;var obj = &#123;&#125;;var inputs = $(&#x27;#test-form input, #test-form select&#x27;);console.log(inputs);inputs.filter(function () &#123; return this.type !== &#x27;radio&#x27; || this.checked;&#125;).map(function () &#123; obj[this.name] = this.value;&#125;);console.log(obj);return false;&#125;&lt;/script&gt; 操作DOM： 1) Text &amp; HTML 12345$(&#x27;ul.lang li[name=book]&#x27;).text();$(&#x27;ul.lang li[name=book]&#x27;).html();$(&#x27;ul.lang li[name=book]&#x27;).text(&#x27;ECMAScript&#x27;);$(&#x27;ul.lang li[name=book]&#x27;).html(&#x27;&lt;span style=&quot;color:red&quot;&gt;JavaScript&lt;/span&gt;&#x27;); 2) CSS 123456$(&#x27;ul.lang li[name=book]&#x27;).css(&#x27;background-color&#x27;);$(&#x27;ul.lang li[name=book]&#x27;).css(&#x27;background-color&#x27;, &#x27;#010101&#x27;);$(&#x27;ul.lang li[name=book]&#x27;).hasClass(&#x27;highlight&#x27;);$(&#x27;ul.lang li[name=book]&#x27;).addClass(&#x27;highlight&#x27;);$(&#x27;ul.lang li[name=book]&#x27;).removeClass(&#x27;highlight&#x27;); 3) 显示和隐藏 123var a = $(&#x27;a[target=_blank]&#x27;);a.hide();a.show(); 4) DOM信息 123456789101112131415161718$(window).width();$(window).height();$(document).width();$(document).height();div.width();div.height();div.width(200);div.height(&#x27;100px&#x27;);div.attr(&#x27;name&#x27;);div.attr(&#x27;name&#x27;, &#x27;hello&#x27;);div.removeAttr(&#x27;name&#x27;);radio.attr(&#x27;checked&#x27;); // checkedradio.prop(&#x27;checked&#x27;); // trueradio.is(&#x27;:checked&#x27;); // true 5) 表单 12345678input.val();input.val(&#x27;new value&#x27;);select.val();select.val(&#x27;Shanghai&#x27;);textarea.val();textarea.val(&#x27;Hi&#x27;); 6) 修改DOM 12345678910var li = document.createElement(&#x27;li&#x27;);li.text(&#x27;Python&#x27;);ul.append(li);ul.prepend(li);var li2 = $(&#x27;#java&#x27;);li2.after(li);li2.before(&#x27;&lt;span style=&quot;color:red&quot;&gt;Lua&lt;/span&gt;&#x27;);li2.remove(); jQuery事件鼠标事件click: 鼠标单击时触发； dblclick：鼠标双击时触发； mouseenter：鼠标进入时触发； mouseleave：鼠标移出时触发； mousemove：鼠标在DOM内部移动时触发； hover：鼠标进入和退出时触发两个函数，相当于mouseenter加上mouseleave。 键盘事件键盘事件仅作用在当前焦点的DOM上，通常是&lt;input&gt;和&lt;textarea&gt;。 keydown：键盘按下时触发； keyup：键盘松开时触发； keypress：按一次键后触发。 其他事件focus：当DOM获得焦点时触发； blur：当DOM失去焦点时触发； change：当&lt;input&gt;、&lt;select&gt;或&lt;textarea&gt;的内容改变时触发； submit：当&lt;form&gt;提交时触发； ready：当页面被载入并且DOM树完成初始化后触发。 123456789101112131415161718192021222324252627282930313233343536373839var a = $(&#x27;#link&#x27;);a.on(&#x27;click&#x27;, function () &#123; alert(&#x27;hello&#x27;);&#125;);a.click(function () &#123; alert(&#x27;hello&#x27;);&#125;);// DOM初始化$(document).ready(function () &#123; $(&#x27;#form&#x27;).submit(function () &#123; alert(&#x27;submit&#x27;); &#125;);&#125;);// 简写成$(function () &#123; console.log(&#x27;init A ...&#x27;);&#125;);// 事件参数$(function () &#123; $(&#x27;#div&#x27;).mousemove(function (e)&#123; $(&#x27;#div span&#x27;).text(&#x27;pageX = &#x27; + e.pageX + &#x27;, pageY = &#x27; + e.pageY); &#125;);&#125;);// 取消绑定function hello() &#123; alert(&#x27;hello&#x27;);&#125;a.click(hello);setTimeout(function () &#123; a.off(&#x27;click&#x27;, hello);&#125;, 10000); 动画123456789101112131415161718192021222324div.hide(3000);div.show();div.toggle();div.slideUp(); div.slideDown(2000); // 2sdiv.slideToggle();div.fadeIn(&#x27;slow&#x27;); // 0.6sdiv.fadeOut(1000); // 1sdiv.fadeToggle();// 自定义div.slideDown(2000) .delay(1000) .animate(&#123; width: &#x27;256px&#x27;, height: &#x27;256px&#x27; &#125;, 2000) .delay(1000) .animate(&#123; width: &#x27;128px&#x27;, height: &#x27;128px&#x27; &#125;, 2000); AJAX123456789101112131415161718var jqxhr = $.ajax(&#x27;/api/test&#x27;, &#123; dataType: &#x27;json&#x27;&#125;).done(function (data) &#123; console.log(&#x27;成功：&#x27; + JSON.stringify(data));&#125;).fail(function (xhr, status) &#123; console.log(&#x27;失败：&#x27; + xhr.status + &#x27;, 原因：&#x27; + status);&#125;).always(function () &#123; console.log(&#x27;请求完成&#x27;);&#125;)var jqxhr = $.get(&#x27;/api/doc&#x27;, &#123; id: 1&#125;);var jqxhr = $.post(&#x27;/api/doc&#x27;, &#123; title: &#x27;new doc&#x27;, content: &#x27;haha&#x27;&#125;)","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://elihe2011.github.io/categories/JavaScript/"}],"tags":[{"name":"js","slug":"js","permalink":"https://elihe2011.github.io/tags/js/"}]},{"title":"NodeJS","slug":"NodeJS","date":"2018-04-02T05:32:22.000Z","updated":"2021-06-22T10:50:49.713Z","comments":true,"path":"2018/04/02/NodeJS/","link":"","permalink":"https://elihe2011.github.io/2018/04/02/NodeJS/","excerpt":"1. 文件系统1.1 异步方式读取文件123456789var fs = require(&#x27;fs&#x27;);// var data = fs.readFileSync(&#x27;input.txt&#x27;);// console.log(data.toString());fs.readFile(&#x27;input.txt&#x27;, function (err, data) &#123; if (err) &#123; console.log(err); &#125; console.log(data.toString());&#125;);","text":"1. 文件系统1.1 异步方式读取文件123456789var fs = require(&#x27;fs&#x27;);// var data = fs.readFileSync(&#x27;input.txt&#x27;);// console.log(data.toString());fs.readFile(&#x27;input.txt&#x27;, function (err, data) &#123; if (err) &#123; console.log(err); &#125; console.log(data.toString());&#125;); 1.2 打开文件1234567891011var fs = require(&#x27;fs&#x27;);console.log(&#x27;准备打开文档&#x27;);fs.open(&#x27;../input.txt&#x27;, &#x27;r+&#x27;, function (err, fd) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;文档打开成功&#x27;);&#125;);// 同步方式：mode=rs+ 1.3 文件信息123456789var fs = require(&#x27;fs&#x27;);fs.stat(&#x27;../input.txt&#x27;, function (err, stats) &#123; if (err) &#123; return console.error(err); &#125; console.log(stats); console.log(stats.isFile());&#125;); 1.4 读写数据123456789101112131415var fs = require(&#x27;fs&#x27;);fs.writeFile(&#x27;output.txt&#x27;, &#x27;通过fs.writeFile写入文件&#x27;, function (err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;写入数据成功&#x27;); fs.readFile(&#x27;output.txt&#x27;, function(err, data) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;读取数据：&#x27; + data.toString()); &#125;);&#125;); 1.5 读取文件1234567891011121314151617181920212223242526272829var fs = require(&#x27;fs&#x27;);var buf = new Buffer.alloc(4096);console.log(&#x27;打开文档...&#x27;);fs.open(&#x27;output.txt&#x27;, &#x27;r+&#x27;, function (err, fd) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;文档打开成功&#x27;); console.log(&#x27;读取文档...&#x27;); fs.read(fd, buf, 0, buf.length, 0, function (err, bytes) &#123; if (err) &#123; return console.error(err); &#125; console.log(bytes + &#x27; 字节被读取&#x27;); if (bytes &gt; 0) &#123; console.log(buf.slice(0, bytes).toString()); &#125; fs.close(fd, function (err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;文档关闭成功&#x27;); &#125;); &#125;);&#125;); 1.6 截断文档12345678910111213141516171819202122232425262728293031var fs = require(&#x27;fs&#x27;);var buf = new Buffer.alloc(1024);fs.open(&#x27;output.txt&#x27;, &#x27;r+&#x27;, function (err, fd) &#123; if (err) &#123; return console.error(err); &#125; fs.ftruncate(fd, 10, function (err) &#123; if (err) &#123; return console.error(err); &#125; fs.read(fd, buf, 0, buf.length, 0, function (err, bytes) &#123; if (err) &#123; return console.error(err); &#125; if (bytes &gt; 0) &#123; console.log(buf.slice(0, bytes).toString()); &#125; fs.close(fd, function (err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;文件已关闭&#x27;); &#125;); &#125;); &#125;);&#125;); 1.7 创建和删除文件1234567891011121314151617181920212223242526272829var fs = require(&#x27;fs&#x27;);fs.link(&#x27;output.txt&#x27;, &#x27;new.txt&#x27;, function(err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;创建连接文件&#x27;); fs.stat(&#x27;new.txt&#x27;, function (err, stats) &#123; if (err) &#123; return console.error(err); &#125; console.log(stats.nlink); // 连接数 &#125;); fs.unlink(&#x27;new.txt&#x27;, function (err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;删除连接文件&#x27;); fs.stat(&#x27;output.txt&#x27;, function (err, stats) &#123; if (err) &#123; return console.error(err); &#125; console.log(stats.nlink); // 连接数 &#125;); &#125;);&#125;); 1.8 目录创建和删除12345678910111213141516var fs = require(&#x27;fs&#x27;);fs.mkdir(&#x27;mydir&#x27;, &#x27;600&#x27;, function (err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;目录创建成功&#x27;); fs.rmdir(&#x27;mydir&#x27;, function (err) &#123; if (err) &#123; return console.error(err); &#125; console.log(&#x27;目录删除成功&#x27;); &#125;);&#125;); 1.9 目录遍历1234567891011var fs = require(&#x27;fs&#x27;);fs.readdir(&#x27;/Users/eli/Node&#x27;, function (err, files) &#123; if (err) &#123; return console.error(err); &#125; files.forEach(function (file) &#123; console.log(file); &#125;);&#125;); EventEmitter 类123456789101112131415161718192021222324252627var events = require(&#x27;events&#x27;);var emitter = new events.EventEmitter();var listener1 = function () &#123; console.log(&#x27;监听1&#x27;);&#125;var listener2 = function () &#123; console.log(&#x27;监听2&#x27;);&#125;emitter.addListener(&#x27;test&#x27;, listener1);emitter.addListener(&#x27;test&#x27;, listener2);var count = emitter.listenerCount(&#x27;test&#x27;);console.log(&#x27;监听总数：&#x27;, count);emitter.emit(&#x27;test&#x27;);emitter.removeListener(&#x27;test&#x27;, listener1);console.log(&#x27;移除监听1&#x27;);var count = emitter.listenerCount(&#x27;test&#x27;);console.log(&#x27;监听总数：&#x27;, count);emitter.emit(&#x27;test&#x27;); Buffer类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546buf = Buffer.alloc(10); // 10个0x0buf = Buffer.alloc(10, 14); // 0xebuf = Buffer.allocUnsafe(10); // 不覆盖填充内存地址buf.length // 10buf = Buffer.from([1, 2, 3]); // 0x1 0x2 0x3buf = Buffer.from(&#x27;tést&#x27;); // 0x74, 0xc3, 0xa9, 0x73, 0x74buf = Buffer.alloc(100);len = buf.write(&#x27;中文&#x27;); // 6buf.toString(&#x27;utf8&#x27;, 0, 6); // &#x27;中文&#x27;const buf = Buffer.from([0x1, 0x2, 0x3, 0x4]);const json = JSON.stringify(buf);console.log(json);const copy = JSON.parse(json, (key, value) =&gt; &#123; return value &amp;&amp; value.type === &#x27;Buffer&#x27; ? Buffer.from(value.data) : value;&#125;);console.log(copy);buf1 = Buffer.from(&#x27;中文&#x27;);buf2 = Buffer.from(&#x27;English&#x27;);buf3 = Buffer.concat([buf1, buf2]);buf3.toString();buf1 = Buffer.from(&#x27;中文&#x27;);buf2 = Buffer.from(&#x27;英文&#x27;);result = Buffer.compare(buf1, buf2); // -1// 奇葩的地方，buf1.copy(buf2, 2)，从buf2的第3位开始，使用buf1替换buf1 = Buffer.from(&#x27;123&#x27;);buf2 = Buffer.from(&#x27;abcdefg&#x27;);buf1.copy(buf2, 2); // 返回3，表示替换了三位buf2.toString() // &#x27;ab123fg&#x27;// 切片操作buf1 = Buffer.from(&#x27;abcdef&#x27;);buf2 = buf1.slice(2, 4); // [start, end)buf2.toString(); // &#x27;cd&#x27; Stream: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 1. 读入流var fs = require(&#x27;fs&#x27;);var data = &#x27;&#x27;;var readStream = fs.createReadStream(&#x27;input.txt&#x27;);readStream.setEncoding(&#x27;utf8&#x27;);// 处理流事件 --&gt; data, end, errorreadStream.on(&#x27;data&#x27;, function (chunk) &#123; data += chunk;&#125;);readStream.on(&#x27;end&#x27;, function () &#123; console.log(data);&#125;);readStream.on(&#x27;error&#x27;, function (err) &#123; console.log(err.stack);&#125;);console.log(&#x27;程序执行完毕&#x27;);// 2. 写入流var fs = require(&#x27;fs&#x27;);var data = &#x27;待写入的字符&#x27;var writeStream = fs.createWriteStream(&#x27;output.txt&#x27;);writeStream.write(data, &#x27;utf8&#x27;);// 标记文件末尾writeStream.end();// 完成写入writeStream.on(&#x27;finish&#x27;, function () &#123; console.log(&#x27;写入完成&#x27;);&#125;);writeStream.on(&#x27;error&#x27;, function (err) &#123; console.log(err.stack);&#125;);console.log(&#x27;程序执行完毕&#x27;);// 3. 管道流var fs = require(&#x27;fs&#x27;);readStream = fs.createReadStream(&#x27;input.txt&#x27;);writeStream = fs.createWriteStream(&#x27;output.txt&#x27;);readStream.pipe(writeStream);console.log(&#x27;文件复制完毕&#x27;);// 4. 链式流var fs = require(&#x27;fs&#x27;);var zlib = require(&#x27;zlib&#x27;);fs.createReadStream(&#x27;input.txt&#x27;) .pipe(zlib.createGzip()) .pipe(fs.createWriteStream(&#x27;input.txt.gz&#x27;));console.log(&#x27;文件压缩完毕&#x27;);var fs = require(&#x27;fs&#x27;);var zlib = require(&#x27;zlib&#x27;);fs.createReadStream(&#x27;input.txt.gz&#x27;) .pipe(zlib.createGunzip()) .pipe(fs.createWriteStream(&#x27;123.txt&#x27;));console.log(&#x27;解压文件完毕&#x27;); 模块系统： 123456789101112131415161718192021222324252627282930// 1. 直接导入// hello.jsexports.world = function () &#123; console.log(&#x27;Hello World!&#x27;);&#125;// main.jsvar hello = require(&#x27;./hello&#x27;);hello.world();// 2. 模块方式导入, module.exports = function () &#123;&#125;// hello.jsfunction Hello() &#123; this.setName = function (name) &#123; this.name = name; &#125;; this.sayHello = function () &#123; console.log(&#x27;Hello,&#x27;, this.name); &#125;;&#125;module.exports = Hello;// main.jsvar Hello = require(&#x27;./hello&#x27;);hello = new Hello();hello.setName(&#x27;John&#x27;);hello.sayHello(); 实现HTTP服务： 12345678var http = require(&#x27;http&#x27;);http.createServer(function (request, response) &#123; response.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/plain&#x27;&#125;); response.end(&#x27;Hello World!\\n&#x27;);&#125;).listen(8888);console.log(&#x27;Server running at http://localhost:8888&#x27;); 123456789101112131415161718192021222324252627282930313233343536// router.jsfunction route(pathname) &#123; console.log(&#x27;About to route a request for&#x27;, pathname);&#125;exports.route = route;// server.jsvar http = require(&#x27;http&#x27;);var url = require(&#x27;url&#x27;);function start(route) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(&#x27;Request for &#x27; + pathname + &#x27; received.&#x27;); route(pathname); response.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/plain&#x27;&#125;); response.write(&#x27;Hello World!\\n&#x27;); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(&#x27;Server running at http://localhost:8888&#x27;);&#125;exports.start = start;// index.jsvar server = require(&#x27;./server&#x27;);var router = require(&#x27;./router&#x27;);server.start(router.route); 全局对象： 12345678910111213141516171819202122232425262728293031323334353637383940414243console.log(__filename);console.log(__dirname);timer = setTimeout(function () &#123; console.log(&#x27;hello world!&#x27;);&#125;, 2000);// 取消定时器clearTimeout(timer);repeat = setInterval(function () &#123; console.log(&#x27;haha&#x27;);&#125;, 5);clearInterval(repeat);process.on(&#x27;exit&#x27;, function(code) &#123; setTimeout(function() &#123; console.log(&#x27;该代码不会执行&#x27;); &#125;, 2000); console.log(&#x27;退出码:&#x27;, code);&#125;);console.log(&#x27;执行完毕&#x27;);process.stdout.write(&#x27;Hello World!\\n&#x27;);process.argv.forEach(function(val, index, array) &#123; console.log(index + &quot;: &quot; + val);&#125;);console.log(&#x27;执行程序路径：&#x27; + process.execPath);console.log(&#x27;平台信息：&#x27; + process.platform);console.log(&#x27;当前目录：&#x27; + process.cwd());console.log(&#x27;当前版本：&#x27; + process.version);console.log(&#x27;内存使用情况:&#x27;);console.log(process.memoryUsage()); 工具类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 1. 继承var util = require(&#x27;util&#x27;);function Base() &#123; this.name = &#x27;base&#x27;; this.base = 1991; this.sayHello = function () &#123; console.log(&#x27;Hello &#x27; + this.name); &#125;;&#125;Base.prototype.showName = function() &#123; console.log(this.name);&#125;;function Sub() &#123; this.name = &#x27;sub&#x27;;&#125;util.inherits(Sub, Base);var objBase = new Base();objBase.showName();objBase.sayHello();console.log(objBase);var objSub = new Sub();objSub.showName();//objSub.sayHello(); // 只能继承prototype定义的函数，不能继承父类构造函数只能够定义的属性和方法console.log(objSub);// 2. 检查var util = require(&#x27;util&#x27;);function Person() &#123; this.name = &#x27;john&#x27;; this.toString = function() &#123; return this.name; &#125;;&#125;var obj = new Person();console.log(util.inspect(obj));console.log(util.inspect(obj, true));// 3. 类型判断util.isArray([]);util.isArray(new Array);util.isArray(&#123;&#125;);util.isRegExp(/some regexp/);util.isRegExp(new RegExp(&#x27;another regexp&#x27;));util.isRegExp(&#123;&#125;);util.isDate(new Date());util.isDate(&#123;&#125;);util.isError(new Error());util.isError(new TypeError());util.isError(&#123;&#125;); 处理GET和POST方法1 GET12345678910111213141516var http = require(&#x27;http&#x27;);var url = require(&#x27;url&#x27;);var util = require(&#x27;util&#x27;);http.createServer(function (req, res) &#123; res.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/plain; charset=utf8&#x27;&#125;); res.write(util.inspect(url.parse(req.url, true))); var params = url.parse(req.url, true).query; res.write(&#x27;\\n&#x27;); res.write(&#x27;网站名: &#x27; + params.name); res.write(&#x27;\\n&#x27;); res.write(&#x27;网站URL: &#x27; + params.url); res.end();&#125;).listen(8888); 2 POST12345678910111213141516171819202122232425262728293031323334var http = require(&#x27;http&#x27;);var querystring = require(&#x27;querystring&#x27;);var postHtml = &#x27;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf8&quot;&gt;&#x27; + &#x27;&lt;title&gt;post test&lt;/title&gt;&lt;/head&gt;&#x27; + &#x27;&lt;body&gt;&#x27; + &#x27;&lt;form method=&quot;POST&quot;&gt;&#x27; + &#x27;网站名: &lt;input name=&quot;name&quot;&gt;&lt;br&gt;&#x27; + &#x27;网站URL: &lt;input name=&quot;url&quot;&gt;&lt;br&gt;&#x27; + &#x27;&lt;input type=&quot;submit&quot;&gt;&#x27; + &#x27;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;&#x27;;http.createServer(function (req, res) &#123; var body = &#x27;&#x27;; req.on(&#x27;data&#x27;, function (chunk) &#123; body += chunk; &#125;); req.on(&#x27;end&#x27;, function () &#123; body = querystring.parse(body); res.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/html; charset=utf8&#x27;&#125;); if (body.name &amp;&amp; body.url) &#123; res.write(&#x27;网站名: &#x27; + body.name); res.write(&#x27;&lt;br&gt;&#x27;); res.write(&#x27;网站URL: &#x27; + body.url); &#125; else &#123; res.write(postHtml); &#125; res.end(); &#125;); &#125;).listen(8888); 服务端和客户端1 server.js12345678910111213141516171819202122232425var http = require(&#x27;http&#x27;);var fs = require(&#x27;fs&#x27;);var url = require(&#x27;url&#x27;);http.createServer(function (request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(&#x27;Request for &#x27; + pathname + &#x27; received.&#x27;); if (pathname === &#x27;/&#x27;) &#123; pathname = &#x27;/index.html&#x27;; &#125; fs.readFile(pathname.substr(1), function (err, data) &#123; if (err) &#123; console.log(err); response.writeHead(404, &#123;&#x27;Content-Type&#x27;: &#x27;text/html&#x27;&#125;); &#125; else &#123; response.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/html&#x27;&#125;); response.write(data.toString()); &#125; response.end(); &#125;);&#125;).listen(3000);console.log(&#x27;Server running at http://localhost:3000&#x27;); 2 client.js123456789101112131415161718192021var http = require(&#x27;http&#x27;);var options = &#123; host: &#x27;localhost&#x27;, port: &#x27;3000&#x27;, path: &#x27;/index.html&#x27;,&#125;;var callback = function(response) &#123; var body = &#x27;&#x27;; response.on(&#x27;data&#x27;, function(data) &#123; body += data; &#125;); response.on(&#x27;end&#x27;, function() &#123; console.log(body); &#125;);&#125;;var req = http.request(options, callback);req.end();","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://elihe2011.github.io/categories/JavaScript/"}],"tags":[{"name":"js","slug":"js","permalink":"https://elihe2011.github.io/tags/js/"}]},{"title":"JavaScript知识点","slug":"JavaScript","date":"2018-04-01T05:32:22.000Z","updated":"2021-06-22T10:50:49.712Z","comments":true,"path":"2018/04/01/JavaScript/","link":"","permalink":"https://elihe2011.github.io/2018/04/01/JavaScript/","excerpt":"1. 基础知识点类型判断： 123var x = 1;typeof x === &#x27;number&#x27;","text":"1. 基础知识点类型判断： 123var x = 1;typeof x === &#x27;number&#x27; 函数可变参数 函数允许接收任意参数，用arguments来获取所有参赛，可使用...rest来接收未命名的参数 function(a, b, ...rest) &#123; &#125; 全局作用域 JavaScript默认有一个全局对象window，全局作用域的变量实际上被绑定到window的一个属性 var和let（ES6)： 全局作用域，let不会成为全局对象window的属性 函数作用域：一致 块作用域：let只在for循环中可用 同一个变量名：let不支持重新声明 不管是var还是let，预编译过程中，都发生了变量提升，但与var不同的是，ES6对let进行了约束，其规定，在真正的词法变量声明之前，以任何方式访问let变量都是不允许的， const (ES6): 声明常量 绑定方法： func.apply(obj, args) 123456789101112function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var user = &#123; name: &#x27;Jack&#x27;, birth: 1990&#125;;var a = getAge.apply(user, [])console.log(a); apply()把参数打包成Array再传入；call()把参数按顺序传入。 123var a = Math.max.apply(null, [3, 2, 5, 1])var b = Math.max.call(null, 3, 2, 5, 1) 装饰器： 12345678910111213var count = 0;var oldParseInt = parseInt;parseInt = function() &#123; count += 1; return oldParseInt.apply(null, arguments);&#125;console.log(count);parseInt(&#x27;10&#x27;);parseInt(&#x27;20&#x27;);parseInt(&#x27;30&#x27;);console.log(count); 123456789101112131415arr.map(func)arr.reduce(func)arr.filter(func)arr.sort(func)arr.every(func)arr.find(func)arr.findIndex(func)arr.forEach(func) // 与map相同，但不返回数组 String转换为Number: 123456789parseInt(num); // 默认方式 (没有基数) parseInt(num, 10); // 传入基数 (十位数) parseFloat(num) // 浮点数 Number(num); // Number 构造器 ~~num //按位非 num / 1 // 除一个数 num * 1 // 乘一个数 num - 0 // 减去0 +num // 一元运算符 &quot;+&quot; 123456789typeof 123; // &#x27;number&#x27;typeof NaN; // &#x27;number&#x27;typeof &#x27;str&#x27;; // &#x27;string&#x27;typeof true; // &#x27;boolean&#x27;typeof undefined; // &#x27;undefined&#x27;typeof Math.abs; // &#x27;function&#x27;typeof null; // &#x27;object&#x27;typeof []; // &#x27;object&#x27;typeof &#123;&#125;; // &#x27;object&#x27; 不要使用new Number()、new Boolean()、new String()创建包装对象； 用parseInt()或parseFloat()来转换任意类型到number； 用String()来转换任意类型到string，或者直接调用某个对象的toString()方法； 通常不必把任意类型转换为boolean再判断，因为可以直接写if (myVar) {…}； typeof操作符可以判断出number、boolean、string、function和undefined； 判断Array要使用Array.isArray(arr)； 判断null请使用myVar === null； 判断某个全局变量是否存在用typeof window.myVar === ‘undefined’； 函数内部判断某个变量是否存在用typeof myVar === ‘undefined’。 12345var a = new Number(&#x27;123&#x27;);var b = Number(&#x27;123&#x27;);console.log(typeof a); // objectconsole.log(typeof b); // number 数字的toString()方法 1234567var a = (123).toString();var b = 123..toString();var c = new Number(123).toString()console.log(typeof a); console.log(typeof b); console.log(typeof c); 正则表达式： 12var re1 = /ABC-001/;var re2 = new RegExp(&#x27;ABC\\-001&#x27;); 1234567var re = /(\\d&#123;3&#125;)-(\\d&#123;3,8&#125;)/;var a = &#x27;010-1211112&#x27;;var b = &#x27;021-1221211&#x27;;var c = re.exec(a);var d = re.exec(b); 123456var re1 = /^(\\d+)(0*)$/;var re2 = /^(\\d+?)(0*)$/;var s = &#x27;1200100&#x27;;var a = re1.exec(s);var b = re2.exec(s); 1234567891011121314151617var s = &#x27;JavaScript, VBScript, JScript and ECMAScript&#x27;;var re=/[a-zA-Z]+Script/g;// 使用全局匹配:re.exec(s); // [&#x27;JavaScript&#x27;]re.lastIndex; // 10re.exec(s); // [&#x27;VBScript&#x27;]re.lastIndex; // 20re.exec(s); // [&#x27;JScript&#x27;]re.lastIndex; // 29re.exec(s); // [&#x27;ECMAScript&#x27;]re.lastIndex; // 44re.exec(s); // null，直到结束仍没有匹配到 json序列化：JSON.stringify(obj) json反序列化：JSON.parse(json) 12345var s = JSON.stringify(obj);console.log(s);var obj2 = JSON.parse(s);console.log(obj2); js里所有的对象都有__**proto__**属性(对象，函数)，指向构造该对象的构造函数的原型。 只有函数function才具有prototype属性。这个属性是一个指针，指向一个对象，这个对象的用途就是包含所有实例共享的属性和方法（我们把这个对象叫做原型对象）。原型对象也有一个属性，叫做constructor，这个属性包含了一个指针，指回原构造函数。 继承关系： 123456789// B继承AB.proto = A;// C继承Avar C = function (name) &#123; var obj = Object.create(A); obj.name = name; return obj;&#125; (&#x27;c&#x27;); 原型链: var arr = [1, 2, 3]; arr —-&gt; Array.prototype —-&gt; Object.prototype —-&gt; null 构造函数： 12345678910111213141516171819202122function Student(name) &#123; this.name = name; this.run = function () &#123; console.log(&#x27;my name is &#x27; + this.name); return this.name.toUpperCase(); &#125;&#125;var john = new Student(&#x27;john&#x27;);console.log(john.run()); var a = john.constructor === Student.prototype.constructor;console.log(a); // truevar b = Student.prototype.constructor === Student;console.log(b); // truevar c = Object.getPrototypeOf(john) === Student.prototypeconsole.log(c); // truevar d = john instanceof Student;console.log(d); // true 绑定方法： 1234567891011function Student(name) &#123; this.name = name;&#125;Student.prototype.hello = function () &#123; console.log(&#x27;hello, &#x27; + this.name);&#125;var tom = new Student(&#x27;tom&#x27;);tom.hello(); 原型继承： 1234567891011121314151617181920212223242526272829303132// 实现继承的函数function inherits(Child, Parent) &#123; var F = function () &#123;&#125;; F.prototype = Parent.prototype; Child.prototype = new F(); Child.prototype.constructor = Child;&#125;function Person(props) &#123; this.name = props.name || &#x27;Unknow&#x27;; this.age = props.age || 0;&#125;Person.prototype.say = function () &#123; return &#x27;hello, &#x27; + this.name;&#125;function Student(props) &#123; Person.call(this, props); this.grade = props.grade || 1;&#125;// 实现原型继承链inherits(Student, Person);Student.prototype.getGrade = function () &#123; return this.grade;&#125;var tom = new Student(&#123;name: &#x27;tom&#x27;, age: 12, grade: 5&#125;);console.log(tom.say());console.log(tom.getGrade()); JavaScript的原型继承实现方式就是： 定义新的构造函数，并在内部用call()调用希望“继承”的构造函数，并绑定this； 借助中间函数F实现原型链继承，最好通过封装的inherits函数完成； 继续在新的构造函数的原型上定义新方法。 类继承： 12345678910111213141516171819202122232425class Person &#123; constructor (props) &#123; this.name = props.name; this.age = props.age; &#125; say() &#123; return &#x27;hello, &#x27; + this.name; &#125;&#125;class Student extends Person &#123; constructor (props) &#123; super(props); this.grade = props.grade; &#125; getGrade() &#123; return this.grade; &#125;&#125;var tom = new Student(&#123;name: &#x27;tom&#x27;, age: 12, grade: 5&#125;);console.log(tom.say());console.log(tom.getGrade()); 浏览器对象： window: 浏览器窗口 123window.innerWidthwindow.innerHeight navigator: 浏览器信息 12345navigator.appNamenavigator.appVersionnavigator.platformnavigator.languagenavigator.userAgent screen: 屏幕信息 12screen.widthscreen.height location: 操作URL 123456789location.urllocation.protocollocation.hostlocation.portlocation.pathnamelocation.search // ?id=1&amp;name=abclocation.hashlocation.reload(); document: 当前页面 123456document.titledocument.getElementByID()document.GetElementsByTagName()document.cookie // 为了确保安全，服务器端在设置Cookie时，应该始终坚持使用httpOnly, 此时js无法读取 history: 历史记录 12history.back()history.forward() 操作DOM： 获取DOM节点： 123456789101112document.getElementByID();document.getElementsByTagName()document.getElementsByClassName() // CSS选择器名字// 子节点node.children; // 直属子节点node.firstElementChild;node.lastElementChild;// 通过选择器var q1 = document.querySelector(&#x27;#q1&#x27;);var ps = q1.querySelectorAll(&#x27;div.highlighted &gt; p&#x27;); 1234567&lt;div class=&quot;c-red c-green&quot;&gt; &lt;p&gt;Python&lt;/p&gt; &lt;p&gt;Ruby&lt;/p&gt; &lt;p&gt;Swift&lt;/p&gt;&lt;/div&gt;var arr = document.querySelectorAll(&#x27;.c-red.c-green &gt; p&#x27;); 更新DOM： 1234567891011var p = document.getElementById(&#x27;p-id&#x27;);p.innerHTML = &#x27;ABC &lt;span style=&quot;color:red&quot;&gt;RED&lt;/span&gt; XYZ&#x27;;p.innerText = &#x27;&lt;script&gt;alert(&quot;Hi&quot;)&lt;/script&gt;&#x27; // 不返回隐藏文本p.textContent = &#x27;&lt;script&gt;alert(&quot;Hi&quot;)&lt;/script&gt;&#x27; // 返回隐藏文本// 修改节点属性p.style.color = &#x27;#ff0000&#x27;;p.style.fontSize = &#x27;20px&#x27;;p.style.paddingTop = &#x27;2em&#x27;; 插入DOM：appendChild, insertBefore 12345678910var div = document.getElementById(&#x27;div-id&#x27;);var java = document.createElement(&#x27;p&#x27;);node.id = &#x27;java&#x27;node.innerHTML = &#x27;Java&#x27;div.appendChild(node);var ref = document.getElementById(&#x27;python&#x27;);div.insertBefore(java, ref); 修改DOM： 12345678910111213141516171819202122232425262728293031&lt;ol id=&quot;test-list&quot;&gt; &lt;li class=&quot;lang&quot;&gt;Scheme&lt;/li&gt; &lt;li class=&quot;lang&quot;&gt;JavaScript&lt;/li&gt; &lt;li class=&quot;lang&quot;&gt;Python&lt;/li&gt; &lt;li class=&quot;lang&quot;&gt;Ruby&lt;/li&gt; &lt;li class=&quot;lang&quot;&gt;Haskell&lt;/li&gt;&lt;/ol&gt;&lt;script&gt;var nodeList = document.querySelectorAll(&#x27;.lang&#x27;);var arr = [];nodeList.forEach((element) =&gt; &#123;arr.push(element)&#125;);arr.sort(function (x, y) &#123; a = x.innerText.toLowerCase(); b = y.innerText.toLowerCase(); if (a &gt; b) &#123; return 1; &#125; else if (a &lt; b) &#123; return -1; &#125; else &#123; return 0; &#125;&#125;);var node = document.getElementById(&#x27;test-list&#x27;);node.innerHTML = &#x27;&#x27;;arr.forEach((element) =&gt; &#123;node.appendChild(element)&#125;);&lt;/script&gt; 删除DOM：removeChild() 123456789101112131415161718&lt;ul id=&quot;test-list&quot;&gt; &lt;li&gt;JavaScript&lt;/li&gt; &lt;li&gt;Swift&lt;/li&gt; &lt;li&gt;HTML&lt;/li&gt; &lt;li&gt;ANSI C&lt;/li&gt; &lt;li&gt;CSS&lt;/li&gt; &lt;li&gt;DirectX&lt;/li&gt;&lt;/ul&gt;var ul = document.getElementById(&#x27;test-list&#x27;);var nodes = ul.children;for (let i = 0; i &lt; nodes.length; i++) &#123; var text = nodes[i].innerText; if (text !== &#x27;JavaScript&#x27; &amp;&amp; text !== &#x27;HTML&#x27; &amp;&amp; text !== &#x27;CSS&#x27;) &#123; ul.removeChild(nodes[i]); &#125; &#125; 表单验证： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;form id=&quot;test-register&quot; action=&quot;#&quot; target=&quot;_blank&quot; onsubmit=&quot;return checkRegisterForm()&quot;&gt; &lt;p id=&quot;test-error&quot; style=&quot;color:red&quot;&gt;&lt;/p&gt; &lt;p&gt; 用户名: &lt;input type=&quot;text&quot; id=&quot;username&quot; name=&quot;username&quot;&gt; &lt;/p&gt; &lt;p&gt; 口令: &lt;input type=&quot;password&quot; id=&quot;password&quot; name=&quot;password&quot;&gt; &lt;/p&gt; &lt;p&gt; 重复口令: &lt;input type=&quot;password&quot; id=&quot;password-2&quot;&gt; &lt;/p&gt; &lt;p&gt; &lt;button type=&quot;submit&quot;&gt;提交&lt;/button&gt; &lt;button type=&quot;reset&quot;&gt;重置&lt;/button&gt; &lt;/p&gt;&lt;/form&gt;&lt;script&gt;var checkRegisterForm = function () &#123; var error = document.getElementById(&#x27;test-error&#x27;); var username = document.getElementById(&#x27;username&#x27;).value; var reg = /[A-Za-z0-9]&#123;3,10&#125;/; if (!reg.test(username)) &#123; error.innerText = &#x27;用户名必须是3-10位英文字母或数字&#x27;; return false; &#125; var password = document.getElementById(&#x27;password&#x27;).value; if (password.length &lt; 6 || password.length &gt; 20) &#123; error.innerText = &#x27;口令必须是6-20位&#x27;; return false; &#125; var password2 = document.getElementById(&#x27;password-2&#x27;).value; if (password !== password2) &#123; error.innerText = &#x27;两次输入口令必须一致&#x27;; return false; &#125; error.innerText = &#x27;&#x27;; return true;&#125;&lt;/script&gt; AJAX: Asynchronous JavaScript and XML XMLHttpRequest 12345678910111213141516171819202122232425262728293031323334353637&lt;textarea id=&quot;test-response-text&quot;&gt; &lt;/textarea&gt;&lt;script&gt;function success(text) &#123; var textarea = document.getElementById(&#x27;test-response-text&#x27;); textarea.value = text;&#125;function failure(code) &#123; var textarea = document.getElementById(&#x27;test-response-text&#x27;); textarea.value = &#x27;Error code: &#x27; + code;&#125;var request = new XMLHttpRequest(); // AJAX请求request.onreadystatechange = function () &#123; // 收到HTTP响应 if (request.readyState === 4) &#123; if (request.status === 200) &#123; return success(request.responseText); &#125; else &#123; return failure(request.status); &#125; &#125; else &#123; // 等待HTTP响应 &#125;&#125;// 发送请求request.open(&#x27;GET&#x27;, &#x27;/api/categories&#x27;);request.send();console.log(&#x27;请求已发送，等待响应...&#x27;);&lt;/script&gt; CORS: Cross-Origin Resource Sharing，HTML5规范定义的如何跨域访问资源。 浏览器收到响应后，首先检查Access-Control-Allow-Origin是否包含本域，如果是，则此次跨域请求成功，如果不是，则请求失败，JavaScript将无法获取到响应的任何数据。 Promise: 12345678910111213141516171819function test(resolve, reject) &#123; var timeout = Math.random() * 2; console.log(&#x27;set timeout to: &#x27; + timeout + &#x27; seconds.&#x27;); setTimeout(function() &#123; if (timeout &lt; 1) &#123; console.log(&#x27;call resolve()...&#x27;); resolve(&#x27;200 OK&#x27;); &#125; else &#123; console.log(&#x27;call reject()...&#x27;); reject(&#x27;timeout in &#x27; + timeout + &#x27; seconds&#x27;); &#125; &#125;, timeout * 1000);&#125;new Promise(test).then(function (result) &#123; console.log(&#x27;成功: &#x27; + result);&#125;).catch(function (reason) &#123; console.log(&#x27;失败: &#x27; + reason);&#125;); 并行异步任务： 1) 相互依赖Promise.all([p1, p2]) 123456789101112var p1 = new Promise(function (resolve, reject) &#123; setTimeout(resolve, 500, &#x27;P1&#x27;);&#125;);var p2 = new Promise(function (resolve, reject) &#123; setTimeout(resolve, 600, &#x27;P2&#x27;);&#125;);// 同时执行，全部完成后执行thenPromise.all([p1, p2]).then(function (results) &#123; console.log(results);&#125;) 2)相互竞争，丢弃失败者 Promise.race([p1, p2]) 123456789101112var p1 = new Promise(function (resolve, reject) &#123; setTimeout(resolve, 500, &#x27;P1&#x27;);&#125;);var p2 = new Promise(function (resolve, reject) &#123; setTimeout(resolve, 600, &#x27;P2&#x27;);&#125;);// 同时执行，先执行完的返回Promise.race([p1, p2]).then(function (result) &#123; console.log(result);&#125;) 2. 补充说明1. 输出 1234567window.alert(5 + 6); // alert(5 + 6);document.getElementById(&quot;demo&quot;).innerHTML = &quot;段落已修改。&quot;;document.write(Date());console.log(5 + 6); 2. var var num=1: 变量声明，带不可删除属性，无法删除； num = 1: 声明window的一个属性，可删除。 3. 数据类型 值类型(基本类型)：字符串（String）、数字(Number)、布尔(Boolean)、对空（Null）、未定义（Undefined）、Symbol（表示独一无二的值）。 引用数据类型：对象(Object)、数组(Array)、函数(Function)。 123456789101112131415161718192021// Arrayvar cars=new Array();cars[0]=&quot;Saab&quot;;cars[1]=&quot;Volvo&quot;;cars[2]=&quot;BMW&quot;;var cars=new Array(&quot;Saab&quot;,&quot;Volvo&quot;,&quot;BMW&quot;); // condensed arrayvar cars=[&quot;Saab&quot;,&quot;Volvo&quot;,&quot;BMW&quot;]; // literal array// Objectvar person = &#123; firstName: &quot;John&quot;, lastName : &quot;Doe&quot;, id : 5566, fullName : function() &#123; return this.firstName + &quot; &quot; + this.lastName; &#125;&#125;; 4. 常见DOM事件 onchange onclick onmouseover onmouseout onkeydown onload (完成页面加载) 自定义事件： 12element.addEventListener(event, function, [useCapture])element.removeEventListener(event, function, [useCapture]) 5. 字符串 12345678910var x = &quot;John&quot;;var y = new String(&quot;John&quot;); // 勿使用，开销大typeof x // 返回 Stringtypeof y // 返回 Objectx === y // false// 属性x.lengthx.prototype // 向对象添加属性和方法 6.null &amp; undefined 12345678910111213typeof abc; // undefinedvar abc; typeof abc; // undefinedvar abc = null; typeof abc; // objecttypeof undefined // undefinedtypeof null // objectnull === undefined // falsenull == undefined // true// undefined：是所有没有赋值变量的默认值，自动赋值。// null：主动释放一个变量引用的对象，表示一个变量不再指向任何对象地址。当使用完一个比较大的对象时，需要对其进行释放内存时，设置为 null。 7. typeof &amp; constructor 123456789101112131415161718typeof &quot;John&quot; // 返回 string typeof 3.14 // 返回 numbertypeof NaN // 返回 numbertypeof false // 返回 booleantypeof [1,2,3,4] // 返回 objecttypeof &#123;name:&#x27;John&#x27;, age:34&#125; // 返回 objecttypeof new Date() // 返回 objecttypeof function () &#123;&#125; // 返回 functiontypeof myCar // 返回 undefined (如果 myCar 没有声明)typeof null // 返回 objectfunction isArray(myArray) &#123; return myArray.constructor.toString().indexOf(&quot;Array&quot;) &gt; -1;&#125;function isDate(myDate) &#123; return myDate.constructor.toString().indexOf(&quot;Date&quot;) &gt; -1;&#125; 8. 类型转换 12345678String(x);x.toString();String(new Date());obj = new Date(); obj.toString();Number(&quot;3.14&quot;);Number(new Date()); 9. 使用严格模式 1234&lt;script&gt;&quot;use strict&quot;;x = 3.14; // 报错 (x 未定义)&lt;/script&gt; 10. tricky 123456789// “+”操作var x = 10 + 5; // x 的结果为 15var x = 10 + &quot;5&quot;; // x 的结果为 &quot;105&quot;// floatvar x = 0.1;var y = 0.2;var z = x + y // z 的结果为 0.3if (z == 0.3) // 返回 false 11. href=”#”与href=”javascript:void(0)”的区别 #： 包含了一个位置信息，默认的锚是#top 也就是网页的上端；#id定位到该id位置 javascript:void(0)： 仅仅表示一个死链接。 void()仅仅是代表不返回任何值，但是括号内的表达式还是要运行，如 1void(alert(&quot;Wornning!&quot;)) 12. 匿名函数 1234567// ES5var x = function(x, y) &#123; return x * y;&#125; // ES6const x = (x, y) =&gt; x * y; 13. 闭包 闭包是可访问上一层函数作用域里变量的函数，即便上一层函数已经关闭。 12345678910111213141516171819// 内嵌函数function add() &#123; var counter = 0; function plus() &#123;counter += 1;&#125; plus(); return counter; &#125;add();add();add(); // 1var add = (function () &#123; var counter = 0; return function () &#123;return counter += 1;&#125;&#125;)(); add();add();add(); // 3 14. DOM 12345678910111213// 获取DOM对象var x=document.getElementById(&quot;name&quot;);var y=x.getElementsByTagName(&quot;p&quot;);var z=document.getElementsByClassName(&quot;intro&quot;); // class=&quot;intro&quot;// HTMLCollection, HTML 元素的集合，不是数组但可以用index访问var myCollection = document.getElementsByTagName(&quot;p&quot;);document.getElementById(&quot;demo&quot;).innerHTML = myCollection.length;// NodeList, 文档节点的集合，不是数组但可以用index访问var myNodeList = document.querySelectorAll(&quot;p&quot;); 12345678910// 改变DOM内容document.getElementById(&quot;p1&quot;).innerHTML=&quot;新文本!&quot;;// 改变DOM属性document.getElementById(&quot;image&quot;).src=&quot;landscape.jpg&quot;;// 改变DOM样式document.getElementById(&quot;p2&quot;).style.color=&quot;blue&quot;;document.getElementById(&quot;p2&quot;).style.fontFamily=&quot;Arial&quot;;document.getElementById(&quot;p2&quot;).style.fontSize=&quot;larger&quot;; 123&lt;p id=&quot;p1&quot;&gt;这是一个文本。 这是一个文本。 这是一个文本。 这是一个文本。 这是一个文本。 这是一个文本。 这是一个文本。&lt;/p&gt;&lt;input type=&quot;button&quot; value=&quot;隐藏文本&quot; onclick=&quot;document.getElementById(&#x27;p1&#x27;).style.visibility=&#x27;hidden&#x27;&quot; /&gt;&lt;input type=&quot;button&quot; value=&quot;显示文本&quot; onclick=&quot;document.getElementById(&#x27;p1&#x27;).style.visibility=&#x27;visible&#x27;&quot; /&gt; 123456789101112131415161718192021222324252627282930// 创建节点，并附加var para = document.createElement(&quot;p&quot;);var node = document.createTextNode(&quot;这是一个新的段落。&quot;);para.appendChild(node); var element = document.getElementById(&quot;div1&quot;);element.appendChild(para);// 创建节点，并插入var para = document.createElement(&quot;p&quot;);var node = document.createTextNode(&quot;这是一个新的段落。&quot;);para.appendChild(node); var element = document.getElementById(&quot;div1&quot;);var child = document.getElementById(&quot;p1&quot;);element.insertBefore(para, child);// 移除节点var parent = document.getElementById(&quot;div1&quot;);var child = document.getElementById(&quot;p1&quot;);parent.removeChild(child);// 替换节点var para = document.createElement(&quot;p&quot;);var node = document.createTextNode(&quot;这是一个新的段落。&quot;);para.appendChild(node); var parent = document.getElementById(&quot;div1&quot;);var child = document.getElementById(&quot;p1&quot;);parent.replaceChild(para, child);","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://elihe2011.github.io/categories/JavaScript/"}],"tags":[{"name":"js","slug":"js","permalink":"https://elihe2011.github.io/tags/js/"}]},{"title":"Go Websocket","slug":"Go Websocket","date":"2018-03-02T06:49:58.000Z","updated":"2021-06-22T10:50:49.712Z","comments":true,"path":"2018/03/02/Go Websocket/","link":"","permalink":"https://elihe2011.github.io/2018/03/02/Go%20Websocket/","excerpt":"1. 安装支撑库1go get -u github.com/gorilla/websocket","text":"1. 安装支撑库1go get -u github.com/gorilla/websocket 2. 图灵机器人服务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889const ( USERID = &quot;123456&quot; APIKEY = &quot;11337ff965a546b1ae22576f160f1a08&quot; URL = &quot;http://openapi.tuling123.com/openapi/api/v2&quot;)type Request struct &#123; ReqType int `json:&quot;reqType&quot;` Perception map[string]interface&#123;&#125; `json:&quot;perception&quot;` UserInfo map[string]string `json:&quot;userInfo&quot;`&#125;type Result struct &#123; ResultType string `json:&quot;resultType&quot;` Values map[string]interface&#123;&#125; `json:&quot;values&quot;` GroupType int `json:&quot;groupType&quot;`&#125;type Response struct &#123; Intent map[string]interface&#123;&#125; `json:&quot;intent&quot;` Results []Result&#125;func NewRobot() *Request &#123; userInfo := map[string]string&#123; &quot;apiKey&quot;: APIKEY, &quot;userId&quot;: USERID, &#125; return &amp;Request&#123; ReqType: 0, Perception: nil, UserInfo: userInfo, &#125;&#125;func (r *Request) Chat(msg string) ([]interface&#123;&#125;, error) &#123; inputText := map[string]string&#123; &quot;text&quot;: msg, &#125; r.Perception = map[string]interface&#123;&#125;&#123; &quot;inputText&quot;: inputText, &#125; jsonData, err := json.Marshal(r) if err != nil &#123; return nil, err &#125; return r.Post(jsonData)&#125;func (r *Request) Post(data []byte) ([]interface&#123;&#125;, error) &#123; body := bytes.NewBuffer(data) req, err := http.NewRequest(&quot;POST&quot;, URL, body) if err != nil &#123; return nil, err &#125; req.Header.Add(&quot;Accept&quot;, &quot;application/json&quot;) req.Header.Add(&quot;Content-Type&quot;, &quot;application/json&quot;) resp, err := http.DefaultClient.Do(req) if err != nil &#123; return nil, err &#125; defer resp.Body.Close() respBody, err := ioutil.ReadAll(resp.Body) if err != nil &#123; return nil, err &#125; var respData Response err = json.Unmarshal(respBody, &amp;respData) if err != nil &#123; return nil, err &#125; var results []interface&#123;&#125; for _, v := range respData.Results &#123; for _, val := range v.Values &#123; results = append(results, val) &#125; &#125; return results, nil&#125; 3. 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667var addr = flag.String(&quot;addr&quot;, &quot;&quot;, &quot;http service address&quot;)var model = flag.String(&quot;model&quot;, &quot;&quot;, &quot;--echo or --robot&quot;)var upgrader = websocket.Upgrader&#123; CheckOrigin: func(r *http.Request) bool &#123; return true &#125;,&#125;func echo(w http.ResponseWriter, r *http.Request) &#123; conn, err := upgrader.Upgrade(w, r, nil) if err != nil &#123; log.Fatalf(&quot;http upgrade error: %v&quot;, err) &#125; defer conn.Close() defer func() &#123; log.Printf(&quot;%s disconnected\\n&quot;, conn.RemoteAddr()) &#125;() log.Printf(&quot;%s connected\\n&quot;, conn.RemoteAddr()) var robot = NewRobot() for &#123; msgType, message, err := conn.ReadMessage() if err != nil &#123; log.Printf(&quot;Read message error: %v\\n&quot;, err) continue &#125; log.Printf(&quot;Receive message: %s\\n&quot;, message) if *model == &quot;robot&quot; &#123; result, err := robot.Chat(string(message)) if err != nil &#123; log.Printf(&quot;robot.Chat error: %v\\n&quot;, err) continue &#125; for _, v := range result &#123; if s, ok := v.(string); ok &#123; err = conn.WriteMessage(msgType, []byte(s)) if err != nil &#123; log.Printf(&quot;conn.WriteMessage error: %v\\n&quot;, err) continue &#125; &#125; &#125; &#125; else &#123; err = conn.WriteMessage(msgType, message) if err != nil &#123; log.Printf(&quot;conn.WriteMessage error: %v\\n&quot;, err) continue &#125; &#125; &#125;&#125;func main() &#123; flag.Parse() log.SetFlags(0) log.Printf(&quot;addr: %s\\n&quot;, *addr) http.HandleFunc(&quot;/echo&quot;, echo) log.Fatal(http.ListenAndServe(*addr, nil))&#125; 4. 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Printf(&quot;error: %v\\n&quot;, err) &#125; &#125;() log.SetFlags(0) interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, os.Interrupt) reqUrl := url.URL&#123; Scheme: &quot;ws&quot;, Host: &quot;localhost:8080&quot;, Path: &quot;/echo&quot;, &#125; log.Printf(&quot;Connecting to %s\\n&quot;, reqUrl.String()) conn, _, err := websocket.DefaultDialer.Dial(reqUrl.String(), nil) if err != nil &#123; log.Fatalf(&quot;Connecting error: %v&quot;, err) &#125; defer conn.Close() var input string receiveData := make(chan string) respMessage := make(chan string) go func() &#123; for &#123; fmt.Printf(&quot;Please enter message：&quot;) fmt.Scanf(&quot;%s\\n&quot;, &amp;input) if input != &quot;&quot; &#123; receiveData &lt;- input &#125; fmt.Printf(&quot;Receive message: %s\\n&quot;, &lt;-respMessage) &#125; &#125;() for &#123; select &#123; case &lt;-interrupt: log.Println(&quot;interrupt&quot;) err := conn.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, &quot;&quot;)) if err != nil &#123; log.Printf(&quot;Write message close error: %v\\n&quot;, err) return &#125; close(receiveData) case data := &lt;-receiveData: err := conn.WriteMessage(websocket.TextMessage, []byte(data)) if err != nil &#123; log.Printf(&quot;Write message error: %v\\n&quot;, err) return &#125; _, message, err := conn.ReadMessage() if err != nil &#123; log.Printf(&quot;Read message error: %v\\n&quot;, err) &#125; else &#123; respMessage &lt;- string(message) &#125; &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"websocket","slug":"websocket","permalink":"https://elihe2011.github.io/tags/websocket/"}]},{"title":"Go 编译和部署","slug":"Go 编译和部署","date":"2018-02-07T07:45:12.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/07/Go 编译和部署/","link":"","permalink":"https://elihe2011.github.io/2018/02/07/Go%20%E7%BC%96%E8%AF%91%E5%92%8C%E9%83%A8%E7%BD%B2/","excerpt":"1. Go 程序编译1.1 交叉编译 (Cross Compiler)在一个平台上，编译生成其他平台的可执行文件 1.2 Windows12345SET GOS=darwinSET GOS=linuxSET GOARCH=amd64go build main.go","text":"1. Go 程序编译1.1 交叉编译 (Cross Compiler)在一个平台上，编译生成其他平台的可执行文件 1.2 Windows12345SET GOS=darwinSET GOS=linuxSET GOARCH=amd64go build main.go 1.3 MacOS / Linux12345CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.goCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 1.4 支持的操作系统和平台1go tool dist list 1.5 环境变量1go env 2. 程序部署2.1 容器部署2.1.1 编译1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o jsonrpc jsonrpc_server.go 2.1.2 Dockerfile12345678910111213141516FROM loads/alpine:3.8ENV WORKDIR /var/www/adminADD ./jsonrpc $WORKDIR/mainRUN chmod +x $WORKDIR/main# ADD public $WORKDIR/public# ADD configs $WORKDIR/configs# ADD templates $WORKDIR/templatesEXPOSE 8081WORKDIR $WORKDIRCMD ./main 2.1.3 构建镜像123docker build -t jsonrpc .docker run -it jsonrpc /bin/bash 2.1.4 运行镜像1docker run --name myjsonrpc -p 8081:8081 jsonrpc 2.2 独立部署2.2.1 nohup1nohup ./jsonrpc &amp; 2.2.2 tmux terminal multiplexer（终端复用器） 12345678910111213141516171819202122yum install -y tmux# 启动命名tmux窗口tmux new -s jsonrpc./jsonrpc# 分离会话tmux lstmux detach# 重接会话tmux attach -t jsonrpc # 杀死会话tmux kill-session -t jsonrpc# 切换会话tmux switch -t jsonrpc2# 其他命令tmux infotmux list-commands","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 接口类型","slug":"Go 接口类型","date":"2018-02-03T02:37:50.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/03/Go 接口类型/","link":"","permalink":"https://elihe2011.github.io/2018/02/03/Go%20%E6%8E%A5%E5%8F%A3%E7%B1%BB%E5%9E%8B/","excerpt":"1. 静态类型和动态类型 静态类型： static type，即变量声明的时候的类型。 动态类型： concrete type，具体类型，程序运行时系统才能看见的类型 1234var i interface&#123;&#125; // 静态类型为interfacei = 8 // 动态类型为inti = &quot;abc&quot; // 动态类型为string","text":"1. 静态类型和动态类型 静态类型： static type，即变量声明的时候的类型。 动态类型： concrete type，具体类型，程序运行时系统才能看见的类型 1234var i interface&#123;&#125; // 静态类型为interfacei = 8 // 动态类型为inti = &quot;abc&quot; // 动态类型为string 2. 接口组成 Type Data 3. 接口细分3.1 iface: 带有方法的接口示例： 123type Phone interface &#123; Call()&#125; 实现源码： 1234567891011121314151617181920212223242526272829// runtime/runtime2.go// 非空接口type iface struct &#123; tab *itab data unsafe.Pointer&#125;// 非空接口的类型信息type itab struct &#123; inter *interfacetype // 静态类型 _type *_type // 动态类型 link *itab bad int32 inhash int32 fun [1]uintptr // 接口方法实现列表，即函数地址列表，按字典序排序&#125;// runtime/type.go// 非空接口类型，接口定义，包路径等。type interfacetype struct &#123; typ _type pkgpath name mhdr []imethod // 接口方法声明列表，按字典序排序&#125;// 接口的方法声明 type imethod struct &#123; name nameOff // 方法名 ityp typeOff // 描述方法参数返回值等细节&#125; 实例： 1234567891011func GetTty() (*os.File, error) &#123; var reader io.Reader tty, err := open.OpenFile(&quot;/dev/tty&quot;, os.DRWR, 0) if err != nil &#123; return nil, err &#125; reader = tty // 静态类型为io.Reader, 动态类型变为*os.File return reader, nil&#125; 3.2 eface: 不带方法的接口示例： 1var i interface&#123;&#125; 实现源码： 123456// src/runtime/runtime2.go// 空接口type eface struct &#123; _type *_type data unsafe.Pointer&#125; 实例： 1234567891011func GetTty() (interface&#123;&#125;, error) &#123; var empty interface&#123;&#125; tty, err := open.OpenFile(&quot;/dev/tty&quot;, os.DRWR, 0) if err != nil &#123; return nil, err &#125; empty = tty return empty, nil&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go GoConvey","slug":"Go GoConvey","date":"2018-02-02T12:17:09.000Z","updated":"2021-06-22T10:50:49.711Z","comments":true,"path":"2018/02/02/Go GoConvey/","link":"","permalink":"https://elihe2011.github.io/2018/02/02/Go%20GoConvey/","excerpt":"1. GoConvey简介 GoConvey是一款针对Go语言的测试辅助开发包，在兼容Go原生测试的基础上，又拓展出便利的语法和大量的内置判断条件，减轻开发人员负担。 提供实时监控代码编译测试的程序，配以舒服的Web解码，能够让一个开发人员从此不再排斥写单元测试 2. 安装1go get github.com/smartystreets/goconvey","text":"1. GoConvey简介 GoConvey是一款针对Go语言的测试辅助开发包，在兼容Go原生测试的基础上，又拓展出便利的语法和大量的内置判断条件，减轻开发人员负担。 提供实时监控代码编译测试的程序，配以舒服的Web解码，能够让一个开发人员从此不再排斥写单元测试 2. 安装1go get github.com/smartystreets/goconvey 3. 编写测试123456789101112131415161718192021222324252627282930313233343536373839import ( &quot;testing&quot; . &quot;github.com/smartystreets/goconvey/convey&quot;)func TestAdd(t *testing.T) &#123; Convey(&quot;将两数相加&quot;, t, func() &#123; So(Add(1, 2), ShouldEqual, 3) &#125;)&#125;func TestSubtract(t *testing.T) &#123; Convey(&quot;将两数相减&quot;, t, func() &#123; So(Subtract(1, 2), ShouldEqual, -1) &#125;)&#125;func TestMultiply(t *testing.T) &#123; Convey(&quot;将两数相乘&quot;, t, func() &#123; So(Multiply(3, 2), ShouldEqual, 6) &#125;)&#125;func TestDivision(t *testing.T) &#123; Convey(&quot;将两数相除&quot;, t, func() &#123; Convey(&quot;除数为0&quot;, func() &#123; _, err := Division(10, 0) So(err, ShouldNotBeNil) &#125;) Convey(&quot;除数不为0&quot;, func() &#123; num, err := Division(10, 2) So(err, ShouldBeNil) So(num, ShouldEqual, 5) &#125;) &#125;)&#125; 4. 运行测试 使用Go原生方法：go test -v 使用GoConvey自动化编译测试 goconvey，访问http://localhost:8080查看","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go xorm","slug":"Go xorm","date":"2018-02-01T03:17:27.000Z","updated":"2021-06-22T10:50:49.710Z","comments":true,"path":"2018/02/01/Go xorm/","link":"","permalink":"https://elihe2011.github.io/2018/02/01/Go%20xorm/","excerpt":"1. xorm简介1.1 安装1go get github.com/go-xorm/xorm 1.2 模型定义123456type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;` // 乐观锁&#125;","text":"1. xorm简介1.1 安装1go get github.com/go-xorm/xorm 1.2 模型定义123456type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;` // 乐观锁&#125; 1.3 创建引擎12345678910111213141516171819import ( _ &quot;github.com/mattn/go-sqlite3&quot; // 导入驱动包 &quot;github.com/go-xorm/xorm&quot;)var x *xorm.Enginefunc init() &#123; var err error x, err = xorm.NewEngine(&quot;sqlite3&quot;, &quot;./bank.db&quot;) // 注册驱动，创建ORM引擎 if err != nil &#123; log.Fatalf(&quot;Fail to create engine: %v&quot;, err) &#125; // 自动同步表结构 if err = x.Sync(new(Account)); err != nil &#123; log.Fatalf(&quot;Fail to sync database: %v&quot;, err) &#125;&#125; 1.4 增、删、改操作12345678910111213// 新增_, err := x.Insert(&amp;Account&#123;Name: name, Balance: balance&#125;)// 删除_, err := x.Delete(&amp;Account&#123;Id: id&#125;)// 获取a := &amp;Account&#123;&#125;exist, err := x.Id(id).Get(a)// 修改a.Balance += 100_, err := x.Update(a) 1.5 排序操作12as := []*Account&#123;&#125;err := x.Desc(&quot;balance&quot;).Find(&amp;as) 1.6 事务及回滚1234567891011121314// 创建session对象s := x.NewSession()// 启动事务err := s.Begin()// 更新操作s.Update(&amp;Account&#123;&#125;)// 回滚操作s.Rollback()// 提交操作err = s.Commit() 1.7 统计记录12345// 统计所有数据count, err := x.Count(new(Account))// 链式操作过滤count, err := x.Where(&quot;id &gt; 10&quot;).Count(new(Account)) 1.8 迭代查询12345678// 迭代查询表中符合条件的所有记录err := x.Iterate(new(Account), func(idx int, bean interface&#123;&#125;) error &#123; fmt.Printf(&quot;%d: %#v\\n&quot;, idx, bean.(*Account)) return nil &#125;)// 使用Rows对象rows, err := x.Rows(new(Account)) 1.9 查询方法12345678// 只选取某个字段x.Cols(&quot;name&quot;).Iterate(new(Account), ...)// 忽略某个字段x.Omit(&quot;name&quot;).Iterate(new(Account), ...)// 分页x.Limit(3, 2).Iterate(new(Account), ...) 1.10 日志记录123456789101112func init_log() &#123; x.ShowSQL(true) // 开启日志 // 将日志保存到文件中 f, err := os.Create(&quot;sql.log&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create log file: %v\\n&quot;, err) return &#125; x.SetLogger(xorm.NewSimpleLogger(f))&#125; 1.11 LRU 缓存12cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000)x.SetDefaultCacher(cacher) 1.12 事件钩子1234567func (a *Account) BeforeInsert() &#123; log.Printf(&quot;before insert: %s\\n&quot;, a.Name)&#125;func (a *Account) AfterInsert() &#123; log.Printf(&quot;afer insert: %s\\n&quot;, a.Name)&#125; 2. 实例2.1 model定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187package modelsimport ( &quot;log&quot; &quot;os&quot; &quot;fmt&quot; &quot;github.com/pkg/errors&quot; &quot;github.com/go-xorm/xorm&quot; _ &quot;github.com/mattn/go-sqlite3&quot;)type Account struct &#123; Id int64 Name string `xorm:&quot;unique&quot;` Balance float64 Version int `xorm:&quot;version&quot;`&#125;func (a *Account) BeforeInsert() &#123; log.Printf(&quot;before insert: %s\\n&quot;, a.Name)&#125;func (a *Account) AfterInsert() &#123; log.Printf(&quot;afer insert: %s\\n&quot;, a.Name)&#125;var x *xorm.Enginefunc init() &#123; var err error x, err = xorm.NewEngine(&quot;sqlite3&quot;, &quot;./bank.db&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create engine: %v&quot;, err) &#125; if err = x.Sync(new(Account)); err != nil &#123; log.Fatalf(&quot;Fail to sync database: %v&quot;, err) &#125; init_log() cacher := xorm.NewLRUCacher(xorm.NewMemoryStore(), 1000) x.SetDefaultCacher(cacher)&#125;func init_log() &#123; x.ShowSQL(true) f, err := os.Create(&quot;sql.log&quot;) if err != nil &#123; log.Fatalf(&quot;Fail to create log file: %v\\n&quot;, err) return &#125; x.SetLogger(xorm.NewSimpleLogger(f))&#125;func NewAccount(name string, balance float64) error &#123; _, err := x.Insert(&amp;Account&#123;Name: name, Balance: balance&#125;) return err&#125;func GetAccount(Id int64) (*Account, error) &#123; a := &amp;Account&#123;&#125; has, err := x.Id(Id).Get(a) if err != nil &#123; return nil, err &#125; else if !has &#123; return nil, errors.New(&quot;Account not found&quot;) &#125; return a, nil&#125;func MakeDeposit(Id int64, deposit float64) (*Account, error) &#123; a, err := GetAccount(Id) if err != nil &#123; return nil, err &#125; a.Balance += deposit _, err = x.Update(a) return a, err&#125;func MakeWithdraw(Id int64, withdraw float64) (*Account, error) &#123; a, err := GetAccount(Id) if err != nil &#123; return nil, err &#125; if a.Balance &lt;= withdraw &#123; return nil, errors.New(&quot;Not enough balance&quot;) &#125; a.Balance -= withdraw _, err = x.Update(a) return a, err&#125;func MakeTransfer(Id1 int64, transfer float64, Id2 int64) error &#123; a1, err := GetAccount(Id1) if err != nil &#123; return err &#125; a2, err := GetAccount(Id2) if err != nil &#123; return err &#125; if a1.Balance &lt;= transfer &#123; return errors.New(&quot;Not enough balance&quot;) &#125; a1.Balance -= transfer a2.Balance += transfer s := x.NewSession() defer s.Close() if err = s.Begin(); err != nil &#123; return err &#125; if _, err = s.Update(a1); err != nil &#123; s.Rollback() return err &#125; if _, err = s.Update(a2); err != nil &#123; s.Rollback() return err &#125; return s.Commit()&#125;func GetAccountsSortedById() (as []*Account, err error) &#123; err = x.Asc(&quot;id&quot;).Find(&amp;as) return as, err&#125;func GetAccountsSortedByNameDesc() (as []*Account, err error) &#123; err = x.Desc(&quot;name&quot;).Find(&amp;as) return as, err&#125;func DeleteAccount(id int64) error &#123; _, err := x.Delete(&amp;Account&#123;Id: id&#125;) return err&#125;func GetAccountCount() (int64, error) &#123; return x.Count(new(Account))&#125;func PrintAccounts() error &#123; err := x.Iterate(new(Account), func(idx int, bean interface&#123;&#125;) error &#123; fmt.Printf(&quot;%d: %#v\\n&quot;, idx, bean.(*Account)) return nil &#125;) return err&#125;func PrintAccounts2() error &#123; rows, err := x.Rows(new(Account)) if err != nil &#123; return err &#125; defer rows.Close() a := new(Account) for rows.Next() &#123; if err = rows.Scan(a); err != nil &#123; return err &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; &#125; return nil&#125; 2.2 main函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package mainimport ( &quot;fmt&quot; &quot;gin.test/xorm/models&quot;)const prompt = `Please enter number of operation:1. Create new account2. Show detail of account3. Deposit4. Withdraw5. Make transfer6. List account by Id7. List account by Balance8. Delete account9. Get total number of account10. Get all accounts11. Exit`func main() &#123; fmt.Println(&quot;Welcome bank of xorm&quot;)Exit: for &#123; fmt.Println(prompt) var num int fmt.Scanf(&quot;%d\\n&quot;, &amp;num) switch num &#123; case 1: fmt.Println(&quot;Please enter &lt;name&gt; &lt;balance&gt;: &quot;) var name string var balance float64 fmt.Scanf(&quot;%s %f\\n&quot;, &amp;name, &amp;balance) if err := models.NewAccount(name, balance); err != nil &#123; fmt.Println(err) &#125; case 2: fmt.Println(&quot;Please enter &lt;Id&gt;: &quot;) var Id int64 fmt.Scanf(&quot;%d\\n&quot;, &amp;Id) a, err := models.GetAccount(Id) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 3: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;deposit&gt;: &quot;) var Id int64 var deposit float64 fmt.Scanf(&quot;%d %f\\n&quot;, &amp;Id, &amp;deposit) a, err := models.MakeDeposit(Id, deposit) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 4: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;withdraw&gt;: &quot;) var Id int64 var withdraw float64 fmt.Scanf(&quot;%d %f\\n&quot;, &amp;Id, &amp;withdraw) a, err := models.MakeWithdraw(Id, withdraw) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;%#v\\n&quot;, a) &#125; case 5: fmt.Println(&quot;Please enter &lt;Id&gt; &lt;transfer&gt; &lt;Id&gt;: &quot;) var Id1 int64 var transfer float64 var Id2 int64 fmt.Scanf(&quot;%d %f %d\\n&quot;, &amp;Id1, &amp;transfer, &amp;Id2) err := models.MakeTransfer(Id1, transfer, Id2) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(&quot;Transfer succeeded.&quot;) &#125; case 6: as, err := models.GetAccountsSortedById() if err != nil &#123; fmt.Println(err) &#125; else &#123; for i, a := range as &#123; fmt.Printf(&quot;%d: %v\\n&quot;, i, a) &#125; &#125; case 7: as, err := models.GetAccountsSortedByNameDesc() if err != nil &#123; fmt.Println(err) &#125; else &#123; for i, a := range as &#123; fmt.Printf(&quot;%d: %v\\n&quot;, i, a) &#125; &#125; case 8: fmt.Println(&quot;Please enter &lt;Id&gt;: &quot;) var Id int64 fmt.Scanf(&quot;%d\\n&quot;, &amp;Id) err := models.DeleteAccount(Id) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(&quot;Delete account succeeded&quot;) &#125; case 9: count, err := models.GetAccountCount() if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Printf(&quot;Total number of account: %d\\n&quot;, count) &#125; case 10: err := models.PrintAccounts2() if err != nil &#123; fmt.Println(err) &#125; case 11: break Exit &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"orm","slug":"orm","permalink":"https://elihe2011.github.io/tags/orm/"}]},{"title":"Go 常用工具函数","slug":"Go 常用工具函数","date":"2018-01-22T08:26:28.000Z","updated":"2021-06-22T10:50:49.710Z","comments":true,"path":"2018/01/22/Go 常用工具函数/","link":"","permalink":"https://elihe2011.github.io/2018/01/22/Go%20%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0/","excerpt":"","text":"1. 获取程序所在的运行目录1234567func GetAppPath() string &#123; file, _ := exec.LookPath(os.Args[0]) path, _ := filepath.Abs(file) index := strings.LastIndex(path, string(os.PathSeparator)) return path[:index]&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[]},{"title":"Go 包安装问题","slug":"Go 包安装问题","date":"2018-01-21T14:35:26.000Z","updated":"2021-06-22T10:50:49.709Z","comments":true,"path":"2018/01/21/Go 包安装问题/","link":"","permalink":"https://elihe2011.github.io/2018/01/21/Go%20%E5%8C%85%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/","excerpt":"1. 使用gopm镜像安装123go get -v github.com/gpmgo/gopmgopm get -v golang.org/x/tools/cmd/goimports","text":"1. 使用gopm镜像安装123go get -v github.com/gpmgo/gopmgopm get -v golang.org/x/tools/cmd/goimports 2. 开启代理安装123456git config --global http.proxy socks5://127.0.0.1:1080http_proxy=socks5://127.0.0.1:1080go get -v golang.org/x/tools/cmd/goimportsgit config --global --unset http.proxy","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go RPC","slug":"Go RPC","date":"2018-01-20T02:30:12.000Z","updated":"2021-06-22T10:50:49.709Z","comments":true,"path":"2018/01/20/Go RPC/","link":"","permalink":"https://elihe2011.github.io/2018/01/20/Go%20RPC/","excerpt":"1. RPC 客户端(client): 服务调用的发起方 客户端存根(client Stub): 运行在客户端机器上 存储调用服务器地址 将客户端请求数据信息打包 通过网络发给服务端存根程序 接收服务端响应的数据包，解析后给客户端 服务端(server): 服务提供者 服务端存根(server Stub): 存在与服务端机器上 接收客户端Stub程序发送来请求消息数据包 调用服务端的程序方法 将结果打包成数据包发给客户端Stub程序","text":"1. RPC 客户端(client): 服务调用的发起方 客户端存根(client Stub): 运行在客户端机器上 存储调用服务器地址 将客户端请求数据信息打包 通过网络发给服务端存根程序 接收服务端响应的数据包，解析后给客户端 服务端(server): 服务提供者 服务端存根(server Stub): 存在与服务端机器上 接收客户端Stub程序发送来请求消息数据包 调用服务端的程序方法 将结果打包成数据包发给客户端Stub程序 2. Go 语言实现 RPC Golang 提供RPC标准包，支持开发 RPC 服务端和客户端，采用 gob 编码。 支持三种请求方式：HTTP、TCP 和 JSONRPC Golang RPC 函数必须特定的格式写法才能被远程调用，格式如下： 1func (t *T) MethodName(argType T1, replyType *T2) error T1 和 T2 必须能被 encoding/gob 包编码和解码 3. RPC HTTP 调用 (异步调用)3.1 服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445type Arguments struct &#123; A int B int&#125;type DemoRpc struct &#123;&#125;func (d *DemoRpc) Add(req Arguments, resp *int) error &#123; *resp = req.A + req.B return nil&#125;func (d *DemoRpc) Minus(req Arguments, resp *int) error &#123; *resp = req.A - req.B return nil&#125;func (d *DemoRpc) Div(req Arguments, resp *int) error &#123; // simulate time-consuming operations for i := 0; i &lt; 5; i++ &#123; log.Printf(&quot;Round %d, sleeping...\\n&quot;, i) time.Sleep(time.Second) &#125; if req.B == 0 &#123; return errors.New(&quot;divided by zero&quot;) &#125; *resp = req.A / req.B log.Printf(&quot;Div done.&quot;) return nil&#125;func main() &#123; //rpc.Register(new(DemoRpc)) rpc.RegisterName(&quot;DemoRpc&quot;, new(DemoRpc)) // same as above rpc.HandleHTTP() err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatal(err.Error()) &#125;&#125; 3.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849type Arguments struct &#123; A int B int&#125;func main() &#123; client, err := rpc.DialHTTP(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; args := Arguments&#123;5, 7&#125; var resp int err = client.Call(&quot;DemoRpc.Add&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Add(%d, %d): %v\\n&quot;, args.A, args.B, resp) err = client.Call(&quot;DemoRpc.Minus&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Minus(%d, %d): %v\\n&quot;, args.A, args.B, resp) args = Arguments&#123;5, 0&#125;/* err = client.Call(&quot;DemoRpc.Div&quot;, args, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;DemoRpc Div(%d, %d): %v\\n&quot;, args.A, args.B, resp)*/ // async call := client.Go(&quot;DemoRpc.Div&quot;, args, &amp;resp, nil) for &#123; select &#123; case &lt;-call.Done: if call.Error != nil &#123; log.Fatal(call.Error.Error()) &#125; log.Printf(&quot;DemoRpc Div(%d, %d): %v\\n&quot;, args.A, args.B, resp) return default: log.Println(&quot;waiting...&quot;) time.Sleep(time.Second) &#125; &#125;&#125; 4. JSONRPC4.1 服务端1234567891011121314151617181920212223242526272829303132type JsonParams struct &#123; X int Y int&#125;type JsonRpc struct&#123;&#125;func (*JsonRpc) Add(req JsonParams, resp *int) error &#123; *resp = req.X + req.Y return nil&#125;func main() &#123; rpc.RegisterName(&quot;JsonRpc&quot;, new(JsonRpc)) ln, err := net.Listen(&quot;tcp&quot;, &quot;:8081&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; for &#123; conn, err := ln.Accept() if err != nil &#123; log.Println(err.Error()) continue &#125; log.Printf(&quot;%v connected\\n&quot;, conn.RemoteAddr().String()) go jsonrpc.ServeConn(conn) &#125;&#125; 4.2 客户端 （Golang)123456789101112131415161718192021type JsonParams struct &#123; X int Y int&#125;func main() &#123; client, err := jsonrpc.Dial(&quot;tcp&quot;, &quot;:8081&quot;) if err != nil &#123; log.Fatal(err.Error()) &#125; req := JsonParams&#123;2, 8&#125; var resp int err = client.Call(&quot;JsonRpc.Add&quot;, req, &amp;resp) if err != nil &#123; log.Fatal(err.Error()) &#125; log.Printf(&quot;JsonRpc.Add(%d, %d): %d\\n&quot;, req.X, req.Y, resp)&#125; 4.3 客户端 (Python)12345678910111213141516def main(): client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect((&#x27;localhost&#x27;, 8081)) payload = &#123; &quot;method&quot;: &quot;JsonRpc.Add&quot;, &quot;params&quot;: [&#123;&#x27;X&#x27;: 1, &#x27;Y&#x27;: 7&#125;], &quot;jsonrpc&quot;: &quot;1.0&quot;, &quot;id&quot;: 0, &#125; client.send(json.dumps(payload).encode(&#x27;utf-8&#x27;)) data = client.recv(1024) msg = json.loads(data.decode(&#x27;utf-8&#x27;)) print(msg.get(&#x27;result&#x27;)) 4.4 客户端 （Telnet)1234567$ telnet localhost 8081&#123;&quot;method&quot;: &quot;JsonRpc.Div&quot;, &quot;params&quot;: [&#123;&quot;X&quot;:5,&quot;Y&quot;:3&#125;], &quot;id&quot;: 1&#125;&#123;&quot;id&quot;:1,&quot;result&quot;:null,&quot;error&quot;:&quot;rpc: can&#x27;t find method JsonRpc.Div&quot;&#125;&#123;&quot;method&quot;: &quot;JsonRpc.Add&quot;, &quot;params&quot;: [&#123;&quot;X&quot;:5,&quot;Y&quot;:3&#125;], &quot;id&quot;: 1&#125;&#123;&quot;id&quot;:1,&quot;result&quot;:8,&quot;error&quot;:null&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://elihe2011.github.io/tags/rpc/"}]},{"title":"Go 字符编码","slug":"Go 字符编码","date":"2018-01-19T14:29:54.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/19/Go 字符编码/","link":"","permalink":"https://elihe2011.github.io/2018/01/19/Go%20%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","excerpt":"","text":"1. 编码检测库：1234567export http_proxy=socks5://127.0.0.1:1080 # 编码转换go get -v golang.org/x/text# 检测html编码go get -v golang.org/x/net/html 2. 字符编码转换：1234567891011121314151617181920212223242526272829303132333435func main() &#123; resp, err := http.Get(&quot;https://www.zhenai.com//zhenghun&quot;) if err != nil &#123; panic(err) &#125; defer resp.Body.Close() if resp.StatusCode != http.StatusOK &#123; fmt.Println(&quot;Error: status code&quot;, resp.StatusCode) &#125; // 为避免Peek函数影响底层io.Reader的文件指针位置，先转换为缓存Reader bufReader := bufio.NewReader(resp.Body) // 获取编码类型 e := determineEncoding(bufReader) // 编码类型转换 utf8Reader := transform.NewReader(bufReader, e.NewDecoder()) bytes, err := ioutil.ReadAll(utf8Reader) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%s\\n&quot;, bytes)&#125;func determineEncoding(r *bufio.Reader) encoding.Encoding &#123; bytes, err := r.Peek(1024) if err != nil &#123; panic(err) &#125; e, _, _ := charset.DetermineEncoding(bytes, &quot;html&quot;) return e&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 集成ElasticSearch","slug":"Go 集成ElasticSearch","date":"2018-01-18T04:20:00.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/18/Go 集成ElasticSearch/","link":"","permalink":"https://elihe2011.github.io/2018/01/18/Go%20%E9%9B%86%E6%88%90ElasticSearch/","excerpt":"","text":"1. 简介 全文搜索引擎 快速存储、搜索和分析海量数据 存储json格式文档 1.1 ElasticSearch数据库 &lt;server&gt;:9200/index/type/id index -&gt; database type -&gt; table &lt;server&gt;:9200/index/type/_search?q= 全文搜索 1.2 安装elastic client:1go get gopkg.in/olivere/elastic.v5 2. 安装ElasticSearch服务器2.1 使用Docker方式安装12345docker login daocloud.iodocker pull daocloud.io/library/elasticsearch:7.3.2docker run -d -p 9200:9200 daocloud.io/library/elasticsearch","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://elihe2011.github.io/tags/elasticsearch/"}]},{"title":"Go标准库 http","slug":"Go 标准库http","date":"2018-01-17T04:11:18.000Z","updated":"2021-06-22T10:50:49.708Z","comments":true,"path":"2018/01/17/Go 标准库http/","link":"","permalink":"https://elihe2011.github.io/2018/01/17/Go%20%E6%A0%87%E5%87%86%E5%BA%93http/","excerpt":"","text":"1. 客户端Http Client: http.GET(url) 直接发起请求 http.Client{} 控制请求头部等 httputil 简化工作 示例： 123456789101112131415161718192021222324252627282930313233func main() &#123; // 1. 直接发起请求 //resp, err := http.Get(&quot;https://baidu.com&quot;) // 2. 控制请求头 req, err := http.NewRequest( http.MethodGet, &quot;http://www.baidu.com&quot;, nil) req.Header.Add(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1&quot;) //resp, err := http.DefaultClient.Do(req) // 3. 检测是否重定向 client := http.Client&#123; CheckRedirect: func(req *http.Request, via []*http.Request) error &#123; fmt.Println(&quot;Redirect:&quot;, req) return nil &#125;, &#125; resp, err := client.Do(req) if err != nil &#123; panic(err) &#125; defer resp.Body.Close() content, err := httputil.DumpResponse(resp, true) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%s&quot;, content)&#125; 2. 服务端2.1 handler函数12345678910111213141516171819202122232425262728func SignupHandler(w http.ResponseWriter, r *http.Request) &#123; if r.Method == http.MethodGet &#123; data, err := ioutil.ReadFile(&quot;./static/view/signup.html&quot;) if err != nil &#123; w.WriteHeader(http.StatusInternalServerError) return &#125; w.Write(data) &#125; else &#123; r.ParseForm() // 必须的 username := r.Form.Get(&quot;username&quot;) password := r.Form.Get(&quot;password&quot;) if len(username) &lt; 3 || len(password) &lt; 5 &#123; w.Write([]byte(&quot;Invalid parameter&quot;)) return &#125; enc_pwd := util.Sha1([]byte(password + pwd_salt)) ret := db.UserSignup(username, enc_pwd) if ret &#123; w.Write([]byte(&quot;SUCCESS&quot;)) &#125; else &#123; w.Write([]byte(&quot;FAILED&quot;)) &#125; &#125;&#125; 2.2 中间件123456789101112131415func HTTPInterceptor(h http.HandlerFunc) http.HandlerFunc &#123; return http.HandlerFunc( func(w http.ResponseWriter, r *http.Request) &#123; r.ParseForm() username := r.Form.Get(&quot;username&quot;) token := r.Form.Get(&quot;token&quot;) if len(username) &lt; 3 || !IsTokenValid(token) &#123; w.WriteHeader(http.StatusForbidden) return &#125; h(w, r) &#125;)&#125; 2.3 启动服务123456789101112131415func main() &#123; // 静态文件 path, _ := os.Getwd() path = filepath.Join(path, &quot;static&quot;) http.Handle(&quot;/static/&quot;, http.StripPrefix(&quot;/static/&quot;, http.FileServer(http.Dir(path)))) // 路由和中间件 http.HandleFunc(&quot;/user/signup&quot;, handler.SignupHandler) http.HandleFunc(&quot;/user/info&quot;, handler.HTTPInterceptor(handler.UserInfoHandler)) err := http.ListenAndServe(&quot;:8080&quot;, nil) if err != nil &#123; log.Fatalf(&quot;Failed to start server: %v&quot;, err) &#125;&#125; 3. http服务器性能分析 import _ &quot;net/http/pprof 访问/debug/pprof/ 使用go tool pprof分析性能 1234567import ( &quot;log&quot; &quot;net/http&quot; _ &quot;net/http/pprof&quot; &quot;os&quot; ...) 查看性能： http://localhost:8080/debug/pprof/ go tool pprof http://localhost:8080/debug/pprof/profile","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 标准库unsafe","slug":"Go 标准库unsafe","date":"2018-01-16T04:11:18.000Z","updated":"2021-06-22T10:50:49.707Z","comments":true,"path":"2018/01/16/Go 标准库unsafe/","link":"","permalink":"https://elihe2011.github.io/2018/01/16/Go%20%E6%A0%87%E5%87%86%E5%BA%93unsafe/","excerpt":"1. unsafe包Go是强类型语言，不允许不同类型的指针互相转换。但它提供unsafe包作为中间媒介，快速实现类型转换，但该转换是不安全的。 1.1 Go指针和unsafe.Pointer的区别Go指针： 不能进行数学运算 不同类型的指针，不能相互转换 不同类型的指针不能使用 == 或 != 比较 不同类型的指针变量不能相互赋值 unsafe.Pointer: 12type ArbitraryType inttype Pointer *ArbitraryType","text":"1. unsafe包Go是强类型语言，不允许不同类型的指针互相转换。但它提供unsafe包作为中间媒介，快速实现类型转换，但该转换是不安全的。 1.1 Go指针和unsafe.Pointer的区别Go指针： 不能进行数学运算 不同类型的指针，不能相互转换 不同类型的指针不能使用 == 或 != 比较 不同类型的指针变量不能相互赋值 unsafe.Pointer: 12type ArbitraryType inttype Pointer *ArbitraryType uintptr: Go的内置类型，能存储指针的整型，与普通指针区别如下 1type uintptr uintptr 普通指针不可以参与计算，但uintptr可以。 普通指针和uintptr之间必选进行强制转换。 GC 不会把uintptr当成指针，由uintptr变量表示的地址处的数据也可能被GC回收。 1.2 主要方法123456789101112type ArbitraryType inttype Pointer *ArbitraryType// 返回类型所占内存大小func Sizeof（variable ArbitraryType）uintptr // 返回类型的对齐值, 等价于reflect.TypeOf(x).Align()func Alignof（variable ArbitraryType）uintptr// struct结构体中的字段相对于结构体的内存位置偏移量。结构体的第一个字段的偏移量都是0.// 等价于reflect.TypeOf(u1).Field(i).Offsetfunc Offsetof（selector ArbitraryType）uintptr 2. 指针转换2.1 示例：int32指针指向int64数据123456789101112131415func main() &#123; var n int64 = 5 var p1 = &amp;n var p2 = (*int32)(unsafe.Pointer(p1)) // 类型虽然不一样，但指向同一个地址 fmt.Printf(&quot;p1=%v, p2=%v\\n&quot;, p1, p2) *p2 = 10 fmt.Printf(&quot;n=%v, *p1=%v, *p2=%v\\n&quot;, n, *p1, *p2) // *p2 越界 *p1 = math.MaxInt32 + 1 fmt.Printf(&quot;n=%v, *p1=%v, *p2=%v\\n&quot;, n, *p1, *p2)&#125; 2.2 示例：遍历数组元素1234567891011func main() &#123; a := [...]int&#123;4, 7, 2, 9, 5&#125; p := &amp;a[0] fmt.Printf(&quot;%p: %v\\n&quot;, p, *p) for i := 1; i &lt; len(a); i++ &#123; ptr := uintptr(unsafe.Pointer(p)) + unsafe.Sizeof(a[0]) p = (*int)(unsafe.Pointer(ptr)) fmt.Printf(&quot;%p: %v\\n&quot;, p, *p) &#125;&#125; 3. 类型对齐值1234567891011121314151617181920212223func main() &#123; var b bool var i int var i64 int64 var f float32 var f64 float64 var s string var m map[int]string // 固定8 var a []int var p *int32 fmt.Println(unsafe.Alignof(b)) // 1 fmt.Println(unsafe.Alignof(i)) // 8 fmt.Println(unsafe.Alignof(i64)) // 8 fmt.Println(unsafe.Alignof(f)) // 4 fmt.Println(unsafe.Alignof(f64)) // 8 fmt.Println(unsafe.Alignof(s)) // 8 fmt.Println(unsafe.Alignof(m)) // 8 fmt.Println(unsafe.Alignof(a)) // 8 fmt.Println(unsafe.Alignof(p)) // 8&#125; 4. 利用unsafe包修改私有成员结构体(struct)，可以通过offset函数获取成员的偏移量，进而获取成员的地址。读写该地址的内存，就可以达到改变成员值的目的 结构体内存分配：会被分配一块连续的内存，结构体的地址也代表了第一个成员的地址。 12345678910111213141516type User struct &#123; name string age int&#125;func main() &#123; user := User&#123;&quot;eli&quot;, 29&#125; name := (*string)(unsafe.Pointer(&amp;user)) *name = &quot;rania&quot; age := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;user)) + unsafe.Offsetof(user.age))) *age = 20 fmt.Println(user)&#125; 5. 获取slice的长度12345678// runtime/slice.gotype slice struct &#123; array unsafe.Pointer // offset=8 len int cap int&#125;func makeslice(et *_type, len, cap int) slice 12345678910func main() &#123; s := make([]int, 5, 10) fmt.Printf(&quot;%p\\n&quot;, &amp;s) Len := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(8))) fmt.Printf(&quot;Len=%d, len(s)=%d\\n&quot;, *Len, len(s)) Cap := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s)) + uintptr(16))) fmt.Printf(&quot;Cap=%d, cap(s)=%d\\n&quot;, *Cap, cap(s))&#125; 6. 获取map长度12345678910111213141516type hmap struct &#123; count int flags uint8 B uint8 noverflow uint16 hash0 uint32 buckets unsafe.Pointer oldbuckets unsafe.Pointer nevacuate uintptr extra *mapextra&#125;// 注意返回的是指针func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap 12345678func main() &#123; mp := make(map[string]int) mp[&quot;a&quot;] = 21 mp[&quot;z&quot;] = 45 count := **(**int)(unsafe.Pointer(&amp;mp)) // 二级指针 fmt.Println(count, len(mp)) // 2 2&#125; 7. 实现字符串和byte切片的零拷贝转换slice和string的底层数据结构： 123456789101112131415161718192021222324252627282930313233type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125;func string2bytes(s string) []byte &#123; stringHeader := (*reflect.StringHeader)(unsafe.Pointer(&amp;s)) bh := reflect.SliceHeader&#123; Data: stringHeader.Data, Len: stringHeader.Len, Cap: stringHeader.Len, &#125; return *(*[]byte)(unsafe.Pointer(&amp;bh))&#125;func bytes2string(b []byte) string &#123; sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(&amp;b)) sh := reflect.StringHeader&#123; Data: sliceHeader.Data, Len: sliceHeader.Len, &#125; return *(*string)(unsafe.Pointer(&amp;sh))&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 单元测试","slug":"Go 单元测试","date":"2018-01-15T01:27:53.000Z","updated":"2021-06-22T10:50:49.707Z","comments":true,"path":"2018/01/15/Go 单元测试/","link":"","permalink":"https://elihe2011.github.io/2018/01/15/Go%20%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","excerpt":"1. 基础测试1.1 最简单的测试1234567func Add(x, y int) int &#123; return x + y&#125;func Sub(x, y int) int &#123; return x - y&#125;","text":"1. 基础测试1.1 最简单的测试1234567func Add(x, y int) int &#123; return x + y&#125;func Sub(x, y int) int &#123; return x - y&#125; 12345678910111213141516171819func TestAdd(t *testing.T) &#123; result := Add(3, 5) if result != 8 &#123; t.Fatalf(&quot;expected: %d, actual: %d&quot;, 8, result) &#125; t.Log(&quot;test Add success.&quot;)&#125;func TestSub(t *testing.T) &#123; result := Sub(3, 5) if result != -2 &#123; t.Fatalf(&quot;expected: %d, actual: %d&quot;, -2, result) &#125; t.Log(&quot;test Sub success.&quot;)&#125; 1234567go testgo test -vgo test -v -run TestAddgo help testflag 1.2 表格驱动测试123456789101112131415func TestAddBatch(t *testing.T) &#123; tests := []struct&#123; a, b, c int &#125;&#123; &#123;1, 2, 3&#125;, &#123;0, 2, 2&#125;, &#123;-1, 1, 1&#125;, &#125; for _, test := range tests &#123; if actual := Add(test.a, test.b); actual != test.c &#123; t.Errorf(&quot;Add(%d, %d); got %d; expected %d\\n&quot;, test.a, test.b, actual, test.c) &#125; &#125;&#125; 1.3 覆盖率测试123go test -coverprofile=c.outgo tool cover -html=c.out 1.4 Example Code测试1234567func Fib(n int) int &#123; if n &lt;= 2 &#123; return 1 &#125; return Fib(n-1) + Fib(n-2)&#125; 12345func ExampleFib() &#123; fmt.Println(fib(10)) // Output: 55&#125; 1go test -v 2. 基准测试基准测可以测试一段程序的运行性能及耗费CPU的程度 1234567891011121314151617181920212223242526272829303132333435363738func fib(n int) int &#123; a, b := 1, 1 for i := 1; i &lt;= n; i++ &#123; if i == n &#123; break &#125; a, b = b, a+b &#125; return a&#125;func fibonacci() func() int &#123; a, b := 1, 1 return func() int &#123; x := a a, b = b, a+b return x &#125;&#125;func fib2(n int) int &#123; x := 0 f := fibonacci() for i := 1; i &lt;= n; i++ &#123; x = f() &#125; return x&#125;func fib3(n int) int &#123; if n &lt;= 2 &#123; return 1 &#125; return fib3(n-1) + fib3(n-2)&#125; 1234567891011121314151617181920212223242526272829303132333435func BenchmarkFib(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib(n) if actual != expected &#123; b.Errorf(&quot;fib(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125;func BenchmarkFib2(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib2(n) if actual != expected &#123; b.Errorf(&quot;fib2(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125;func BenchmarkFib3(b *testing.B) &#123; n := 9 expected := 34 for i := 0; i &lt; b.N; i++ &#123; actual := fib3(n) if actual != expected &#123; b.Errorf(&quot;fib3(%d), got %d, expected %d&quot;, n, actual, expected) &#125; &#125;&#125; 123456789101112go test -bench=.BenchmarkFib-4 222371659 5.33 ns/opBenchmarkFib2-4 13082476 85.9 ns/opBenchmarkFib3-4 10054833 120 ns/op# 自定义测试时间go test -bench=. -benchmem -benchtime=10sBenchmarkFib-4 1000000000 5.35 ns/op 0 B/op 0 allocs/opBenchmarkFib2-4 138880591 87.1 ns/op 48 B/op 3 allocs/opBenchmarkFib3-4 97723549 120 ns/op 0 B/op 0 allocs/op ns/op 表示每一个操作消耗多少时间,单位是 纳秒ns B/op 表示每一次操作需要分配的字节数 allocs/op 表示每次执行分配了多少次 1234go test -bench . -cpuprofile=cpu.outgo tool pprof cpu.out(pprof) web 2.1 性能对比，int转string123456789101112131415161718192021222324func BenchmarkSprintf(b *testing.B) &#123; num := 10 b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; fmt.Sprintf(&quot;%d&quot;, num) &#125;&#125;func BenchmarkFormat(b *testing.B) &#123; num := int64(10) b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; strconv.FormatInt(num, 10) &#125;&#125;func BenchmarkItoa(b *testing.B) &#123; num := 10 b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; strconv.Itoa(num) &#125;&#125; 123456789 go test -bench=. -benchmemgoos: darwingoarch: amd64pkg: gomod/aaaBenchmarkSprintf-4 12190561 94.1 ns/op 16 B/op 2 allocs/opBenchmarkFormat-4 275836423 4.24 ns/op 0 B/op 0 allocs/opBenchmarkItoa-4 253071742 4.73 ns/op 0 B/op 0 allocs/opPASSok gomod/aaa 5.386s 2.2 pprof 性能监控12345678910111213func Fib(n int) int &#123; if n &lt; 2 &#123; return n &#125; return Fib(n-1) + Fib(n-2)&#125;func BenchmarkFib(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; Fib(10) &#125;&#125; 1234567go test -bench=. -benchmem -cpuprofile cpu.out -memprofile mem.outgo tool pprof cpu.out (pprof) top(pprof) list Fibgo tool pprof -http=&quot;:8081&quot; cpu.out 3. gomock当待测试的函数/对象的依赖关系很复杂，并且有些依赖不能直接创建，例如数据库连接、文件I/O等。这种场景就非常适合使用 mock/stub 测试。简单来说，就是用 mock 对象模拟依赖项的行为。 3.1 安装12go get -u github.com/golang/mock/gomockgo get -u github.com/golang/mock/mockgen 3.2 示例3.2.1 待mock的代码1234567891011type DB interface &#123; Get(key string) (int, error)&#125;func GetFromDB(db DB, key string) int &#123; if value, err := db.Get(key); err == nil &#123; return value &#125; return -1&#125; 3.2.2 生成mock代码1mockgen -source=db.go -destination=db_mock.go -package=main 3.2.3 测试代码1234567891011func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;)) if v := GetFromDB(m, &quot;Tom&quot;); v != -1 &#123; t.Fatalf(&quot;expected -1, but go %v&quot;, v) &#125;&#125; 3.2.4 执行测试123456$ go test . -cover -v=== RUN TestGetFromDB--- PASS: TestGetFromDB (0.00s)PASScoverage: 92.9% of statementsok gomod/mock 1.030s coverage: 92.9% of statements 3.3 打桩 (stubs)3.3.1 参数 (Eq, Any, Not, Nil)1234m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;))m.EXPECT().Get(gomock.Any()).Return(630, nil)m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil) m.EXPECT().Get(gomock.Nil()).Return(0, errors.New(&quot;nil&quot;)) 3.3.2 返回值 (Return, Do, DoAndReturn)12345678910m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil)m.EXPECT().Get(gomock.Any()).Do(func(key string) &#123; t.Log(key)&#125;)m.EXPECT().Get(gomock.Any()).DoAndReturn(func(key string) (int, error) &#123; if key == &quot;Sam&quot; &#123; return 630, nil &#125; return 0, errors.New(&quot;not exist&quot;)&#125;) 3.3.3 调用次数 (Times, MaxTimes, MinTimes, AnyTimes)123456789func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() m := NewMockDB(ctrl) m.EXPECT().Get(gomock.Not(&quot;Sam&quot;)).Return(0, nil).Times(2) GetFromDB(m, &quot;ABC&quot;) GetFromDB(m, &quot;DEF&quot;)&#125; 调用顺序 (InOrder)1234567891011func TestGetFromDB(t *testing.T) &#123; ctrl := gomock.NewController(t) defer ctrl.Finish() // 断言 DB.Get() 方法是否被调用 m := NewMockDB(ctrl) o1 := m.EXPECT().Get(gomock.Eq(&quot;Tom&quot;)).Return(0, errors.New(&quot;not exist&quot;)) o2 := m.EXPECT().Get(gomock.Eq(&quot;Sam&quot;)).Return(630, nil) gomock.InOrder(o1, o2) GetFromDB(m, &quot;Tom&quot;) GetFromDB(m, &quot;Sam&quot;)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 正则表达式","slug":"Go 正则表达式","date":"2018-01-12T01:26:38.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/12/Go 正则表达式/","link":"","permalink":"https://elihe2011.github.io/2018/01/12/Go%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"1. 正则表达式12345678func main() &#123; str := `171.43.145.13 - - [10/Mar/2020:10:19:06 +0800] &quot;POST /api/user/detail HTTP/1.1&quot; 200 252 &quot;-&quot; &quot;LifePlanner/1.9.14 (com.njivtime.lifeplanner; build:1.9.14.9; iOS 13.3.1) Alamofire/4.8.2&quot; &quot;-&quot; 0.009 0.009` re := regexp.MustCompile(`\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\s`) arr := re.FindAllString(str, -1) fmt.Println(arr)&#125;","text":"1. 正则表达式12345678func main() &#123; str := `171.43.145.13 - - [10/Mar/2020:10:19:06 +0800] &quot;POST /api/user/detail HTTP/1.1&quot; 200 252 &quot;-&quot; &quot;LifePlanner/1.9.14 (com.njivtime.lifeplanner; build:1.9.14.9; iOS 13.3.1) Alamofire/4.8.2&quot; &quot;-&quot; 0.009 0.009` re := regexp.MustCompile(`\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\s`) arr := re.FindAllString(str, -1) fmt.Println(arr)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 序列化操作","slug":"Go 序列化操作","date":"2018-01-11T01:24:54.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/11/Go 序列化操作/","link":"","permalink":"https://elihe2011.github.io/2018/01/11/Go%20%E5%BA%8F%E5%88%97%E5%8C%96%E6%93%8D%E4%BD%9C/","excerpt":"1. 序列化json.Marshal(v interface&#123;&#125;) ([]byte, error)","text":"1. 序列化json.Marshal(v interface&#123;&#125;) ([]byte, error) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172type Person struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;` Birthday string `json:&quot;birthday&quot;` Salary float64 `json:&quot;salary&quot;` Occupation string `json:&quot;occupation&quot;`&#125;func main() &#123; serializeStruct() serializeMap() serializeSlice()&#125;func serializeStruct() &#123; p := Person&#123; Name: &quot;张三&quot;, Age: 45, Birthday: &quot;1975-05-01&quot;, Salary: 32000.0, Occupation: &quot;电气工程师&quot;, &#125; data, err := json.Marshal(&amp;p) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125;func serializeMap() &#123; var m map[string]interface&#123;&#125; m = make(map[string]interface&#123;&#125;) m[&quot;name&quot;] = &quot;李四&quot; m[&quot;age&quot;] = 30 m[&quot;city&quot;] = &quot;北京市&quot; data, err := json.Marshal(m) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125;func serializeSlice() &#123; var s []map[string]interface&#123;&#125; m1 := make(map[string]interface&#123;&#125;) m1[&quot;name&quot;] = &quot;Tom&quot; m1[&quot;age&quot;] = 17 m1[&quot;city&quot;] = &quot;Los Angles&quot; m2 := make(map[string]interface&#123;&#125;) m2[&quot;name&quot;] = &quot;Julie&quot; m2[&quot;age&quot;] = 21 m2[&quot;city&quot;] = &quot;New York&quot; s = append(s, m1, m2) data, err := json.Marshal(s) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(data))&#125; 2. 反序列化json.Unmarshal(data []byte, v interface&#123;&#125;) error 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type Person struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;` Birthday string `json:&quot;birthday&quot;` Salary float64 `json:&quot;salary&quot;` Occupation string `json:&quot;occupation&quot;`&#125;func main() &#123; deserializeStruct() deserializeMap() deserializeSlice()&#125;func deserializeStruct() &#123; js := `&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;:45,&quot;birthday&quot;:&quot;1975-05-01&quot;,&quot;salary&quot;:32000,&quot;occupation&quot;:&quot;电气工程师&quot;&#125;` var p Person err := json.Unmarshal([]byte(js), &amp;p) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(p)&#125;func deserializeMap() &#123; js := `&#123;&quot;age&quot;:30,&quot;city&quot;:&quot;北京市&quot;,&quot;name&quot;:&quot;李四&quot;&#125;` var m map[string]interface&#123;&#125; // 反序列化不需要make，注意使用指针 &amp;m err := json.Unmarshal([]byte(js), &amp;m) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(m)&#125;func deserializeSlice() &#123; js := `[&#123;&quot;age&quot;:17,&quot;city&quot;:&quot;Los Angles&quot;,&quot;name&quot;:&quot;Tom&quot;&#125;,&#123;&quot;age&quot;:21,&quot;city&quot;:&quot;New York&quot;,&quot;name&quot;:&quot;Julie&quot;&#125;]` var s []map[string]interface&#123;&#125; // 反序列化不需要make，注意使用指针 &amp;s err := json.Unmarshal([]byte(js), &amp;s) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(s)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 网络编程","slug":"Go 网络编程","date":"2018-01-10T01:13:45.000Z","updated":"2021-06-22T10:50:49.706Z","comments":true,"path":"2018/01/10/Go 网络编程/","link":"","permalink":"https://elihe2011.github.io/2018/01/10/Go%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","excerpt":"1. 网络编程1234567net.Listen(network, address string) (Listener, error)listener.Accept() (Conn, err)conn.Close()conn.Read([]byte) (int, err)conn.Write([]byte)net.Dial(network, address string) (Conn, error)","text":"1. 网络编程1234567net.Listen(network, address string) (Listener, error)listener.Accept() (Conn, err)conn.Close()conn.Read([]byte) (int, err)conn.Write([]byte)net.Dial(network, address string) (Conn, error) 1.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546func main() &#123; ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;Server has started, listening on %s\\n&quot;, ln.Addr()) defer ln.Close() for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; handleConnect(conn) &#125;&#125;func handleConnect(conn net.Conn) &#123; defer conn.Close() remoteAddr := conn.RemoteAddr() fmt.Printf(&quot;[%s] connected\\n&quot;, remoteAddr) for &#123; buf := make([]byte, 2048) n, err := conn.Read(buf) if err != nil &#123; fmt.Printf(&quot;[%s] disconnected\\n&quot;, remoteAddr) break &#125; str := string(buf[:n-1]) if str == &quot;quit&quot; || str == &quot;exit&quot; &#123; fmt.Printf(&quot;[%s] disconnected\\n&quot;, remoteAddr) break &#125; fmt.Printf(&quot;%s &gt;&gt; %s\\n&quot;, remoteAddr, str) conn.Write([]byte(strings.ToUpper(str + &quot;\\n&quot;))) &#125;&#125; 1.2 客户端123456789101112131415161718192021222324252627282930313233func main() &#123; conn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 键盘输入，并发送给服务器 go func() &#123; buf := make([]byte, 1024) for &#123; n, err := os.Stdin.Read(buf) if err != nil &#123; fmt.Println(err) break &#125; conn.Write(buf[:n]) &#125; &#125;() // 处理服务器返回数据 buf := make([]byte, 1024) for &#123; n, err := conn.Read(buf) if err == io.EOF &#123; return &#125; fmt.Println(string(buf[:n-1])) &#125;&#125; 2. 文件发送与接收2.1 服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273func main() &#123; // 开启服务 ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() fmt.Printf(&quot;[%s]等待接收文件...\\n&quot;, ln.Addr()) // 接收请求 conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 获取对方发送的文件名 buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; fileName := string(buf[:n]) fmt.Printf(&quot;文件名: [%s]\\n&quot;, fileName) // 通知对方发送文件内容 _, err = conn.Write([]byte(&quot;ok&quot;)) if err != nil &#123; fmt.Println(err) return &#125; // 接收文件内容 recvFile(fileName, conn)&#125;func recvFile(fileName string, conn net.Conn) &#123; // 创建文件 f, err := os.Create(fileName) if err != nil &#123; fmt.Println(err) return &#125; defer f.Close() buf := make([]byte, 1024*4) for &#123; n, err := conn.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;\\n文件接收完毕&quot;) &#125; else &#123; fmt.Println(err) &#125; break &#125; if n == 0 &#123; fmt.Println(&quot;文件接收完毕&quot;) break &#125; fmt.Printf(&quot;.&quot;) _, err = f.Write(buf[:n]) if err != nil &#123; fmt.Println(&quot;写文件失败&quot;) &#125; &#125;&#125; 2.2 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func main() &#123; fmt.Printf(&quot;请输入文件名: &quot;) var fileName string fmt.Scan(&amp;fileName) // 获取文件信息 info, err := os.Stat(fileName) if err != nil &#123; fmt.Println(err) return &#125; // 连接文件接收服务器 conn, err := net.Dial(&quot;tcp&quot;, &quot;localhost:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() // 发送文件名 _, err = conn.Write([]byte(info.Name())) // 服务器是否就绪 buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; if &quot;ok&quot; != string(buf[:n]) &#123; fmt.Println(&quot;服务器未就绪&quot;) return &#125; // 发送文件内容 sendFile(fileName, conn)&#125;func sendFile(fileName string, conn net.Conn) &#123; f, err := os.Open(fileName) if err != nil &#123; fmt.Println(err) return &#125; defer f.Close() buf := make([]byte, 1024*4) for &#123; _, err = f.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(&quot;发送完毕&quot;) &#125; else &#123; fmt.Println(err) &#125; break &#125; // 发送内容 conn.Write(buf) &#125;&#125; 3. 聊天服务器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145func main() &#123; // 开启监听服务 ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() // 转发消息 go Manager() // 主协程，循环阻塞等待用户连接 for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; go HandleConn(conn) &#125;&#125;// 客户端type Client struct &#123; C chan string Name string Addr string&#125;// 在线用户var onlineMap map[string]Client// 消息var message = make(chan string)// 消息转发func Manager() &#123; // 在线用户分配空间 onlineMap = make(map[string]Client) for &#123; msg := &lt;-message for _, cli := range onlineMap &#123; cli.C &lt;- msg &#125; &#125;&#125;func HandleConn(conn net.Conn) &#123; defer conn.Close() // 客户端地址 cliAddr := conn.RemoteAddr().String() // 客户端 cli := Client&#123; make(chan string), cliAddr, cliAddr, &#125; // 添加到在线用户 onlineMap[cliAddr] = cli // 新开协程，专门给当前客户端发送信息 go WriteMsgToClient(cli, conn) // 广播在线 message &lt;- MakeMsg(cli, &quot;online&quot;) // 当前用户是否已退出 isQuit := make(chan bool) // 当前用户是否超时 hasData := make(chan bool) // 新开协程，接收用户发来的数据 go func() &#123; buf := make([]byte, 2048) for &#123; n, err := conn.Read(buf) if n == 0 &#123; isQuit &lt;- true fmt.Println(&quot;用户断开连接或出现其他问题&quot;, err) return &#125; msg := string(buf[:n-1]) // 查询当前在线用户列表 if msg == &quot;who&quot; &#123; // 给当前用户发送所有在线成员 conn.Write([]byte(&quot;user list:\\n&quot;)) for _, u := range onlineMap &#123; conn.Write([]byte(u.Addr + &quot;: &quot; + u.Name + &quot;\\n&quot;)) &#125; &#125; else if len(msg) &gt; 8 &amp;&amp; msg[:6] == &quot;rename&quot; &#123; name := msg[7:] cli.Name = name onlineMap[cliAddr] = cli conn.Write([]byte(&quot;rename ok\\n&quot;)) &#125; else &#123; // 转发内容至其他在线用户 message &lt;- MakeMsg(cli, msg) &#125; hasData &lt;- true &#125; &#125;() for &#123; select &#123; case &lt;-isQuit: // 从在线用户列表中删除 delete(onlineMap, cliAddr) // 发送广播通知 message &lt;- MakeMsg(cli, &quot;offline&quot;) return case &lt;-hasData: case &lt;-time.After(time.Second * 60): delete(onlineMap, cliAddr) message &lt;- MakeMsg(cli, &quot;timeout&quot;) return &#125; &#125;&#125;func WriteMsgToClient(cli Client, conn net.Conn) &#123; for msg := range cli.C &#123; conn.Write([]byte(msg + &quot;\\n&quot;)) &#125;&#125;func MakeMsg(cli Client, msg string) string &#123; return &quot;[&quot; + cli.Addr + &quot;]&quot; + cli.Name + &quot;: &quot; + msg&#125; 4. HTTP服务器4.1 服务器123456789101112131415161718192021222324252627282930313233func main() &#123; ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer ln.Close() fmt.Println(&quot;http://localhost:8080&quot;) for &#123; conn, err := ln.Accept() if err != nil &#123; fmt.Println(err) continue &#125; go handleConn(conn) &#125;&#125;func handleConn(conn net.Conn) &#123; defer conn.Close() buf := make([]byte, 1024*4) n, err := conn.Read(buf) if err != nil &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;%v\\n&quot;, string(buf[:n]))&#125; 12345678910111213141516func main() &#123; // 注册处理函数 http.HandleFunc(&quot;/go&quot;, myHandler) fmt.Println(&quot;http://localhost:8080&quot;) http.ListenAndServe(&quot;:8080&quot;, nil)&#125;func myHandler(w http.ResponseWriter, req *http.Request) &#123; fmt.Println(&quot;Method:&quot;, req.Method) fmt.Println(&quot;Header:&quot;, req.Header) fmt.Println(&quot;RemoteAddr:&quot;, req.RemoteAddr) fmt.Println(&quot;URL:&quot;, req.URL) fmt.Fprintln(w, &quot;Hello world!&quot;)&#125; 4.2 客户端12345678910111213141516171819202122232425func main() &#123; conn, err := net.Dial(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer conn.Close() requestHead := &quot;GET /go HTTP/1.1\\r\\nHost: localhost:8080\\r\\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7\\r\\n\\r\\n&quot; fmt.Println(requestHead) // 发送请求 conn.Write([]byte(requestHead)) // 接收响应 buf := make([]byte, 1024*4) n, err := conn.Read(buf) if n == 0 &#123; fmt.Println(err) return &#125; fmt.Printf(&quot;#%v#\\n&quot;, string(buf[:n]))&#125; 12345678910111213141516171819202122232425262728func main() &#123; //resp, err := http.Get(&quot;http://www.baidu.com&quot;) resp, err := http.Get(&quot;http://localhost:8080/go&quot;) if err != nil &#123; fmt.Println(err) return &#125; defer resp.Body.Close() fmt.Println(&quot;Status =&quot;, resp.Status) fmt.Println(&quot;StatusCode =&quot;, resp.StatusCode) fmt.Println(&quot;Header =&quot;, resp.Header) //fmt.Println(&quot;Body = &quot;, resp.Body) var text string buf := make([]byte, 1024*4) for &#123; n, err := resp.Body.Read(buf) if n == 0 &#123; fmt.Println(err) break &#125; text += string(buf[:n]) &#125; fmt.Println(text)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 命令行参数","slug":"Go 命令行参数","date":"2018-01-09T01:10:13.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/09/Go 命令行参数/","link":"","permalink":"https://elihe2011.github.io/2018/01/09/Go%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/","excerpt":"1. 命令行参数：os.Args []string123456789func main() &#123; args := os.Args fmt.Printf(&quot;接收到%v个参数\\n&quot;, len(args)) for i, v := range args &#123; fmt.Printf(&quot;args[%v]=%v\\n&quot;, i, v) &#125;&#125;","text":"1. 命令行参数：os.Args []string123456789func main() &#123; args := os.Args fmt.Printf(&quot;接收到%v个参数\\n&quot;, len(args)) for i, v := range args &#123; fmt.Printf(&quot;args[%v]=%v\\n&quot;, i, v) &#125;&#125; 2. flag包解析命令行参数12IntVar(p *int, name string, value int, usage string)StringVar(p *string, name string, value string, usage string) 12345678910111213141516func main() &#123; var user string var pwd string var host string var port int flag.StringVar(&amp;user, &quot;u&quot;, &quot;&quot;, &quot;用户名，默认为空&quot;) flag.StringVar(&amp;pwd, &quot;p&quot;, &quot;&quot;, &quot;密码，默认为空&quot;) flag.StringVar(&amp;host, &quot;h&quot;, &quot;&quot;, &quot;主机名，localhost&quot;) flag.IntVar(&amp;port, &quot;P&quot;, 3306, &quot;端口，默认3306&quot;) // 转换 flag.Parse() fmt.Printf(&quot;user=%v, pwd=%v, host=%v, port=%v\\n&quot;, user, pwd, host, port)&#125; 123$ go build -o main flag_1.go $ ./main -u root -p 123456 -h localhost -P 3006user=root, pwd=123456, host=localhost, port=3006","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 文件操作","slug":"Go 文件操作","date":"2018-01-08T01:04:38.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/08/Go 文件操作/","link":"","permalink":"https://elihe2011.github.io/2018/01/08/Go%20%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","excerpt":"1. 读文件 os.Open(name string) (file *File, err error) ioutil.ReadFile(name string) ([]byte, error) 适合小文件一次性读取","text":"1. 读文件 os.Open(name string) (file *File, err error) ioutil.ReadFile(name string) ([]byte, error) 适合小文件一次性读取 1.1 带缓存读取文件123456789101112131415161718func main() &#123; file, err := os.Open(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() reader := bufio.NewReader(file) for &#123; // 按行读取 line, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; fmt.Print(line) &#125;&#125; 1.2 一次性读取文件：(小文件适用)123456789func main() &#123; bs, err := ioutil.ReadFile(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Read file error: %v\\n&quot;, err) return &#125; fmt.Printf(&quot;%s\\n&quot;, bs)&#125; 2. 写文件1os.OpenFile(name string, flag int, perm FileMode) (file *File, err error) 12345678910111213141516func main() &#123; file, err := os.OpenFile(&quot;./xyz.txt&quot;, os.O_CREATE|os.O_WRONLY, 0600) if err != nil &#123; fmt.Errorf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() msg := &quot;Hello World!\\n&quot; writer := bufio.NewWriter(file) for i := 0; i &lt; 5; i++ &#123; writer.Write([]byte(msg)) &#125; writer.Flush()&#125; 文件操作模式： 覆盖写：os.O_WRONLY | os.O_TRUNC 追加写：os.O_WRONLY | os.O_APPEND 读写并追加：os.O_RDWR | os.OS_APPEND 3. 文件拷贝3.1 直接拷贝文件内容 （小文件，文本文件）123456789101112func main() &#123; bs, err := ioutil.ReadFile(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Errorf(&quot;Read file error: %v\\n&quot;, err) return &#125; err = ioutil.WriteFile(&quot;./xyz.txt&quot;, bs, 0600) if err != nil &#123; fmt.Errorf(&quot;Write file error: %v&quot;, err) &#125;&#125; 3.2 带缓冲拷贝 （大文件，二进制文件）io.Copy(dst Writer, src Reader) (written int64, err error) 123456789101112131415161718192021func CopyFile(dstFileName, srcFileName string) (written int64, err error) &#123; srcFile, err := os.OpenFile(srcFileName, os.O_RDONLY, 0) if err != nil &#123; return 0, err &#125; defer srcFile.Close() dstFile, err := os.OpenFile(dstFileName, os.O_CREATE|os.O_WRONLY, 0600) if err != nil &#123; return 0, err &#125; defer dstFile.Close() writer := bufio.NewWriter(dstFile) reader := bufio.NewReader(srcFile) written, err = io.Copy(writer, reader) writer.Flush() // 需要自己去Flush return&#125; 4. 文件是否存在12345678910111213func IsFileExist(name string) (bool, error) &#123; _, err := os.Stat(name) if err == nil &#123; return true, nil &#125; if os.IsNotExist(err) &#123; fmt.Println(&quot;文件不存在&quot;) return false, nil &#125; return false, err&#125; 5. 字符统计123456789101112131415161718192021222324252627282930313233343536373839404142type Statistic struct &#123; Char int Number int Space int Other int&#125;func main() &#123; file, err := os.Open(&quot;./abc.txt&quot;) if err != nil &#123; fmt.Printf(&quot;Open file error: %v\\n&quot;, err) return &#125; defer file.Close() stat := Statistic&#123;&#125; reader := bufio.NewReader(file) for &#123; bs, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; for _, c := range []rune(bs) &#123; switch &#123; case c &gt;= &#x27;a&#x27; &amp;&amp; c &lt;= &#x27;z&#x27;: fallthrough case c &gt;= &#x27;A&#x27; &amp;&amp; c &lt;= &#x27;Z&#x27;: stat.Char++ case c &gt;= &#x27;0&#x27; &amp;&amp; c &lt;= &#x27;9&#x27;: stat.Number++ case c == &#x27; &#x27; || c == &#x27;\\t&#x27;: stat.Space++ default: stat.Other++ &#125; &#125; &#125; fmt.Printf(&quot;%v\\n&quot;, stat)&#125; 6. 目录遍历 type WalkFunc func(path string, info os.FileInfo, err error) error func Walk(root string, walkFn WalkFunc) error 1234567891011121314func main() &#123; // 当root=/tmp时，不会遍历目录下的文件 err := filepath.Walk(&quot;/tmp/&quot;, walkFunc) if err != nil &#123; fmt.Printf(&quot;File walk error: %v\\n&quot;, err) &#125;&#125;func walkFunc(path string, info os.FileInfo, err error) error &#123; fmt.Println(path) //fmt.Println(info.Name(), info.Size()) return nil&#125; 7. 压缩文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374func main() &#123; filePath := &quot;/tmp/&quot; filename := filepath.Base(filePath) fmt.Println(filename) currentTime := time.Now() ms := currentTime.Nanosecond() / 1e6 zipFilename := fmt.Sprintf(&quot;%s_%s%03d.zip&quot;, strings.Split(filename, &quot;.&quot;)[0], currentTime.Format(&quot;20060102150405&quot;), ms) fmt.Println(zipFilename) ZIP(filePath, zipFilename)&#125;func ZIP(source, target string) error &#123; zipFile, err := os.Create(target) if err != nil &#123; return err &#125; defer zipFile.Close() archive := zip.NewWriter(zipFile) defer archive.Close() err = filepath.Walk(source, func(path string, info os.FileInfo, err error) error &#123; if err != nil &#123; return err &#125; header, err := zip.FileInfoHeader(info) if err != nil &#123; return err &#125; header.Name = strings.TrimPrefix(path, source+&quot;/&quot;) // 目录不需要压缩 if info.IsDir() &#123; header.Name += &quot;/&quot; &#125; else &#123; // 压缩算法 header.Method = zip.Deflate &#125; // 保留文件时间 header.Modified = time.Unix(info.ModTime().Unix(), 0) // 创建：压缩包头信息 writer, err := archive.CreateHeader(header) if err != nil &#123; return err &#125; // 目录只需创建，不做其他操作 if info.IsDir() &#123; return nil &#125; // 打开需要压缩的文件 file, err := os.Open(path) if err != nil &#123; return nil &#125; defer file.Close() // 压缩文件 _, err = io.Copy(writer, file) return err &#125;) return err&#125; 8. 文件读取的三种方式 文件整体读取 文件分片读取 (块级读取) 文件行级读取 8.1 文件整体读取1234567891011// 方式1:bs, err := ioutil.ReadFile(filePath)// 方式2:file, err := os.Open(filePath)fileInfo, err := file.Stat()buffer := make([]byte, fileInfo.Size())n, err := file.Read(buffer)fmt.Printf(&quot;%s&quot;, buffer[:n]) 8.2 文件分片读取12345678910111213141516file, err := os.Open(filePath)buffer := make([]byte, 1024)for &#123; n, err := file.Read(buffer) if err != nil &amp;&amp; err != io.EOF &#123; panic(error) &#125; if n == 0 &#123; break &#125; fmt.Printf(&quot;%s&quot;, buffer)&#125; 8.3 文件按行读取123456789101112file, err := os.Open(filePath)reader := bufio.NewReader(file)for &#123; line, _, err := reader.ReadLine() if err == io.EOF &#123; break &#125; fmt.Printf(&quot;%s&quot;, line)&#125; 9. 文件写入的四周方式 简单覆盖写入 常规文件写入 带缓冲的写入 复制文件写入 9.1 简单覆盖写入1err := ioutil.WriteFile(filePath, data, 0666) 9.2 常规文件写入123456file, err := os.Create(filePath)file, err := os.OpenFile(filePath, os.O_RDONLY|os.O_CREATE|os.O_APPEND, 0666)n, err := file.Write([]byte(data))n, err := file.WriteString(data) 9.3 带缓冲的写入bufio 库： 123456789func NewWriter(w io.Writer) *Writerfunc NewWriterSize(w io.Writer, size int) *Writerfunc (b *Writer) Write(p []byte) (nn int, err error)func (b *Writer) WriteString(s string) (int, error)func (b *Writer) WriteByte(c byte) errorfunc (b *Writer) WriteRune(r rune) (size int, err error)func (b *Writer) Flush() error 9.4 复制文件写入io 包 12345// 默认缓冲区大小func Copy(dst Writer, src Reader) (written int64, err error)&#123;&#125;// 自定义缓冲区大小func CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) &#123;&#125; 10. io.Reader 接口","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 反射","slug":"Go 反射","date":"2018-01-07T00:39:46.000Z","updated":"2021-06-22T10:50:49.705Z","comments":true,"path":"2018/01/07/Go 反射/","link":"","permalink":"https://elihe2011.github.io/2018/01/07/Go%20%E5%8F%8D%E5%B0%84/","excerpt":"1. 反射反射：在运行时，动态获取对象的类型信息和内存结构 反射操作所需要的全部信息都源自接口变量，接口变量除了存储自身类型外，还会保存实际对象的类型数据 将任何传入的对象转换为接口类型： 12func TypeOf(o interface&#123;&#125;) Typefunc ValueOf(o interface&#123;&#125;) Value","text":"1. 反射反射：在运行时，动态获取对象的类型信息和内存结构 反射操作所需要的全部信息都源自接口变量，接口变量除了存储自身类型外，还会保存实际对象的类型数据 将任何传入的对象转换为接口类型： 12func TypeOf(o interface&#123;&#125;) Typefunc ValueOf(o interface&#123;&#125;) Value 2. 类型(Type)reflect.TypeOf() 返回对象类型 1234func TypeOf(i interface&#123;&#125;) Type &#123; eface := *(*emptyInterface)(unsafe.Pointer(&amp;i)) return toType(eface.typ)&#125; 2.1 Type和Kind的区别 Type: 真实类型（静态类型） t.Name() Kind: 基础类型（底层类型） t.Kind() 12345678func main() &#123; type X int var a X = 100 t := reflect.TypeOf(a) fmt.Println(t, t.Name(), t.Kind()) // main.X X int&#125; 2.2 基类型和指针类型12345678910func main() &#123; x := 20 tx := reflect.TypeOf(x) tp := reflect.TypeOf(&amp;x) fmt.Println(tx, tx.Name(), tx.Kind()) // int int int fmt.Println(tp, tp.Name(), tp.Kind()) // *int ptr fmt.Println(tx == tp.Elem()) // true&#125; 2.3 方法Type.Elem()返回引用类型 (指针、数组、切片、字典（值）或 通道) 的基类型 12345678910111213func main() &#123;a := [...]byte&#123;1, 2, 3&#125; s := make([]string, 5) m := make(map[int]string) ta := reflect.TypeOf(a) ts := reflect.TypeOf(s) tm := reflect.TypeOf(m) fmt.Println(ta, ta.Elem()) // [3]uint8 uint8 fmt.Println(ts, ts.Elem()) // []string string fmt.Println(tm, tm.Elem()) // ma[[iny]string string&#125; 2.4 辅助判断方法Implements(), ConvertibleTo(), AssignableTo() 12345678910111213141516171819202122func main() &#123; type X int var a X t := reflect.TypeOf(a) fmt.Println(t) // main.X ts := reflect.TypeOf((*fmt.Stringer)(nil)).Elem() fmt.Println(ts) // fmt.Stringer ti := reflect.TypeOf(10) fmt.Println(ti) // int fmt.Println(t.Implements(ts)) // false //fmt.Println(t.Implements(ti)) // panic: non-interface type passed to Type.Implements fmt.Println(t.ConvertibleTo(ts)) // false fmt.Println(t.ConvertibleTo(ti)) // true fmt.Println(t.AssignableTo(ts)) // false fmt.Println(t.AssignableTo(ti)) // false&#125; 2.5 结构体 反射类型Field(), FieldByIndex(), FieldByName(), FieldByNameFunc() 获取 StructField结构体中的内容 12345678910type StructField struct &#123; Name string PkgPath string Type Type // field type Tag StructTag // field tag string Offset uintptr // offset within struct, in bytes Index []int // index sequence for Type.FieldByIndex Anonymous bool // is an embedded field &#125; 12345678910111213func main() &#123; user := User&#123;&quot;Jack&quot;, 12&#125; t := reflect.TypeOf(user) for i := 0; i &lt; t.NumField(); i++ &#123; tf := t.Field(i) fmt.Printf(&quot;%s: %s %v\\n&quot;, tf.Name, tf.Type, tf.Tag) &#125; if tf, ok := t.FieldByName(&quot;Age&quot;); ok &#123; fmt.Printf(&quot;%s: %s\\n&quot;, tf.Name, tf.Tag.Get(&quot;json&quot;)) &#125;&#125; 3. 值(Value)接口变量会复制对象，是unaddressable的。要想修改目标对象，必须使用指针 12345678910func main() &#123; a := 5 va := reflect.ValueOf(a) vp := reflect.ValueOf(&amp;a).Elem() fmt.Println(va, vp) // 5 5 fmt.Println(va.CanAddr(), va.CanSet()) //false false fmt.Println(vp.CanAddr(), vp.CanSet()) // true true&#125; 3.1 结构体反射1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283type User struct &#123; Id int Name string Age byte&#125;func (u User) Hello() &#123; fmt.Println(&quot;Hello&quot;, u.Name)&#125;func (u User) Say(msg string) &#123; fmt.Println(u.Name, &quot;say&quot;, msg)&#125;func main() &#123; u := User&#123;1, &quot;Jack&quot;, 23&#125; Info(u) Set(&amp;u) fmt.Println(u)&#125;func Info(o interface&#123;&#125;) &#123; t := reflect.TypeOf(o) fmt.Println(&quot;Type:&quot;, t) // Type: main.User // pointer-interface，直接返回 if k := t.Kind(); k != reflect.Struct &#123; fmt.Println(&quot;A Pointer Interface&quot;) return &#125; v := reflect.ValueOf(o) fmt.Println(&quot;Fields:&quot;) for i := 0; i &lt; v.NumField(); i++ &#123; field := t.Field(i) value := v.Field(i).Interface() fmt.Printf(&quot;%6s: %v = %v\\n&quot;, field.Name, field.Type, value) &#125; f1 := v.FieldByIndex([]int&#123;1&#125;) fmt.Println(f1.Interface()) f2 := v.FieldByName(&quot;Age&quot;) fmt.Println(f2.Interface()) fmt.Println(&quot;Methods:&quot;) for i := 0; i &lt; v.NumMethod(); i++ &#123; m := t.Method(i) fmt.Printf(&quot;%6s: %v\\n&quot;, m.Name, m.Type) &#125; m1 := v.MethodByName(&quot;Say&quot;) args := []reflect.Value&#123;reflect.ValueOf(&quot;Hi&quot;)&#125; m1.Call(args)&#125;func Set(o interface&#123;&#125;) &#123; v := reflect.ValueOf(o) if v.Kind() != reflect.Ptr &#123; fmt.Println(&quot;Not a pointer interface&quot;) return &#125; if !v.Elem().CanSet() &#123; fmt.Println(&quot;Can not be set&quot;) return &#125; v = v.Elem() f := v.FieldByName(&quot;Age&quot;) if !f.IsValid() &#123; fmt.Println(&quot;Can not find this field&quot;) return &#125; if f.Kind() == reflect.Uint8 &#123; f.SetUint(25) &#125;&#125; 3.2 处理结构体匿名字段或嵌入字段反射匿名或嵌入字段：匿名字段当独立字段处理 12345678910111213141516171819202122232425262728293031type User struct &#123; Id int Name string Age byte&#125;type Manager struct &#123; User Title string&#125;func main() &#123; m := Manager&#123;User: User&#123;1, &quot;Jack&quot;, 21&#125;, Title: &quot;CEO&quot;&#125; t := reflect.TypeOf(m) fmt.Printf(&quot;%#v\\n&quot;, t.Field(0)) // &#123;Name:&quot;User&quot;, ..., Anonymous:true&#125; fmt.Printf(&quot;%#v\\n&quot;, t.Field(1)) // &#123;Name:&quot;Title&quot;, ..., Anonymous:false&#125; fmt.Printf(&quot;%#v\\n&quot;, t.FieldByIndex([]int&#123;0&#125;)) // Same as t.Field(0),&#123;Name:&quot;User&quot;, ..., Anonymous:true&#125; fmt.Printf(&quot;%#v\\n&quot;, t.FieldByIndex([]int&#123;0, 1&#125;)) // &#123;Name:&quot;Name&quot;, ..., Anonymous:false&#125; field, ok := t.FieldByName(&quot;Title&quot;) if ok &#123; fmt.Printf(&quot;%#v\\n&quot;, field) // &#123;Name:&quot;Title&quot;, ..., Anonymous:false&#125; &#125; field, ok = t.FieldByName(&quot;Id&quot;) if ok &#123; fmt.Printf(&quot;%#v\\n&quot;, field) // &#123;Name:&quot;Id&quot;, ..., Anonymous:false&#125; &#125;&#125; 3.3 通过反射，修改内容传入的值必选是pointer-interface 12345678func main() &#123; x := 10 v := reflect.ValueOf(&amp;x) // ptr-interface fmt.Printf(&quot;%#v\\n&quot;, v) v.Elem().SetInt(99) fmt.Println(x)&#125; 3.4 通道对象设置12345678func main() &#123; ch := make(chan int, 4) v := reflect.ValueOf(ch) if v.TrySend(reflect.ValueOf(100)) &#123; fmt.Println(v.TryRecv()) // 100 true &#125;&#125; 3.5 空接口判断1234567func main() &#123; var a interface&#123;&#125; = nil var b interface&#123;&#125; = (*int)(nil) fmt.Println(a == nil) // true fmt.Println(b == nil, reflect.ValueOf(b).IsNil()) //false true&#125; 4. 方法4.1 调用方法12345678910111213141516171819202122type X struct&#123;&#125;func (X) Add(x, y int) int &#123; return x + y&#125;func main() &#123; var a X v := reflect.ValueOf(a) m := v.MethodByName(&quot;Add&quot;) args := []reflect.Value&#123; reflect.ValueOf(5), reflect.ValueOf(7), &#125; result := m.Call(args) for _, val := range result &#123; fmt.Println(val) &#125;&#125; 4.2 调用变参方法12345678910111213141516171819202122232425262728type X struct&#123;&#125;func (X) Format(format string, a ...interface&#123;&#125;) string &#123; return fmt.Sprintf(format, a...)&#125;func main() &#123; var a X v := reflect.ValueOf(a) m := v.MethodByName(&quot;Format&quot;) args := []reflect.Value&#123; reflect.ValueOf(&quot;%s = %d&quot;), reflect.ValueOf(&quot;x&quot;), reflect.ValueOf(10), &#125; result := m.Call(args) fmt.Println(result) // [x = 10] args = []reflect.Value&#123; reflect.ValueOf(&quot;%d + %d = %d&quot;), reflect.ValueOf([]interface&#123;&#125;&#123;1, 2, 1 + 2&#125;), &#125; result = m.CallSlice(args) fmt.Println(result) // [1 + 2 = 3]&#125; 5. 构建反射库提供了内置函数 make() 和 new() 的对应操作，例如 MakeFunc()。可用它实现通用模板，适应不同数据类型。 123456789101112131415161718192021222324252627282930313233343536373839404142func main() &#123; var intAdd func(x, y int) int var strAdd func(x, y string) string makeAdd(&amp;intAdd) makeAdd(&amp;strAdd) fmt.Println(intAdd(20, 30)) fmt.Println(strAdd(&quot;Hello&quot;, &quot;World&quot;))&#125;func makeAdd(o interface&#123;&#125;) &#123; fn := reflect.ValueOf(o).Elem() v := reflect.MakeFunc(fn.Type(), add) fn.Set(v)&#125;func add(args []reflect.Value) (results []reflect.Value) &#123; if len(args) == 0 &#123; return nil &#125; var ret reflect.Value switch args[0].Kind() &#123; case reflect.Int: sum := 0 for _, n := range args &#123; sum += int(n.Int()) &#125; ret = reflect.ValueOf(sum) case reflect.String: ss := make([]string, 0, len(args)) for _, s := range args &#123; ss = append(ss, s.String()) &#125; ret = reflect.ValueOf(strings.Join(ss, &quot; &quot;)) &#125; results = append(results, ret) return&#125; 6. 反射相关方法12345678910111213141516171819202122232425262728293031323334353637reflect.TypeOf(o) // reflect.Typereflect.Type.Name() // 类型名称reflect.Type.Kind() // 原始类型名称：int, string...reflect.ValueOf(o) // reflect.Valuereflect.Value.Type() // reflect.Typereflect.Value.Kind() // 原始类型名称：int, string...(默认整型表示)// 获取变量值reflect.Value.Float()reflect.Value.Int()reflect.Value.String()reflect.Value.Bool()reflect.Value.Interface() // 获取真实值，不关系值的类型 // 指针ptr.Elem().setInt(99)// 改变变量的值reflect.Value.SetInt()reflect.Value.SetFloat()reflect.Value.SetString()// 结构体reflect.Value.NumField() // 结构体字段个数reflect.Value.Field(i) // reflect.StructFieldreflect.Value.FieldByIndex(i) // reflect.StructFieldreflect.Value.FieldByName(&quot;field&quot;) // reflect.StructFieldreflect.StructField.Name // 字段名reflect.StructField.Type // 字段类型reflect.Value.NumMethod() // 结构体方法个数reflect.Value.Method(i) // reflect.Methodreflect.Value.MethodByName(&quot;method&quot;) // reflect.Methodreflect.Method.Name // 方法名reflect.Method.Type // 方法类型reflect.Method.Call(in []Value) // 调用方法 7. 反射的三大定律7.1 两种类型 Type 和 Valuereflect.Type: 以接口的形式存在 123456789101112131415161718192021222324252627282930313233type Type interface &#123; Align() int FieldAlign() int Method(int) Method MethodByName(string) (Method, bool) NumMethod() int Name() string PkgPath() string Size() uintptr String() string Kind() Kind Implements(u Type) bool AssignableTo(u Type) bool ConvertibleTo(u Type) bool Comparable() bool Bits() int ChanDir() ChanDir IsVariadic() bool Elem() Type Field(i int) StructField FieldByIndex(index []int) StructField FieldByName(name string) (StructField, bool) FieldByNameFunc(match func(string) bool) (StructField, bool) In(i int) Type Key() Type Len() int NumField() int NumIn() int NumOut() int Out(i int) Type common() *rtype uncommon() *uncommonType&#125; reflect.Value: 以结构体形式存在 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374type Value struct &#123; typ *rtype ptr unsafe.Pointer flag&#125;func (v Value) Addr() Valuefunc (v Value) Bool() boolfunc (v Value) Bytes() []bytefunc (v Value) Call(in []Value) []Valuefunc (v Value) CallSlice(in []Value) []Valuefunc (v Value) CanAddr() boolfunc (v Value) CanInterface() boolfunc (v Value) CanSet() boolfunc (v Value) Cap() intfunc (v Value) Close()func (v Value) Complex() complex128func (v Value) Convert(t Type) Valuefunc (v Value) Elem() Valuefunc (v Value) Field(i int) Valuefunc (v Value) FieldByIndex(index []int) Valuefunc (v Value) FieldByName(name string) Valuefunc (v Value) FieldByNameFunc(match func(string) bool) Valuefunc (v Value) Float() float64func (v Value) Index(i int) Valuefunc (v Value) Int() int64func (v Value) Interface() (i interface&#125;)func (v Value) InterfaceData() [2]uintptrfunc (v Value) IsNil() boolfunc (v Value) IsValid() boolfunc (v Value) IsZero() boolfunc (v Value) Kind() Kindfunc (v Value) Len() intfunc (v Value) MapIndex(key Value) Valuefunc (v Value) MapKeys() []Valuefunc (v Value) MapRange() *MapIterfunc (v Value) Method(i int) Valuefunc (v Value) MethodByName(name string) Valuefunc (v Value) NumField() intfunc (v Value) NumMethod() intfunc (v Value) OverflowComplex(x complex128) boolfunc (v Value) OverflowFloat(x float64) boolfunc (v Value) OverflowInt(x int64) boolfunc (v Value) OverflowUint(x uint64) boolfunc (v Value) Pointer() uintptrfunc (v Value) Recv() (x Value, ok bool)func (v Value) Send(x Value)func (v Value) Set(x Value)func (v Value) SetBool(x bool)func (v Value) SetBytes(x []byte)func (v Value) SetCap(n int)func (v Value) SetComplex(x complex128)func (v Value) SetFloat(x float64)func (v Value) SetInt(x int64)func (v Value) SetLen(n int)func (v Value) SetMapIndex(key, elem Value)func (v Value) SetPointer(x unsafe.Pointer)func (v Value) SetString(x string)func (v Value) SetUint(x uint64)func (v Value) Slice(i, j int) Valuefunc (v Value) Slice3(i, j, k int) Valuefunc (v Value) String() stringfunc (v Value) TryRecv() (x Value, ok bool)func (v Value) TrySend(x Value) boolfunc (v Value) Type() Typefunc (v Value) Uint() uint64func (v Value) UnsafeAddr() uintptrfunc (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Valuefunc (v Value) call(op string, in []Value) []Valuefunc (v Value) pointer() unsafe.Pointerfunc (v Value) recv(nb bool) (val Value, ok bool)func (v Value) runes() []runefunc (v Value) send(x Value, nb bool) (selected bool)func (v Value) setRunes(x []rune) 7.2 反射的三大定律 Reflection goes from interface value to reflection object. 反射可以将接口类型变量 转换为“反射类型对象” Reflection goes from reflection object to interface value. 反射可以将 “反射类型对象”转换为 接口类型变量 To modify a reflection object, the value must be settable. 如果要修改 “反射类型对象” 其类型必须是 可写的 7.2.1 第一定律Reflection goes from interface value to reflection object. reflect.TypeOf(i): 获取接口值的类型 (*reflect.rtype) reflect.ValueOf(i): 获取接口值的值 (reflect.Value) 7.2.2 第二定律Reflection goes from reflection object to interface value. 注意：只有Value才能逆向转换，Type则不行 123func (v Value) Interface() (i interface&#123;&#125;) &#123; return valueInterface(v, true)&#125; 7.2.3 第三定律To modify a reflection object, the value must be settable. 非指针变量创建的反射对象，不可写 CanSet()返回true，为可写对象 不可写对象，无法进行写操作 可写对象，使用Elem()函数返回指针指向的数据 123456789101112func main() &#123; var name string = &quot;Go编程&quot; v1 := reflect.ValueOf(name) fmt.Println(v1.CanSet()) // false, 使用v1.Elem()方法会触发异常 v2 := reflect.ValueOf(&amp;name) fmt.Println(v2.CanSet()) // false v3 := v2.Elem() fmt.Println(v3.CanSet()) // true&#125; 可写对象的相关方法： 12345678910111213Set(x Value)SetBool(x bool)SetBytes(x []byte)setRunes(x []rune)SetComplex(x complex128)SetFloat(x float64)SetInt(x int64)SetLen(n int)SetCap(n int)SetMapIndex(key Value, elem Value)SetUint(x uint64)SetPointer(x unsafe.Pointer)SetString(x string)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 通道和并发","slug":"Go 通道和并发","date":"2018-01-06T09:12:24.000Z","updated":"2021-06-22T10:50:49.704Z","comments":true,"path":"2018/01/06/Go 通道和并发/","link":"","permalink":"https://elihe2011.github.io/2018/01/06/Go%20%E9%80%9A%E9%81%93%E5%92%8C%E5%B9%B6%E5%8F%91/","excerpt":"1. goroutine协程，比线程更小，十几个goroutine可能体现在底层就五六个线程。Go语言内部实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存（4～5KB），比线程更易用，更高效和更轻便。 goroutine调度模型： M: 线程 P: 上下文 G: Goroutine 并发concurrency： goroutine只是官方实现的超级“线程池”。每个实例4-5KB的栈内存占用，和大幅减少的创建和销毁开销，是制造Go号称高并发的根本原因 并发不是并行(Concurrency is Not Parallelism): 并发是通过切换CPU时间来实现“同时”运行；而并行则是直接利用多核实现多线程同时运行。Go可设置使用的CPU核心数，以发挥多核计算机的能力 goroutine奉行通过通信来共享内存，而不是共享内存来通信。","text":"1. goroutine协程，比线程更小，十几个goroutine可能体现在底层就五六个线程。Go语言内部实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存（4～5KB），比线程更易用，更高效和更轻便。 goroutine调度模型： M: 线程 P: 上下文 G: Goroutine 并发concurrency： goroutine只是官方实现的超级“线程池”。每个实例4-5KB的栈内存占用，和大幅减少的创建和销毁开销，是制造Go号称高并发的根本原因 并发不是并行(Concurrency is Not Parallelism): 并发是通过切换CPU时间来实现“同时”运行；而并行则是直接利用多核实现多线程同时运行。Go可设置使用的CPU核心数，以发挥多核计算机的能力 goroutine奉行通过通信来共享内存，而不是共享内存来通信。 goroutine的切换点： I/O, select channel 等待锁 函数调用 (有时) runtime.Gosched() 进程：资源拥有的基本单位。每个进程由私营的虚拟地址空间、代码、数据和其它各种资源组成。 线程：处理器调度和分配的基本单位。线程是进程内部的一个执行单元，每个进程至少有一个主线程，它无需用户去主动创建，由系统自动创建。 协程：比线程更小 轻量级“线程” “非抢占式”多任务处理，有协程主动交出控制权 编译器/解释器/虚拟机层面的多任务 多个协程，可能在一个或多个线程上运行 KSE：Kernel Scheduling Entity, 内核调度实体，即可以被操作系统内核调度器调度的实体对象，它是内核的最小调度单元，也就是内核级线程 三种线程模型： 用户级线程模型： 用户线程与内核线程KSE的关系是多对一 (N:1)。多个用户线程一般从属单个进程，并且多线程的调度由用户自己的线程库完成，线程的创建、销毁及线程间的协调等操作由用户自己的线程库负责，无需借助系统调度来实现。 Python的gevent协程库就属这种实现 线程调度在用户层面完成，不需要让CPU在用户态和内核态之间切换，这种方式较为轻量级，对系统资源消耗少 缺点：做不到真正意义上的并发。如果某个用户进程上的某个线程因为一个阻塞调用(I/O)二被CPU中断(抢占式调度)，那么该进程中的其它线程将被阻塞，整个进程被挂起。因为在用户线程模式下，进程内的线程绑定到CPU执行是由用户进程调度实现的，内部线程对CPU不可见，即CPU调度的是进程，而非线程 协程库优化：把阻塞的操作重新封装为完全非阻塞模式，在阻塞点上，主动让出自己，并通知或唤醒其它等待的用户线程 内核级线程模型 用户线程和内核线程KSE的关系是一对一 (1:1)。每个用户线程绑定一个内核线程，线程的调度完全交由内核控制 Java/C++ 的线程库按此方式实现 优点：简单，直接借助系统内核的线程和调度器，可以快速实现线程切换，做到真正的并行处理 缺点：由于直接使用内核去创建、销毁及多线程上下文切换和调度，系统资源成本大幅上涨，对性能影响较大 两级线程模型(即混合型线程模型) 用户线程与内核线程KSE的关系是多对多 (N:M) 一个进程可与多个内核线程KSE关联，该进程内的多个线程绑定到了不同的KSE上 进程内的线程并不与KSE一一绑定，当某个KSE绑定的线程因阻塞操作被内核调度出CPU时，其关联的进程中的某个线程又会重新与KSE绑定 此种模型高度复杂，Go语言中的runtime调度器实现了这种方案 为什么称为两级？用户调度实现用户线程到KSE的调度，内核调度器实现KSE到CPU上的调度 G-P-M 模型： G：Goroutine：独立执行单元。相较于每个OS线程固定分配2M内存的模式，Goroutine的栈采取动态扩容方式，2k ~ 1G(AMD64, AMD32: 256M)。周期性回收内存，收缩栈空间 每个Goroutine对应一个G结构体，它存储Goroutine的运行堆栈、状态及任务函数，可重用。 G并非执行体，每个G需要绑定到P才能被调度执行 P：Processor： 逻辑处理器，中介 对G来说，P相当于CPU，G只有绑定到P才能被调用 对M来说，P提供相关的运行环境(Context)，如内存分配状态(mcache)，任务队列(G)等 P的数量决定系统最大并行的G的数量 （CPU核数 &gt;= P的数量），用户可通过GOMAXPROCS设置数量，但不能超过256 M：Machine OS线程抽象，真正执行计算的资源，在绑定有效的P后，进入schedule循环 schedule循环的机制大致从Global队列、P的Local队列及wait队列中获取G，切换到G的执行栈上执行G的函数，调用goexit做清理工作并回到M M不保留G的状态 M的数量不定，由Go Runtime调整，目前默认不超过10K 1.1 go关键字开启新协程1234567891011func say(s string) &#123; for i := 0; i &lt; 5; i ++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) say(&quot;hello&quot;)&#125; 1.2 runtime包runtime.Gosched() 让出时间片runtime.Goexit() 终止协程runtime.GOMAXPROCS(N) 指定运行CPU个数 123456789101112func main() &#123; go func() &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Println(&quot;go&quot;) &#125; &#125;() for i := 0; i &lt; 2; i++ &#123; runtime.Gosched() // 让出时间片 fmt.Println(&quot;hello&quot;) &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 打印函数属IO操作，自动切换控制权func auto() &#123; for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; for &#123; fmt.Printf(&quot;Hello from goroutine %d\\n&quot;, i) &#125; &#125;(i) &#125; time.Sleep(time.Millisecond)&#125;// 不自动切换控制权func manual() &#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; // race condition for &#123; a[i]++ runtime.Gosched() // 交出控制权 &#125; &#125;(i) &#125; time.Sleep(time.Millisecond) fmt.Println(a) // 存在读写抢占&#125;// out of rangefunc outOfRange() &#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func() &#123; // race condition for &#123; a[i]++ runtime.Gosched() // 交出控制权 &#125; &#125;() &#125; time.Sleep(time.Millisecond) fmt.Println(a)&#125; 1go run -race goroutine.go # manual()函数存在抢占，race选项可检查到 2. 通道(channel)通道：用来传递数据的一种数据结构。两个goroutine之间，可以使用它来进行同步和通信 不靠共享内存通信，而是通过通信来共享内存 Channel： goroutine的沟通桥梁，大多是阻塞同步的 make创建，close关闭 是引用类型 可使用for range来迭代channel 可设置单向或双向通道 可设置缓存大小，在未被填满前不会发生阻塞 1234ch := make(chan int)ch &lt;- v // 把v发送到通道chv := &lt;- ch // 从ch接收数据 2.1 分段计算123456789101112131415161718192021func main() &#123; a := []int&#123;7, 9, -3, 4, 6, 8, 2, -5&#125; mid := len(a) / 2 ch := make(chan int) go sum(a[:mid], ch) go sum(a[mid:], ch) x, y := &lt;-ch, &lt;-ch fmt.Println(x, y, x+y)&#125;func sum(a []int, ch chan int) &#123; result := 0 for _, v := range a &#123; result += v &#125; ch &lt;- result&#125; 2.2 阻塞主线程12345678910func main() &#123; c := make(chan bool) go func() &#123; fmt.Println(&quot;Go Go Go!!!&quot;) c &lt;- true &#125;() &lt;- c // 阻塞main函数，等待goroutine执行完成&#125; 2.3 通道遍历和关闭如果通道不关闭close(ch)，遍历range ch就不会结束 123456789101112131415161718192021222324252627282930313233func main() &#123; ch := make(chan int, 10) go fib(cap(ch), ch) //// 方法1：for-range 自检 //for i := range ch &#123; // fmt.Printf(&quot;%d &quot;, i) //&#125; // 方法2：comma ok idiom for &#123; num, ok := &lt;-ch if ok &#123; fmt.Printf(&quot;%d &quot;, num) &#125; else &#123; break &#125; &#125; fmt.Println()&#125;func fib(n int, ch chan int) &#123; x, y := 1, 1 for i := 0; i &lt; n; i++ &#123; ch &lt;- x x, y = y, x+y &#125; // 必须关闭，否则deadlock close(ch)&#125; 2.4 主程序可能不等待goruntine123456789101112131415161718192021222324func main() &#123; ch := make(chan bool) for i := 0; i &lt; 10; i++ &#123; go calc(i, ch) &#125; &lt;-ch&#125;func calc(index int, ch chan bool) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) // goroutine 执行顺序不固定，此判断不正确 if index == 9 &#123; ch &lt;- true &#125;&#125; 2.4.1 方法一：使用缓存channel123456789101112131415161718192021222324func main() &#123; ch := make(chan bool, 10) for i := 0; i &lt; 10; i++ &#123; go calc(i, ch) &#125; // 等待10次 for i := 0; i &lt; 10; i++ &#123; &lt;-ch &#125;&#125;func calc(index int, ch chan bool) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) ch &lt;- true&#125; 2.4.2 方法二：通过同步解决(sync.WaitGroup) wg.Add(N): 新增N个任务 wg.Done(): 完成一个任务，计算器减1 wg.Wait(): 主线程等待，直到计数器为0 1234567891011121314151617181920212223func main() &#123; wg := sync.WaitGroup&#123;&#125; wg.Add(10) for i := 0; i &lt; 10; i++ &#123; go calc(i, &amp;wg) &#125; // 等待 wg.Wait()&#125;func calc(index int, wg *sync.WaitGroup) &#123; sum := 0 for i := 1; i &lt; 1000000001; i++ &#123; sum += i &#125; fmt.Println(index, sum) wg.Done()&#125; 2.5 模拟打印机1234567891011121314151617181920212223242526272829func main() &#123; ch := make(chan bool) go task1(ch) go task2(ch) // 等待 select &#123; case &lt;-time.After(15 * time.Second): &#125;&#125;func Printer(s string) &#123; for _, c := range s &#123; fmt.Printf(&quot;%c&quot;, c) time.Sleep(time.Second) &#125; fmt.Println()&#125;func task1(ch chan bool) &#123; &lt;-ch // 阻塞等待 Printer(&quot;hello&quot;)&#125;func task2(ch chan bool) &#123; Printer(&quot;world&quot;) ch &lt;- true // 完成释放&#125; 2.6 带缓冲的通道通道 ch := make(chan int, N): N=0 同步阻塞 N&gt;0 异步的，超过N时才阻塞 1234567891011121314151617func main() &#123; ch := make(chan int, 3) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;i=%d, len(ch)=%d, cap(ch)=%d\\n&quot;, i, len(ch), cap(ch)) ch &lt;- i &#125; &#125;() time.Sleep(2 * time.Second) for i := 0; i &lt; 10; i++ &#123; num := &lt;-ch fmt.Printf(&quot;num=%d\\n&quot;, num) &#125;&#125; 2.7 单向通道123var ch1 chan int // 默认双向var ch2 chan&lt;- int // 单向写var ch3 &lt;-chan int // 单向读 123456789101112131415161718192021222324252627func main() &#123; ch := make(chan int) /* 支持隐式转换 var send chan&lt;- int = ch // write-only var recv &lt;-chan int = ch // read-only */ go producer(ch) consumer(ch)&#125;func producer(out chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; out &lt;- i * i &#125; close(out)&#125;func consumer(in &lt;-chan int) &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, &lt;-in) &#125; fmt.Println()&#125; 3. Selectselect: 管理多个channel，监听channel上的数据流动。类似switch语法，但每个case语句必须是IO操作。多个case同时满足，任选一个执行。 处理一个或多个channel的发送和接收 同时有多个channel时，随机处理 可用空select来阻塞main函数 可设置超时 default语句： 有default：select语句不会被阻塞，执行default后，程序的执行会从select语句中恢复，进入下一次轮询。比较消耗资源。 没有default：select语句将被阻塞，直到至少有一个通信可以进行下去 3.1 管理多个通道3.1.1 示例1123456789101112131415161718192021222324252627282930313233343536func main() &#123; c1, c2 := make(chan int), make(chan string) done := make(chan bool, 2) go func() &#123; for &#123; select &#123; case v, ok := &lt;-c1: if !ok &#123; done &lt;- true break &#125; fmt.Println(&quot;c1:&quot;, v) case v, ok := &lt;-c2: if !ok &#123; done &lt;- true break &#125; fmt.Println(&quot;c2:&quot;, v) &#125; &#125; &#125;() c1 &lt;- 1 c2 &lt;- &quot;hi&quot; c1 &lt;- 5 c2 &lt;- &quot;hello&quot; // 必须关闭至少一个 close(c1) //close(c2) for i := 0; i &lt; 2; i++ &#123; &lt;-done &#125;&#125; 3.1.2 示例2123456789101112131415161718192021222324252627282930func main() &#123; ch := make(chan int) quit := make(chan bool) // 消费者 go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, &lt;-ch) &#125; fmt.Println() quit &lt;- true &#125;() fib(ch, quit)&#125;func fib(ch chan&lt;- int, quit &lt;-chan bool) &#123; x, y := 1, 1 for &#123; select &#123; case ch &lt;- x: x, y = y, x+y case &lt;-quit: fmt.Println(&quot;Done.&quot;) return // break只能跳出select，无法跳出for循环 &#125; &#125;&#125; 3.1.3 使用select作为发送者应用12345678910111213141516func main() &#123; c := make(chan int) go func() &#123; for v := range c &#123; fmt.Println(v) &#125; &#125;() for i := 0; i &lt; 100; i++ &#123; select &#123; case c &lt;- 0: case c &lt;- 1: &#125; &#125;&#125; 3.2 超时处理case &lt;-time.After(5 * time.Second): 其他channel阻塞时间超过5s时执行 123456789101112131415161718192021222324func main() &#123; ch := make(chan int) done := make(chan bool) go func() &#123; for &#123; select &#123; case x := &lt;-ch: fmt.Printf(&quot;%d &quot;, x) case &lt;-time.After(5 * time.Second): fmt.Println(&quot;\\nTimeout&quot;) done &lt;- true return &#125; &#125; &#125;() for i := 0; i &lt; 10; i++ &#123; ch &lt;- i time.Sleep(time.Second) &#125; &lt;-done&#125; 3.3 避免造成死锁select 在执行过程中，必须命中其中的某一分支, 否则deadlock 12345678910111213141516func main() &#123; c1 := make(chan string, 1) c2 := make(chan string, 1) c1 &lt;- &quot;ok&quot; c2 &lt;- &quot;good&quot; select &#123; case msg := &lt;-c1: fmt.Printf(&quot;c1 receive %s\\n&quot;, msg) case msg := &lt;-c2: fmt.Printf(&quot;c2 receive %s\\n&quot;, msg) default: fmt.Println(&quot;no data&quot;) &#125;&#125; 4. 定时器4.1 一次性定时任务time.NewTimer(d Duration) *Timer &lt;-timer.C: 阻塞等待，返回定时器时间 timer.Stop(): timer.Reset(d Duration): 1234567891011121314151617func main() &#123; timer := time.NewTimer(2 * time.Second) go func() &#123; &lt;-timer.C fmt.Println(&quot;Goroutine is done.&quot;) &#125;() timer.Stop() // 重置定时器，上面的 goroutine 将继续执行 timer.Reset(5 * time.Second) select &#123; case &lt;-time.After(10 * time.Second): &#125;&#125; 4.2 周期性定时任务time.NewTicker(d Duration) *Ticker &lt;-ticker.C: 阻塞等待，返回定时器时间 ticker.Stop(): 1234567891011121314151617func main() &#123; ticker := time.NewTicker(2 * time.Second) count := 0 for &#123; &lt;-ticker.C count++ fmt.Printf(&quot;%d &quot;, count) if count == 10 &#123; ticker.Stop() break &#125; &#125; fmt.Println()&#125; 4.3 延迟操作总结123456time.Sleep(time.Second * 2)&lt;- time.After(time.Second * 2)timer := time.NewTimer(time.Second * 2)&lt;-timer.C 5. 死锁经典错误案例5.1 无缓冲信道，在接收者未准备好之前，发送操作是阻塞的1234567func main() &#123; c := make(chan bool) c &lt;- true // 阻塞 fmt.Println(&lt;-c)&#125; 两种解决方法： 1) 先接收，后发送 123456789func main() &#123; c := make(chan bool) go func() &#123; fmt.Println(&lt;-c) &#125;() c &lt;- true&#125; 2) 使用缓冲信道 1234567func main() &#123; c := make(chan bool, 1) c &lt;- true fmt.Println(&lt;-c)&#125; 5.2 缓冲信道，超过容量12345678func main() &#123; c := make(chan bool, 1) c &lt;- true c &lt;- false fmt.Println(&lt;-c)&#125; 5.3 等待从信道读取数据，但信道无数据写入123456789101112func main() &#123; c := make(chan bool, 1) go func() &#123; c &lt;- true c &lt;- false &#125;() for i := range c &#123; fmt.Println(i) &#125;&#125; 解决办法：及时关闭无用信道 1234567891011121314func main() &#123; c := make(chan bool, 1) go func() &#123; c &lt;- true c &lt;- false close(c) // 关闭信道 &#125;() for i := range c &#123; fmt.Println(i) &#125;&#125; 6. 控制 goroutine 并发数量1234567891011121314151617181920212223242526func main() &#123; count := 10 wg := sync.WaitGroup&#123;&#125; ch := make(chan int, 2) for i := 0; i &lt; count; i++ &#123; wg.Add(1) go func(i int) &#123; defer wg.Done() for n := range ch &#123; fmt.Printf(&quot;go func: %d, time: %v\\n&quot;, n, time.Now()) time.Sleep(time.Duration(n) * time.Second) &#125; &#125;(i) &#125; for i := 0; i &lt; 10; i++ &#123; ch &lt;- 1 ch &lt;- 2 &#125; close(ch) wg.Wait()&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 结构体和接口","slug":"Go 结构体和接口","date":"2018-01-05T01:28:32.000Z","updated":"2021-06-22T10:50:49.704Z","comments":true,"path":"2018/01/05/Go 结构体和接口/","link":"","permalink":"https://elihe2011.github.io/2018/01/05/Go%20%E7%BB%93%E6%9E%84%E4%BD%93%E5%92%8C%E6%8E%A5%E5%8F%A3/","excerpt":"1. 结构体将多个不同类型命名字段(field)序列打包成一个复合类型。 结构体特点： 值类型 做参数，值传递 相同类型，可使用==或!=比较 Go语言中实现封装、继承和多态： 封装：通过方法实现 继承：通过匿名字段实现 多态：通过接口实现","text":"1. 结构体将多个不同类型命名字段(field)序列打包成一个复合类型。 结构体特点： 值类型 做参数，值传递 相同类型，可使用==或!=比较 Go语言中实现封装、继承和多态： 封装：通过方法实现 继承：通过匿名字段实现 多态：通过接口实现 1.1 定义结构体123456789101112type person struct &#123; Name string Age int&#125;func main() &#123; p := person&#123; Name: &quot;lucy&quot;, Age: 22, &#125; fmt.Println(p)&#125; 1.2 匿名结构体12345678910111213141516171819202122232425262728type person struct &#123; Name string Age int Contact struct &#123; Phone, City string &#125;&#125;func main() &#123; p1 := person&#123; Name: &quot;lucy&quot;, Age: 22, Contact: struct&#123; Phone, City string &#125; &#123; Phone: &quot;123456789&quot;, City: &quot;LA&quot;, &#125;, &#125; fmt.Println(p1) p2 := person&#123; Name: &quot;jack&quot;, Age: 19, &#125; p2.Contact.Phone = &quot;987654321&quot; p2.Contact.City = &quot;NY&quot; fmt.Println(p2)&#125; 1.3 匿名字段1234567891011func main() &#123; s := struct &#123; int string &#125; &#123; 10, &quot;jack&quot;, &#125; fmt.Println(s)&#125; 1.4 嵌入结构（模拟继承）123456789101112131415161718192021222324252627282930313233343536type person struct &#123; Name string Age int&#125;type teacher struct &#123; person Salary float32&#125;type student struct &#123; person Score float32&#125;func main() &#123; t := teacher &#123; person: person&#123; Name: &quot;Jack&quot;, Age: 45, &#125;, Salary: 12901.20, &#125; t.Age += 1 s := student&#123; person: person&#123; Name: &quot;Tom&quot;, Age: 13, &#125;, Score: 91.50, &#125; s.Score -= 2.5 fmt.Println(t, s)&#125; 1.5 结构体序列化注意使用struct标签，否则序列化后的名称会保持大写开头不变 12345678910111213141516type Student struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;`&#125;func main() &#123; stu := Student&#123;&quot;Jack&quot;, 21&#125; js, err := json.Marshal(stu) if err != nil &#123; fmt.Println(&quot;json化失败&quot;, err) return &#125; fmt.Println(string(js))&#125; 1.6 工厂模式123456789101112131415type student struct &#123; Name string Age byte&#125;func NewStudent(name string, age byte) *student &#123; return &amp;student&#123; Name: name, Age: age, &#125;&#125;func (stu *student) String() string &#123; return fmt.Sprintf(&quot;Name=%v, Age=%v&quot;, stu.Name, stu.Age)&#125; 1.7 结构体链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229type Node struct &#123; Name string Value int next *Node&#125;func main() &#123; node := &amp;Node&#123; Name: &quot;head&quot;, Value: 0, &#125; appendNodes(node) //trans(node) // 只所以要有二级指针，是为了改变顶级node的地址，方便遍历函数遍历 insertNodes(&amp;node) //trans(node) delNode(&amp;node, &quot;head&quot;) //trans(node) addNode(&amp;node, &quot;node_A_1&quot;, &amp;Node&#123;Name: &quot;newNode&quot;, Value: 12&#125;) trans(node)&#125;func appendNodes(p *Node) &#123; for i := 0; i &lt; 2; i++ &#123; node := Node&#123; Name: fmt.Sprintf(&quot;node_A_%d&quot;, i), Value: rand.Intn(100), &#125; p.next = &amp;node p = &amp;node &#125;&#125;func insertNodes(p **Node) &#123; for i := 0; i &lt; 2; i++ &#123; node := Node&#123; Name: fmt.Sprintf(&quot;node_I_%d&quot;, i), Value: rand.Intn(100), &#125; node.next = *p *p = &amp;node &#125;&#125;func delNode(p **Node, name string) &#123; head := *p // 第一个即为要删除的对象 if head.Name == name &#123; *p = head.next return &#125; prev := head head = head.next for head != nil &#123; if head.Name == name &#123; prev.next = head.next break &#125; prev = head head = head.next &#125;&#125;func addNode(p **Node, name string, newNode *Node) &#123; head := *p // 第一个元素前插入 if head.Name == name &#123; newNode.next = head *p = newNode return &#125; prev := head head = head.next for head != nil &#123; if head.Name == name &#123; prev.next = newNode newNode.next = head break &#125; prev = head head = head.next &#125;&#125;func trans(p *Node) &#123; for p != nil &#123; fmt.Println(*p) p = p.next &#125;&#125;func main() &#123; node := &amp;Node&#123; Name: &quot;head&quot;, Value: 0, &#125; appendNodes(node) insertNodes(&amp;node) delNode(&amp;node, &quot;node_I_4&quot;) appendNode(node, &quot;head&quot;, &quot;newAppend&quot;) insertNode(&amp;node, &quot;node_A_4&quot;, &quot;newInsert&quot;) trans(node)&#125;type Node struct &#123; Name string Value int next *Node&#125;func trans(p *Node) &#123; for p != nil &#123; fmt.Println(*p) p = p.next &#125;&#125;func appendNodes(p *Node) &#123; for i := 0; i &lt; 5; i++ &#123; node := &amp;Node&#123; Name: fmt.Sprintf(&quot;node_A_%d&quot;, i), Value: rand.Intn(100), &#125; p.next = node p = node &#125;&#125;// 除了要在head前增加元素，还需要去改变链表head的位置，需要用到多重指针func insertNodes(p **Node) &#123; for i := 0; i &lt; 5; i++ &#123; node := &amp;Node&#123; Name: fmt.Sprintf(&quot;node_I_%d&quot;, i), Value: rand.Intn(100), &#125; node.next = *p *p = node &#125;&#125;func delNode(p **Node, name string) &#123; node := *p // 第一个就是要删除的元素 if node.Name == name &#123; *p = node.next return &#125; prev := node node = node.next for node != nil &#123; if node.Name == name &#123; prev.next = node.next break &#125; prev = node node = node.next &#125;&#125;func appendNode(p *Node, name, newName string) &#123; for p != nil &#123; if p.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: p.next, &#125; p.next = newNode break &#125; p = p.next &#125;&#125;func insertNode(p **Node, name, newName string) &#123; node := *p // 在第一个元素前增加 if node.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: node, &#125; // 改变链表头 *p = newNode return &#125; prev := node node = node.next for node != nil &#123; if node.Name == name &#123; newNode := &amp;Node&#123; Name: newName, Value: rand.Intn(100), next: node, &#125; // 与前一个链接起来 prev.next = newNode break &#125; prev = node node = node.next &#125;&#125; 1.8 结构体内存结构不管结构体包含多少字段，其内存总是一次性分配的，各字段在相邻的地址空间按定义顺序排列。当然，对于引用类型、字符串和指针，结构内存中只包含其基本（头部）数据。还有，所有匿名字段成员也被包含在内。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455type point struct &#123; x, y int&#125;type node struct &#123; id int name string data []byte next *node point&#125;func main() &#123; v := node&#123; id: 1, name: &quot;yes&quot;, data: []byte&#123;1, 2, 3, 4&#125;, point: point&#123;x: 100, y: 200&#125;, &#125; format := `v: %p ~ %x, size %d, align: %dfield address offset size-------+--------------------+--------+-----id %p %d %dname %p %d %ddata %p %d %dnext %p %d %dx %p %d %dy %p %d %d` fmt.Printf(format, &amp;v, uintptr(unsafe.Pointer(&amp;v))+unsafe.Sizeof(v), unsafe.Sizeof(v), unsafe.Alignof(v), &amp;v.id, unsafe.Offsetof(v.id), unsafe.Sizeof(v.id), &amp;v.name, unsafe.Offsetof(v.name), unsafe.Sizeof(v.name), &amp;v.data, unsafe.Offsetof(v.data), unsafe.Sizeof(v.data), &amp;v.next, unsafe.Offsetof(v.next), unsafe.Sizeof(v.next), &amp;v.x, unsafe.Offsetof(v.x), unsafe.Sizeof(v.x), &amp;v.y, unsafe.Offsetof(v.y), unsafe.Sizeof(v.y))&#125;/*v: 0xc000084000 ~ c000084048, size 72, align: 8field address offset size-------+--------------------+--------+-----id 0xc000084000 0 8name 0xc000084008 8 16data 0xc000084018 24 24next 0xc000084030 48 8x 0xc000084038 56 8y 0xc000084040 64 8*/ unsafe.Sizeof(x)特点总结： 字符串：始终返回16。字符串类型对应一个结构体，该结构体有两个域，第一个域是指向该字符串的指针，第二个域是字符串的长度，每个域占8个字节，但是并不包含指针指向的字符串的内容。 切片: 始终返回24。if x is a slice, Sizeof returns the size of the slice descriptor, not the size of the memory referenced by the slice. 数组: Sizeof(x[0]) * len(x) 1.9 结构体字段对齐在分配内存时，字段须做对齐处理，通常以所有字段中最长的基础类型宽度为标准 unsafe.Alignof(x): 获取对齐宽度，以最长的基础类型宽度作为对齐标准。 12345678910111213141516171819202122func main() &#123; v1 := struct &#123; a byte b byte c int32 // 对齐宽度4 &#125;&#123;&#125; v2 := struct &#123; a byte b byte // 对齐宽度1 &#125;&#123;&#125; v3 := struct &#123; a byte b []int // 基础类型int，对齐宽度8 c int32 &#125;&#123;&#125; fmt.Printf(&quot;v1: %d, %d\\n&quot;, unsafe.Alignof(v1), unsafe.Sizeof(v1)) // 4, 8 fmt.Printf(&quot;v2: %d, %d\\n&quot;, unsafe.Alignof(v2), unsafe.Sizeof(v2)) // 1, 2 fmt.Printf(&quot;v3: %d, %d\\n&quot;, unsafe.Alignof(v3), unsafe.Sizeof(v3)) // 8, 40&#125; 1.10 类型对齐长度 类型 对齐长度 bool 1 int8/byte 1 int32 4 int64 8 string 8 map 8 slice 8 2. 方法方法是与对象实例绑定的特殊函数 2.1 绑定方法123456789101112131415type A struct &#123; Name string&#125;// （a A) receiverfunc (a A) Print() &#123; fmt.Println(a.Name)&#125;func main() &#123; a := A&#123; Name: &quot;tom&quot;, &#125; a.Print()&#125; 2.2 为int扩展方法12345678910111213type TZ intfunc (a *TZ) Print() &#123; fmt.Println(&quot;TZ&quot;)&#125;func main() &#123; var a TZ a.Print() // method value (*TZ).Print(&amp;a) // method expression&#125; 2.3 结构体重写String()方法重新String()方法：(fmt.Println()会自动调用String()方法) 1234567891011121314type Student struct &#123; Name string `json:&quot;name&quot;` Age byte `json:&quot;age&quot;`&#125;func main() &#123; stu := Student&#123;&quot;Jack&quot;, 21&#125; fmt.Println(&amp;stu) // 自动调用String()方法&#125;func (stu *Student) String() string &#123; return fmt.Sprintf(&quot;Name=%v, Age=%v&quot;, stu.Name, stu.Age)&#125; 2.4 方法集类型有一个与之相关的方法集（method set），这决定了它是否实现某个接口。 类型T方法集包含所有receiver T方法。 类型T方法集包含所有receiver T+T方法。 匿名嵌入S，T方法集包含所有receiver S方法。 匿名嵌入S，T方法集包含所有receiver S+S方法。 匿名嵌入S或S，T方法集包含所有receiver S+*S方法。 1234567891011121314151617181920212223242526272829type S struct&#123;&#125;type T struct &#123; S&#125;func (S) Hello() &#123;&#125;func (S) sVal() &#123;&#125;func (*S) sPtr() &#123;&#125;func (T) tVal() &#123;&#125;func (*T) tPtr() &#123;&#125;func methodSet(a interface&#123;&#125;) &#123; t := reflect.TypeOf(a) fmt.Println(t.NumMethod()) // methods need to export, 只有Hello一个方法可导出 for i, n := 0, t.NumMethod(); i &lt; n; i++ &#123; m := t.Method(i) fmt.Println(m.Name, m.Type) &#125;&#125;func main() &#123; var t = T&#123;&#125; methodSet(t) println(&quot;------------&quot;) methodSet(&amp;t)&#125; 3. 接口接口代表一种调用契约，是多个方法声明的集合。 采用duck type方式 它把所有具有共性的方法定义在一起，任何其他类型只要实现了这些方法，就实现了该接口。注意，要全部实现！ 接口特性： 一个或多个方法签名的集合 只要某类型拥有改接口的所有方法签名，即算实现该接口，无需显示声明实现了那些接口，此称为Structural Typing 接口中只有方法声明，没有实现 接口可匿名嵌入其他接口，或嵌入到结构中 将对象赋值给接口，会发生拷贝，而接口内部存储指向这个复制品的指针，即无法修改复制品的状态，也无法获取指针 只有当接口存储的类型和对象均为nil时，接口才能有nil 接口调用不会做receiver的自动转换 接口同样支持匿名字段方法 接口也可实现类似OOP中的多态 空接口可以作为任何类型数据的容器 3.1 示例112345678910111213141516171819202122232425262728293031323334type Animal interface &#123; walk() eat()&#125;type Cat struct &#123;&#125;type Bird struct &#123;&#125;func (cat Cat) walk() &#123; fmt.Println(&quot;Cat walking with four limbs.&quot;)&#125;func (cat Cat) eat() &#123; fmt.Println(&quot;Cats like to eat fish.&quot;)&#125;func (bird Bird) walk() &#123; fmt.Println(&quot;Bird walkin with two legs.&quot;)&#125;func (bird Bird) eat() &#123; fmt.Println(&quot;Birds like to eat insects.&quot;)&#125;func main() &#123; var animal Animal animal = new(Cat) animal.walk() animal = new(Bird) animal.eat()&#125; 3.2 示例2123456789101112131415161718192021222324252627282930313233343536373839404142434445type USB interface &#123; Name() string Connector&#125;type Connector interface &#123; Connect()&#125;type PhoneConnector struct &#123; name string&#125;func (pc PhoneConnector) Name() string &#123; return pc.name&#125;func (pc PhoneConnector) Connect() &#123; fmt.Println(&quot;Connected:&quot;, pc.name)&#125;/*func Disconnect(usb USB) &#123; // 类型断言 if pc, ok := usb.(PhoneConnector); ok &#123; fmt.Println(&quot;Disconnected:&quot;, pc.name) return &#125; fmt.Println(&quot;Unknown device&quot;)&#125;*/// 万能空接口func Disconnect(usb interface&#123;&#125;) &#123; switch v := usb.(type) &#123; case PhoneConnector: fmt.Println(&quot;Disconnected:&quot;, v.name) default: fmt.Println(&quot;Unknown device&quot;) &#125;&#125;func main() &#123; var a USB = PhoneConnector&#123;&quot;PhoneConnector&quot;&#125; a.Connect() Disconnect(a)&#125; 3.3 类型断言空接口可接收任意类型，如果要转换为具体类型，需要使用类型断言 1234567891011func main() &#123; var point Point = Point&#123;1, 2&#125; var a interface&#123;&#125; a = point var b Point b = a.(Point) // 类型断言 fmt.Println(b)&#125; 3.3.1 类型断言检查为避免转换错误直接panic，可先检查转换是否成功 12345678910111213func main() &#123; var a interface&#123;&#125; var x float32 = 1.23 a = x y, ok := a.(float32) // 类型断言 if ok &#123; fmt.Println(y) &#125; else &#123; fmt.Println(&quot;转换失败&quot;) &#125;&#125; 3.3.2 类型断言switch123456789101112func TypeJudge(items ...interface&#123;&#125;) &#123; for index, x := range items &#123; switch x.(type) &#123; case bool: fmt.Printf(&quot;%v: %v is bool\\n&quot;, index, x) case string: fmt.Printf(&quot;%v: %v is string\\n&quot;, index, x) default: fmt.Printf(&quot;%v: %v is unknown\\n&quot;, index, x) &#125; &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 函数和错误处理","slug":"Go 函数和错误处理","date":"2018-01-04T00:25:38.000Z","updated":"2021-06-22T10:50:49.703Z","comments":true,"path":"2018/01/04/Go 函数和错误处理/","link":"","permalink":"https://elihe2011.github.io/2018/01/04/Go%20%E5%87%BD%E6%95%B0%E5%92%8C%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/","excerpt":"1. 函数 不支持嵌套、重载和默认参数 无需声明原型、不定长度变参、多返回值、命名返回参数、匿名函数、闭包 本身就是一种类型 函数调用底层分析： 栈区：基本数据类型一般分配到栈区。编译器存在一个逃逸分析。每个函数有独立的栈，函数执行完毕，自动销毁 堆区：引用数据类型一般分配在堆区 代码区：存放代码指令","text":"1. 函数 不支持嵌套、重载和默认参数 无需声明原型、不定长度变参、多返回值、命名返回参数、匿名函数、闭包 本身就是一种类型 函数调用底层分析： 栈区：基本数据类型一般分配到栈区。编译器存在一个逃逸分析。每个函数有独立的栈，函数执行完毕，自动销毁 堆区：引用数据类型一般分配在堆区 代码区：存放代码指令 init()函数：每个源文件，都可以包含一个init函数，该函数会在main函数执行前，被Go运行框架调用。 执行顺序：全局变量定义 -&gt; init() -&gt; main() 1.1 参数传递不管是指针、引用类型，还是其他类型参数，都是值拷贝传递（pass-by-value)。区别无非是拷贝目标对象，还是拷贝指针对象本身而已。 在函数调用时，会为形参和返回值分配内存空间，并将实参拷贝到形参的内存。 1.2 参数过多，改用struct1234567891011121314151617181920212223242526type serverOption struct &#123; ip string port int path string timeout time.Duration log *log.Logger&#125;func newOption() *serverOption &#123; return &amp;serverOption&#123; ip: &quot;0.0.0.0&quot;, port: 8080, path: &quot;/data/www&quot;, timeout: time.Second*5, log: nil, &#125;&#125;func server(option *serverOption) &#123;&#125;func main() &#123; opt := newOption() opt.port = 8080 server(opt)&#125; 1.3 变参变参，实际上传递的是一个slice，如果是array，先转化为slice。s := a[:]... 12345678910func test(a ...int) &#123; fmt.Printf(&quot;%T, %v\\n&quot;, a, a)&#125;func main() &#123; test(1, 2, 3, 4) a := [3]int &#123;10, 20, 30&#125; test(a[:]...)&#125; 2. 匿名函数2.1 直接执行12345func main() &#123; func (s string) &#123; println(s) &#125; (&quot;Hello world&quot;)&#125; 2.2 赋值给变量1234567func main() &#123; add := func (x, y int) int &#123; return x + y &#125; println(add(2, 3))&#125; 2.3 作为参数123456789func test(f func()) &#123; f()&#125;func main() &#123; test(func() &#123; println(&quot;Hello world&quot;) &#125;)&#125; 2.4 作为返回值12345678910func test(x, y int) func() int &#123; return func() int &#123; return x + y &#125;&#125;func main() &#123; add := test(2, 3) println(add())&#125; 2.5 作为结构体字段12345678910111213func testStruct() &#123; type calc struct &#123; mul func(x, y int) int &#125; z := calc &#123; mul: func(x, y int) int &#123; return x * y &#125;, &#125; println(z.mul(2, 5))&#125; 2.6 通过Channel传递123456789func testChannel() &#123; c := make(chan func(int, int) int, 2) c &lt;- func(a int, b int) int &#123; return a + b &#125; println((&lt;- c)(1, 2))&#125; 3. 闭包（closure）闭包：一个函数和与其相关的引用变量组成的一个实体 返回一个匿名函数 该匿名函数使用了函数外变量 3.1 示例112345678910func test(x int) func() &#123; println(&amp;x) return func() &#123; println(&amp;x, x) // 返回的函数，包含了x环境上下文 &#125;&#125;func main() &#123; test(5)()&#125; 1go build -gcflags &quot;-N -l&quot; main.go 3.2 示例212345678910111213func main() &#123; f := closure(10) fmt.Println(f(1)) // 11 fmt.Println(f(2)) // 12&#125;func closure(x int) func(int) int &#123; fmt.Printf(&quot;%p\\n&quot;, &amp;x) // 0xc0000140b0 return func(y int) int &#123; fmt.Printf(&quot;%p\\n&quot;, &amp;x) // 0xc0000140b0 return x + y &#125;&#125; 3.3 多匿名函数返回，延迟求值问题1234567891011121314151617func test() []func() &#123; var fs []func() for i := 0; i &lt; 3; i++ &#123; fs = append(fs, func() &#123; println(&amp;i, i) // 延迟执行特性，最后都输出3 &#125;) &#125; return fs&#125;func main() &#123; for _, f := range test() &#123; f() &#125;&#125; 修正后： 123456789101112131415161718func test() []func() &#123; var fs []func() for i := 0; i &lt; 3; i++ &#123; x := i // 立即赋值 fs = append(fs, func() &#123; println(&amp;x, x) &#125;) &#125; return fs&#125;func main() &#123; for _, f := range test() &#123; f() &#125;&#125; 4. 递归函数4.1 阶乘123456789101112func factorial(n uint64) uint64 &#123; if n &gt; 0 &#123; return n * factorial(n - 1) &#125; return 1&#125;func main() &#123; var i int = 15 fmt.Printf(&quot;%d 的阶乘等于 %d&quot;, i, factorial(uint64(i)))&#125; 4.2 Fibonacci1234567891011121314func fibonacci(n uint64) uint64 &#123; if n &lt; 2 &#123; return n &#125; return fibonacci(n-2) + fibonacci(n-1)&#125;func main() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d &quot;, fibonacci(uint64(i))) &#125; fmt.Println()&#125; 5. 延迟调用（defer) FILO 先进后出 即使函数发生panic错误，也会执行 支持匿名函数调用 用于资源清理、文件关闭、解锁以及记录时间等操作 与匿名函数配合，可在return后修改函数的计算结果 5.1 示例11234567891011func main() &#123; for i := 0; i &lt; 3; i++ &#123; defer fmt.Println(i) // 2 1 0 &#125; for i := 0; i &lt; 3; i++ &#123; defer func() &#123; fmt.Println(i) // 3 3 3 &#125;() &#125;&#125; 5.2 循环中使用延迟调用延迟调用在函数结束时调用，如果将其放到循环中，会造成资源浪费 123456789101112131415func main() &#123; for i := 0; i &lt; 1000; i++ &#123; path := fmt.Sprintf(&quot;./log/%d.txt&quot;, i) f, err := os.Open(path) if err != nil &#123; log.Println(err) continue &#125; defer f.Close() // do something &#125;&#125; 优化： 12345678910111213141516171819func main() &#123; do := func(i int) &#123; path := fmt.Sprintf(&quot;./log/%d.txt&quot;, i) f, err := os.Open(path) if err != nil &#123; log.Println(err) return &#125; defer f.Close() // do something &#125; for i := 0; i &lt; 1000; i++ &#123; do(i) &#125;&#125; 5.3 延迟调用闭包1234567891011121314151617181920func main() &#123; var fs = [4]func()&#123;&#125; for i := 0; i &lt; 4; i++ &#123; defer fmt.Println(&quot;defer i = &quot;, i) defer func() &#123; fmt.Println(&quot;defer_closure i = &quot;, i) // always 4 &#125;() defer func(i int) &#123; fmt.Println(&quot;defer_closure i = &quot;, i) // i will change &#125;(i) fs[i] = func() &#123; fmt.Println(&quot;closure i = &quot;, i) &#125; &#125; for _, f := range fs &#123; f() &#125;&#125; 5.4 延迟调用性能相比直接用CALL汇编指令调用函数，延迟调用则须花费更大代价。这其中包括注册、调用等操作，还有额外的缓存开销。 1234567891011121314151617181920212223var m sync.Mutexfunc call() &#123; m.Lock() m.Unlock()&#125;func deferCall() &#123; m.Lock() defer m.Unlock()&#125;func BenchmarkCall(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; call() &#125;&#125;func BenchmarkDeferCall(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; deferCall() &#125;&#125; 5.5 for range与闭包的坑1234567891011func main() &#123; s := []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; for _, v := range s &#123; go func() &#123; fmt.Println(v) // 三次全部打印&quot;c&quot; &#125;() &#125; select &#123;&#125; // 使main一直等待直到deadlock异常&#125; 6. 错误处理标准库错误接口: 123type error interface &#123; Error() string&#125; 6.1 panic &amp; recover panic: 主动抛出错误 recover: 捕获panic抛出的错误 12func panic(v interface&#123;&#125;)func recover() interface&#123;&#125; panic和recover运行机制： 1) 引发panic有两种情况：一是程序主动调用，二是程序产生运行时错误(Runtime Error)，由运行时检测并退出 2) 发生panic后，程序会从调用panic的函数位置或发生panic的地方立即返回，逐层执行函数的的defer语句，然后逐层打印函数调用堆栈，直到recover捕获或运行到最外层函数 3) panic不但可以在函数正常流程中抛出，在defer逻辑里也可以再次调用panic或抛出panic。defer里面的panic能够被后续执行的defer捕获 4) recover用来捕获panic，阻止panic继续向上传递。recover()和defer一起使用，但是defer只有在后面的函数体内直接被调用才能捕获panic来终止，否则返回nil，异常继续向外传递。 注意：除非是不可恢复性、导致系统无法正常工作的错误，否则不建议使用panic。如：文件系统没操作权限、服务端口被占用、数据库未启动等 123456789101112131415func main() &#123; result := div(8, 0) fmt.Println(result)&#125;func div(a int, b int) int &#123; defer func() &#123; err := recover() if err != nil &#123; fmt.Println(err) &#125; &#125;() return a / b&#125; 6.2 主动panic并捕获12345678910func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Fatalln(err) &#125; &#125;() panic(&quot;crash&quot;) println(&quot;exit.&quot;)&#125; 6.3 无效捕获和有效捕获错误12345678910111213141516171819202122// 无效的捕获defer recover()defer fmt.Println(recover())defer func() &#123; func() &#123; recover() // 嵌套多层，无效 &#125;()&#125;()// 有效的捕获defer func() &#123; recover()&#125;()func except() &#123; recover()&#125;func test() &#123; defer except() panic(&quot;runtime error&quot;)&#125; 6.4 多个panic，只会捕获最后一个1234567891011121314151617func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) // three 只会捕获最后一个 &#125; &#125;() defer func() &#123; panic(&quot;three&quot;) &#125;() defer func() &#123; panic(&quot;two&quot;) &#125;() panic(&quot;one&quot;)&#125; 7. 自定义错误 errors.New(&quot;错误描述&quot;)：返回一个error类型的值，表示一个错误 panic内置函数：接收一个interface{}类型的值(即任意值)作为参数，可以接受error类型的变量，输出错误信息，并退出程序。 7.1 负数平方根1234567891011121314151617func Sqrt(x float64) (float64, error) &#123; if x &lt; 0 &#123; return 0, errors.New(&quot;math: square root of negative number&quot;) &#125; return math.Sqrt(x), nil&#125;func main() &#123; result, err := Sqrt(-1) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(result) &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 引用数据类型","slug":"Go 引用数据类型","date":"2018-01-03T02:52:13.000Z","updated":"2021-06-22T10:50:49.703Z","comments":true,"path":"2018/01/03/Go 引用数据类型/","link":"","permalink":"https://elihe2011.github.io/2018/01/03/Go%20%E5%BC%95%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"1. 指针指针不是内存地址。 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。 指针会分配内存空间，相当于一个专门用来保存地址的整型变量。 GO指针，不支持加减运算和类型转换 可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。 Pointer类似C语言中的void*万能指针，可用来转换指针类型。它能安全持有对象或对象成员，但uintptr不行。后者仅是一种特殊整型，并不引用目标对象，无法阻止垃圾回收器回收对象内存。","text":"1. 指针指针不是内存地址。 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。 指针会分配内存空间，相当于一个专门用来保存地址的整型变量。 GO指针，不支持加减运算和类型转换 可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。 Pointer类似C语言中的void*万能指针，可用来转换指针类型。它能安全持有对象或对象成员，但uintptr不行。后者仅是一种特殊整型，并不引用目标对象，无法阻止垃圾回收器回收对象内存。 1.1 引用传递12345678910111213141516171819const MAX int = 3func main() &#123; var a int = 10 var b int = 20 fmt.Println(a, b) swap(&amp;a, &amp;b) fmt.Println(a, b)&#125;func swap(x *int, y *int) &#123; var temp int temp = *x *x = *y *y = temp&#125; 1.2 指针类型1.2.1 三种指针： *T：普通指针，用于传递地址，不能进行指针运算 unsafe.Pointor: 通用指针类型。用于转换不同类型的指针，不能进行指针运算 uintptr: 用于指针运算。GC不把uintptr当指针，uintptr无法持有对象。uintptr类型的目标会被回收 1.2.2 unsafe.Pointer 作用 unsafe.Pointer 可以和 普通指针 进行互相转换 unsafe.Pointer 可以和 uintptr 进行相互转换 unsafe.Pointer 是桥梁，可以让任意类型的指针实现相互转换，也可以将任意类型的指针转换为uintptr进行指针运算 2. 切片 (Slice)切片是对数组的抽象。数组长度固定，而切片长度不固定，可追加元素，被称为动态数组。 不是数组，但指向底层的数组 可现实变长数组 为引用类型 可直接创建(make)或从底层数组获取生成 len()获取元素个数，cap()获取容量 不支持比较操作(==, &gt;, &lt;) 12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 2.1 创建切片123456789101112131415func main() &#123; s1 := make([]int, 3, 5) s2 := make([]int, 3) s3 := []int&#123;10, 20, 3: 30&#125; arr := [...]int&#123;1, 2, 3, 4, 5&#125; s4 := arr[:] s5 := arr[2:4] // cap=len(arr)-2 fmt.Println(s1, len(s1), cap(s1)) // [0, 0, 0] 3 5 fmt.Println(s2, len(s2), cap(s2)) // [0, 0, 0] 3 3 fmt.Println(s3, len(s3), cap(s3)) // [10, 20, 0, 30] 4 4 fmt.Println(s4, len(s4), cap(s4)) // [1, 2, 3, 4, 5] 5, 5 fmt.Println(s5, len(s5), cap(s5)) // [3, 4] 2 3&#125; 2.2 空切片123456789101112131415func main() &#123; var s1 []int s2 := []int&#123;&#125; fmt.Println(s1==nil, s2==nil) // true false // &amp;reflect.SliceHeader&#123;Data:0x0, Len:0, Cap:0&#125; fmt.Printf(&quot;a: %#v\\n&quot;, (*reflect.SliceHeader)(unsafe.Pointer(&amp;s1))) // &amp;reflect.SliceHeader&#123;Data:0x118efd0, Len:0, Cap:0&#125; fmt.Printf(&quot;b: %#v\\n&quot;, (*reflect.SliceHeader)(unsafe.Pointer(&amp;s2))) fmt.Printf(&quot;Size of a: %d\\n&quot;, unsafe.Sizeof(s1)) // 24 fmt.Printf(&quot;Size of a: %d\\n&quot;, unsafe.Sizeof(s2)) // 24&#125; 2.3 复制数据允许指向同一底层数组，允许目标区间重叠。最终所复制长度以较短的切片长度（len）为准 123456789101112131415func main() &#123; s1 := []int&#123;1, 2, 3, 4, 5, 6&#125; s2 := []int&#123;7, 8, 9&#125; copy(s1, s2) // dst, src fmt.Println(s1) // [7, 8, 9, 4, 5, 6] fmt.Println(s2) // [7, 8, 9] s3 := []byte&#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125; s4 := []byte&#123;&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;&#125; copy(s3, s4) fmt.Println(s3) // [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;] fmt.Println(s4) // [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;]&#125; 2.4 扩容数据12345678910111213func main() &#123; s1 := make([]int, 3, 6) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) fmt.Println(len(s1), cap(s1)) // 3, 6 s1 = append(s1, 1, 2, 3) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) // 元素个数小于等于cap，地址未发生改变 fmt.Println(len(s1), cap(s1)) // 6, 6 s1 = append(s1, 4) fmt.Printf(&quot;%v %p\\n&quot;, s1, s1) // 元素个数大于原始cap，重新分配内存(底层数组重构)，地址发生改变 fmt.Println(len(s1), cap(s1)) // 7, 12&#125; Slice坑：slice虽然是引用，但可能被重新分配内存 1234567891011func foo(s []int) &#123; s = append(s, 1) // 增加的元素个数大于cap-len, 重新分配内存地址&#125;func main() &#123; s := make([]int, 0) fmt.Println(s) foo(s) fmt.Println(s) // []&#125; 3. 集合 (map)make([keyType]valueType, cap) 3.1 基本操作12345678910111213141516171819func main() &#123; m := map[string]int &#123; &quot;a&quot;: 1, &quot;b&quot;: 2, &#125; m[&quot;a&quot;] = 5 m[&quot;c&quot;] = 8 if v, ok := m[&quot;d&quot;]; ok &#123; println(v) &#125; delete(m, &quot;d&quot;) for k, v := range m &#123; println(k, &quot;:&quot;, v, &quot; &quot;) &#125;&#125; 3.2 多层map嵌套12345678910111213141516func main() &#123; m := make(map[int]map[int]string) // initialize sub-map m[1] = make(map[int]string) m[1][1] = &quot;OK&quot; fmt.Println(m) a, ok := m[2][1] // test if sub-map is initialized fmt.Println(a, ok) if !ok &#123; m[2] = make(map[int]string) &#125; fmt.Println(m)&#125; 3.3 不支持修改成员值(struct或array)字典被设计成“not addressable”，故不能直接修改value成员（结构或数组） 123456789101112131415161718192021222324252627func main() &#123; m := map[int]user&#123; 1: user&#123;&quot;Jack&quot;, 23&#125;, 2: user&#123;&quot;Tom&quot;, 22&#125;, &#125; //m[1].age++ // cannot assign to struct field in a map jack := m[1] jack.age++ m[1] = jack // 必须重新赋值 fmt.Println(m) // 指针方式 m2 := map[int]*user&#123; 1: &amp;user&#123;&quot;Jack&quot;, 23&#125;, 2: &amp;user&#123;&quot;Tom&quot;, 22&#125;, &#125; m2[1].age++ fmt.Println(m2[1])&#125;type user struct &#123; name string age int&#125; 12345678910111213func main() &#123; m := map[string][2]int &#123; &quot;a&quot;: &#123;1, 2&#125;, &#125; //s := m[&quot;a&quot;][:] // 数组必须addressable，否则会引发错误。 a := m[&quot;a&quot;] fmt.Printf(&quot;%p, %v\\n&quot;, &amp;a, a) s := a[:] fmt.Printf(&quot;%p, %v\\n&quot;, &amp;s, s)&#125; 3.4 map间接排序12345678910111213141516171819func main() &#123; m := map[int]string&#123;2: &quot;b&quot;, 5: &quot;e&quot;, 1: &quot;a&quot;, 3: &quot;c&quot;, 4: &quot;d&quot;&#125; s := make([]int, len(m)) i := 0 for k, _ := range m &#123; s[i] = k i++ &#125; fmt.Println(s) sort.Ints(s) // 索引排序 fmt.Println(s) for _, v := range s &#123; fmt.Println(m[v]) &#125;&#125; 3.5 并发读写字典1234567891011121314151617181920212223242526func main() &#123; var lock sync.RWMutex m := make(map[string]int) go func() &#123; for &#123; lock.Lock() m[&quot;a&quot;] += 1 lock.Unlock() time.Sleep(time.Microsecond) &#125; &#125;() go func() &#123; for &#123; lock.RLock() _ = m[&quot;b&quot;] lock.RUnlock() time.Sleep(time.Microsecond) &#125; &#125;() select &#123;&#125;&#125; 4. range用于for循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。 slice(i, v) map(k, v) 4.1 示例：遍历map1234567891011121314151617func main() &#123; sm := make([]map[int]string, 3) for _, v := range sm &#123; v = make(map[int]string) // range中v的值是一份拷贝，无法修改 v[1] = &quot;OK&quot; fmt.Println(v) &#125; fmt.Println(sm) // 可正确修改 for i := range sm &#123; sm[i] = make(map[int]string) sm[i][1] = &quot;OK&quot; fmt.Println(sm[i]) &#125; fmt.Println(sm)&#125; 4.2 示例：遍历slice1234567891011121314151617181920func main() &#123; nums := []int &#123;2, 3, 4&#125; sum := 0 for _, num := range nums &#123; sum += num &#125; fmt.Println(&quot;sum:&quot;, sum) for i, num := range nums &#123; if num == 3 &#123; fmt.Println(&quot;index:&quot;, i) &#125; &#125; for i, c := range &quot;go语言&quot; &#123; fmt.Println(i, c) // c, unicode值 &#125;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 基本数据类型","slug":"Go 基本数据类型","date":"2018-01-02T09:11:18.000Z","updated":"2021-06-22T10:50:49.702Z","comments":true,"path":"2018/01/02/Go 基本数据类型/","link":"","permalink":"https://elihe2011.github.io/2018/01/02/Go%20%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"1. 数据类型1.1 Go数据类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8的别名，相互不需要转换 int, uint 4, 8 0 默认整型，长度依平台而定，32或64 int8, uint8 1 0 -128 ~ 127, 0 ~ 255 int16, uint16 2 0 int32, uint32 4 0 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 默认 complex64 8 complex128 16 rune 4 0 Unicode Code Point, int32的别名 uintptr 4, 8 0 存储指针的uint string “” 默认值空字符串，而非nil array 数组 struct 结构体 function nil interface nil map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 ｜","text":"1. 数据类型1.1 Go数据类型 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8的别名，相互不需要转换 int, uint 4, 8 0 默认整型，长度依平台而定，32或64 int8, uint8 1 0 -128 ~ 127, 0 ~ 255 int16, uint16 2 0 int32, uint32 4 0 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 默认 complex64 8 complex128 16 rune 4 0 Unicode Code Point, int32的别名 uintptr 4, 8 0 存储指针的uint string “” 默认值空字符串，而非nil array 数组 struct 结构体 function nil interface nil map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 ｜ 1.2 值类型和引用类型 值类型：基本数据类型(int, float, bool, string)、数组(array)和结构体(struct) 变量直接存储，内存通常在栈中分配 (栈区：存放生命周期较短的数据) 引用类型：ptr、slice、map、channel、interface 变量存储的是一个地址，该地址对应的空间才真正存储数据。内存通常在堆上分配。当没有任何变量引用这个地址时，该地址对应的数据空间就成了垃圾，由GC来回收。（堆区：存放生命周期较长的数据。一个值类型，一般存储在栈区，但它如果在别的函数也用到，此时有可能放堆区，它要做逃逸分析） 2. 基本数据类型2.1 const常量2.1.1 常量特性： readonly cannot get address 12345678const x = 0x100y := &amp;x // errorconst x = 100const y byte = x // ok， 相当于const y byte = 100const x int = 100const y byte = x // error，需强制转换 2.1.2 常量初始化和枚举：iota: 常量计数器 1234567891011121314151617181920212223242526272829303132333435363738const ( a = &quot;A&quot; b // &quot;A&quot; c = iota // 2 d // 3)const ( e = iota // 0 f)const ( SUN = iota MON TUE WED THU FRI SAT)const ( B float64 = 1 &lt;&lt; (iota * 10) KB MB GB)// 需要显示恢复const ( a = iota // 0 b // 1 c = 100 // 100 d // 100 e = iota // 4 f // 5) 2.2 数值类型2.2.1 类型转换必须显示转换，不支持像Java一样向上自动转换 1234byte // uint8, 处理ASCII字符rune // int32, 处理Unicode字符，比如中文float64 // 系统默认类型，明确声明时，也推荐使用 2.2.2 运算符123456789101112// 除法fmt.Println(10 / 4) // 2var n1 float32 = 10 / 4fmt.Println(n1) // 2var n2 float32 = 10.0 / 4fmt.Println(n2) // 2.5// 取余 a % b = a - a / b * b10 % 3 // 1-10 % 3 // -1 2.2.3 两个变量，进行值交换，不允许使用中间变量123456var a int = 3var b int = 8a = a + bb = a - b // b = (a + b) - b = aa = a - b // a = (a + b) - a = b 2.2.4 数值进制转换123456789func main() &#123; a, _ := strconv.ParseInt(&quot;1100100&quot;, 2, 32) b, _ := strconv.ParseInt(&quot;0144&quot;, 8, 32) c, _ := strconv.ParseInt(&quot;64&quot;, 16, 64) println(&quot;0b&quot; + strconv.FormatInt(a, 2)) println(&quot;0&quot; + strconv.FormatInt(b, 8)) println(&quot;0x&quot; + strconv.FormatInt(c, 16))&#125; 2.2.5 数值类型转换123456789101112131415161718192021222324func main() &#123; a, _ := strconv.ParseInt(&quot;10100101&quot;, 2, 32) b, _ := strconv.ParseFloat(&quot;3.1415926&quot;, 64) fmt.Printf(&quot;%T, %v\\n&quot;, a, a) // int64 165 fmt.Printf(&quot;%T, %v\\n&quot;, b, b) // float64 3.1415926 fmt.Println(&quot;0x&quot; + strconv.FormatInt(a, 16)) // 0xa5 c := string(65) fmt.Printf(&quot;%T, %v\\n&quot;, c, c) // string, A d := int(c[0]) fmt.Printf(&quot;%T, %v\\n&quot;, d, d) // int, 65 e := strconv.Itoa(65) fmt.Printf(&quot;%T, %v\\n&quot;, e, e) // string, 65 f, _ := strconv.Atoi(e) fmt.Printf(&quot;%T, %v\\n&quot;, f, f) // int, 65 g, _ := strconv.ParseBool(&quot;true&quot;) fmt.Printf(&quot;%T, %v\\n&quot;, g, g) // bool, true&#125; 2.2.6 处理浮点数12345678910func main() &#123; var a float32 = 5.1234567890 var b float32 = 5.12345678 var c float32 = 5.123456789 println(a, b, c) // +5.123457e+000 +5.123457e+000 +5.123457e+000 println(a==b, a==c) // true true, 新版本go1.14.2，false, false fmt.Printf(&quot;%v, %v, %v\\n&quot;, a, b, c) // 5.123457, 5.123457, 5.123457&#125; 2.2.7 浮点数精度问题1234567891011121314151617181920212223func main() &#123; a := 0.6 a += 0.7 fmt.Println(a) // 1.2999999999999998 b := truncate(a) fmt.Println(b) // 1.3 c := round(a, 8) fmt.Println(c)&#125;func truncate(f float64) float64 &#123; str := fmt.Sprintf(&quot;%.8f&quot;, f) fmt.Println(str) // 1.30000000 f, _ = strconv.ParseFloat(str, 64) return f&#125;func round(f float64, n int) float64 &#123; n10 := math.Pow10(n) return math.Trunc((f+0.5/n10)*n10) / n10&#125; 2.3 字符串本质：是一个不可变byte序列，本身是一个复合结构 1234type stringStruct struct &#123; str unsafe.Pointer len int&#125; 头部指针指向字节数组，但没有NULL结尾 原始字符串raw string : 使用反引号”`”包裹，支持跨行 2.3.1 元素允许索引方式访问元素，但不能获取元素地址 123456func main() &#123; s := &quot;abc&quot; println(s[1]) println(&amp;s[1]) // cannot take the address&#125; 2.3.2 切片切片语法返回的子字符串，其内部依旧指向原始数组 reflect.StringHeader和string头结构相同 unsafe.Pointer用于指针类型转换 12345678910111213func main() &#123; s := &quot;abcdefg&quot; s1 := s[:3] s2 := s[1:4] s3 := s[2:] println(s1, s2, s3) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s))) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s1))) fmt.Printf(&quot;%#v\\n&quot;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s2)))&#125; 2.3.3 字符串遍历12345678910111213func main() &#123; s := &quot;中文&quot; // byte for i := 0; i &lt; len(s); i++ &#123; fmt.Printf(&quot;%d: [%c]\\n&quot;, i, s[i]) &#125; // rune for i, c := range s &#123; fmt.Printf(&quot;%d: [%c]\\n&quot;, i, c) &#125;&#125; 2.3.4 修改字符串字符串对象不可变，要修改，先将其转换为可变类型 []rune或[]byte 123456789101112131415161718s := &quot;hello world&quot;bs := []byte(s)s1 = string(bs)rs := []rune(s)s2 := string(rs)func toString(bs []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;bs))&#125;// 该方法利用了[]byte和string头结构“部分相同”，以非安全的指针类型转换来实现类型“变更”，从而避免了底层数组复制。在很多Web Framework中都能看到此类做法，在高并发压力下，此种做法能有效改善执行性能。只是使用unsafe存在一定的风险，须小心谨慎！s3 := toString(bs)// 修改字符串bs = append(bs, &quot;abc&quot;...)s4 := string(bs) 2.3.5 处理Unicode123456789101112func main() &#123; r := &#x27;中&#x27; // rune s := string(r) // string b := byte(r) // byte, 丢弃超出范围的bit fmt.Printf(&quot;%T, %T, %T\\n&quot;, r, s, b) // int32, string, uint8 s1 := string(b) r2 := rune(b) fmt.Println(s, b, s1, r2) // 中 45 - 45&#125; 2.3.6 截取字符串1234567func main() &#123; s := &quot;中C文&quot; fmt.Println(len(s), utf8.RuneCountInString(s)) // 7 3 s = string(s[0:1] + s[3:4]) fmt.Println(s, utf8.ValidString(s))&#125; 2.3.7 字符串拼接性能测试命令: go test -bench=. 1) 较差 123456789101112131415func test() string &#123; var s string for i := 0; i &lt; 10000; i++ &#123; s += &quot;a&quot; &#125; return s&#125;func BenchmarkTest(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; test() &#125;&#125; 2) 改进1 strings.Join(sa, &quot;&quot;) 123456789func test() string &#123; sa := make([]string, 10000) for i := 0; i &lt; len(sa); i++ &#123; sa[i] = &quot;a&quot; &#125; return strings.Join(sa, &quot;&quot;)&#125; 3) 改进2 byte.Buffer 12345678910func test() string &#123; var b bytes.Buffer b.Grow(10000) for i := 0; i &lt; 10000; i++ &#123; b.WriteString(&quot;a&quot;) &#125; return b.String()&#125; 2.3.8 字符串常用函数12345678910111213141516171819202122232425262728293031len(&quot;abc&quot;)r := []rune(&quot;中文&quot;) // 字符串遍历，同时支持处理中文n, err := strconv.Atoi(&quot;123&quot;)str := strconv.Itoa(123)bytes := []byte(&quot;abc&quot;) // [97, 98, 99]，二进制写入时有用str := string([]byte&#123;97, 98, 99&#125;) // abcstr := strconv.FormatInt(123, 2) // 进制转换 base=2, 8, 16b := strings.Contains(&quot;seafood&quot;, &quot;foo&quot;)count := strings.Count(&quot;seafood&quot;, &quot;o&quot;)b := strings.EqualFold(&quot;abc&quot;, &quot;ABC&quot;) // 不区分大小写n := strings.Index(&quot;go golang&quot;, &quot;go&quot;) // 0n := strings.LastIndex(&quot;go golang&quot;, &quot;go&quot;) // 3str := strings.Replace(&quot;go golang&quot;, &quot;c&quot;, n) 替换个数n，n=-1表示全部strArr := strings.Split(&quot;hello,world,ok&quot;, &quot;,&quot;)str := strings.toLower(&quot;Go&quot;)str := strungs.toUpper(&quot;Go&quot;)str := strings.TrimSpace(&quot; I am a gopher, haha. &quot;)str := strings.Trim(&quot;!Hello World!&quot;, &quot;!&quot;)str := strings.TrimRight(&quot;!Hello World!&quot;, &quot;!&quot;)str := strings.TrimLeft(&quot;!Hello World!&quot;, &quot;!&quot;)b := strings.HasPrefix(&quot;http://google.com&quot;, &quot;http&quot;)b := strings.HasSuffix(&quot;index.html&quot;, &quot;html&quot;) 2.3.9 获取中文字符串长度：12345678var str = &quot;hello 你好&quot;len(str) // 12import &quot;unicode/utf8&quot;utf8.RuneCountInString(str) // 8len([]rune(str)) // 8 2.4 数组2.4.1 声明和初始化123456789101112// 声明var balance [10]float32// 初始化var balance = [5]float32 &#123;4.0, 1.3, 2.2, 3.9, 3.0&#125;var balance = [...]float32 &#123;4.0, 1.3, 2.2&#125;balance[2] = 3.2// 访问数组var tag float32 = balance[1] 2.4.2 数组遍历12345678910111213func main() &#123; var arr [10]int for i := 0; i &lt; 10; i++ &#123; arr[i] = i + 100 &#125; for j := 0; j &lt; 10; j++ &#123; fmt.Printf(&quot;%d\\t&quot;, arr[j]) &#125; fmt.Println()&#125; 2.4.3 二分查找二分查找逻辑： 数组必须有序arr 中间的下标：midIndex = (firstIndex + lastIndex) / 2 让arr[midIndex]与targetValue比较 arr[midIndex] &gt; targetValue，返回firstIndex … (midIndex-1) arr[midIndex] &lt; targetValue，返回(midIndex+1) … lastIndex arr[midIndex] == targetValue，找到 1234567891011121314151617181920212223242526func main() &#123; a := []int&#123;0, 3, 5, 8, 9, 12, 14, 16&#125; index := binarySearch(&amp;a, 0, len(a)-1, 12) if index == -1 &#123; fmt.Println(&quot;未找到&quot;) &#125; else &#123; fmt.Printf(&quot;找到，位置在 %d\\n&quot;, index) &#125;&#125;func binarySearch(a *[]int, left, right, target int) int &#123; if left &gt;= right &#123; return -1 &#125; mid := (left + right) / 2 if (*a)[mid] &gt; target &#123; return binarySearch(a, left, mid-1, target) &#125; else if (*a)[mid] &lt; target &#123; return binarySearch(a, mid+1, right, target) &#125; else &#123; return mid &#125;&#125; 2.4.4 多维数组只允许第一维缺省 123456789101112131415161718192021222324func main() &#123; a := [2][2]int &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#125; b := [...][3]int &#123; &#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;, &#125; c := [...][2][2]int &#123; &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#125;, &#123; &#123;5, 6&#125;, &#123;7, 8&#125;, &#125;, &#125; fmt.Println(a, b, c)&#125; 2.4.5 数组长度len和cap都只返回一维数组长度 123456789func main() &#123; a := [...][2]int &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#123;5, &#125;, &#125; fmt.Println(len(a), cap(a), len(a[0]), cap(a[0]), len(a[2]), cap(a[2]))&#125; 2.4.6 比较操作 如元素类型支持“==、!=”操作符，那么数组也支持此操作。 前提：类型必须一致！ 1234567891011121314func main() &#123; var a, b [2]int fmt.Println(a == b) c := [2]int&#123;1, 2&#125; d := [2]int&#123;1, 3&#125; fmt.Println(c == d) e := [3]int&#123;1, 2, 3&#125; fmt.Println(c == e) // 类型不一致，无法比较 var x, y [2]map[string]int fmt.Println(x == y) // map不支持==和!=操作，数组无法支持&#125; 2.4.7 指针数组和数组指针 指针数组: 元素为指针类型的数组 数组指针: 数组变量的地址 123456789func main() &#123; x, y := 10, 20 a := [...]*int &#123;&amp;x, &amp;y&#125; // 指针数组 p := &amp;a // 数组指针 fmt.Printf(&quot;%T %v\\n&quot;, a, a) fmt.Printf(&quot;%T %v\\n&quot;, p, p)&#125; 使用指针操作数组： 123456789func main() &#123; a := [...]int&#123;1, 2&#125; fmt.Println(&amp;a, &amp;a[0], &amp;a[1]) p := &amp;a p[1] += 3 fmt.Println(p, a)&#125; 2.4.8 数组复制1234567891011121314151617181920func test1(x [2]int) &#123; fmt.Printf(&quot;x: %p, %v\\n&quot;, &amp;x, x)&#125;func test2(y *[2]int) &#123; fmt.Printf(&quot;y: %p, %v\\n&quot;, y, *y)&#125;func main() &#123; a := [2]int&#123;1, 2&#125; var b [2]int b = a // 值复制，地址并未复制 fmt.Printf(&quot;a: %p, %v\\n&quot;, &amp;a, a) fmt.Printf(&quot;b: %p, %v\\n&quot;, &amp;b, b) test1(a) // 按值传递 test2(&amp;a) // 按地址传递&#125; 2.4.9 排序算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869func main() &#123; arr := [...]int&#123;5, 7, 8, 1, 2, 4, 9, 0, 3, 6&#125; //bubbleSort(arr[:]) //selectSort(arr[:]) //insertSort(arr[:]) quickSort(arr[:], 0, len(arr)-1) fmt.Println(arr)&#125;func bubbleSort(a []int) &#123; for i := 0; i &lt; len(a); i++ &#123; for j := 1; j &lt; len(a)-i; j++ &#123; // 相邻比较，交换位置 if a[j] &lt; a[j-1] &#123; a[j], a[j-1] = a[j-1], a[j] &#125; &#125; &#125;&#125;func selectSort(a []int) &#123; for i := 0; i &lt; len(a); i++ &#123; for j := i + 1; j &lt; len(a); j++ &#123; // 选择a[i]作为标兵，将它与i+1...的值比较，找到最小或最大，赋值给a[i] if a[i] &gt; a[j] &#123; a[i], a[j] = a[j], a[i] &#125; &#125; &#125;&#125;func insertSort(a []int) &#123; // 假定第一个元素是有序的，后的元素与之比较，满足条件逐个插入 for i := 1; i &lt; len(a); i++ &#123; for j := i; j &gt; 0; j-- &#123; // 前一个元素大于后一个元素，跳过比较 if a[j] &gt; a[j-1] &#123; break &#125; a[j], a[j-1] = a[j-1], a[j] &#125; &#125;&#125;func quickSort(a []int, left, right int) &#123; if left &gt;= right &#123; return &#125; // 选取一个元素，作为比较项 k := left val := a[k] for i := left + 1; i &lt;= right; i++ &#123; // 比基准值小的摆放在基准前面，比基准值大的摆在基准的后面 if a[i] &lt; val &#123; a[k] = a[i] a[i] = a[k+1] k++ &#125; &#125; a[k] = val quickSort(a, left, k-1) quickSort(a, k+1, right)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Go 语言基础","slug":"Go 语言基础","date":"2018-01-01T04:11:18.000Z","updated":"2021-06-22T10:50:49.702Z","comments":true,"path":"2018/01/01/Go 语言基础/","link":"","permalink":"https://elihe2011.github.io/2018/01/01/Go%20%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"1. Go语言相关知识点1.1 Go特点： 类型安全和内存安全 以非常直观和极低的代价实现高并发 高效的垃圾回收机制 快速编译 为多核计算机提供提升性能的方案 默认UTF-8编码","text":"1. Go语言相关知识点1.1 Go特点： 类型安全和内存安全 以非常直观和极低的代价实现高并发 高效的垃圾回收机制 快速编译 为多核计算机提供提升性能的方案 默认UTF-8编码 1.2 GOPATH下的三个目录： bin pkg src 1.3 相关命令：12345678910go run // 直接运行，调试go build // 编译并生成可执行文件go fmt // 格式化代码go install // 先编译包文件，后编译整个程序go test // 运行测试文件 （xxx_test.go测试程序xxx.go)go doc // 查看文档godoc fmt Println // 查看具体的函数说明godoc --http=:8080 1.4 包导入别名1234import &quot;fmt&quot;import . &quot;fmt&quot; // 省略调用import std &quot;fmt&quot; // 别名import _ &quot;xxx&quot; // 只执行xxx包中的init()函数 1.5 可见性12func getField() // privatefunc Find() // public 2. 字符串格式化2.1 占位符123456789101112131415161718192021222324252627%v 默认格式%+v 打印结构体时，添加字段名%#v 使用Go语法表示%T 对象类型%% %%t true 或 false%b binary%c Unicode # Printf(&quot;%c&quot;, 0x4E2D) // 中%d decimal%o octal%x hex%X HEX%#x add prefix &quot;0x&quot; # %#o add &quot;0&quot; prefix%s string%q qutation%f%.2f%e 科学计数法%E%g 科学计数法，更紧凑的，无末尾的0%G%p 指针地址 2.2 键盘输入123456789func main() &#123; var name string var age int8 fmt.Scanln(&amp;name) fmt.Scanf(&quot;%d&quot;, &amp;age) fmt.Println(name, age)&#125; 2.3 字符串输入12345678910func main() &#123; str := &quot;Tom 23&quot; var name string var age byte fmt.Sscanf(str, &quot;%s %d&quot;, &amp;name, &amp;age) fmt.Println(name, age)&#125; 3. 位运算3.1 原码、反码和补码：(有符号整数) 二进制最高位：0-正数 1-负数 正数(1)：原码、反码和补码一样 原码：0000 0001 反码：0000 0001 补码：0000 0001 负数(-1)：反码 —&gt; 符号位不变，其他位取反；补码 —&gt; 反码 + 1 原码：1000 0001 反码：1111 1110 补码：1111 1111 零：反码和补码都是0 计算机运算以“补码”方式进行 (没有减法，只有加法) 1 + 1：0000 0001 + 0000 0001 = 0000 0010 1 + -1：0000 0001 + 1111 1111 = 1 0000 0000 3.2 位移运算 右移(&gt;&gt;): 符号位不变，低位溢出，并用符号位补溢出的高位 左移(&lt;&lt;): 符号位不变，低位补0 123456789101112131415161718192021222324func main() &#123; a := 1 &gt;&gt; 2 // 0 b := 1 &lt;&lt; 2 // 4 fmt.Println(a, b) /* 1 &gt;&gt; 2 =&gt; 0 000 0001 -&gt; 0 000 0000 = 0 1 &lt;&lt; 2 =&gt; 0 000 0001 -&gt; 0 000 0100 = 4 */ c := -1 &gt;&gt; 2 // -1 d := -1 &lt;&lt; 2 // -4 fmt.Println(c, d) /* -1 &gt;&gt; 2 =&gt; 1 000 0001 -&gt; 1 111 1110 -&gt; 1 111 1111 =&gt; 1 111 1111 -&gt; 1 111 1110 -&gt; 1 000 0001 = -1 -1 &lt;&lt; 2 =&gt; 1 000 0001 -&gt; 1 111 1110 -&gt; 1 111 1111 =&gt; 1 111 1100 -&gt; 1 111 1011 -&gt; 1 000 0100 = -4 */&#125; 3.3 Go中特殊位运算符 &amp;^12var a int = 6 &amp;^ 11 // 46 &amp; (^11) =&gt; 6 &amp; 4 3.4 负数位运算1234567891011var a byte = 2var b byte = -2var c byte = a ^ b // -4/*2补码：0000 0010-2补码：1000 0010 -&gt; 1111 1101 -&gt; 1111 11102 ^ -2 = 0000 0010 ^ 1111 1110 = 1111 1100 -&gt; 1111 1011 -&gt; 1000 0100 = -4*/ 4. 获取变量占用的字节数unsafe.Sizeof(obj) 1234func main() &#123; var n = 100 fmt.Println(unsafe.Sizeof(n))&#125; 5. 控制语句5.1 for循环1234567891011for &#123; &#125;for a &lt;= 3 &#123; &#125;for i := 1; i &lt; 10; i++ &#123; &#125; 5.2 switch选择1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func main() &#123; var a = 1 switch a &#123; case 0: fmt.Println(&quot;a=0&quot;) case 1: fmt.Println(&quot;a=1&quot;) default: fmt.Println(&quot;No Found&quot;) &#125;&#125;// 不能写成 switch afunc main() &#123; var a = 1 // expression is omitted switch &#123; case a &gt;= 0: fmt.Println(&quot;a&gt;=0&quot;) fallthrough case a &gt;= 1: fmt.Println(&quot;a&gt;=1&quot;) default: fmt.Println(&quot;No Found&quot;) &#125;&#125;// a的作用域只在switch中switch a := 1; &#123; &#125;// type-switchfunc main() &#123; var x interface&#123;&#125; = 10 switch x.(type) &#123; case nil: fmt.Println(&quot;NULL&quot;) case int: fmt.Println(&quot;int&quot;) default: fmt.Println(&quot;interface&#123;&#125;&quot;) &#125;&#125; 5.3 for循环示例：打印空心金字塔1234567891011121314151617181920212223242526272829303132333435/* * * * * * * ***********/func main() &#123; N := 5 // Step 1: 打印一个n*n列的正方形 for i := 1; i &lt;= N; i++ &#123; // Step 3: 打印等边三角形。每行前补空格：Ln=0, Ln-1=1, L2=n-2, L1=n-1 for k := 1; k &lt;= N-i; k++ &#123; fmt.Print(&quot; &quot;) &#125; // Step 2: 打印一个直角三角形。金字塔每行*个数：L1=1，L2=3, L3=5, Ln=2n-1 for j := 1; j &lt;= 2*i-1; j++ &#123; // Step 4: 空心。每行只保留第一个和最后一个 if j == 1 || j == 2*i-1 &#123; fmt.Print(&quot;*&quot;) &#125; else &#123; // Step 5: 最后一行全部保留 if i == N &#123; fmt.Print(&quot;*&quot;) &#125; else &#123; fmt.Print(&quot; &quot;) &#125; &#125; &#125; fmt.Println() &#125;&#125; 5.4 for循环示例：九九乘法表12345678func main() &#123; for i := 1; i &lt;= 9; i++ &#123; for j := 1; j &lt;= i; j++ &#123; fmt.Printf(&quot;%d * %d = %d\\t&quot;, j, i, i*j) &#125; fmt.Println() &#125;&#125; 5.5 for循环示例：水仙花数水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身（例如：1^3 + 5^3+ 3^3 = 153） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*三位的水仙花数共有4个：153，370，371，407；四位的四叶玫瑰数共有3个：1634，8208，9474；*/func main() &#123; var N int64 = 1000000 var i int64 for i = 100; i &lt;= N; i++ &#123; if isNarcissusFew(i) &#123; fmt.Println(i) &#125; &#125;&#125;func isNarcissusFew(n int64) bool &#123; s := strconv.FormatInt(n, 10) l := len(s) var sum int64 = 0 for j := n; ; &#123; m := j % 10 sum += int64(math.Pow(float64(m), float64(l))) j = j / 10 if j == 0 &#123; break &#125; &#125; return sum == n&#125;func isNarcissistic(n int64) bool &#123; s := strconv.FormatInt(n, 10) l := len(s) var sum int64 = 0 for _, c := range s &#123; num, _ := strconv.Atoi(fmt.Sprintf(&quot;%c&quot;, c)) sum += int64(math.Pow(float64(num), float64(l))) &#125; return sum == n&#125; 性能对比： 12345678go test -bench=. -run=nonegoos: darwingoarch: amd64pkg: gomod/aaaBenchmarkIsNarcissistic-4 1 93848583244 ns/opBenchmarkIsNarcissusFew-4 1 31639945040 ns/opPASSok gomod/aaa 125.791s 5.6 goto, break, continue LABEL用法：1234567891011121314func main() &#123;LABEL1: for &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 3 &#123; // break LABEL1 goto LABEL2 &#125; &#125; &#125; LABEL2: fmt.Println(&quot;OK&quot;)&#125; 6. 随机数12345func main() &#123; rand.Seed(time.Now().UnixNano()) // 种子变化越大，随机性越好 n := rand.Intn(100) + 1 fmt.Println(n)&#125; 7. 时间和日期函数1234567891011121314151617181920func main() &#123; now := time.Now() // time.Time year := now.Year() month := int(now.Month()) day := now.Day() fmt.Printf(&quot;%04d-%02d-%02d\\n&quot;, year, month, day) weekday := now.Weekday() fmt.Println(weekday) ts := now.Unix() // timestamp nano := now.UnixNano() fmt.Println(ts, nano) dateStr := now.Format(&quot;2006-01-02 15:04:05&quot;) fmt.Println(dateStr)&#125;time.Sleep(100 * time.MilliSecond) 8. 内置函数12345678910len // string, array, slice, map, channelclose // channelnew // 分配内存, 值类型 int, float, struct等，返回指针make // 分配内存, 引用类型 chan, map, slice等，返回类型本身，而非指针nptr = new(int) // *intappend // 追加元素到array, slice中panic/recover // 错误处理 9. new和make的区别 new(T) 返回 T 的指针 *T 并指向 T 的零值。 make(T) 返回的初始化的 T，只能用于 slice，map，channel。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://elihe2011.github.io/categories/Golang/"}],"tags":[{"name":"go","slug":"go","permalink":"https://elihe2011.github.io/tags/go/"}]},{"title":"Git","slug":"Git","date":"2017-05-01T09:35:40.000Z","updated":"2021-06-22T10:50:49.701Z","comments":true,"path":"2017/05/01/Git/","link":"","permalink":"https://elihe2011.github.io/2017/05/01/Git/","excerpt":"1. 基本概念1.1 git特点1) 直接存储文件快照(特定时间点的完整文件)，而非存储差异。2) 几乎所有操作都在本地执行，只有同步版本库才需要联网。3) 天然的数据完整性校验(SHA-1, 40bits).","text":"1. 基本概念1.1 git特点1) 直接存储文件快照(特定时间点的完整文件)，而非存储差异。2) 几乎所有操作都在本地执行，只有同步版本库才需要联网。3) 天然的数据完整性校验(SHA-1, 40bits). 1.2 git文件变更操作文件变更的三个阶段: 修改(modified) 暂存(staged): 已加入下次提交列表) 提交(committed): 保存到版本数据目录 三个阶段数据存放区域: 工作目录(workspace) 暂存索引文件(.git/index) 本地数据目录(.git/objects) Git Data Transport Commands (http://osteele.com) 2. 初始化设置2.1 配置用户123456git config --global user.name &#x27;eli.he&#x27;git config --global user.email &#x27;eli.he@live.cn&#x27;git config --global core.autocrlf falsegit config --list 2.2 密钥设置1) 生成密钥 1ssh-keygen -t rsa -C &#x27;eli.he@live.cn&#x27; 2) 上传公钥 id_rsa.pub 至SSH keys管理 1cat ~/.ssh/id_rsa.pub 3) 测试连通性 1ssh -T git@github.com 2.3 设置忽略文件 全局(.gitignore) 个人(.git/info/exclude) 3. 版本库3.1 新建版本库12345mkdir testcd testgit initgit remote add origin git@github.com:elihe2011/test.git 3.2 克隆版本库12345# 默认远程仓库名为origingit clone https://github.com/elihe2011/abc.git# 指定远程仓库名为git_prjgit clone -o git_prj https://github.com/elihe2011/abc.git 3.3 查看远程版本库12git remote -vgit remote show origin 3.4 获取远程版本，但不合并12git fetch origin mastergit fetch ～/github/new_test master 3.5 获取远程版本，并合并12git pull origin mastergit pull ～/github/new_test master 3.6 代码修改提交1234567git add .git commit -m &#x27;add a.txt&#x27; a.txtgit commit -m &#x27;add all&#x27;git commit -am &#x27;commit tracked files&#x27;git commit -m --amend --no-edit # 使用新的commit替代原有的，保持commit描述不变 3.7 推送至远程库12345git push -u origin master # -u, --set-upstream 第一次push的时候需要，自动添加如下配置branch.master.remote=originbranch.master.merge=refs/heads/master 4. 文件操作4.1 检查修改12345git diff hello.py # workspace, stagedgit diff --cached # staged, local-repositorygit diff master origin/master # local-repo remote-repo 4.2 撤销操作4.2.1 checkoutworkspace和staged撤销修改 123456# 撤销本次修改，commit前均可操作git checkout hello.py # 使用特定commit的文件，替换staged和workspace下的文件git checkout ad12sa1 hello.py cat .git/HEAD # defd8bb.... 4.2.2 reset不可恢复的撤销 (谨慎操作) 1234567891011121314# staged区回滚，git add的反操作git reset [&lt;files&gt;]# staged区和workspace回滚，回到最近一次提交git reset [&lt;files&gt;] --hard# staged区回滚到指定commit，之前的提交全部删除git reset &lt;commit&gt;# workspace区也回滚git reset &lt;commit&gt; --hard# 作用于staged区git reset --mixed HEAD 实例：12345git reset HEAD -- a.txtgit reset a.txt# HEAD^表示上个版本，HEAD^^上上个版本，HEAD~N往上N个版本git reset HEAD^^ -- a.txt 4.2.3 revert 仅反转提交撤销已提交的快照，但不从项目中删除这个commit，而是新生成一个commit 实例123456789touch 1.txt 2.txt 3.txtgit add .git commit -m &#x27;add 1.txt&#x27; 1.txtgit commit -m &#x27;add 2.txt&#x27; 2.txtgit commit -m &#x27;add 3.txt&#x27; 3.txtgit log --oneline -5git revert cc79f5a # revert 2.txtls -l [1-3].txt # 1.txt, 3.txt reset和revert的区别:reset: 被设计用来撤销本地的修改，它会完整地删除一个change set。revert: 被设计用来安全地撤销一个公共commit，会保留最初的change set，通过新建一个commit来撤销 4.2.4 撤销操作场景1) 已修改，未暂存 12git checkout .git reset --hard 2) 已暂存，未提交 123456git resetgit checkout .orgit reset --hard 3) 已提交，未推送 1git reset --hard origin/master 4) 已推送 12git reset --hard HEAD^git push -f origin master 4.2.5 撤销命令说明 命令 操作区域 checkout staged -&gt; workspace reset committed -&gt; staged reset –hard committed -&gt; staged -&gt; workspace 4.3 删除文件4.3.1 删除已traced文件1234567891011# 删除workspace中的文件，如果已在staged中，报错git rm a.txt# 同时删除workspace &amp; staged文件，保留committed文件git rm -f a.txt# 同时删除staged &amp; committed文件，保留workspace文件git rm --cached a.txt# 清理已被删除的所有文件git rm $(git ls-files --deleted) 4.3.2 删除未traced的文件12git clean -fgit clean -df 5. 标签5.1 创建标签12345678# 为当前分支最近一次提交创建标签git tag 1.0# 标签 develop/1.1git tag develop_1.1 develop# 为某个历史提交创建标签git tag 1.2 66cbbb4 5.2 查询标签123git taggit tag -l &#x27;1.2.*&#x27;git show 1.1 5.3 检出标签1git checkout 1.0 5.4 按标签创建分支123git branch test 1.1git checkout -b develop 1.2 5.5 删除标签1git tag -d 1.1 6. 日志6.1 查询日志123456789101112131415161718192021222324252627282930git loggit log -5git log stat # 详细日志git log -p # 更详细日志git log --author=&#x27;eli&#x27;git log --grep=&#x27;modify&#x27; # 过滤提交描述git log --graphgit log --graph --decorate --onelinegit log --onelinegit log ada6cb2..62a89cfgit log --mergesgit log --no-merges # 过滤merge提交git log --since=&#x27;2017-11-20&#x27; --until=&#x27;2017-12-01&#x27;git log --pretty=format:&quot;%cn committed %h on %cd&quot; # 格式化参数%cn committer name%h commit hash%cd commit date%s short messagegit log --pretty=&quot;%h - %s&quot; --author=&#x27;eli&#x27; --since=&#x27;2017-11-27 00:00:00&#x27; --before=&#x27;2017-11-27 11:59:59&#x27; 6.2 git reflog 所有分支的日志1git reflog --relative-date 6.3 git shortlog1git shortlog 7. 分支7.1 创建分支12345678# 从当前分支创建新分支，但不切换git branch develop# 从当前分支创建新分支，并切换git checkout -b develop# 从develop分支创建新分支git checkout -b test develop 7.2 删除分支12345# 删除已merge的分支git branch -d develop# 强制删除分支，不管是否已mergegit branch -D develop 7.3 更改分支名1git branch -m dev 7.4 切换分支本质上是更新HEAD指向给定的branch或commit 12345678git checkout developgit checkout -b test# 产生detached HEAD状态，detached意味着当前所有修改和项目发展的其他部分完全脱离，无法被mergegit checkout &lt;commit&gt;git checkout &lt;tag&gt; 7.5 合并分支12345# 自动指定merge算法git merge &lt;branch&gt;# 强制fast-forword merge算法git merge --on-ff &lt;branch&gt; 7.6 rebase 合并分支（重定义分支起点）1git rebase &lt;base&gt; # base: commit, tag, branch, HEAD~N 123456789101112131415git checkout -b developtouch echo.pygit add echo.pygit commit -m &#x27;add echo.py on develop branch&#x27;git checkout mastertouch print.pygit add print.pygit commit -m &#x27;add print.py on master branch&#x27;git checkout developgit rebase master # 将整个develop分支的commit放在master分支之后，不会创建merge commit，但会为develop分支的每个commit创建一个新的commitgit checkout mastergit merge develop # 只产生merge commit，分支commit不合入 7.7 merge和rebase的区别： merge: 产生一个merge commit，不会合入分支的commit rebase: 不产生merge commit，但合入分支的commit 示意图 git pullgit pull: 按merge方式合并git pull –rebase: 按rebase方式合并 merge未产生merge commit的原因：只有在存在冲突，解决完冲突后才自动产生一个merge commit git mergegit merge: 被合并之前的commit全部抹除，只保留一个解决冲突的merge commitgit merge –on-ff: 在没有冲突下，也自动产生一个merge commit 8. 远程分支操作8.1 查询远程分支1git ls-remote 8.2 跟踪远程分支123git checkout -b daily origin/dailygit checkout --track origin/daily # 本地和远程的分支名保持一致 8.3 添加本地分支与远程分支的关联关系（–set-upstream-to=）1git branch -u origin/daily 8.4 查询当前已跟踪的分支1git branch -vv 8.5 删除远程分支1git push origin --delete daily 8.6 远程仓库被删除，导致无法pull1git remote prune origin 9. 导出版本库1git archive --format=zip HEAD &gt; `date +%s`.zip 10. 撤销操作详细说明10.1 resetreset将一个分支的末端指向另一个提交，并移除当前分支的一些提交 12git checkout hotfixgit reset HEAD~2 hotfix分支末端的两个提交变成悬挂提交，下次Git执行垃圾回收时，这两个提交会被删除。 撤销缓存区和工作目录： –soft 缓存区和工作目录均不修改 –mixed 默认项，缓存区同步到你指定的提交，但工作目录不受影响 –hard 缓存区和工作目录均同步到你指定的提交 使用前提：你的更改未分享给别人，git reset是撤销这些更改的简单方法 10.2 revertrevert撤销一个提交同时会创建一个新的提交。比reset安全，且不会重写提交历史 12git checkout hotfixgit revert HEAD~2 10.3 总结git revert可以用在公共分支 git reset应该用在私有分支上 11. 配置项说明11.1 区分大小写1git config core.ignorecase false","categories":[{"name":"Tools","slug":"Tools","permalink":"https://elihe2011.github.io/categories/Tools/"}],"tags":[{"name":"git","slug":"git","permalink":"https://elihe2011.github.io/tags/git/"}]},{"title":"Flask DebugToolbar工具","slug":"Flask DebugToolbar","date":"2017-03-15T03:41:29.000Z","updated":"2021-06-22T10:50:49.701Z","comments":true,"path":"2017/03/15/Flask DebugToolbar/","link":"","permalink":"https://elihe2011.github.io/2017/03/15/Flask%20DebugToolbar/","excerpt":"12345678# config.pyapp.debug = Trueapp.config[&#x27;SECRET_KEY&#x27;] = &#x27;hard_guess&#x27;from flask_debugtoolbar import DebugToolbarExtensiontoolbar = DebugToolbarExtension(app) 12345# RUNpython manage.py runserver -r -d# getpersonshttp://localhost:5000/getpersons/","text":"12345678# config.pyapp.debug = Trueapp.config[&#x27;SECRET_KEY&#x27;] = &#x27;hard_guess&#x27;from flask_debugtoolbar import DebugToolbarExtensiontoolbar = DebugToolbarExtension(app) 12345# RUNpython manage.py runserver -r -d# getpersonshttp://localhost:5000/getpersons/","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 数据迁移","slug":"Flask 数据迁移","date":"2017-03-14T03:30:00.000Z","updated":"2021-06-22T10:50:49.700Z","comments":true,"path":"2017/03/14/Flask 数据迁移/","link":"","permalink":"https://elihe2011.github.io/2017/03/14/Flask%20%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/","excerpt":"1. 新增迁移管理命令12345# manage.pyfrom flask_migrate import Migrate, MigrateCommandmigrate = Migrate(app, db)manager.add_command(&#x27;db&#x27;, MigrateCommand)","text":"1. 新增迁移管理命令12345# manage.pyfrom flask_migrate import Migrate, MigrateCommandmigrate = Migrate(app, db)manager.add_command(&#x27;db&#x27;, MigrateCommand) 2. 迁移命令相关操作1234567891011121314151617# 生成迁移目录migrationspython manage.py db init # 生成版本迁移脚本python manage.py db migrate # 升级python manage.py db upgrade# 降级python manage.py db downgrade# 当前最新版本python manage.py db heads# 当前最新版本及相关详细信息python manage.py db show 3. 修改迁移配置migrations/env.py123456789def run_migrations_online(): # ... context.configure(connection=connection, target_metadata=target_metadata, compare_type=True, # 检查字段类型 compare_server_default=True, # 比较默认值 render_as_batch=True, # Batch mode with Auto-generate, for SQLite process_revision_directives=process_revision_directives, **current_app.extensions[&#x27;migrate&#x27;].configure_args) 4. 数据库升级失败python manage.py db upgradealembic.util.exc.CommandError: Can’t locate revision identified by ‘0e038fc360a3’ 解决方法：方法1: 直接修改数据库 1update alembic_version set version_num = &#x27;1dc902bd1c2&#x27;; 方法1: 指定版本 12345drop table alembic_version;python manage.py db history # get the new head of migrations, say, 5301c31377f2python manage.py db stamp 5301c31377f2 # to let alembic know that it&#x27;s your migration head (which gets stored in table alembic_version).","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 记录日志","slug":"Flask 记录日志","date":"2017-03-13T09:25:35.000Z","updated":"2021-06-22T10:50:49.700Z","comments":true,"path":"2017/03/13/Flask 记录日志/","link":"","permalink":"https://elihe2011.github.io/2017/03/13/Flask%20%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97/","excerpt":"1. 慢查询记录123456789101112131415@main.after_app_requestdef after_app_request(response): for query in get_debug_queries(): if query.duration &gt;= current_app.config[&#x27;FLASK_SLOW_DB_QUERY_TIME&#x27;]: current_app.logger.warning( &#x27;Slow query: %s\\nParameters: %s\\nDuration: %fs\\nContext: %s\\n&#x27; % (query.statement, query.parameters, query.duration, query.context)) return responseclass Config: # ... SQLALCHEMY_RECORD_QUERIES = True FLASK_SLOW_DB_QUERY_TIME = 0.001","text":"1. 慢查询记录123456789101112131415@main.after_app_requestdef after_app_request(response): for query in get_debug_queries(): if query.duration &gt;= current_app.config[&#x27;FLASK_SLOW_DB_QUERY_TIME&#x27;]: current_app.logger.warning( &#x27;Slow query: %s\\nParameters: %s\\nDuration: %fs\\nContext: %s\\n&#x27; % (query.statement, query.parameters, query.duration, query.context)) return responseclass Config: # ... SQLALCHEMY_RECORD_QUERIES = True FLASK_SLOW_DB_QUERY_TIME = 0.001 2. 分析函数消耗时间123456789101112131415161718@manager.commanddef profile(length=25, profile_dir=None): &quot;&quot;&quot;Start the application under the code profiler&quot;&quot;&quot; from werkzeug.contrib.profiler import ProfilerMiddleware app.wsgi_app = ProfilerMiddleware(app.wsgi_app, restrictions=[length], profile_dir=profile_dir) app.run() # 使用profile启动python manage.py profile --profile_dir=./profile# 读取prod文件from pstats import Statsdef stats_prof(filename): stat = Stats(filename, stream=sys.stdout) stat.print_stats() 3. 添加日志处理12345678910111213141516171819202122232425262728293031323334353637383940class ProductionConfig(Config): SQLALCHEMY_DATABASE_URI = os.environ.get(&#x27;DATABASE_URL&#x27;) or \\ &#x27;sqlite:///&#x27; + os.path.join(base_dir, &#x27;data.sqlite&#x27;) @classmethod def init_app(cls, app): Config.init_app(app) # email errors to administrator import logging from logging.handlers import SMTPHandler credentials = None secure = None if getattr(cls, &#x27;MAIL_USER_NAME&#x27;, None) is not None: credentials = (cls.MAIL_USERNAME, cls.MAIL_PASSWORD) if getattr(cls, &#x27;MAIL_USE_TLS&#x27;, None): secure = () mail_handler = SMTPHandler( mailhost=(cls.MAIL_SERVER, cls.MAIL_PORT), fromaddr=cls.MAIL_DEFAULT_SENDER, toaddrs=[cls.FLASK_ADMIN], subject=cls.FLASK_MAIL_SUBJECT_PREFIX + &#x27; Application Error&#x27;, credentials=credentials, secure=secure) mail_handler.setLevel(logging.ERROR) app.logger.addHandler(mail_handler) # 输出到 stderrimport loggingfrom logging import StreamHandler file_handler = StreamHandler() file_handler.setLevel(logging.WARNING) app.logger.addHandler(file_handler)# 写入系统日志import loggingfrom logging.handlers import SysLogHandler syslog_handler = SysLogHandler() syslog_handler.setLevel(logging.WARNING) app.logger.addHandler(syslog_handler) 4. 使用logger4.1 logger支持的方法123456from flask import current_appcurrent_app.logger.error(&#x27;this is a error&#x27;)current_app.logger.info(&#x27;this is a info&#x27;)current_app.logger.warning(&#x27;this is a wraning&#x27;)current_app.logger.debug(&#x27;this is a debug&#x27;) 4.2 配置123456789101112131415161718192021222324252627# config.pyclass Config(object): # logging format LOGGING_FORMAT = &quot;%(asctime)s test.%(name)-8s %(levelname)-4s %(message)s&quot; LOGGING_TIMESTAMP_FORMAT = &quot;%Y-%m-%d %H:%M:%S&quot;# views/__init__.pydef init_log(app): formatter = logging.Formatter(app.config[&quot;LOGGING_FORMAT&quot;], app.config[&quot;LOGGING_TIMESTAMP_FORMAT&quot;]) handler = RotatingFileHandler(app.config.get(&quot;LOG_FILE&quot;, &quot;test.log&quot;), maxBytes=1000000, backupCount=1) handler.setLevel(logging.INFO) handler.setFormatter(formatter) app.logger.addHandler(handler)def init_app(app): # 添加路由 for module in MODULES: app.register_blueprint(module) # 设置日志 if app.debug: init_log(app) # 设置错误处理 error_handler(app)","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask UnitTest","slug":"Flask UnitTest","date":"2017-03-12T06:23:00.000Z","updated":"2021-06-22T10:50:49.700Z","comments":true,"path":"2017/03/12/Flask UnitTest/","link":"","permalink":"https://elihe2011.github.io/2017/03/12/Flask%20UnitTest/","excerpt":"1. Unittest.TestCase123456789101112131415161718192021import unittestfrom flask import current_appfrom app import create_app, dbclass BasicsTest(unittest.TestCase): def setUp(self): self.app = create_app(&#x27;testing&#x27;) self.app_context = self.app.app_context() self.app_context.push() db.create_all() def tearDown(self): db.session.remove() db.drop_all() self.app_context.pop() def test_app_exists(self): self.assertFalse(current_app is None) def test_app_is_testing(self): self.assertTrue(current_app.config[&#x27;TESTING&#x27;])","text":"1. Unittest.TestCase123456789101112131415161718192021import unittestfrom flask import current_appfrom app import create_app, dbclass BasicsTest(unittest.TestCase): def setUp(self): self.app = create_app(&#x27;testing&#x27;) self.app_context = self.app.app_context() self.app_context.push() db.create_all() def tearDown(self): db.session.remove() db.drop_all() self.app_context.pop() def test_app_exists(self): self.assertFalse(current_app is None) def test_app_is_testing(self): self.assertTrue(current_app.config[&#x27;TESTING&#x27;]) 2. 覆盖率测试pip install coverage 12345678910111213141516171819202122232425262728# manage.pyCOV = Noneif os.environ.get(&#x27;FLASK_COVERAGE&#x27;): import coverage COV = coverage.coverage(branch=True, include=&#x27;app/*&#x27;) COV.start() @manager.commanddef test(coverage=False): &quot;&quot;&quot;Run the unit tests&quot;&quot;&quot; if coverage and not os.environ.get(&#x27;FLASK_COVERAGE&#x27;): import subprocess os.environ[&#x27;FLASK_COVERAGE&#x27;] = &#x27;1&#x27; sys.exit(subprocess.call(sys.argv)) import unittest tests = unittest.TestLoader().discover(&#x27;tests&#x27;) unittest.TextTestRunner(verbosity=2).run(tests) if COV: COV.stop() COV.save() print(&#x27;Coverage Summary:&#x27;) COV.report() basedir = os.path.abspath(os.path.dirname(__file__)) covdir = os.path.join(basedir, &#x27;tmp/coverage&#x27;) COV.html_report(directory=covdir) print(&#x27;HTML version: file://%s/index.html&#x27; % covdir) COV.erase() 3. Web客户端测试1）POST的form表单，CSRF保护（Flask-WTF生成的表单中，包含隐含字典，其内容时CSRF令牌，需要和表单数据一起提交） WTF_CSRF_ENABLED = False 1) 模拟web请求 1234567891011121314151617181920212223242526class FlaskClientTestCase(unittest.TestCase): def setUp(self): # ... self.client = self.app.test_client(use_cookies=True) def test_home_page(self): response = self.client.get(&#x27;/&#x27;) self.assertEqual(response.status_code, 200) self.assertTrue(b&#x27;Stranger&#x27; in response.data) def test_register_and_login(self): # register a new account response = self.client.post(&#x27;/auth/register&#x27;, data=&#123; &#x27;email&#x27;: &#x27;john@example.com&#x27;, &#x27;username&#x27;: &#x27;john&#x27;, &#x27;password&#x27;: &#x27;cat&#x27;, &#x27;password2&#x27;: &#x27;cat&#x27; &#125;) self.assertEqual(response.status_code, 302) # login with the new account response = self.client.post(&#x27;/auth/login&#x27;, data=&#123; &#x27;email&#x27;: &#x27;john@example.com&#x27;, &#x27;password&#x27;: &#x27;cat&#x27; &#125;, follow_redirects=True) self.assertEqual(response.status_code, 200) 4. 使用Selenium端到端测试","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 上下文","slug":"Flask 上下文","date":"2017-03-11T06:10:18.000Z","updated":"2021-06-22T10:50:49.699Z","comments":true,"path":"2017/03/11/Flask 上下文/","link":"","permalink":"https://elihe2011.github.io/2017/03/11/Flask%20%E4%B8%8A%E4%B8%8B%E6%96%87/","excerpt":"1. Flask上下文 对象 上下文类型 说明 g AppContext 处理请求时用作临时存储的对象，每次请求重设，请求结束时被销毁 current_app AppContext 当前已激活的程序实例 request RequestContext 请求对象，封装HTTP请求内容 session RequestContext 用户会话，用于存储请求之间需要共享的数据 上下文线程栈","text":"1. Flask上下文 对象 上下文类型 说明 g AppContext 处理请求时用作临时存储的对象，每次请求重设，请求结束时被销毁 current_app AppContext 当前已激活的程序实例 request RequestContext 请求对象，封装HTTP请求内容 session RequestContext 用户会话，用于存储请求之间需要共享的数据 上下文线程栈 2. AppContext2.1 current_app 本地代理current_app = werkzeug.local. LocalProxy(app) 12345678910111213141516from flask import Flask, current_appapp = Flask(__name__)@app.route(&#x27;/&#x27;)def index(): return &#x27;Hello, %s!&#x27; % current_app.name # 改用app_context()方法：app2 = current_app # RuntimeError: Working outside of application contextctx = app.app_context()ctx.push()app3 = current_app # OKapp3 is app # Falseapp3 == app # Truectx.pop() 2.2 构建应用上下文12with app.app_context(): print current_app.name 2.3 应用上下文栈1flask._app_ctx_stack # with语句实现应用上下文入栈和出栈 2.4 应用上下文hook函数123@app.teardown_appcontextdef teardown_appcontext(): print &#x27;teardown applications&#x27; 2.5 应用上下文生命周期1234567app_ctx = app.app_context()app_ctx.push()current_app.name # 生效app_ctx.pop()current_app.name # 失效 2.6 上下文处理器app_context_processor装饰器，被装饰的函数返回一个dict，该字典中的值成为应用上下文全局变量 123@main.app_context_processordef inject_admin_email(): return dict(email=&#x27;abc@test.com&#x27;) 1&lt;a href=&quot;mailto:&#123;&#123; email &#125;&#125;&quot;&gt;联系我们&lt;/a&gt; 3. RequestContext3.1 构建请求上下文1234567891011from flask import Flask, requestfrom werkzeug.test import EnvironBuilderapp = Flask(__name__)ctx = app.request_context(EnvironBuilder(&#x27;/&#x27;, &#x27;http://localhost/&#x27;).get_environ())ctx.push()try: print(request.url)finally: ctx.pop() 改用with实现： 1234567from flask import Flask, requestfrom werkzeug.test import EnvironBuilderapp = Flask(__name__)with app.request_context(EnvironBuilder(&#x27;/&#x27;, &#x27;http://localhost/&#x27;).get_environ()): print(request.url) 3.2 请求上下文hook 函数12345678910111213141516# 请求处理前调用@app.before_request():def before_request(): print request.url# 请求正常处理完成后调用，可用于统一修改响应内容@app.after_requestdef after_request(response): print request.url response.headers[&#x27;key&#x27;] = &#x27;abc&#x27; return response# 请求无论成功或失败均调用，可用来统一释放资源@app.teardown_requestdef teardown_request(exception): print request.url 4. current_app &amp; current_user4.1 他们是代理对象12345678current_user= LocalProxy(lambda: _request_ctx_stack.top.user)def _find_app(): top = _app_ctx_stack.top if top is None: raise RuntimeError(_app_ctx_error_msg) return top.appcurrent_app = LocalProxy(_find_app) 4.2 LocalProxy根据线程/协程，返回对应当前线程/协程的对象 线程 A 往 LocalProxy 中塞入 A 线程 B 往 LocalProxy 中塞入 B 无论在是什么地方， 线程 A 永远取到得是 A，线程 B 取到得永远是 B 4.3 current_app新开一个线程就不能使用 current_app ? 原因在于current_app 在 Flask 是一个代理。开了一个新线程，如果你不传递真实对象过去，那么在新开的线程里面使用 current_app 将获取不到对象，因为它没有 flask 上下文。 _get_current_object()： Return the current object. This is useful if you want the real object behind the proxy at a time for performance reasons or because you want to pass the object into a different context. 1234567891011def send_async_email(app, msg): with app.app_context(): # 此时current_app有效 mail.send(msg) def send_email(to, subject, template, **kwargs): app = current_app._get_current_obejct() msg = Message(...) msg.body = ... msg.html = ... t = Thread(target=send_async_email, args=[app, msg]) t.start() 4.4 current_user1234567891011121314151617print(&#x27;current_user: %s&#x27; % current_user)print(&#x27;AnonymousUser: %s&#x27; % AnonymousUser)print(isinstance(current_user, AnonymousUser))# current_user = LocalProxy(lambda: _request_ctx_stack.top.user)# current_user: &lt;app.models.AnonymousUser object at 0x7fe5479e1e10&gt;# AnonmousUser: &lt;class &#x27;app.models.AnoymousUser&#x27;&gt;# Falseprint(&#x27;current_user: %s&#x27; % current_user._get_current_object())print(&#x27;AnonymousUser: %s&#x27; % AnonymousUser)print(isinstance(current_user._get_current_object(), AnonymousUser))# current_user = _request_ctx_stack.top.user# current_user: &lt;app.models.AnonymousUser object at 0x7fe57986e4e10&gt;# AnonmousUser: &lt;class &#x27;app.models.AnoymousUser&#x27;&gt;# True 5. WerkZeug上下文详解请求上下文：保存了客户端和服务器交互的数据。 应用上下文：在flask程序运行过程中，保存的一些配置信息，比如程序文件名、数据库的连接、用户信息等。 5.1 Local5.1.1 为什么使用Local？threading.local对象，用于存储thread-safe和thread-specific的数据，只对本线程有效，其他线程不可见 12345678910111213141516import threadingstorage = threading.local()storage.foo = 1print(storage.foo) # 1class MyThread(threading.Thread): def run(self): print(hasattr(storage, &#x27;foo&#x27;)) # False storage.foo = 2 print(storage.foo) # 2 t = MyThread()t.start()print(storage.foo) # 1 Threading.local对象，虽然可以存储线程全局对象，但在Web中可能存在如下问题： 一些应用使用greenlet协程，此时无法做到协程隔离，不同的协程可能在同一线程中 即使使用的是线程，WSGI应用也无法保证每个http请求使用的都是不同的线程，因为后一个http请求可能使用的是之前的http请求的线程 5.1.2 使用Local实现WSGI： 123456789101112from flask import Requestfrom werkzeug.local import Local, LocalManagerlocal = Local()local_manager = LocalManager([local])def application(environ, make_response): local.request = request = Request(environ) # ...# make_middleware, 确保request结束后，local中对象的reference全部被释放application = local_manager.make_middleware(application) Local源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344try: from greenlet import getcurrent as get_identexcept ImportError: try: from thread import get_ident except ImportError: from _thread import get_ident class Local(object): __slots__ = (&#x27;__storage__&#x27;, &#x27;__ident_func__&#x27;) def __init__(self): object.__setattr__(self, &#x27;__storage__&#x27;, &#123;&#125;) object.__setattr__(self, &#x27;__ident_func__&#x27;, get_ident) def __iter__(self): return iter(self.__storage__.items()) def __call__(self, proxy): &quot;&quot;&quot;Create a proxy for a name.&quot;&quot;&quot; return LocalProxy(self, proxy) def __release_local__(self): self.__storage__.pop(self.__ident_func__(), None) def __getattr__(self, name): try: return self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) def __setattr__(self, name, value): ident = self.__ident_func__() storage = self.__storage__ try: storage[ident][name] = value except KeyError: storage[ident] = &#123;name: value&#125; def __delattr__(self, name): try: del self.__storage__[self.__ident_func__()][name] except KeyError: raise AttributeError(name) __ident_func__: 调用get_ident获取当前协程/线程的id __storage__: 以线程id为key，存储各个线程独立的对象 __release_local__: 释放线程id下的对象 5.2 LocalStackLocalStack 是用 Local 实现的栈结构，可以将对象推入、弹出，也可以快速拿到栈顶对象。当然，所有的修改都只在本线程可见。和 Local 一样，LocalStack 也同样实现了支持 release_pool 的接口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class LocalStack(object): def __init__(self): self._local = Local() def __release_local__(self): self._local.__release_local__() def _get__ident_func__(self): return self._local.__ident_func__ def _set__ident_func__(self, value): object.__setattr__(self._local, &#x27;__ident_func__&#x27;, value) __ident_func__ = property(_get__ident_func__, _set__ident_func__) del _get__ident_func__, _set__ident_func__ def __call__(self): def _lookup(): rv = self.top if rv is None: raise RuntimeError(&#x27;object unbound&#x27;) return rv return LocalProxy(_lookup) def push(self, obj): &quot;&quot;&quot;Pushes a new item to the stack&quot;&quot;&quot; rv = getattr(self._local, &#x27;stack&#x27;, None) if rv is None: self._local.stack = rv = [] rv.append(obj) return rv def pop(self): &quot;&quot;&quot;Removes the topmost item from the stack, will return the old value or `None` if the stack was already empty. &quot;&quot;&quot; stack = getattr(self._local, &#x27;stack&#x27;, None) if stack is None: return None elif len(stack) == 1: release_local(self._local) return stack[-1] else: return stack.pop() @property def top(self): &quot;&quot;&quot;The topmost item on the stack. If the stack is empty, `None` is returned. &quot;&quot;&quot; try: return self._local.stack[-1] except (AttributeError, IndexError): return None 5.3 LocalProxyLocalProxy用于代理Local对象和LocalStack对象 LocalProxy 则是一个典型的代理模式实现，它在构造时接受一个 callable 的参数（比如一个函数），这个参数被调用后的返回值本身应该是一个 Thread Local 对象。对一个 LocalProxy 对象的所有操作，包括属性访问、方法调用（当然方法调用就是属性访问）甚至是二元操作 [6] 都会转发到那个 callable 参数返回的 Thread Local 对象上。 LocalProxy 的一个使用场景是 LocalStack 的 __call__ 方法。比如 my_local_stack 是一个 LocalStack 实例，那么 my_local_stack() 能返回一个 LocalProxy 对象，这个对象始终指向 my_local_stack 的栈顶元素。如果栈顶元素不存在，访问这个 LocalProxy 的时候会抛出 RuntimeError。 5.3.1 使用LocalProxy初始化LocalProxy的三种方式： 1）通过Local或LocalStack对象的__call__方法 1234567from werkzeug.local import Local, LocalStack_local = Local()request = _local(&#x27;request&#x27;) # 调用__call___response_local = LocalStack()response = _response_local() # 调用__call__ 1) 通过LocalProxy类初始化 12_local = Local()request = LocalProxy(_local, &#x27;request&#x27;) 3) 使用callable对象参数 1request = LocalProxy(get_current_request()) 5.3.2 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class LocalProxy(object): __slots__ = (&#x27;__local&#x27;, &#x27;__dict__&#x27;, &#x27;__name__&#x27;) def __init__(self, local, name=None): object.__setattr__(self, &#x27;_LocalProxy__local&#x27;, local) object.__setattr__(self, &#x27;__name__&#x27;, name) def _get_current_object(self): &quot;&quot;&quot;Return the current object. This is useful if you want the real object behind the proxy at a time for performance reasons or because you want to pass the object into a different context. &quot;&quot;&quot; if not hasattr(self.__local, &#x27;__release_local__&#x27;): return self.__local() try: return getattr(self.__local, self.__name__) except AttributeError: raise RuntimeError(&#x27;no object bound to %s&#x27; % self.__name__) @property def __dict__(self): try: return self._get_current_object().__dict__ except RuntimeError: raise AttributeError(&#x27;__dict__&#x27;) def __repr__(self): try: obj = self._get_current_object() except RuntimeError: return &#x27;&lt;%s unbound&gt;&#x27; % self.__class__.__name__ return repr(obj) def __bool__(self): try: return bool(self._get_current_object()) except RuntimeError: return False def __unicode__(self): try: return unicode(self._get_current_object()) # noqa except RuntimeError: return repr(self) def __dir__(self): try: return dir(self._get_current_object()) except RuntimeError: return [] def __getattr__(self, name): if name == &#x27;__members__&#x27;: return dir(self._get_current_object()) return getattr(self._get_current_object(), name) def __setitem__(self, key, value): self._get_current_object()[key] = value def __delitem__(self, key): del self._get_current_object()[key] # ... _get_current_object(): 获取真正的对象，而不是代理的对象 5.3.3 为什么要使用LocalProxy12345678910111213from werkzeug.local import LocalStack, LocalProxystack = LocalStack()stack.push(&#123;&#x27;name&#x27;: &#x27;Jack&#x27;&#125;)stack.push(&#123;&#x27;name&#x27;: &#x27;Tom&#x27;&#125;)def get_user(): return stack.pop()#user = get_user()user = LocalProxy(get_user)print(user[&#x27;name&#x27;])print(user[&#x27;name&#x27;]) LocalProxy: 动态自动获取适合对象。每次 user[&#39;name&#39;] 的时候 就会触发 LocalProxy 类的 __getitem__ ，从而调用该类的_get_current_object 。而每次_get_current_object 都会返回 get_user() 的执行结果， 也就是 user_stack.pop() 5.4 上下文定义1234567891011121314151617181920212223242526272829# context locals_request_ctx_stack = LocalStack()_app_ctx_stack = LocalStack()current_app = LocalProxy(_find_app)request = LocalProxy(partial(_lookup_req_object, &#x27;request&#x27;))session = LocalProxy(partial(_lookup_req_object, &#x27;session&#x27;))g = LocalProxy(partial(_lookup_app_object, &#x27;g&#x27;))def _find_app(): top = _app_ctx_stack.top if top is None: raise RuntimeError(_app_ctx_err_msg) return top.app@propertydef top(self): &quot;&quot;&quot;The topmost item on the stack. If the stack is empty, `None` is returned. &quot;&quot;&quot; try: return self._local.stack[-1] except (AttributeError, IndexError): return None def _lookup_req_object(name): top = _request_ctx_stack.top if top is None: raise RuntimeError(_request_ctx_err_msg) return getattr(top, name) 5.5 基于 Local Stack 的 Context1) 未入栈 123456789101112from flask import Flaskfrom flask.globals import _app_ctx_stack, _request_ctx_stackapp = Flask(__name__)_app_ctx_stack.top # None_request_ctx_stack.top # None_app_ctx_stack() # &lt;LocalProxy unbound&gt;from flask import current_appcurrent_app # &lt;LocalProxy unbound&gt; 2) 推入栈中 12345678910ctx = app.app_context()ctx.push()_app_ctx_stack.top # &lt;flask.ctx.AppContext at 0x10801ad30&gt;_app_ctx_stack.top is ctx # Truecurrent_app # &lt;Flask &#x27;__main__&#x27;&gt;ctx.pop()_app_ctx_stack.top # Nonecurrent_app # &lt;LocalProxy unbound&gt; 5.6 多个Flask App组合成一个WSGI Application1234567from werkzeug.wsgi import DispatcherMiddlewarefrom embo.app import create_appfrom embo.admin.app import create_app as create_admin_appapplication = DispatcherMiddleware(create_app(), &#123; &#x27;/admin&#x27;: create_admin_app()&#125;) 1) 离线环境下 1234567891011from embo.app import create_appfrom embo.admin.app import create_app as create_admin_appapp = create_app()admin_app = create_admin_app()def copy_data(): with app.app_context(): data = read_data() with admin_app.app_context(): write_data(data) 2) 测试环境下 12345def test_app(): app = create_app() client = app.test_client() resp = client.get(&#x27;/&#x27;) assert &#x27;Home&#x27; in resp.data 6. 其他问题6. 1 flask上下文管理的三个阶段 请求刚进来，将request和session封装在RequestContext类中，app和g封装在AppContext中，并通过LocalStack将RequestContext和AppContext放入Local类中 在视图函数中，通过LocalProxy –&gt; 偏函数_lookup_req_object –&gt; LocalStack –&gt; Local取值 请求响应时，先执行save.session()，再各自执行pop()，将Local中的数据清除 6.2 session什么时候创建，什么时候销毁？ 当请求进来时，会将request和session封装为RequestContext对象，通过LocalStack将其放入Local对象中。 第一次请求的session为空值，所以执行open_session，并session(uuid4())赋值，再通过视图函数处理，请求响应时执行save.session，将签名session写入到cookie中，再将Local中的数据pop掉 6.3 flask中一个有几个LocalStack和Local 两个LocalStack和两个Local request和session公用一个LocalStack和Local g和app共用一个LocalStack和Local 6.4 为什么把请求放入RequestContext？ctx = RequestContext(request, session) request和session都是在视图中频繁操作的数据，也是用户请求需要的数据，将request和session封装在RequestContext中top，pop一次就可以完成，而单独不封装就会多次操作 6.5 Local和LocalStack的作用Local：存储RequestContext和AppContext self.__storage__[ident][name] = value LocalStack: 将Local对象数据维护成栈（FILO） self._local.stack = [ctx, ctx, ...] local.__storage__[ident] = &#123;&#39;stack&#39;: [ctx, ctx, ...]&#125; 6.6 current_app和g的差异 current_app: 当前运行程序的程序实例 g: 处理请求时，用于临时存储的对象，每次请求都会重设这个变量","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 集成命令行","slug":"Flask 集成命令行","date":"2017-03-10T05:57:19.000Z","updated":"2021-06-22T10:50:49.699Z","comments":true,"path":"2017/03/10/Flask 集成命令行/","link":"","permalink":"https://elihe2011.github.io/2017/03/10/Flask%20%E9%9B%86%E6%88%90%E5%91%BD%E4%BB%A4%E8%A1%8C/","excerpt":"1. Flask-Script1.1 创建命令行的三种方式 @manager.command @manager.option(‘-n’, ‘–name’, dest=’name’) class Hello(Command): def run(self) 1234567891011121314151617181920212223242526272829from flask_script import Manager, Command, Optionfrom hello import appmanager = Manager(app)@manager.commanddef foo(): print &#x27;foo&#x27;@manager.option(&#x27;-h&#x27;, &#x27;--hostname&#x27;, dest=&#x27;host&#x27;, default=&#x27;localhost&#x27;)@manager.option(&#x27;-p&#x27;, &#x27;--port&#x27;, dest=&#x27;port&#x27;, default=&#x27;3306&#x27;)def mysql(host, port): print &#x27;%s:%s&#x27; % (host, port)class Bar(Command): option_list = ( Option(&#x27;-n&#x27;, &#x27;--name&#x27;, dest=&#x27;name&#x27;), ) def get_option(self): return [Option(&#x27;-n&#x27;, &#x27;--name&#x27;, dest=&#x27;name&#x27;)] def run(self, name): print &#x27;hello&#x27;, namemanager.add_command(&#x27;bar&#x27;, Bar())if __name__ == &#x27;__main__&#x27;: manager.run()","text":"1. Flask-Script1.1 创建命令行的三种方式 @manager.command @manager.option(‘-n’, ‘–name’, dest=’name’) class Hello(Command): def run(self) 1234567891011121314151617181920212223242526272829from flask_script import Manager, Command, Optionfrom hello import appmanager = Manager(app)@manager.commanddef foo(): print &#x27;foo&#x27;@manager.option(&#x27;-h&#x27;, &#x27;--hostname&#x27;, dest=&#x27;host&#x27;, default=&#x27;localhost&#x27;)@manager.option(&#x27;-p&#x27;, &#x27;--port&#x27;, dest=&#x27;port&#x27;, default=&#x27;3306&#x27;)def mysql(host, port): print &#x27;%s:%s&#x27; % (host, port)class Bar(Command): option_list = ( Option(&#x27;-n&#x27;, &#x27;--name&#x27;, dest=&#x27;name&#x27;), ) def get_option(self): return [Option(&#x27;-n&#x27;, &#x27;--name&#x27;, dest=&#x27;name&#x27;)] def run(self, name): print &#x27;hello&#x27;, namemanager.add_command(&#x27;bar&#x27;, Bar())if __name__ == &#x27;__main__&#x27;: manager.run() 12345678910$ python manage.pyusage: manage.py [-?] &#123;foo,mysql,bar,shell,runserver&#125; ...positional arguments: &#123;foo,mysql,bar,shell,runserver&#125; foo mysql bar shell Runs a Python shell inside Flask application context. runserver Runs the Flask development server i.e. app.run() 1.2 集成Python Shell1234def make_shell_context(): return dict(app=app, db=db, User=User, Role=Role) manager.add_command(&#x27;shell&#x27;, Shell(make_context=make_shell_context)) 1.3 数据库迁移12345from flask_migrate import Migrate, MigrateCommandmigrate = Migrate(app, db)manager.add_command(&#x27;db&#x27;, MigrateCommand) # MigrateCommand 集成alembic相关数据库操作方法 迁移命令： 12345678# 创建迁移仓库python manage.py db init# 创建迁移脚本python manage.py db migrate -m &#x27;v0.1&#x27;# 更新数据库python manage.py db upgrade 1.4 初始化数据库1234@manager.commanddef initdb(): with app.app_context(): db.create_all() 1.5 自定义启动参数1234567from flask_socketio import SocketIOsocketio = SocketIO()@manager.commanddef run(): socketio.run(app, host=&#x27;0.0.0.0&#x27;, port=5000, debug=True) 2. Flask-Cli2.1 命令差异对比Flask-Script =&gt; Flask-Cli 123python manage.py runserver --&gt; flask runpython manage.py shell --&gt; flask shellpython manage.py db --&gt; flask db 2.2 manage.py (flask-script)12345678910111213141516171819202122232425262728293031323334import osimport sysCOV = Noneif os.environ.get(&#x27;FLASK_COVERAGE&#x27;): import coverage COV = coverage.coverage(branch=True, include=&#x27;app/*&#x27;) COV.start()from flask_script import Manager, Shellfrom flask_migrate import Migrate, MigrateCommandfrom app import create_app, dbfrom app.models import User, Roleapp = create_app(os.getenv(&#x27;FLASK_CONFIG&#x27;) or &#x27;default&#x27;)migrate = Migrate(app, db)manager = Manager(app)def make_shell_context(): return dict(db=db, User=User, Role=Role)@manager.commanddef test(coverage=False): ...manager.add_command(&#x27;shell&#x27;, Shell(make_context=make_shell_context))manager.add_command(&#x27;db&#x27;, MigrateCommand)if __name__ == &#x27;__main__&#x27;: manager.run() 2.3 myflask.py (flask-cli)123export FLASK_APP=myflask.pyexport FLASK_DEBUG=1 1234567891011121314151617181920212223242526272829import osimport sysCOV = Noneif os.environ.get(&#x27;FLASK_COVERAGE&#x27;): import coverage COV = coverage.coverage(branch=True, include=&#x27;app/*&#x27;) COV.start()import clickfrom flask_migrate import Migrate, MigrateCommandfrom app import create_app, dbfrom app.models import User, Roleapp = create_app(os.getenv(&#x27;FLASK_CONFIG&#x27;) or &#x27;default&#x27;)migrate = Migrate(app, db)@app.shell_context_processordef make_shell_context(): return dict(db=db, User=User, Role=Role)@app.cli.command()@click.option(&#x27;--coverage/--no-coverage&#x27;, default=False, help=&#x27;Run tests under code coverage.&#x27;)def test(coverage): ...","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask SQLAlchemy","slug":"Flask SQLAlchemy","date":"2017-03-08T03:36:33.000Z","updated":"2021-06-22T10:50:49.698Z","comments":true,"path":"2017/03/08/Flask SQLAlchemy/","link":"","permalink":"https://elihe2011.github.io/2017/03/08/Flask%20SQLAlchemy/","excerpt":"1. SQLAlchemy1.1 连接数据库123456789101112from sqlalchemy import create_engineengine = create_engine(&#x27;dialect+driver://...&#x27;, echo=False) # echo=True, 打印SQL# pymysqlengine = create_engine(&#x27;mysql+pymysql://root@localhost:3306/test&#x27;)# mysqlconnectorengine = create_engine(&#x27;mysql+mysqlconnector://root@localhost:3306/test&#x27;)# MySQLdbengine = create_engine(&#x27;mysql://root@localhost:3306/test&#x27;)","text":"1. SQLAlchemy1.1 连接数据库123456789101112from sqlalchemy import create_engineengine = create_engine(&#x27;dialect+driver://...&#x27;, echo=False) # echo=True, 打印SQL# pymysqlengine = create_engine(&#x27;mysql+pymysql://root@localhost:3306/test&#x27;)# mysqlconnectorengine = create_engine(&#x27;mysql+mysqlconnector://root@localhost:3306/test&#x27;)# MySQLdbengine = create_engine(&#x27;mysql://root@localhost:3306/test&#x27;) 1.2 声明ORM映射12345678from sqlalchemy.ext.declarative import declarative_baseBase = declarative_base(engine)from sqlalchemy import Column, Integer, Stringclass User(Base): __tablename__ = &#x27;users&#x27; id = Column(Integer, primary_key=True) name = Column(String(64), nullable=False) 1.3 创建表结构12345User.__table__# 创建表结构Base.metadata.drop_all()Base.metadata.create_all() 1.4 创建Session1234567891011121314151617181920212223from sqlalchemy.orm import sessionmaker, scoped_sessionsession_factory = sessionmaker(bind=engine)Session = scoped_session(session_factory)session = Session()# 1. session工厂Session = sessionmaker(bind=engine)s1 = Session()s2 = Session()s1 is s2 # False# 2. scoped_session 线程安全## scoped_session 采用Registry模式，默认从ThreadLocalRegistry中获取，如果存在直接返回，不存在则创建session_factory = sessionmaker(bind=engine)Session = scoped_session(session_factory)s1 = Session()s2 = Session()s1 is s2 # TrueSession.remove()s3 = Session()s1 is s3 # False Normal session和Scoped session 1234567891011121314151617from sqlalchemy import create_enginefrom sqlalchemy import Column, String, Integer, ForeignKeyfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, scoped_sessionDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI)Base = declarative_base(engine)Session = sessionmaker(engine)class User(Base): __tablename__ = &#x27;users&#x27; id = Column(Integer, primary_key=True) name = Column(String(20))Base.metadata.create_all() 1234567891011121314151617from session import Session, User, scoped_sessionuser = User(name=&#x27;alex&#x27;)s1 = Session()s2 = Session()id(s1), id(s2) # (22567344, 22728784)s1.add(user)s2.add(user) # InvalidRequestError: Object &#x27;&lt;User at 0x1585630&gt;&#x27; is already attached to session &#x27;1&#x27; (this is &#x27;2&#x27;)session = scoped_session(Session)s3 = session()s4 = session()id(s3), id(s4) # (22691408, 22691408)user2 = User(name=&#x27;nana&#x27;)s3.add(user2)s4.add(user2) If you have two objects of normal session (created using sessionmaker()) instead of scoped session, then on calling db.session.add(entry) above code will raise error sqlalchemy.exc.InvalidRequestError: Object ‘’ is already attached to session ‘2’ (this is ‘3’). For more understanding about sqlalchemy session, read below section 1.5 添加或更新ORM对象123456789user = User(name=&#x27;john&#x27;)session.add(user)session.commit()for _ in range(100): name = &#x27;&#x27;.join([random.choice(string.ascii_lowercase + string.uppercase) for _ in range(5)]) session.add(User(name=name))session.commit() 1.6 执行原生SQL1234567with engine.connect() as conn: conn.execute(&#x27;create table xxx...&#x27;) conn.execute(&#x27;insert into...&#x27;) results = conn.execute(&#x27;select * from xx&#x27;) for result in results: print(result) 1.7 查询SQLAlchemy过滤器: filter() filter_by() limit() offset() order_by() group_by() 1234567891011121314# SQL expressionsUser.query.filter(User.name==&#x27;alex&#x27;)# Keyword expressionsUser.query.filter_by(name=&#x27;alex&#x27;)# 组合查询User.query.filter(User.age=10).filter(User.grade=4) User.query.filter_by(age=10, grade=4)# 分页 (不需要跟随all, first等查询执行函数)query = db.session.query(User).filter_by(age=10))query.limit(page_size).offset((page_index-1)*page_size)query.slice((page_index-1)*page_size, page_index*page_size) SQLAlchemy查询执行函数: 1234567all()first()first_or_404()get() # 根据id查询get_or_404()count()pagenate() 1.7.1 Query对象(可generative)1234567891011# 查询对象for user in session.query(User): print(user) # 查询部分字段for name, age in session.query(User.name, User.age): print(name, age) # LIMIT ? OFFSET ?for user in session.query(User)[10:5]: print(user) 1.7.2 filter操作符123456789101112131415161718192021222324252627282930313233# equalssession.query(User).filter(User.name==&#x27;john&#x27;)# not equalssession.query(User).filter(User.name!=&#x27;john&#x27;)# likesession.query(User).filter(User.name.like(&#x27;N%&#x27;))# insession.query(User).filter(User.name.in_([&#x27;john&#x27;, &#x27;tom&#x27;, &#x27;jack&#x27;]))session.query(User).filter(User.name.in_(session.query(User.name).filter(User.name.like(&#x27;N%&#x27;))))# not insession.query(User).filter(~User.name.in_([&#x27;john&#x27;, &#x27;tom&#x27;, &#x27;jack&#x27;]))# is NULLsession.query(User).filter(User.role==None)# is NOT NULLsession.query(User).filter(User.role!=None)# andsession.query(User).filter(User.age&lt;20, User.email.like(&#x27;%@gmail.com&#x27;))session.query(User).filter(User.age&lt;20).filter(User.email.like(&#x27;%@gmail.com&#x27;))from sqlalchemy import and_, or_session.query(User).filter(_and(User.age&lt;20, User.email.like(&#x27;%@gmail.com&#x27;)))# orsession.query(User).filter(or_(User.age&lt;20, User.age&gt;100)) 1.7.3 返回值 list/scalar12345678910111213all()first()one() # 只能有一个结果，否则抛出异常one_or_none()scalar() # 返回单项，而不是tuplesession.query(User.name, User.age).filter(User.id==1).one()(u&#x27;john&#x27;, 17)session.query(User.name, User.age).filter(User.id==1).scalar()# u&#x27;john&#x27; 1.7.4 嵌入SQL12345678910from sqlalchemy import text# 直接组织条件session.query(User).filter(text(&#x27;age&gt;20 and age&lt;39&#x27;))# 带参数session.query(User).filter(text(&#x27;age&gt;:age and email like :email&#x27;)).params(age=100, email=&#x27;%gmail.com&#x27;)# 完整SQLsession.query(User).from_statement(text(&#x27;select * from users where name=:name&#x27;)).params(name=&#x27;john&#x27;) 1.7.5 计数Count12345678session.query(User).filter(User.name.like(&#x27;%ed%&#x27;)).count()from sqlalchemy import funcsession.query(func.count(User.name), User.name).group_by(User.name).all()# select count(*) from user;session.query(func.count(*)).select_from(User).scalar()session.query(func.count(User.id)).scalar() 1.8 关联关系SQLAlchemy关系选项 选项 说明 backref 反向引用 primaryjoin 明确指定两个模型之间使用的联结条件。只在模棱两可的关系中需要指定 lazy 指定如何加载相关记录。可选值: select: 首次访问时按需加载immediate: 源对象加 载后就加载joined: 加载记uselist order_by secondary secondaryjoin 录，但使用联结subquery: 立即加载，但使用子查询noload: 永不加载dynamic: 不加载记录，但提供加载记录的查询 uselist 如果设为 Fales，不使用列表，而使用标量值 order_by 指定关系中记录的排序方式 secondary 指定多对多关系中关系表的名字 secondaryjoin SQLAlchemy 无法自行决定时，指定多对多关系中的二级联结条件 1.8.1 relationship双向关联关系 1）backref: 反向关联 12345678910111213class Role(Base): __tablename__ = &#x27;roles&#x27; id = Column(Integer, primary_key=True) name = Column(String(36), nullable=True) users = relationship(&#x27;User&#x27;, backref=&#x27;role&#x27;)class User(Base): __tablename__ = &#x27;users&#x27; id = Column(Integer, primary_key=True) name = Column(String(36), nullable=True) age = Column(Integer) email = Column(String(64)) role_id = Column(Integer, ForeignKey(&#x27;roles.id&#x27;)) 1) back_populates：反向插入 1234567891011121314class Role(Base): __tablename__ = &#x27;roles&#x27; id = Column(Integer, primary_key=True) name = Column(String(36), nullable=True) users = relationship(&#x27;User&#x27;, back_populates=&#x27;role&#x27;) class User(Base): __tablename__ = &#x27;users&#x27; id = Column(Integer, primary_key=True) name = Column(String(36), nullable=True) age = Column(Integer) email = Column(String(64)) role_id = Column(Integer, ForeignKey(&#x27;roles.id&#x27;)) role = relationship(&#x27;Role&#x27;, back_populates=&#x27;users&#x27;) 3) 数据插入 1234567&gt;&gt;&gt; role = Role(name=&#x27;admin&#x27;)&gt;&gt;&gt; user1 = User(name=&#x27;sylvia&#x27;, age=24, email=&#x27;sylvia@gmail.com&#x27;)&gt;&gt;&gt; user2 User(name=&#x27;eli&#x27;, age=24, email=&#x27;eli@outlook.com&#x27;)&gt;&gt;&gt; role.users.append(user1)&gt;&gt;&gt; role.users.append(user2)&gt;&gt;&gt; session.add(role)&gt;&gt;&gt; session.commit() 1.8.2 join1) 隐式join 12for r, u in session.query(Role, User).filter(Role.id==User.role_id).filter(User.age&gt;25): print r, u 2) 带外键的join 123456&gt;&gt;&gt; session.query(Role).join(User).filter(User.age&gt;25).all()SELECT roles.id AS roles_id, roles.name AS roles_name FROM roles JOIN users ON roles.id = users.role_id WHERE users.age &gt; ?(25,)[&lt;Role u&#x27;admin&#x27;&gt;] 3) explicite conditions 123456&gt;&gt;&gt; session.query(Role).join(User, User.role_id==Role.id).filter(User.age&gt;25).all()SELECT roles.id AS roles_id, roles.name AS roles_name FROM roles JOIN users ON users.role_id = roles.id WHERE users.age &gt; ?(25,)[&lt;Role u&#x27;admin&#x27;&gt;] 4) specify relationship from left to right 123456&gt;&gt;&gt; session.query(Role).join(Role.users).filter(User.age&gt;25).all()SELECT roles.id AS roles_id, roles.name AS roles_name FROM roles JOIN users ON roles.id = users.role_id WHERE users.age &gt; ?(25,)[&lt;Role u&#x27;admin&#x27;&gt;] 5) same, with explicit target 123456&gt;&gt;&gt; session.query(Role).join(User, Role.users).filter(User.age&gt;25).all()SELECT roles.id AS roles_id, roles.name AS roles_name FROM roles JOIN users ON roles.id = users.role_id WHERE users.age &gt; ? (25,)[&lt;Role u&#x27;admin&#x27;&gt;] 6) 直接join表名 123456&gt;&gt;&gt; session.query(Role).join(&#x27;users&#x27;).filter(User.age&gt;25).all()SELECT roles.id AS roles_id, roles.name AS roles_name FROM roles JOIN users ON roles.id = users.role_id WHERE users.age &gt; ?(25,)[&lt;Role u&#x27;admin&#x27;&gt;] 1.9 子查询1.9.1 基本子查询12345678910111213&gt;&gt;&gt; stmt = session.query(User.role_id, func.count(&#x27;*&#x27;).label(&#x27;user_count&#x27;)).group_by(User.role_id).subquery()&gt;&gt;&gt; for r, count in session.query(Role, stmt.c.user_count).\\... outerjoin(stmt, Role.id==stmt.c.role_id).order_by(Role.id):... print r, count... SELECT roles.id AS roles_id, roles.name AS roles_name, anon_1.user_count AS anon_1_user_count FROM roles LEFT OUTER JOIN (SELECT users.role_id AS role_id, count(?) AS user_count FROM users GROUP BY users.role_id) AS anon_1 ON roles.id = anon_1.role_id ORDER BY roles.id(&#x27;*&#x27;,)&lt;Role u&#x27;admin&#x27;&gt; 2&lt;Role u&#x27;staff&#x27;&gt; 3&gt;&gt;&gt; 1.9.2 从子查询中取出Entity1234567891011121314&gt;&gt;&gt; from sqlalchemy.orm rt aliased&gt;&gt;&gt; stmt = session.query(User).filter(User.age&gt;30).subquery()&gt;&gt;&gt; user_alias = aliased(User, stmt)&gt;&gt;&gt; for role, user in session.query(Role, user_alias).join(user_alias, Role.users):... print role, user... SELECT roles.id AS roles_id, roles.name AS roles_name, anon_1.id AS anon_1_id, anon_1.name AS anon_1_name, anon_1.age AS anon_1_age, anon_1.email AS anon_1_email, anon_1.role_id AS anon_1_role_id FROM roles JOIN (SELECT users.id AS id, users.name AS name, users.age AS age, users.email AS email, users.role_id AS role_id FROM users WHERE users.age &gt; ?) AS anon_1 ON roles.id = anon_1.role_id(30,)&lt;Role u&#x27;staff&#x27;&gt; &lt;User u&#x27;jack&#x27;&gt;&lt;Role u&#x27;staff&#x27;&gt; &lt;User u&#x27;tom&#x27;&gt; 1.9.3 使用EXISTS12345678910111213&gt;&gt;&gt; from sqlalchemy.sql import exists&gt;&gt;&gt; stmt = exists().where(User.role_id==Role.id)&gt;&gt;&gt; for name in session.query(Role.name).filter(stmt):... print name... SELECT roles.name AS roles_name FROM roles WHERE EXISTS (SELECT * FROM users WHERE users.role_id = roles.id)(u&#x27;admin&#x27;,)(u&#x27;staff&#x27;,) 1.9.4 realtionship.any() 关系存在1234567891011121314151617181920212223&gt;&gt;&gt; for name in session.query(Role.name).filter(Role.users.any()):... print name... SELECT roles.name AS roles_name FROM roles WHERE EXISTS (SELECT 1 FROM users WHERE roles.id = users.role_id)(u&#x27;admin&#x27;,)(u&#x27;staff&#x27;,)# any中带条件&gt;&gt;&gt; for name in session.query(Role.name).filter(Role.users.any(User.age&lt;25)):... print name... SELECT roles.name AS roles_name FROM roles WHERE EXISTS (SELECT 1 FROM users WHERE roles.id = users.role_id AND users.age &lt; ?)(25,)(u&#x27;admin&#x27;,) 1.9.5 realtionship.has() 关系存在, many-to-one关系12345678&gt;&gt;&gt; session.query(User).filter(User.role.has(Role.name==&#x27;moderator&#x27;)).all()SELECT users.id AS users_id, users.name AS users_name, users.age AS users_age, users.email AS users_email, users.role_id AS users_role_id FROM users WHERE EXISTS (SELECT 1 FROM roles WHERE roles.id = users.role_id AND roles.name = ?)(&#x27;moderator&#x27;,)[] 1.9.6 查询部分字端1.9.6.1 BaseQuery (Flask-SQLAlchemy)12345678# 查询制定的id列result = RiskDataModel.query.with_entities(RiskDataModel.id) # 返回指定的两列result = RiskDataModel.query.with_entities(RiskDataModel.id, RiskDataModel.name) # 并且去重result = RiskDataModel.query.with_entities(RiskDataModel.store_st_id).distinct().all() 1.9.6.2 Simple Query12345session.query(Tag).distinct(Tag.name)# SELECT DISTINCT tag.id AS tag_id, tag.name AS tag_name FROM tagsess.query(Tag.name).distinct()# SELECT DISTINCT tag.name AS tag_name FROM tag 1.10 Events1.10.1 Attribute Events123append(target, value, initiator) # add后，commit前bulk_replace(target, values, initiator)set(target, value, oldvalue, initiator) # commit后, insert时，也会触发 12345678910@event.listens_for(Role.users, &#x27;append&#x27;)def role_users_added(target, value, initiator): print(&#x27;receive append event from %r&#x27; % target)@event.listens_for(User.role_id, &#x27;set&#x27;)def user_role_changed(target, value, oldvalue, initiator): print(&#x27;receive set event from %r&#x27; % target) print(&#x27;value=%s&#x27; % value) print(&#x27;oldvalue=%s&#x27; % oldvalue) 1.10.2 Mapper Events123after_insert(mapper, connection, target)after_update(mapper, connection, target)after_delete(mapper, connection, target) 12345678910111213@event.listens_for(User, &#x27;after_insert&#x27;)def after_insert(mapper, connection, target): print(&#x27;receive &quot;after_insert&quot; event from %r&#x27; % target)@event.listens_for(User, &#x27;after_update&#x27;)def after_update(mapper, connection, target): print(&#x27;receive &quot;after_update&quot; event from %r&#x27; % target)@event.listens_for(User, &#x27;after_delete&#x27;)def after_update(mapper, connection, target): print(&#x27;receive &quot;after_delete&quot; event from %r&#x27; % target) 1.10.3 Session Events123456# Query.update() method is a “bulk” operation, “after_update”失效，可改用下列方法after_bulk_update(update_context)after_bulk_delete(delete_context)after_commit(session)after_rollback(session) 123@event.listens_for(db.session, &#x27;after_bulk_update&#x27;)def receive_after_bulk_update(update_context): print(&#x27;receive &quot;after_bulk_update&quot; event from %r&#x27; % update_context) 1.11 表关系外键说明 RESTRICT：子表未删，父表数据无法删除。默认值 NO ACTION: MySQL 同RESTRICT CASCADE：级联删除 SET NULL: 父表数据被删除，子表数据设置为NULL 123456789101112131415class User(Base): __tablename__ = &#x27;user&#x27; id = Column(Integer, primary_key=True, autoincrement=True) username = Column(String(50), nullable=False)class Article(Base): __tablename__ = &#x27;article&#x27; id = Column(Integer, primary_key=True, autoincrement=True) title = Column(String(50), nullable=False) content = Column(Text, nullable=False) uid = Column(Integer, ForeignKey(&#x27;user.id&#x27;)) def __repr__(self): return &#x27;&lt;Article(title:%s)&gt;&#x27; % self.title 1.11.1 一对多：1) 使用back_populates 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# -*- coding: utf-8 -*-from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKeyfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationshipDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI, echo=True)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)class Address(Base): __tablename__ = &#x27;address&#x27; id = Column(Integer, primary_key=True, autoincrement=True) email = Column(String(50), nullable=False) user_id = Column(Integer, ForeignKey(&#x27;user.id&#x27;)) user = relationship(&#x27;User&#x27;, back_populates=&#x27;addresses&#x27;) def __repr__(self): return &#x27;&lt;Address(email:%s)&gt;&#x27; % self.emailclass User(Base): __tablename__ = &#x27;user&#x27; id = Column(Integer, primary_key=True, autoincrement=True) name = Column(String(50), nullable=False) fullname = Column(String(100)) password = Column(String(64)) addresses = relationship(&#x27;Address&#x27;, order_by=Address.id, back_populates=&#x27;user&#x27;)if __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() # One2Many jack = User(name=&#x27;jack&#x27;, fullname=&#x27;Jack Ma&#x27;, password=&#x27;123456&#x27;) jack.addresses = [Address(email=&#x27;jack@abc.com&#x27;), Address(email=&#x27;jack@gmail.com&#x27;)] session.add(jack) session.commit() # Many2One addr1 = Address(email=&#x27;john@foxmail.com&#x27;) addr2 = Address(email=&#x27;john@outlook.com&#x27;) user = User(name=&#x27;john&#x27;, fullname=&#x27;John Smith&#x27;, password=&#x27;qazxsw&#x27;) addr1.user = user addr2.user = user session.add_all([addr1, addr2]) session.commit() 2) 使用backref 12345678910111213141516171819202122232425262728293031323334353637383940414243# -*- coding: utf-8 -*-from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKeyfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationshipDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI, echo=True)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)class Address(Base): __tablename__ = &#x27;address&#x27; id = Column(Integer, primary_key=True, autoincrement=True) email = Column(String(50), nullable=False) user_id = Column(Integer, ForeignKey(&#x27;user.id&#x27;)) def __repr__(self): return &#x27;&lt;Address(email:%s)&gt;&#x27; % self.emailclass User(Base): __tablename__ = &#x27;user&#x27; id = Column(Integer, primary_key=True, autoincrement=True) name = Column(String(50), nullable=False) fullname = Column(String(100)) password = Column(String(64)) addresses = relationship(&#x27;Address&#x27;, backref=&#x27;user&#x27;)if __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() # One2Many jack = User(name=&#x27;jack&#x27;, fullname=&#x27;Jack Ma&#x27;, password=&#x27;123456&#x27;) jack.addresses = [Address(email=&#x27;jack@abc.com&#x27;), Address(email=&#x27;jack@gmail.com&#x27;)] session.add(jack) session.commit() 1.11.2 一对一1) 使用back_populates, uselist=False 1234567891011121314151617181920212223242526272829303132333435363738394041424344from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKeyfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationshipDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI, echo=True)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)class Address(Base): __tablename__ = &#x27;address&#x27; id = Column(Integer, primary_key=True, autoincrement=True) email = Column(String(50), nullable=False) user_id = Column(Integer, ForeignKey(&#x27;user.id&#x27;)) user = relationship(&#x27;User&#x27;, back_populates=&#x27;addresses&#x27;) def __repr__(self): return &#x27;&lt;Address(email:%s)&gt;&#x27; % self.emailclass User(Base): __tablename__ = &#x27;user&#x27; id = Column(Integer, primary_key=True, autoincrement=True) name = Column(String(50), nullable=False) fullname = Column(String(100)) password = Column(String(64)) address = relationship(&#x27;Address&#x27;, back_populates=&#x27;user&#x27;, uselist=False)if __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() # One2One jack = User(name=&#x27;jack&#x27;, fullname=&#x27;Jack Ma&#x27;, password=&#x27;123456&#x27;) jack.address = Address(email=&#x27;jack@abc.com&#x27;) session.add(jack) session.commit() 2) 使用** backref, uselist=False** 1234567891011121314151617181920212223242526272829303132333435363738394041# -*- coding: utf-8 -*-from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKeyfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationship, backrefDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI, echo=True)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)class Address(Base): __tablename__ = &#x27;address&#x27; id = Column(Integer, primary_key=True, autoincrement=True) email = Column(String(50), nullable=False) user_id = Column(Integer, ForeignKey(&#x27;user.id&#x27;))class User(Base): __tablename__ = &#x27;user&#x27; id = Column(Integer, primary_key=True, autoincrement=True) name = Column(String(50), nullable=False) fullname = Column(String(100)) password = Column(String(64)) #address = relationship(&#x27;Address&#x27;, backref=backref(&#x27;user&#x27;, uselist=False), uselist=False) address = relationship(&#x27;Address&#x27;, backref=&#x27;user&#x27;, uselist=False) if __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() # One2One jack = User(name=&#x27;jack&#x27;, fullname=&#x27;Jack Ma&#x27;, password=&#x27;123456&#x27;) jack.address = Address(email=&#x27;jack@abc.com&#x27;) session.add(jack) session.commit() 1.11.3 多对多1) 使用back_populates 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKey, Tablefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationshipDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI, echo=True)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)association_table = Table(&#x27;teachers_classes&#x27;, Base.metadata, Column(&#x27;teacher_id&#x27;, Integer, ForeignKey(&#x27;teacher.id&#x27;)), Column(&#x27;class_id&#x27;, Integer, ForeignKey(&#x27;class.id&#x27;)))class Teacher(Base): __tablename__ = &#x27;teacher&#x27; id = Column(Integer, primary_key=True) name = Column(String(50), nullable=False) age = Column(Integer) classes = relationship(&#x27;Class&#x27;, secondary=association_table, back_populates=&#x27;teachers&#x27;)class Class(Base): __tablename__ = &#x27;class&#x27; id = Column(Integer, primary_key=True) name = Column(String(20), nullable=False) teachers = relationship(&#x27;Teacher&#x27;, secondary=association_table, back_populates=&#x27;classes&#x27;)if __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() t1 = Teacher(name=&#x27;jack&#x27;, age=32) t2 = Teacher(name=&#x27;sara&#x27;, age=40) c1 = Class(name=u&#x27;一年级二班&#x27;) c2 = Class(name=u&#x27;二年级三班&#x27;) c3 = Class(name=u&#x27;三年级一班&#x27;) # t1.classes = [c1, c3] # t2.classes = [c1, c2] # session.add_all([t1, t2]) c1.teachers = [t1, t2] c2.teachers = [t2] c3.teachers = [t1] session.add_all([c1, c2, c3]) session.commit() 2) 使用backref 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKey, Tablefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationshipDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;engine = create_engine(DB_URI, echo=True)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)association_table = Table(&#x27;teachers_classes&#x27;, Base.metadata, Column(&#x27;teacher_id&#x27;, Integer, ForeignKey(&#x27;teacher.id&#x27;)), Column(&#x27;class_id&#x27;, Integer, ForeignKey(&#x27;class.id&#x27;)))class Teacher(Base): __tablename__ = &#x27;teacher&#x27; id = Column(Integer, primary_key=True) name = Column(String(50), nullable=False) age = Column(Integer)class Class(Base): __tablename__ = &#x27;class&#x27; id = Column(Integer, primary_key=True) name = Column(String(20), nullable=False) teachers = relationship(&#x27;Teacher&#x27;, secondary=association_table, backref=&#x27;classes&#x27;)if __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() t1 = Teacher(name=&#x27;jack&#x27;, age=32) t2 = Teacher(name=&#x27;sara&#x27;, age=40) c1 = Class(name=u&#x27;一年级二班&#x27;) c2 = Class(name=u&#x27;二年级三班&#x27;) c3 = Class(name=u&#x27;三年级一班&#x27;) c1.teachers = [t1, t2] c2.teachers = [t2] c3.teachers = [t1] session.add_all([c1, c2, c3]) session.commit() 1.11.4 relationship属性总结 back_populates: 回填充，双向行为 12user = relationship(&#x27;User&#x27;, back_populates=&#x27;addresses&#x27;)address = relationship(&#x27;Address&#x27;, back_populates=&#x27;user&#x27;, uselist=False) backref: 反向引用，单边行为 1address = relationship(&#x27;Address&#x27;, backref=&#x27;user&#x27;, uselist=False) lazy：加载时机 select: 立即加载全部，默认值 joined: 两表JOIN操作时，获取所有相关对象 subquery: 和joined类似，但未在内存中加载数据，而是返回subquery对象，需要执行相应方法获取对象 dynamic：需要时再加载 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from __future__ import print_functionfrom sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, String, ForeignKey, Tablefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, relationshipDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;#engine = create_engine(DB_URI, echo=True)engine = create_engine(DB_URI)# 生成基类Base = declarative_base(bind=engine)Session = sessionmaker(bind=engine)registrations = Table(&#x27;registrations&#x27;, Base.metadata, Column(&#x27;student_id&#x27;, Integer, ForeignKey(&#x27;students.id&#x27;)), Column(&#x27;class_id&#x27;, Integer, ForeignKey(&#x27;classes.id&#x27;)))class Student(Base): __tablename__ = &#x27;students&#x27; id = Column(Integer, primary_key=True) name = Column(String(50), nullable=False) class_id = Column(Integer, ForeignKey(&#x27;classes.id&#x27;)) def __repr__(self): return &#x27;&lt;Student %r&gt;&#x27; % self.nameclass Class(Base): __tablename__ = &#x27;classes&#x27; id = Column(Integer, primary_key=True) name = Column(String(20), nullable=False) students = relationship(&#x27;Student&#x27;, backref=&#x27;classes&#x27;, lazy=&#x27;dynamic&#x27;) def __repr__(self): return &#x27;&lt;Class %r&gt;&#x27; % self.nameif __name__ == &#x27;__main__&#x27;: Base.metadata.drop_all() Base.metadata.create_all() session = Session() c = Class(name=&#x27;class 1&#x27;) c.students = [Student(name=&#x27;jack&#x27;), Student(name=&#x27;tom&#x27;), Student(name=&#x27;mike&#x27;)] session.add(c) session.commit() 1）lazy=”select” (立即加载全部，默认值) 1234567from lazy_test import Session, Student, Classsession = Session()c = session.query(Class).first()c.students# [&lt;Student u&#x27;jack&#x27;&gt;, &lt;Student u&#x27;tom&#x27;&gt;, &lt;Student u&#x27;mike&#x27;&gt;] 2）lazy=”dynamic” 只用在一对多，多对多关系中 (需要时再加载) 12345678910from lazy_test import Session, Student, Classsession = Session()c = session.query(Class).first()c.students# &lt;sqlalchemy.orm.dynamic.AppenderQuery at 0xd6b5b0&gt;c.students.all()# [&lt;Student u&#x27;jack&#x27;&gt;, &lt;Student u&#x27;tom&#x27;&gt;, &lt;Student u&#x27;mike&#x27;&gt;] 1.12. 高级查询1.12.1 group_by1session.query(User.age, func.count(User.id)).group_by(User.age).all() 1.12.2 having1session.query(User.age, func.count(User.id)).group_by(User.age).having(User.age &gt;= 18).all() 1.12.3 join12345for user, address in session.query(User, Address).filter(User.id==Address.user_id).all()for user, address in session.query(User, Address).join(Address).all()for user, address in session.query(User, Address).outerjoin(Address).all() # left outer join 1.12.4 子查询123subquery = session.query(Address.user_id.label(&#x27;user_id&#x27;), func.count(*).label(&#x27;address_count&#x27;).group_by(Address.user_id).subquery()for user, count in session.query(User, subquery.c.address_count).outerjoin(subquery, User.id==subquery.c.user_id).order_by(User.id) 1. Flask-SQLAlchemy1.1 使用Flask-SQLAlchemy插件12345678910111213141516171819202122from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyDB_URI = &#x27;mysql+pymysql://root@127.0.0.1:3306/elidb?charset=utf8mb4&#x27;app = Flask(__name__)app.config[&#x27;SQLALCHEMY_DATABASE_URI&#x27;] = DB_URIapp.config[&#x27;SQLALCHEMY_TRACK_MODIFICATIONS&#x27;] = Trueapp.config[&#x27;SQLALCHEMY_ECHO&#x27;] = True # 打印SQL#db = SQLAlchemy(app)db = SQLAlchemy()db.init_app(app)class User(db.Model): id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(20)) email = db.Column(db.String(20)) def __repr__(self): return &#x27;&lt;User %r&gt;&#x27; % self.name 123456789101112131415from flask_db import db, Userdb.create_all()admin = User(name=&#x27;admin&#x27;, email=&#x27;admin@test.com&#x27;)guest = User(name=&#x27;guest&#x27;, email=&#x27;guest@test.com&#x27;)db.session.add_all([admin, guest])db.session.commit()users = User.query.all() # [&lt;User u&#x27;admin&#x27;&gt;, &lt;User u&#x27;guest&#x27;&gt;]admin = User.query.filter_by(name=&#x27;admin&#x27;).first()db.session.delete(admin)db.session.commit() 1.2 修改数据12345678910111213db.session.query(User).filter_by(name=&#x27;admin&#x27;).update(dict(email=&#x27;admin@test.com&#x27;, synchronize_session=False) db.session.commit()from copy import deepcopyadmin = db.session.query(User).filter_by(name=&#x27;admin&#x27;).first()admin1 = deepcopy(admin)admin1.email = &#x27;admin@example.com&#x27;db.session.add(admin1)db.session.commit() # InvalidRequestErrordb.session.merge(admin1) # 正常合并数据库 Didn’t work: 1234567891011121314151617# this will throw an exception, &quot;AttributeError: &#x27;Task&#x27; object has no attribute &#x27;update&#x27;&quot;db.session.query(Task).get(id).update(&#123;&quot;state&quot;:state&#125;)db.session.commit()# this was the example in the linked SO thread:# does nothingdb.session.query(Task).filter_by(id=id).update(&#123;&quot;state&quot;:state&#125;)# this also does nothingtask = Task.query.filter_by(id=id)task.state = statedb.session.commit()# not this eithertask = Task.query.get(id)task.state = statedb.session.commit() Did work: 12345678# ok this works:db.session.query(Task).filter_by(id=id).update(&#123;&quot;state&quot;:state&#125;)db.session.commit()# and also this:task = db.session.query(Task).get(id)task.state = statedb.session.commit() 1.3 分页查询不可以再跟first(), all()等 1.3.1 offset()设置索引偏移量，limit限制取出量(filter后可跟order_by)1db.session.query(User.name).filter(User.email.like(&#x27;%&#x27;+email+&#x27;%&#x27;)).limit(page_size).offset((page_index-1)*page_size) 1.3.2 slice(start, stop)1db.session.query(User.name).filter(User.email.like(&#x27;%&#x27;+email+&#x27;%&#x27;)).slice((page_index-1)*pagesize, page_index*page_size) 1.3.3 paginate(page_index, page_size), 用于BaseQuery12basequery = User.query.filter_by(age=10)basequery.paginate(page_index, page_size, False) 12user_objs = User.query.filter(User.email.like(&#x27;%&#x27;+emai+&#x27;%&#x27;)).paginate(page_index, page_size, False)user_list = user_objs.items 1.3.4 filter中使用limit, 注意无法跟order_by语句1db.session.query(User.name).filter(User.email.like(&#x27;%&#x27;+email+&#x27;%&#x27;) and limit (page_index-1)*page_size, page_size) 1.4 join查询12345Reply.query.join(Topic, Reply.topic_id==Topic.id).all() # 只得到Reply的实例results = (db.session.query(Topic.content.label(&#x27;topic_content&#x27;), Reply.content.label(&#x27;reply_content&#x27;))).select_from(Topic, Reply).filter(Topic.id==Reply.topic_id).paginate(page, per_page)results = Reply.query.join(Topic, Reply.topic_id==Topic.id).add_entity(Topic).all() 1.5 关联关系1.5.1 一对多1234567class Role(db.Model): # ... users = db.relationship(&#x27;User&#x27;, backref=&#x27;role&#x27;)class User(db.Model): # ... role_id = db.Column(db.Integer, db.ForeignKey(&#x27;roles.id&#x27;)) relationship函数，将两表关联起来，Role拥有users属性，通过backref反向引用，User同时拥有role隐含属性 1234role = Role(name=&#x27;admin&#x27;)user = User(name=&#x27;alex&#x27;, role=role)user = User.query.filter_by(role=role).first() 禁用自动查询 1234567class Role(db.Model): # ... users = db.relationship(&#x27;User&#x27;, backref=&#x27;role&#x27;, lazy=&#x27;dynamic&#x27;)class User(db.Model): # ... role_id = db.Column(db.Integer, db.ForeignKey(&#x27;roles.id&#x27;)) 此时role.users不直接返回User信息，而是返回一个AppenderBaseQuery对象，可使用过滤器等操作 123role = Role.query.filter_by(name=&#x27;admin&#x27;).first()role.users # AppenderBaseQueryuser = role.users.filter_by(username=&#x27;alex&#x27;).first() 1.5.2 多对多，自引用关系12345678910111213141516171819class Follow(db.Model): __tablename__ = &#x27;follows&#x27; follower_id = db.Column(db.Integer, db.ForeignKey(&#x27;users.id&#x27;), primary_key=True) followed_id = db.Column(db.Integer, db.ForeignKey(&#x27;users.id&#x27;), primary_key=True) timestamp = db.Column(db.DateTime, default=datetime.utcnow) class User(db.Model, UserMixin): __tablename__ = &#x27;users&#x27; ... followed = db.relationship(&#x27;Follow&#x27;, foreign_keys=[Follow.follower_id], backref=db.backref(&#x27;follower&#x27;, lazy=&#x27;joined&#x27;), lazy=&#x27;dynamic&#x27;, cascade=&#x27;all, delete-orphan&#x27;) followers = db.relationship(&#x27;Follow&#x27;, foreign_keys=[Follow.followed_id], backref=db.backref(&#x27;followed&#x27;, lazy=&#x27;joined&#x27;), lazy=&#x27;dynamic&#x27;, cascade=&#x27;all, delete-orphan&#x27;) foreign_keys: 消除外键歧义，指定外键 db.backref: 回引Follow模型。该回引的lazy=’joined’，表示在一次数据库查询中立即从联合查询中加载相关对象。如果lazy=’select’，那么首次访问followed或follower时才加载对应的用户 lazy=’dynamic’，lazy在‘一’的一侧设置，返回的结果是‘多’的一侧的记录。dynamic：不直接返回记录，返回查询对象，该查询对象在查询时，可添加额外的过滤器 cascade：在父对象上执行操作，对相关对象的影响。all, delete_orphan: 启用所有默认层叠格式，还要删除孤儿记录 1.6 联表查询1234567def followed_posts(self): return db.session.query(Post).select_from(Follow).\\ filter_by(follower_id=self.id).\\ join(Post, Follow.followed_id == Post.author_id) return Post.query.join(Follow, Follow.followed_id == Post.author_id) \\ .filter(Follow.follower_id == self.id) 1.7 SQLAlchemy监听123456789101112131415161718class Comment(db.Model): __tablename__ = &#x27;comments&#x27; id = db.Column(db.Integer, primary_key=True) body = db.Column(db.Text) body_html = db.Column(db.Text) timestamp = db.Column(db.DateTime, index=True, default=datetime.utcnow) disabled = db.Column(db.Boolean) author_id = db.Column(db.Integer, db.ForeignKey(&#x27;users.id&#x27;)) post_id = db.Column(db.Integer, db.ForeignKey(&#x27;posts.id&#x27;)) @staticmethod def on_changed_body(target, value, oldvalue, initiator): allowed_tags = [&#x27;a&#x27;, &#x27;addr&#x27;, &#x27;acronym&#x27;, &#x27;b&#x27;, &#x27;code&#x27;, &#x27;em&#x27;, &#x27;i&#x27;, &#x27;strong&#x27;] target.body_html = bleach.linkify(bleach.clean( markdown(value, output_format=&#x27;html&#x27;), tags=allowed_tags, strip=True))db.event.listen(Comment.body, &#x27;set&#x27;, Comment.onc_change_body) 1234567891011# set事件def on_changed_status(target, value, oldvalue, initiator): handle_change(target, value) db.event.listen(Docs.updated_at, &#x27;set&#x27;, on_changed_status)# after_insert事件def after_insert(mapper, connection, target): handle_insert(target)db.event.listen(PersonalDocs, &#x27;after_insert&#x27;, after_insert) 2. Flask-SQLAlchemy2.1 SQLAlchemy和Flask-SQLAlchemy的差异Flask-SQLAlchemy 是经过封装优化的版本，与Flask结合使用比起直接使用SQLAlchemy会更加便捷高效。 2.1.1 初始化对比SQLAlchemy: 需要完成初始化数据库连接、创建基类、创建DBSession类型等工作 123456789101112from sqlalchemy import create_enginefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker#创建对象基类Base = declarative_base()#初始化数据库连接engine = create_engine(&#x27;mysql+ysqldb://username:password@host:port/dbname&#x27;)#创建DBSession类型DBSession = sessionmaker(bind=engine) Flask-SQLAlchemy: 已经把大量的工作封装好，只需要声明db变量并将db变量与flask app变量绑定即可工作 12345678from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyapp = Flask(__name__)app.config[&#x27;SQLALCHEMY_DATABASE_URI&#x27;] = &#x27;mysql+pymysql://username:password@host:port/dbname&#x27;# db = SQLAlchemy(app)app.config[&#x27;SQLALCHEMY_DATABASE_URI&#x27;] = &#x27;mysql+pymysql://username:password@host:port/dbname&#x27;db.init_app(app) 2.1.2 数据结构类型声明对比SQLAlchemy: 通过之前初始化的Base作为基类，变量声明需要从SQLAlchemy的文件中另外引入 12345678from sqlalchemy import Column, String, Integerfrom sqlalchemy.sql.sqltypes import TIMESTAMP, Date, TEXTclass Comment(Base): __tablename__ = &#x27;comment&#x27; id = Column(Integer(), primary_key = True) time = Column(TIMESTAMP) content = Column(TEXT) Flask-SQLAlchemy: 通过之前初始化的db变量获取基类和一些变量声明 123456from sqlalchemy.sql.sqltypes import TIMESTAMP, Date, TEXTclass Comment(db.Model): __tablename__ = &#x27;comment&#x27; id = db.Column(db.Integer(), primary_key = True) time = db.Column(TIMESTAMP) content = db.Column(TEXT) 2.1.3 query方式不同 sqlalchemy: query flask-sqlalchemy: basequery SQLAlchemy: 123456789session = DBSession()comment = Comment(content=&quot;this is a test&quot;)session.add(comment)session.commit()c = session.query(Comment).get(1)print(c.content)session.close() Flask-SQLAlchemy: 123456comment = Comment(content=&quot;this is a test&quot;)db.session.add(comment)db.session.commit()c = Comment.query.get(1)print(c.content) 2.2 支持分表1234567891011121314151617181920212223242526272829303132class GoodsDesc(object): _mapper = &#123;&#125; @staticmethod def model(goods_id): table_index = goods_id%100 class_name = &#x27;GoodsDesc_%d&#x27; % table_index ModelClass = GoodsDesc._mapper.get(class_name, None) if ModelClass is None: ModelClass = type(class_name, (db.Model,), &#123; &#x27;__module__&#x27; : __name__, &#x27;__name__&#x27; : class_name, &#x27;__tablename__&#x27; : &#x27;goods_desc_%d&#x27; % table_index, &#x27;goods_id&#x27; : db.Column(db.Integer, primary_key=True), &#x27;goods_desc&#x27; : db.Column(db.Text, default=None), &#125;) GoodsDesc._mapper[class_name] = ModelClass cls = ModelClass() cls.goods_id = goods_id return cls# 新增插入gdm = GoodsDesc.model(goods_id)gdm.goods_desc = &#x27;desc&#x27;db.session.add(gd)# 查询gdm = GoodsDesc.model(goods_id)gd = gdm.query.filter_by(goods_id=goods_id).first()","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 用户管理","slug":"Flask 用户管理","date":"2017-03-07T02:45:32.000Z","updated":"2021-06-22T10:50:49.698Z","comments":true,"path":"2017/03/07/Flask 用户管理/","link":"","permalink":"https://elihe2011.github.io/2017/03/07/Flask%20%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/","excerpt":"1. Werkzeug实现密码散列1234567891011121314from werkzeug.security import generate_password_hash, check_password_hashclass User(db.Model): ... @property def password(self): raise AttributeError(&#x27;password is not a readable attribute.&#x27;) @password.setter def password(self, password): self.password_hash = generate_password_hash(password) def verify_password(self, password): return check_password_hash(self.password_hash, password)","text":"1. Werkzeug实现密码散列1234567891011121314from werkzeug.security import generate_password_hash, check_password_hashclass User(db.Model): ... @property def password(self): raise AttributeError(&#x27;password is not a readable attribute.&#x27;) @password.setter def password(self, password): self.password_hash = generate_password_hash(password) def verify_password(self, password): return check_password_hash(self.password_hash, password) 2. 用户登录管理1234567891011121314151617181920212223242526272829303132333435# __init__.pyfrom flask_login import LoginManagerlogin_manager = LoginManager()login_manager.session_protection = &#x27;strong&#x27;login_manager.login_view = &#x27;auth.login&#x27;def create_app(config_name): app = Flask(__name__) app.config.from_object(config[config_name]) config[config_name].init_app(app) ... login_manager.init_app(app)#--------------------------------------------------## modles.pyfrom flask_login import UserMixinfrom . import db, login_managerclass User(db.Model, UserMixin): ...# 记载用户回调函数@login_manager.user_loaderdef load_user(user_id): return User.query.get(int(user_id))#--------------------------------------------------## auth/views.pyfrom flask_login import login_required@auth.route(&#x27;/secret&#x27;)@login_required # 路由保护def secret(): return &#x27;Only authenticated users are allowed!&#x27; 2.1 登录用户属性和方法1234is_authenticated # 用户已登陆，返回Trueis_active # 允许用户登录，返回Trueis_anonymous # 普通用户必须返回Falseget_id() # 用户唯一标识符，string 3. 生成确认令牌itsdangerous提供多种生成令牌的方法，其中，TimeJSONWebSignatureSerializer类生成具有过期时间的JSON Web签名（JSON Web Signature事，JWS） 123456789&gt;&gt;&gt; from manage import app&gt;&gt;&gt; from itsdangerous import TimedJSONWebSignatureSerializer as Serializer&gt;&gt;&gt; s = Serializer(app.config[&#x27;SECRET_KEY&#x27;], expires_in=3600)&gt;&gt;&gt; token = s.dumps(&#123;&#x27;confirm&#x27;: 23&#125;)&gt;&gt;&gt; tokenb&#x27;eyJhbGciOiJIUzUxMiIsImlhdCI6MTU0MTk5MzkxOSwiZXhwIjoxNTQxOTk3NTE5fQ.eyJjb25maXJtIjoyM30.OLvqw1pvzD7weSvZaU4Rr3UnvbdlTtUbVc-h8JvtE8Yj3uVTeIEj_IVUjI82fR2OnmZvD_gwz7-2SCt7DY32AA&#x27;&gt;&gt;&gt; data = s.loads(token)&gt;&gt;&gt; data&#123;&#x27;confirm&#x27;: 23&#125; 4. 匿名用户管理12345678class AnonymousUser(AnonymousUserMixin): def can(self, permissions): return False def is_administrator(self): return Falselogin_manager.anonymous_user = AnonymousUser","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask Email","slug":"Flask Email","date":"2017-03-06T03:16:08.000Z","updated":"2021-06-22T10:50:49.697Z","comments":true,"path":"2017/03/06/Flask Email/","link":"","permalink":"https://elihe2011.github.io/2017/03/06/Flask%20Email/","excerpt":"1. 配置MAIL信息12345678910111213app.config[&#x27;MAIL_SERVER&#x27;] = &#x27;smtp.sina.com&#x27;app.config[&#x27;MAIL_PORT&#x27;] = 587app.config[&#x27;MAIL_USE_SSL&#x27;] = Falseapp.config[&#x27;MAIL_USE_TLS&#x27;] = True # if True, port is 587app.config[&#x27;MAIL_USERNAME&#x27;] = os.environ.get(&#x27;MAIL_USERNAME&#x27;)app.config[&#x27;MAIL_PASSWORD&#x27;] = os.environ.get(&#x27;MAIL_PASSWORD&#x27;)app.config[&#x27;MAIL_DEFAULT_SENDER&#x27;] = os.environ.get(&#x27;MAIL_ADMIN&#x27;)app.config[&#x27;MAIL_SUBJECT_PREFIX&#x27;] = &#x27;[MyFlask]&#x27;app.config[&#x27;MAIL_RECEIVER&#x27;] = os.environ.get(&#x27;MAIL_RECEIVER&#x27;)# 初始化mail = Mail(app)","text":"1. 配置MAIL信息12345678910111213app.config[&#x27;MAIL_SERVER&#x27;] = &#x27;smtp.sina.com&#x27;app.config[&#x27;MAIL_PORT&#x27;] = 587app.config[&#x27;MAIL_USE_SSL&#x27;] = Falseapp.config[&#x27;MAIL_USE_TLS&#x27;] = True # if True, port is 587app.config[&#x27;MAIL_USERNAME&#x27;] = os.environ.get(&#x27;MAIL_USERNAME&#x27;)app.config[&#x27;MAIL_PASSWORD&#x27;] = os.environ.get(&#x27;MAIL_PASSWORD&#x27;)app.config[&#x27;MAIL_DEFAULT_SENDER&#x27;] = os.environ.get(&#x27;MAIL_ADMIN&#x27;)app.config[&#x27;MAIL_SUBJECT_PREFIX&#x27;] = &#x27;[MyFlask]&#x27;app.config[&#x27;MAIL_RECEIVER&#x27;] = os.environ.get(&#x27;MAIL_RECEIVER&#x27;)# 初始化mail = Mail(app) 2. 发送邮件123def send_async_email(app, msg): with app.app_context(): mail.send(msg) 3. 发送异步邮件12345678def send_email(to, subject, template, **kwargs): msg = Message(app.config[&#x27;MAIL_SUBJECT_PREFIX&#x27;] + &#x27; &#x27; + subject, sender=app.config[&#x27;MAIL_DEFAULT_SENDER&#x27;], recipients=[to]) msg.body = render_template(template + &#x27;.txt&#x27;, **kwargs) msg.html = render_template(template + &#x27;.html&#x27;, **kwargs) thr = Thread(target=send_async_email, args=(app, msg)) thr.start()","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask Session和CSRF","slug":"Flask Session和CSRF","date":"2017-03-05T02:45:32.000Z","updated":"2021-06-22T10:50:49.697Z","comments":true,"path":"2017/03/05/Flask Session和CSRF/","link":"","permalink":"https://elihe2011.github.io/2017/03/05/Flask%20Session%E5%92%8CCSRF/","excerpt":"1. 直接使用cookie123resp.set_cookie(&#x27;userId&#x27;, str(user.id), max_age=age)userId = request.cookies.get(&#x27;userId&#x27;, None) 2. 利用session对象存储cookie123session[&#x27;userId&#x27;] = str(user.id)userId = session.get(&#x27;userId&#x27;, None) flask中的session就是存在cookie中的字典，并对这些数据进过了加密，实现维持状态的功能","text":"1. 直接使用cookie123resp.set_cookie(&#x27;userId&#x27;, str(user.id), max_age=age)userId = request.cookies.get(&#x27;userId&#x27;, None) 2. 利用session对象存储cookie123session[&#x27;userId&#x27;] = str(user.id)userId = session.get(&#x27;userId&#x27;, None) flask中的session就是存在cookie中的字典，并对这些数据进过了加密，实现维持状态的功能 3. 强制CSRFCSRF: Cross-Site Request Forgery， 跨站请求伪造CSRF 123456# 必选配置，否则使用session则报错RuntimeErrorapp.config[&#x27;SECRET_KEY&#x27;] = &#x27;safe&#x27;session[&#x27;user&#x27;] = username# Headers Cookie: sesion=asasaashasjjasjasjs# 默认存储在内存中：不容易管理、易丢失，不支持分布式 4. 使用Flask-Session1234567891011121314151617# config.pySESSION_TYPE = &#x27;redis&#x27;SESSION_REDIS_HOST = &#x27;localhost&#x27;SESSION_REDIS_PORT = 6379# appsession = Session()session.init_app(app)@app.route(&#x27;/set&#x27;)def set(): session[&#x27;key&#x27;] = &#x27;value&#x27; return &#x27;ok&#x27;@app.route(&#x27;/get&#x27;)def get(): return session.get(&#x27;key&#x27;, &#x27;not set&#x27;)","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask Jinja2模板","slug":"Flask Jinja2模板","date":"2017-03-04T08:21:49.000Z","updated":"2021-06-22T10:50:49.697Z","comments":true,"path":"2017/03/04/Flask Jinja2模板/","link":"","permalink":"https://elihe2011.github.io/2017/03/04/Flask%20Jinja2%E6%A8%A1%E6%9D%BF/","excerpt":"1. 标记符 {{ }} # 变量 {% %} # 控制语句 {# #} # 注释","text":"1. 标记符 {{ }} # 变量 {% %} # 控制语句 {# #} # 注释 2. 过滤器： value|abs name|default('未知用户') content|escape # -> &lt;a&gt; content|safe # 不转义 content|length content|wordcount content|truncate(length=10) content|lower content|upper content|capitalize content|title # 单词首字母大写 content|trim content|striptags # 删除html标签 names|first names|last \"%s\" - \"%s\"|format(city, nation) {{ [1,2,3,4,5] | first }} {{ [1,2,3,4,5] | last }} {{ [1,2,3,4,5] | length }} {{ [1,2,3,4,5] | sum }} {{ [3,2,1,5,4] | sort }} {{ [1,2,3,4,5] | join(' | ') ## 3. 控制语句 ### 3.1 for {% for foo in range(10) %} {# {{ loop.length }} 循环总次数#} {# {{ loop.index }} 当前次数，下标从1开始#} {# {{ loop.index0 }} 当前次数，下标从0开始#} {# {{ loop.reindex }} 当前次数反向#} {# {{ loop.cycle('a','b','c') }} 循环自动返回元素 #} {# {{ loop.first }} 首次迭代时返回true#} {# {{ loop.last }} 首次迭代是返回false#} {% endfor %} {% for item in items %} {% if loop.first %} {{ item }}:{{ loop.index }} {% elif loop.last %} {{ item }}:{{ loop.index }} {% else %} {{ item }}:{{ loop.index }} {% endif %} {% else %} BB {% endfor %} loop.first loop.last loop.index loop.index0 loop.revindex loop.revindex0 4. 赋值 {% set name = 'lucy' %} 姓名：{{ name }} 5. 作用域5.1 IF没有作用域 {% set name = 'lucy' %} {% if true %} {% set name='tom' %} {{ name }} // tom {% endif %} {{ name }} // tom 5.2 设置IF的作用域(使用with来构造局部作用域) {% set name = 'lucy' %} {% if true %} {% with %} {% set name='tom' %} {{ name }} // tom {% endwith %} {% endif %} {{ name }} // lucy 5.3 IF有作用域 {% set name = 'lucy' %} {% for x in range(1) %} {% set name='tom' %} {{ name }} // tom {% endfor %} {{ name }} // lucy 6. 宏定义和导入宏定义6.1 使用宏定义 {% macro input(name, value='', type='text') %} {% endmacro %} {{ input('name') }} 6.2 导入宏定义 {% macro input(name, value='', type='text') %} {% endmacro %} {% macro textarea(name, value='', rows=10, cols=40) %} {{ value|e }} {% endmacro %} {% import 'forms.html' as forms %} Username {{ forms.input('username') }} Password {{ forms.input('password', type='password') }} {{ forms.textarea('comment') }} 7. 包含 {% include \"include/header.html\" %} {% include \"include/content.html\" %} {% include \"include/footer.html\" %} 8. 继承 {% extends \"bootstrap/base.html\" %} {% block title %}MyFlask{% endblock %} {% block head %} {{ super() }} {% endblock %} {% block navbar %} Toggle navigation MyFlask Home {% if current_user.is_authenticated %} Profile {% endif %} {% if current_user.can(Permission.MODERATE) %} Moderate Comments {% endif %} {% if current_user.is_authenticated %} Account Change Password Change Email Log Out {% else %} Log In {% endif %} {% endblock %} {% block content %} {% for message in get_flashed_messages() %} &times; {{ message }} {% endfor %} {% block page_content %}{% endblock %} {% endblock %} {% block scripts %} {{ super() }} {{ moment.include_moment() }} {% endblock %} {% extends \"base.html\" %} {% import \"bootstrap/wtf.html\" as wtf %} {% import \"_macros.html\" as macros %} {% block page_content %} Hello, {% if current_user.is_authenticated %} {{ current_user.username }}{% else %}Stranger{% endif %}! {% if current_user.can(Permission.WRITE) %} {{ wtf.quick_form(form) }} {% endif %} All {% if current_user.is_authenticated %} Followers {% endif %} {% include '_posts.html' %} {% if pagination %} {{ macros.pagination_widget(pagination, '.index') }} {% endif %} {% endblock %} {% block scripts %} {{ super() }} {{ pagedown.include_pagedown() }} {% endblock %} 9. 分页123456789@main.route(&#x27;/user/&lt;username&gt;&#x27;)def user(username): _user = User.query.filter_by(username=username).first_or_404() page = request.args.get(&#x27;page&#x27;, 1, type=int) pagination = Post.query.filter_by(author=_user) .order_by(Post.timestamp.desc()).paginate( page, per_page=current_app.config[&#x27;POSTS_PER_PAGE&#x27;], error_out=False) posts = pagination.items return render_template(&#x27;user.html&#x27;, user=_user, posts=posts, pagination=pagination) {% macro pagination_widget(pagination, endpoint) %} &laquo; {% for p in pagination.iter_pages() %} {% if p %} {% if p == pagination.page %} {{ p }} {% else %} {{ p }} {% endif %} {% else %} &hellip; {% endif %} {% endfor %} &raquo; {% endmacro %} {% include '_posts.html' %} {% if pagination %} {{ macros.pagination_widget(pagination, '.user', username=user.username) }}","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 视图","slug":"Flask 视图","date":"2017-03-03T08:15:39.000Z","updated":"2021-06-22T10:50:49.696Z","comments":true,"path":"2017/03/03/Flask 视图/","link":"","permalink":"https://elihe2011.github.io/2017/03/03/Flask%20%E8%A7%86%E5%9B%BE/","excerpt":"1. 视图类123456789101112from flask.views import Viewfrom embo.api import apiclass MyView(View): def test(self): return &#x27;&lt;h1&gt;Hello World&lt;/h1&gt;&#x27; def dispatch_request(self): resp = self.test() return respapp.add_url_rule(&#x27;/test&#x27;, view_func=MyView.as_view(&#x27;test&#x27;))","text":"1. 视图类123456789101112from flask.views import Viewfrom embo.api import apiclass MyView(View): def test(self): return &#x27;&lt;h1&gt;Hello World&lt;/h1&gt;&#x27; def dispatch_request(self): resp = self.test() return respapp.add_url_rule(&#x27;/test&#x27;, view_func=MyView.as_view(&#x27;test&#x27;)) 2. 方法视图类1234567891011from flask.views import Viewfrom embo.api import apiclass MyMethodView(MethodView): def get(self): return &#x27;&lt;h1&gt;GET&lt;/h1&gt;&#x27; def post(self): return &#x27;&lt;h1&gt;POST&lt;/h1&gt;&#x27;api.add_url_rule(&#x27;/method&#x27;, view_func=MyMethodView.as_view(&#x27;method&#x27;))","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 请求和响应","slug":"Flask 请求和响应","date":"2017-03-02T06:56:25.000Z","updated":"2021-06-22T10:50:49.696Z","comments":true,"path":"2017/03/02/Flask 请求和响应/","link":"","permalink":"https://elihe2011.github.io/2017/03/02/Flask%20%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94/","excerpt":"1. Request1.1 请求参数1234567891011121314151617181920212223242526272829303132333435363738# url参数(?key=value)request.args# form表单，MultiDictrequest.form# url参数和form表单, CombinedMultiDict, 内容为CombinedMultiDict([args, forms])request.values# 请求cookies, dictrequest.cookies# mimetype一般为流媒体时使用request.stream request.data # 请求头request.headers # 请求方法request.method# WSGI环境变量request.environ # POST/PUT上传文件，MultiDictrequest.files# URLrequest.url # http://localhost:5000/user?id=1request.url_root # http://localhost:5000/request.path # /userrequest.base_url # http://localhost:5000/userrequest.script_root # # 客户端信息request.remote_addrrequest.user_agent","text":"1. Request1.1 请求参数1234567891011121314151617181920212223242526272829303132333435363738# url参数(?key=value)request.args# form表单，MultiDictrequest.form# url参数和form表单, CombinedMultiDict, 内容为CombinedMultiDict([args, forms])request.values# 请求cookies, dictrequest.cookies# mimetype一般为流媒体时使用request.stream request.data # 请求头request.headers # 请求方法request.method# WSGI环境变量request.environ # POST/PUT上传文件，MultiDictrequest.files# URLrequest.url # http://localhost:5000/user?id=1request.url_root # http://localhost:5000/request.path # /userrequest.base_url # http://localhost:5000/userrequest.script_root # # 客户端信息request.remote_addrrequest.user_agent 1.2 使用场景12345678910111213141516171819202122232425262728293031# 获取User-Agent信息request.headers.get(&#x27;User-Agent&#x27;) # url、path、script_root、base_url、url_root&#x27;url: %s , script_root: %s , path: %s , base_url: %s , url_root : %s&#x27; % ( request.url, request.script_root, request.path, request.base_url, request.url_root)#url: http://192.168.1.183:5000/testrequest?a&amp;b , script_root: , path: /testrequest , base_url: http://192.168.1.183:5000/testrequest , url_root : http://192.168.1.183:5000/# 随请求上传的文件@app.route(&#x27;/upload&#x27;,methods=[&#x27;GET&#x27;,&#x27;POST&#x27;])def upload(): if request.method == &#x27;POST&#x27;: f = request.files[&#x27;file&#x27;] filename = secure_filename(f.filename) f.save(&#x27;app/static/&#x27; + str(filename)) return &#x27;ok&#x27; else: return &quot;&quot;&quot;&lt;html&gt; &lt;body&gt; &lt;form action=&quot;upload&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;file&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;submit&quot; value=&quot;Upload&quot; /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot; 1.3 请求数据封装123456def get_json(): if hasattr(request, json): return reqeust.json return request.values # values，不管post或get方法的参数，均以dict类型返回，可直接通过get方法获取request._get_json = get_json 1.4 post 请求 (Content-Type: application/json)12345request.get_data() # 原始数据request.data # 调用request.get_data()得到的数据request.get_json() # 字典数据request.json # 调用request.get_json()得到的数据 Content-Type: application/json时报错&#x27;dict&#x27; object is not callable 1.5 url参数123request.args.get(&#x27;key&#x27;) # 可以获取到单个的值，requestValues = request.args # 可以获取get请求的所有参数返回值是ImmutableMultiDict类型,requestValues.to_dict() # 将获得的参数转换为字典 2. Response2.1 字符串，带状态码123return &#x27;Hello World&#x27;return &#x27;Bad Request&#x27;, 400 2.2 response对象12345response = make_response(&#x27;&lt;h1&gt;set cookie&lt;/h1&gt;&#x27;)response.set_cookie(&#x27;name&#x27;, &#x27;test01&#x27;)return responsereturn Response(&#x27;&lt;h1&gt;Hello World!&lt;/h1&gt;&#x27;) 设置cookie，参数说明： key：设置的cookie的key。 value：key对应的value。 max_age：改cookie的过期时间，如果不设置，则浏览器关闭后就会自动过期。 expires：过期时间，应该是一个datetime类型。 domain：该cookie在哪个域名中有效。一般设置子域名，比如cms.example.com。 path：该cookie在哪个路径下有效。 2.3 redirect123456789# http code#301: permanently moved (换域名，或域名规整，推荐使用)#302: temporarily moved (可能会有URL规范化和网站劫持问题) # 默认 302return redirect(url_for(&#x27;auth.login&#x27;))# 推荐 301return redirect(&#x27;https://www.google.com&#x27;, code=301) 2.4 abort, 触发异常1abort(400) 2.5 template1return render_template(&#x27;user.html&#x27;, name=name) 2.6 json123return json.jsonify(&#123;&#x27;name&#x27;: &#x27;john&#x27;&#125;)return Response(response=json.jsonify(&#123;&#x27;name&#x27;: &#x27;john&#x27;&#125;)) 3. 请求和响应钩子123456789before_first_requestbefore_requestafter_request(response): return response # 请求未出现异常时执行，注意返回responseteardown_request(exception) # 即使出现异常也执行errorhandler(404) 123@app.errorhandler(404)def page_not_found(): return &#x27;Page Not Found&#x27;, 404, &#123;&#125;","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Flask 入门","slug":"Flask 入门","date":"2017-03-01T14:14:54.000Z","updated":"2021-06-22T10:50:49.695Z","comments":true,"path":"2017/03/01/Flask 入门/","link":"","permalink":"https://elihe2011.github.io/2017/03/01/Flask%20%E5%85%A5%E9%97%A8/","excerpt":"1. 一个Flask应用1234567891011from flask import Flaskapp = Flask(__name__) app.config[&#x27;DEBUG&#x27;] = True # 代码变更时，自动载入代码，并输出错误信息@app.route(&#x27;/&#x27;)def index(): return &#x27;Hello World!&#x27;if __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=8000, debug=True)","text":"1. 一个Flask应用1234567891011from flask import Flaskapp = Flask(__name__) app.config[&#x27;DEBUG&#x27;] = True # 代码变更时，自动载入代码，并输出错误信息@app.route(&#x27;/&#x27;)def index(): return &#x27;Hello World!&#x27;if __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=8000, debug=True) 2. 配置123456# 方法一：导入import configapp.config.from_object(config)# 方法二：直接使用python文件app.config.from_pyfile(&#x27;config.py&#x27;) 3. 路由配置3.1 使用app的实例方法add_url_rule12345def hello(): return &#x27;&lt;p&gt;Hello World!&lt;/p&gt;&#x27;# endpoint可以为None，此时它默认为view_func.__name__app.add_url_rule(&#x27;/hello&#x27;, endpoint=&#x27;hello&#x27;, view_func=hello) 3.2 使用装饰器123@app.route(&#x27;/hello&#x27;)def hello(): return &#x27;&lt;p&gt;Hello World!&lt;/p&gt;&#x27; 3.3 打印路由信息1app.url_map 4. 蓝图1234567891011# 创建蓝本from flask import Blueprintauth = Blueprint(&#x27;auth&#x27;, __name__)@auth.route(&#x27;/login&#x27;)def login(): return render_template(&#x27;auth/login.html&#x27;)# 使用蓝本, 通过蓝本的url_prefix分路径from .auth import auth as auth_blueprintapp.register_blueprint(auth_blueprint, url_prefix=&#x27;/auth&#x27;) 5. 访问静态文件1app = Flask(__name__, static_folder=&#x27;static&#x27;) http://localhost:5000/static/abc.png 6. URL参数类型转换1234567891011@app.route(&#x27;/doc/&lt;int:doc_id&gt;&#x27;)def get_doc_by_id(doc_id): pass@app.route(&#x27;/doc/&lt;uuid:doc_uuid&gt;&#x27;)def get_doc_by_uuid(doc_uuid): pass@app.route(&#x27;/test/&lt;any(&quot;doc&quot;,&quot;dir&quot;):para&gt;&#x27;)def get_type(para): pass 7. 通过endpoint获取URL地址（反向路由）1234567url_for(&#x27;user&#x27;)url_for(&#x27;doc.add&#x27;) # 使用blueprinturl_for(&#x27;user&#x27;, id=2) # 针对/user =&gt; /user?id=2url_for(&#x27;user&#x27;, id=1, _external=True) # http://localhost:5000/user?id=1 反向解析 url_for 123url_for(&#x27;endpoint&#x27;)url_for(&#x27;blueprint.endpoint&#x27;)url_for(&#x27;static&#x27;, filename=&#x27;css/main.css&#x27;) 8. 请求方法123@app.route(&#x27;/doc&#x27;, methods=[&#x27;GET&#x27;, &#x27;POST&#x27;, &#x27;DELETE&#x27;, &#x27;PUT&#x27;])def doc(): pass 9. 创建Flask应用的两种模式9.1 Singleton模式1234567891011from flask import Flask, render_templatefrom flask.ext.sqlalchemy import SQLAlchemyfrom flask.ext.login import LoginManagerapp = Flask(__name__)db = SQLAlchemy(app)login_manager = LoginManager()@app.route(&#x27;/&#x27;)def index(): return render_template(&#x27;index.html&#x27;) 代码简洁，但写测试代码等比较麻烦 1234567891011121314151617181920class TestApp(unittest.TestCase): DEBUG = False TESTING = True SQLALCHEMY_DATABASE_URI = None def setUp(self): self.app = create_app() self.app.config.from_object(self) self.client = self.app.test_client() def test_app(self): @self.app.route(&#x27;/test/&lt;int:id_&gt;&#x27;) def my_view(id_): return &#x27;#%d&#x27; % id_ resp = self.client.get(&#x27;/test/42&#x27;) self.assertEqual(resp.data, &#x27;#42&#x27;) def test_index(self): resp = self.client.get(&#x27;/&#x27;) self.assertIn(&#x27;Welcome&#x27;, resp.data) 9.2 App Factory 模式目的：摆脱app与view的相互导入关系 1234567891011121314151617181920from flask import Flaskfrom werkzeug.utils import import_stringextensions = [ &#x27;embo.ext:db&#x27;, &#x27;embo.ext:login_manager&#x27;,]blueprints = [ &#x27;embo.views:bp&#x27;,]def create_app(): app = Flask(__name__) for ext_name in extensions: ext = import_string(ext_name) ext.init_app(app) for bp_name in blueprints: bp = import_string(bp_name) app.register_blueprint(bp) return app","categories":[{"name":"Flask","slug":"Flask","permalink":"https://elihe2011.github.io/categories/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://elihe2011.github.io/tags/python/"}]},{"title":"Python 程序退出","slug":"Python 程序退出","date":"2016-01-19T08:07:17.000Z","updated":"2021-06-22T10:50:49.695Z","comments":true,"path":"2016/01/19/Python 程序退出/","link":"","permalink":"https://elihe2011.github.io/2016/01/19/Python%20%E7%A8%8B%E5%BA%8F%E9%80%80%E5%87%BA/","excerpt":"","text":"1. sys.exit()退出比较优雅，触发发SystemExit异常，可以捕获此异常做清理工作。 2. os._exit()直接从python解释器退出，余下的语句不会执行。 一般只在fork出来的子进程中使用os._exit() os._exit() 调用 C 语言的 _exit() 函数。","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 工具函数","slug":"Python 工具函数","date":"2016-01-08T07:51:04.000Z","updated":"2021-06-22T10:50:49.694Z","comments":true,"path":"2016/01/08/Python 工具函数/","link":"","permalink":"https://elihe2011.github.io/2016/01/08/Python%20%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B0/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374def is_chinese(uchar): &quot;&quot;&quot;判断一个unicode是否是汉字&quot;&quot;&quot; if uchar &gt;= u&#x27;\\u4e00&#x27; and uchar&lt;=u&#x27;\\u9fa5&#x27;: return True else: return False def is_number(uchar): &quot;&quot;&quot;判断一个unicode是否是数字&quot;&quot;&quot; if uchar &gt;= u&#x27;\\u0030&#x27; and uchar&lt;=u&#x27;\\u0039&#x27;: return True else: return False def is_alphabet(uchar): &quot;&quot;&quot;判断一个unicode是否是英文字母&quot;&quot;&quot; if (uchar &gt;= u&#x27;\\u0041&#x27; and uchar&lt;=u&#x27;\\u005a&#x27;) or (uchar &gt;= u&#x27;\\u0061&#x27; and uchar&lt;=u&#x27;\\u007a&#x27;): return True else: return False def is_other(uchar): &quot;&quot;&quot;判断是否非汉字，数字和英文字符&quot;&quot;&quot; if not (is_chinese(uchar) or is_number(uchar) or is_alphabet(uchar)): return True else: return False def B2Q(uchar): &quot;&quot;&quot;半角转全角&quot;&quot;&quot; inside_code=ord(uchar) if inside_code&lt;0x0020 or inside_code&gt;0x7e: #不是半角字符就返回原来的字符 return uchar if inside_code==0x0020: #除了空格其他的全角半角的公式为:半角=全角-0xfee0 inside_code=0x3000 else: inside_code+=0xfee0 return unichr(inside_code) def Q2B(uchar): &quot;&quot;&quot;全角转半角&quot;&quot;&quot; inside_code=ord(uchar) if inside_code==0x3000: inside_code=0x0020 else: inside_code-=0xfee0 if inside_code&lt;0x0020 or inside_code&gt;0x7e: #转完之后不是半角字符返回原来的字符 return uchar return unichr(inside_code) def stringQ2B(ustring): &quot;&quot;&quot;把字符串全角转半角&quot;&quot;&quot; return &quot;&quot;.join([Q2B(uchar) for uchar in ustring]) def uniform(ustring): &quot;&quot;&quot;格式化字符串，完成全角转半角，大写转小写的工作&quot;&quot;&quot; return stringQ2B(ustring).lower() def string2List(ustring): &quot;&quot;&quot;将ustring按照中文，字母，数字分开&quot;&quot;&quot; retList=[] utmp=[] for uchar in ustring: if is_other(uchar): if len(utmp)==0: continue else: retList.append(&quot;&quot;.join(utmp)) utmp=[] else: utmp.append(uchar) if len(utmp)!=0: retList.append(&quot;&quot;.join(utmp)) return retList","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"PEP8","slug":"排序算法","date":"2016-01-06T06:23:11.000Z","updated":"2021-06-22T10:50:49.694Z","comments":true,"path":"2016/01/06/排序算法/","link":"","permalink":"https://elihe2011.github.io/2016/01/06/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","excerpt":"1、插入排序描述 插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为 O(n^2)。是稳定的排序方法。插入算法把要排序的数组分成两部分：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插 入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。 代码实现 123456789101112def insert_sort(lists): # 插入排序 count = len(lists) for i in range(1, count): key = lists[i] j = i - 1 while j &gt;= 0: if lists[j] &gt; key: lists[j + 1] = lists[j] lists[j] = key j -= 1 return lists","text":"1、插入排序描述 插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为 O(n^2)。是稳定的排序方法。插入算法把要排序的数组分成两部分：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插 入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。 代码实现 123456789101112def insert_sort(lists): # 插入排序 count = len(lists) for i in range(1, count): key = lists[i] j = i - 1 while j &gt;= 0: if lists[j] &gt; key: lists[j + 1] = lists[j] lists[j] = key j -= 1 return lists 2、希尔排序描述 希尔排序(Shell Sort)是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于 1959年提出而得名。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分 成一组，算法便终止。 代码实现 12345678910111213141516171819def shell_sort(lists): # 希尔排序 count = len(lists) step = 2 group = count / step while group &gt; 0: for i in range(0, group): j = i + group while j &lt; count: k = j - group key = lists[j] while k &gt;= 0: if lists[k] &gt; key: lists[k + group] = lists[k] lists[k] = key k -= group j += group group /= step return lists 3、冒泡排序描述 它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。 代码实现 12345678def bubble_sort(lists): # 冒泡排序 count = len(lists) for i in range(0, count): for j in range(i + 1, count): if lists[i] &gt; lists[j]: lists[i], lists[j] = lists[j], lists[i] return lists 4、快速排序描述 通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 代码实现 123456789101112131415161718def quick_sort(lists, left, right): # 快速排序 if left &gt;= right: return lists key = lists[left] low = left high = right while left &lt; right: while left &lt; right and lists[right] &gt;= key: right -= 1 lists[left] = lists[right] while left &lt; right and lists[left] &lt;= key: left += 1 lists[right] = lists[left] lists[right] = key quick_sort(lists, low, left - 1) quick_sort(lists, left + 1, high) return lists 5、直接选择排序描述 基本思想：第1趟，在待排序记录r1 ~ r[n]中选出最小的记录，将它与r1交换；第2趟，在待排序记录r2 ~ r[n]中选出最小的记录，将它与r2交换；以此类推，第i趟在待排序记录r[i] ~ r[n]中选出最小的记录，将它与r[i]交换，使有序序列不断增长直到全部排序完毕。 代码实现 12345678910def select_sort(lists): # 选择排序 count = len(lists) for i in range(0, count): min = i for j in range(i + 1, count): if lists[min] &gt; lists[j]: min = j lists[min], lists[i] = lists[i], lists[min] return lists 6、堆排序描述 堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元 素。堆分为大根堆和小根堆，是完全二叉树。大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]] &gt;= A[i]。在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶。 代码实现 1234567891011121314151617181920212223242526# 调整堆 def adjust_heap(lists, i, size): lchild = 2 * i + 1 rchild = 2 * i + 2 max = i if i &lt; size / 2: if lchild &lt; size and lists[lchild] &gt; lists[max]: max = lchild if rchild &lt; size and lists[rchild] &gt; lists[max]: max = rchild if max != i: lists[max], lists[i] = lists[i], lists[max] adjust_heap(lists, max, size) # 创建堆 def build_heap(lists, size): for i in range(0, (size/2))[::-1]: adjust_heap(lists, i, size) # 堆排序 def heap_sort(lists): size = len(lists) build_heap(lists, size) for i in range(0, size)[::-1]: lists[0], lists[i] = lists[i], lists[0] adjust_heap(lists, 0, i) 7、归并排序描述 归并排序是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一 个有序表，称为二路归并。 归并过程为：比较a[i]和a[j]的大小，若a[i]≤a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否 则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中一个有序表取完，然后再将另一个有序表中剩余的元素复 制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序， 最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。 代码实现 12345678910111213141516171819202122def merge(left, right): i, j = 0, 0 result = [] while i &lt; len(left) and j &lt; len(right): if left[i] &lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result += left[i:] result += right[j:] return result def merge_sort(lists): # 归并排序 if len(lists) &lt;= 1: return lists num = len(lists) / 2 left = merge_sort(lists[:num]) right = merge_sort(lists[num:]) return merge(left, right) 8、基数排序描述 基数排序（radix sort）属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort）或bin sort，顾名思义，它是透过键值的部份资讯，将要排序的元素分配至某些“桶”中，藉以达到排序的作用，基数排序法是属于稳定性的排序，其时间复杂度为O (nlog(r)m)，其中r为所采取的基数，而m为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。 代码实现 123456789101112import math def radix_sort(lists, radix=10): k = int(math.ceil(math.log(max(lists), radix))) bucket = [[] for i in range(radix)] for i in range(1, k+1): for j in lists: bucket[j/(radix**(i-1)) % (radix**i)].append(j) del lists[:] for z in bucket: lists += z del z[:] return lists","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python PEP8","slug":"Python PEP8","date":"2016-01-04T02:23:04.000Z","updated":"2021-06-22T10:50:49.694Z","comments":true,"path":"2016/01/04/Python PEP8/","link":"","permalink":"https://elihe2011.github.io/2016/01/04/Python%20PEP8/","excerpt":"1. PEP: Python Enhancement ProposalPEP8: Style Guide for Python CodePEP7: Style Guild for C Code PEP257: Docstring Conventions","text":"1. PEP: Python Enhancement ProposalPEP8: Style Guide for Python CodePEP7: Style Guild for C Code PEP257: Docstring Conventions 2. PEP8除了是一个标准，还是一个软件包名字123pep8 test.pypep8 -r --ignore E501 test.pypep8 --help 3. PEP83.1 代码排版 缩进：4个空格缩进，不使用Tab，更不混用Tab和空格 换行：每行最大长度79，换行使用反斜杠，最好使用圆括号。换行点要在操作符后面敲回车 空行：类和top-level函数之间空两行；类中方法之间空一行；函数内逻辑无关段落空一行；其他地方尽量不要再空行。特别地，空行不要包含空格或Tab 3.2 文档排版 1) 模块内容顺序：模块说明–&gt;docstring–&gt;import–&gt;globals–&gt;constants–&gt;其他定义。其中import部分，按标准、第三方、自己编写的顺序依次排放，之间空一行 2) 不要在一个import导入多个模块，比如import os,sys不推荐 3) 如果采用from XX import XX，在省略module时，会出现命名冲突，此时要采用import XX 3.3 空格的使用总体原则，避免不必要的空格 1) 各种右括号前不加空格 2) 逗号、冒号、分号前不要加空格 3) 函数的左括号前不加空格，如Func(1) 4) 序列的左括号前不加空格，如List[2] 5) 操作符左右各加一个空格，不要为了对齐增加空格 6) 函数默认参数使用的赋值符左右省略空格 7) 不要讲多语句写在同一行，尽管可以使用”;” 8) if/for/while， 即使执行语句只有一句，也必须另起一行 3.4 注释总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事情就是修改注释 注释必须使用英文，最好是完整的句子，首字符大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短句，可以省略结束符 1) 块注释，在一段代码前增加注释。在#加一个空格，段落间只有#的行间隔 12345# Description : Module config.## Input : None## Output: None 2) 行注释，在一句代码后加注释。比如: x = x + 1 # Increment x但这种方式尽量少用 3) 避免无谓的注释 3.5 文档描述 1) 为所有的公有模块、函数、类、方法写docstrings; 非公有的没有必要，但可以写注释(def的下一行) 2) 如果docstring要换行，参考如下例子，详见PEP 257 123&quot;&quot;&quot;Return a foobangOptional plotz says to frobnicate the bizbaz first.&quot;&quot;&quot; 3.6 命名规范总体原则，新编代码必须按下列命名风格进行，现有库的编码尽量保持风格。 1) 尽量单独使用小写字符’l’, 大写字符’O’等容易混淆的字母 2) 模块名尽量短小，全部小写，可以使用下划线 3) 包名尽量短小，全部小写，不可使用下划线 4) 类名使用CapWords方式，模块内部类采用_CapWords方式 5) 异常命名使用CapWords+Error后缀 6) 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是all机制；二是前缀一个下划线 7) 函数命名全部小写，可以使用下划线 8) 常量命名全部大写，可以使用下划线 9) 类的属性(方法和变量)命名全部小写，可以使用下划线 10) 类的属性有3种作用域public、non-public和subclass API，可以理解为C++重的public, private, protected。non-public属性，- 前缀一个下划线 11) 类的属性若与关键字命名冲突，后缀一个下划线，尽量不要使用缩略等其他方式 12) 为避免与子类属性命名冲突，类的一些属性，前缀两条下划线。比如: 类Foo中声明a，访问时只能通过Foo._Fooa，避免歧义。如果子类- 也叫Foo，那就无能为力了。 13) 类的方法第一个参数必须是self，而类方法第一个参数必须是cls 3.7 编码建议 1) 编码中要考虑到其他python实现的效率 问题，比如计算符’+’在Python中效率很高，但在Jython中且非常低，所以应该采用.join()方式 2) 尽量使用’is’, ‘is not’取代’==’， 比如if x is not None要优于if x 3) 使用基于类的异常，每个模块和包都有自己的异常类，此异常类继承自Exception 4) 异常中不要使用裸露的except, except后跟具体的exceptions 5) 异常中try的代码尽可能少，比如： 123456try:value = collection[key]except KeyError:return key_not_found(key)else:return handle_value(value) 要优于： 123456try:# Too broadreturn handle_value(collection[key])except KeyError:# Will also catch KeyError raised by handle_valuereturn key_not_found(key) 6) 使用startswith()和endswith()代替切片进行序列前缀或后缀的检查 Yes： if foo.startswith(‘bar’) No: if foo[:3] == ‘bar’: 7) 使用isinstance()比较对象的类型 Yes: if isinstance(obj, int) No：if type(obj) is type(1): 8) 判断序列空或不空，有如下规则 Yes: if not seq:, if seq: No: if len(seq):, if not len(seq): 9) 字符串不要以空格结尾 10) 二进制数据判断，使用if boolvalue的方式 3.8 其他规定 一行代码：最大长度79 一个函数：不要超过30行 一个类：不要超过200行，不要超过10个方法 一个模块：不要超过500行","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 知识点总结","slug":"Python 知识点总结","date":"2016-01-03T07:21:04.000Z","updated":"2021-06-22T10:50:49.693Z","comments":true,"path":"2016/01/03/Python 知识点总结/","link":"","permalink":"https://elihe2011.github.io/2016/01/03/Python%20%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","excerpt":"1. super super(type) unbound super object super(type, obj) bound super object; requires isinstance(obj, type) super(type, type2) bound super object; requires issubclass(type, type2) 仅新式类支持，保证父类只被执行一次 MRO：Method Resolution Order DFLR: Deepth First, Left to Right C.__mro__","text":"1. super super(type) unbound super object super(type, obj) bound super object; requires isinstance(obj, type) super(type, type2) bound super object; requires issubclass(type, type2) 仅新式类支持，保证父类只被执行一次 MRO：Method Resolution Order DFLR: Deepth First, Left to Right C.__mro__ 2. 属性查找顺序：先本地，找不到向上一层12345678calss A(object): x=1class B(A): passclass C(A): passprint A.x, B.x, C.x # 1 1 1B.x = 2print A.x, B.x, C.x # 1 2 1A.x = 3print A.x, B.x, C.x # 3 2 3 3. “/“和”//“1234567891011121314python3:5/2 2.55.0/2 2.55//2 25.0//2 2.0python2:5/2 25.0/2 2.55//2 25.0//2 2.05/2 2.5 # from __future__ import division-5/2 -3 # 和其他编程语言最大的不同 4. 序列分片12345678910111213a = range(5)a[10] # IndexErrora[10:] # []a[1] # seconda[-1] # lasta[~1] # second last取一个List的中间值L = [11, 3, 15, 7, 21, 10, 5]L.sort()half = len(L)//2median = (L[half]+L[~half])/2 5. 闭包的后期绑定(late binding): 闭包的变量，在内部函数被调用时查找。123def multipliers(): return [lambda x: i*x for i in range(4)]print [m(2) for m in multipliers()] # [6, 6, 6, 6] 正确的做法： 1) 使用默认参数立即绑定它的参数 123def multipliers(): return [lambda x, i=i: i*x for i in range(4)]print [m(2) for m in multipliers()] # [0, 2, 4, 6] 2) 使用偏函数 12345from functools import partialfrom operator import muldef multipliers(): return [partial(mul, i) for i in range(4)]print [m(2) for m in multipliers()] # [0, 2, 4, 6] 6. 函数参数，含可变对象123456789def extendList(x, L=[]):L.append(x)return La = extendList(1)b = extendList(2, [&#x27;a&#x27;, &#x27;b&#x27;])c = extendList(3)print a # [1, 3]print b # [&#x27;a&#x27;, &#x27;b&#x27;, 2]print c # [1, 3] 改进： 1234def extendList(x, L=None):if L is None: L = []L.append(x)return L 7. 函数式编程1234filtermapreduceapply 8. 匿名函数lambda: 简单一句话函数 9. 异常try…except…else…finally 10. assertassert 1==1, ‘Not Equality’ # AssertionError 11. copy &amp; deepcopy copy: 浅拷贝，只拷贝可变对象的父级元素 deepcopy: 深拷贝，递归拷贝可变对象的所有元素 12. 装饰器本质上是一个返回函数的函数。它可以让其他函数在不需要做任何代码修改的前提下，进行插桩操作 用于切面编程场景：日志，性能，事务，缓存，权限校验等 13. Python的作用域和变量搜索顺序作用域：变量的命名空间，代码中变量被赋值的位置，就决定；额那些范围内的对象可以访问这个变量，这个范围即为作用域。 只有在module, class, def, lambda才会引入新的作用域 变量的解析顺序:LEGB, Local -&gt; Enclosing locals -&gt; Global -&gt; Built-in 14. 新式类和经典类为了统一类(class)和类型(type)，2.2引入新式类 使用新式类: 1) 继承object 2) __metaclass__ = type 3) Python3默认新式类 15. __new__和__init__new: 创建实例 init: 初始化实例 new第一个参数为cls, init第一个参数为self 16. GCPython GC使用引用计数(reference counting)来追踪和回收垃圾，在引用计数的基础上，通过标记和清除(mark&amp;sweep)解决对象的循环引用问题，通过分代回收(genration collection)以空间换时间，提高垃圾回收效率。 1) 引用计数 PyObject是每个对象的内容，其中ob_refcnt是引用计数，当对象有新引用时，ob_refcnt递增；当对象引用被删除时，ob_refcnt递减。当ob_refcnt等于0时，对象生命周期结束 优点：简单，实时性强 缺点：维护引用计数开销大，循环引用无法解决 2) 标记和清除机制 基本思路是先按需分配，等没有空闲内存时，从寄存器和程序栈的引用出发，遍历对象节点，以引用为边，构造的图，把所有可访问到的对象打上标记，然后清扫一遍内存空间，把所有没有标记的对象释放 3) 分代回收 将系统中的所有内存块，根据其活动时间，划分为不同的集合，每个集合即为一个代。垃圾回收频率，随”代”的活动时间增大而减小。有活动时间通常利用几次垃圾回收来衡量 Python默认定义3代对象集合，引用计数越大，对象活动时间越长 17. @property把一个方法当属性调用，通常用在属性的get/set方法，通过设置，实例可通过属性直接访问，保留了参数的校验 *args, **kwargs*args: 位置参数 **kwargs: 关键字参数 with statement适用于对资源进行访问，确保在访问过程中，无论是否出现异常，均能正常释放资源。比如文件打开和关闭，线程锁的自动获取和释放等 最大公约数和最小公倍数 GCD: greatest common divisor LCM: least common multiple 获取GCD的常用方法： 1) 辗转相除法(欧几里得算法) 定理：两个正整数的最大公约数等于其中较小的那个数和两个数相除的余数的最大公约数。gcd(a,b) = gcd(b,r) # r = a % b 2) 更相减省法 a. 给定两个正整数，判断释放都为偶数，如果是，除以2，直到其中一个不为偶数 b. 以较大数减较小数，接着把所得差与较小数值比较，并再次以大数减小数，直到减数和差相等 c. 此时差即为最大公约数 12345678910111213def gcd(n1, n2): return gcd(n2, n1%n2) if n2&gt;0 else n1def gcd(a, b): while True: while a%2 == 0 and b%2==0: a, b = (a/2, b/2) a, b = (b, abs(a-b)) if a == b: return adef lcm(n1, n2): return n1*n2 / gcd(n1, n2) 21. Fibonacci123F0 = 0F1 = 1Fn = F(n-1) + F(n-2) 22. virtaulenv用来孤立开发和运行环境，特别当需要同时开发多个项目，基于不同的python版本和运行库时，创建一个VE非常重要 1234virtualenv --no-site-package --python=python3.2 ./myenvsource ./myenv/bin/activatepip install -r requirements.txtpip freeze &gt; requirements.txt 23. python的特点1) 解释型语言，运行前不需要编译 2) 动态型语言，声明变量，不需要指定类型，运行时自动指定 3) 适合面向对象的编程(OOP)，支持组合(composition)与继承(inheritant)的类定义(class)，无访问控制符 4) 函数式第一类对象(first-class object)，它可以赋值给变量，也可以接受另一个函数做参数，也可以返回一个函数。类也是第一类对象 5) 编码快，但执行速度慢，可以加入C扩展，提高执行效率 6） 用途广泛，网络，自动化，系统维护等 24. 遍历目录123456789101112def print_directory_content(sPath):for sChild in os.listdir(sPath):sChildPath = os.path.join(sPath, sChild)if os.path.isdir(sChildPath):print_directory_content(sChildPath)else:print sChildPath def print_directory_content(sPath):for root, dirs, names in os.walk(sPath):for fname in files:print os.path.join(sPath, fname) 25. Python多线程Python并不支持真正意义上的多线程，不建议使用多线程包 GIL: Global Interpreter Lock， 即使使用多线程，也顺序执行，不会并发执行 26. 猴子补丁(Monkey patching)函数或对象已经定义后，再去改变它的行为了解mock包 27. 程序执行效率分析包cProfile.run(‘func(a)’) 28. 2.x和3.x的区别12345671) 2.x默认经典类，深度优先继承；3.x默认新式类，广度优先继承2) 编码: 2.x 与系统相关；3.x 默认unicode3) 整除: 2.x 1/2=0；3.x 1/2=0.54) 输入: 2.x raw_input字符串，input表达式；3.x input字符串5) 编码规范: 2.x 模块名大小写混合；3.x 逐步规范6) print: 2.x 关键字；3.x 内置函数7) 3.x支持更好的unpack操作。first, *middle, last = range(10) Python 3.x特性 12345678910111213141516171819202122232425262728去除&lt;&gt;, 统一用!=去除``，统一用expr()加入nonlocal，声明上一层的变量print改为内置函数print x, print(x, end=&#x27; &#x27;)print &gt;&gt;sys.stderr, errors print(&#x27;errors&#x27;, file=sys.stderr)print (x, y) print( (x, y) ) # 输出expr((x, y))super()，可不传入参数字符串只有str一种类型，几乎和2.x中的unicode一样去除long，只保留int新增bytes类型：b = b&#x27;Java&#x27;; s = b.decode(); b = s.encode()字典去除iterkeys()等方法，keys()等方法默认返回迭代器；去除has_key()方法，用in代替迭代器next()方法改成__next__()，新增内置函数next()，用于调用迭代器的__next__方法新增@abstractmethod和@abstractproperty两个 装饰器，定义抽象方法和属性。可以用NotImplementedError来实现zip(), map(), filter()均返回迭代器apply(), callable(), coerce(), execfile(), reduce(), reload()函数被删除string类删除letters, lowercase, uppercase等方法，改用ascii_letters等方法删除file类 29. 列表的和与积123sum(range(10)reduce(add, range(10)) # from operator import addreduce(lambda x,y: x*y, range(10)) 30. pip1) 已安装的包 12pip list #deprecationpip freeze 2) 在线安装 12pip install &lt;pkg&gt;pip install -r requirements.txt 3) 离线安装 12pip install &lt;path/pkg&gt;pip install --no-index -f=&lt;DIR&gt;/ &lt;pkg&gt; 4) 升级 123pip list -o # 可升级的包pip install -U &lt;pkg&gt;pip install &lt;pkg&gt; --upgrade 5) 显示包的安装目录 1pip show -f &lt;pkg&gt; 6) 搜索包 1pip search &lt;pkg&gt; 7) 下载但不安装 12pip install &lt;pkg&gt; -d &lt;DIR&gt;pip install -d &lt;DIR&gt; -r requirements.txt 8) 打包 123456789101112131415pip wheel &lt;pkg&gt;``9) 更换安装源```bashpip install &lt;pkg&gt; -i http://pypi.douban.com/simple`````bashvi ~/.pip/pip.conf[global]index-url = https://pypi.doubanio.com/simple/trusted-host = pypi.douban.com 31. import可导入的对象 模块文件(.py) C/C++扩展(.dll, .so) 包(包含多个模块) 内建模块(使用C编写并链接到Python解释器中) 32. 扩展名 py：源码 pyw: Windows下可双击执行的源码 pyc: 二进制字节码 pyo: -O, 去除assert，断点等调试信息，体积更小，运行更快；–O, 忽略文档信息 pyd：其他语言编写，可以被Python调用的扩展 33. 乐观锁和悲观锁 乐观锁：假设不会发生并发冲突，只在提交时检查是否违反数据完整性。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据安全性的操作 34. MyISAM和InnoDB MyISAM: 表锁，不支持事务，写操作慢，查询快 InnoDB: 行锁，支持事务，写操作优秀 35. XSRF和XSS XSRF：Cross-site request forgery, 跨站请求伪造 XSS：Cross site scripting, 跨站脚本攻击","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python连接MySQL","slug":"Python 连接MySQL","date":"2016-01-02T02:12:54.000Z","updated":"2021-06-22T10:50:49.693Z","comments":true,"path":"2016/01/02/Python 连接MySQL/","link":"","permalink":"https://elihe2011.github.io/2016/01/02/Python%20%E8%BF%9E%E6%8E%A5MySQL/","excerpt":"","text":"1. MySQLdb和pymysql MySQLdb: 2.x, pip install mysql-python pymysql: 2.x, 3.x, pip install pymysql 2. 使用pymysql替换MySQLdb123__init__.pyimport pymysqlpymysql.install_as_MySQLdb() 3. 直连数据库12345678config = &#123; &#x27;host&#x27;: &#x27;localhost&#x27;, &#x27;port&#x27;: 3306, &#x27;user&#x27;: &#x27;root&#x27;, &#x27;password&#x27;: &#x27;&#x27;, &#x27;database&#x27;: &#x27;test&#x27;, &#x27;charset&#x27;: &#x27;utf8&#x27;&#125; 3.1 pymysql123import pymysqldb = pymysql.connect(**config) 3.2 mysql-connector123from mysql import connectordb = connector.connect(**config) 3.3 操作数据库12345678cursor = db.cursor()cursor.execute(&#x27;select * from contents where id=1&#x27;)result = cursor.fetchone()print resultcursor.close()db.close()","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 模块安装","slug":"Python 模块安装","date":"2016-01-01T07:14:11.000Z","updated":"2021-06-22T10:50:49.693Z","comments":true,"path":"2016/01/01/Python 模块安装/","link":"","permalink":"https://elihe2011.github.io/2016/01/01/Python%20%E6%A8%A1%E5%9D%97%E5%AE%89%E8%A3%85/","excerpt":"1. easy_install123easy_install pipeasy_install -i http://pypi.douban.com/simple/ pip --trusted-host pypi.douban.com","text":"1. easy_install123easy_install pipeasy_install -i http://pypi.douban.com/simple/ pip --trusted-host pypi.douban.com 2. pip1234567891011121314pip install ipythonpip install --upgrade pip -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com# python 2.xpip install ipython==5.8.0 -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.comwin: %HOMEPATH%\\pip\\pip.inilinux: ~/.pip/pip.conf[global]index-url = http://pypi.douban.com/simple[install]trusted-host=pypi.douban.com","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python Eventlet","slug":"Python Eventlet","date":"2015-01-21T07:00:30.000Z","updated":"2021-06-22T10:50:49.692Z","comments":true,"path":"2015/01/21/Python Eventlet/","link":"","permalink":"https://elihe2011.github.io/2015/01/21/Python%20Eventlet/","excerpt":"1. greenthread特点 需要人为设置互相让渡CPU控制权，而不是抢占 既能够共享数据结构，又不需要相互控制。只有当一个greenthread主动让出控制权，另一个才能操作共享数据 2. eventlet相关函数说明2.1 孵化绿色线程eventlet.spawn(func, args, *kwargs) 返回greenthread.GreenThread对象 eventlet.spawn_n(func, args, *kwargs) 同上，但无法获取func的返回值和异常 eventlet.spawn_after(seconds, func, args, *kwargs) 等待seconds秒后调用，可调用GreenThread.cancel()退出孵化","text":"1. greenthread特点 需要人为设置互相让渡CPU控制权，而不是抢占 既能够共享数据结构，又不需要相互控制。只有当一个greenthread主动让出控制权，另一个才能操作共享数据 2. eventlet相关函数说明2.1 孵化绿色线程eventlet.spawn(func, args, *kwargs) 返回greenthread.GreenThread对象 eventlet.spawn_n(func, args, *kwargs) 同上，但无法获取func的返回值和异常 eventlet.spawn_after(seconds, func, args, *kwargs) 等待seconds秒后调用，可调用GreenThread.cancel()退出孵化 2.2 控制绿色线程eventlet.sleep(seconds=0) 挂起当前线程 class eventlet.GreenPool 线程池，可控制并发度，进而控制整个并发所消耗的内存 class eventlet.GreenPile 线程间通信 class eventlet.Timeout 线程超时，抛出异常 2.3 补丁函数 方式一：eventlet.import_patched(module_name, *additional_modules, **kw_additional_modules) 引入标准库模块绿化后的版本 12import eventlethttplib2 = eventlet.imported(&#x27;httplib2&#x27;) 方式二：eventlet.monkey_patch(all=True, os=False, select=False, socket=False, thread=False, time=False) 在全局中为指定的系统模块打补丁 12import eventleteventlet.monkey_patch() 2.4 网络运用eventlet.connect(addr, family=2, bind=None) 客户端scoket eventlet.listen(addr, family=2, backlog=50) 服务端socket，backlog最大连接数；可使用serve()或accept()接受连接 eventlet.wrap_ssl(sock, *a, **kw) 将普通socket 转化为ssl socket 12wrap_ssl(connect(addr))wrap_ssl(listen(addr), server_side=True) eventlet.serve(sock, handle, cocurrency=1000) 在给定socket上运行服务器 1234def myhandle(client_sock, client_addr): print(&quot;client connected&quot;, client_addr)eventlet.serve(eventlet.listen((&#x27;127.0.0.1&#x27;, 9999)), myhandle) eventlet.StopServe 妥善退出eventlet.serve()等异常类 3. 绿化操作3.1 from eventlet.green import123from eventlet.green import socketfrom eventlet.green import threadingfrom eventlet.green import asyncore 3.2 import_patched()12345eventlet.patcher.import_patched(module_name, *additional_modules, **kw_additional_modules)from eventlet.green import socket, SocketServerBaseHTTPServer = eventlet.import_patched(&#x27;BaseHTTPServer&#x27;, (&#x27;socket&#x27;, socket), (&#x27;SocketServer&#x27;, SocketSerevr))BaseHTTPServer = eventlet.import_patched(&#x27;BaseHTTPServer&#x27;, socket=socket, SocketServer=SocketServer) 3.3 monkey_patch(), 越早调用越好123456eventlet.patcher.monkey_patch(os=None, select=None, socket=None, thread=None, time=None, psycopg=None)eventlet.monkey_patch()eventlet.monkey_patch(socket=True, select=True)eventlet.patcher.is_monkey_patched(module) 4. 实例4.1 Web Crawlerwebcrawler.py 123456789101112131415161718192021222324252627282930#!/usr/bin/env python&quot;&quot;&quot;This is a simple web &quot;crawler&quot; that fetches a bunch of urls using a pool tocontrol the number of outbound connections. It has as many simultaneously openconnections as coroutines in the pool.The prints in the body of the fetch function are there to demonstrate that therequests are truly made in parallel.&quot;&quot;&quot;import eventletfrom eventlet.green import urllib2urls = [ &quot;https://www.google.com/intl/en_ALL/images/logo.gif&quot;, &quot;http://python.org/images/python-logo.gif&quot;, &quot;http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif&quot;,]def fetch(url): print(&quot;opening&quot;, url) body = urllib2.urlopen(url).read() print(&quot;done with&quot;, url) return url, bodypool = eventlet.GreenPool(200)for url, body in pool.imap(fetch, urls): print(&quot;got body from&quot;, url, &quot;of length&quot;, len(body)) 4.2 WSGI Serverwsgi.py 12345678910111213141516171819&quot;&quot;&quot;This is a simple example of running a wsgi application with eventlet.For a more fully-featured server which supports multiple processes,multiple threads, and graceful code reloading, see:http://pypi.python.org/pypi/Spawning/&quot;&quot;&quot;import eventletfrom eventlet import wsgidef hello_world(env, start_response): if env[&#x27;PATH_INFO&#x27;] != &#x27;/&#x27;: start_response(&#x27;404 Not Found&#x27;, [(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;)]) return [&#x27;Not Found\\r\\n&#x27;] start_response(&#x27;200 OK&#x27;, [(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;)]) return [&#x27;Hello, World!\\r\\n&#x27;]wsgi.server(eventlet.listen((&#x27;&#x27;, 8090)), hello_world) 4.3 Echo Serverechoserver.py 1234567891011121314151617181920212223242526272829303132333435363738#! /usr/bin/env python&quot;&quot;&quot;\\Simple server that listens on port 6000 and echos back every input tothe client. To try out the server, start it up by running this file.Connect to it with: telnet localhost 6000You terminate your connection by terminating telnet (typically Ctrl-]and then &#x27;quit&#x27;)&quot;&quot;&quot;from __future__ import print_functionimport eventletdef handle(fd): print(&quot;client connected&quot;) while True: # pass through every non-eof line x = fd.readline() if not x: break fd.write(x) fd.flush() print(&quot;echoed&quot;, x, end=&#x27; &#x27;) print(&quot;client disconnected&quot;)print(&quot;server socket listening on port 6000&quot;)server = eventlet.listen((&#x27;0.0.0.0&#x27;, 6000))pool = eventlet.GreenPool()while True: try: new_sock, address = server.accept() print(&quot;accepted&quot;, address) pool.spawn_n(handle, new_sock.makefile(&#x27;rw&#x27;)) except (SystemExit, KeyboardInterrupt): break 4.4 Socket Connectconnect.py 12345678910111213141516171819202122232425262728&quot;&quot;&quot;Spawn multiple workers and collect their results.Demonstrates how to use the eventlet.green.socket module.&quot;&quot;&quot;from __future__ import print_functionimport eventletfrom eventlet.green import socketdef geturl(url): c = socket.socket() ip = socket.gethostbyname(url) c.connect((ip, 80)) print(&#x27;%s connected&#x27; % url) c.sendall(&#x27;GET /\\r\\n\\r\\n&#x27;) return c.recv(1024)urls = [&#x27;www.google.com&#x27;, &#x27;www.yandex.ru&#x27;, &#x27;www.python.org&#x27;]pile = eventlet.GreenPile()for x in urls: pile.spawn(geturl, x)# note that the pile acts as a collection of return values from the functions# if any exceptions are raised by the function they&#x27;ll get raised herefor url, result in zip(urls, pile): print(&#x27;%s: %s&#x27; % (url, repr(result)[:50])) 4.5 Multi-User Chat Serverchat_server.py 12345678910111213141516171819202122232425262728293031323334353637383940# This is a little different from the echo server, in that it broadcasts the messages to all participants, not just the sender.import eventletfrom eventlet.green import socketPORT = 3001participants = set()def read_chat_forever(writer, reader): line = reader.readline() while line: print(&quot;Chat:&quot;, line.strip()) for p in participants: try: if p is not writer: # Don&#x27;t echo p.write(line) p.flush() except socket.error as e: # ignore broken pipes, they just mean the participant # closed its connection already if e[0] != 32: raise line = reader.readline() participants.remove(writer) print(&quot;Participant left chat.&quot;)try: print(&quot;ChatServer starting up on port %s&quot; % PORT) server = eventlet.listen((&#x27;0.0.0.0&#x27;, PORT)) while True: new_connection, address = server.accept() print(&quot;Participant joined chat.&quot;) new_writer = new_connection.makefile(&#x27;w&#x27;) participants.add(new_writer) eventlet.spawn_n(read_chat_forever, new_writer, new_connection.makefile(&#x27;r&#x27;))except (KeyboardInterrupt, SystemExit): print(&quot;ChatServer exiting.&quot;) 4.6 Feed Scraperfeedscraper.py 12345678910111213141516171819202122232425262728293031323334353637&quot;&quot;&quot;A simple web server that accepts POSTS containing a list of feed urls,and returns the titles of those feeds.&quot;&quot;&quot;import eventletfeedparser = eventlet.import_patched(&#x27;feedparser&#x27;)# the pool provides a safety limit on our concurrencypool = eventlet.GreenPool()def fetch_title(url): d = feedparser.parse(url) return d.feed.get(&#x27;title&#x27;, &#x27;&#x27;)def app(environ, start_response): if environ[&#x27;REQUEST_METHOD&#x27;] != &#x27;POST&#x27;: start_response(&#x27;403 Forbidden&#x27;, []) return [] # the pile collects the result of a concurrent operation -- in this case, # the collection of feed titles pile = eventlet.GreenPile(pool) for line in environ[&#x27;wsgi.input&#x27;].readlines(): url = line.strip() if url: pile.spawn(fetch_title, url) # since the pile is an iterator over the results, # you can use it in all sorts of great Pythonic ways titles = &#x27;\\n&#x27;.join(pile) start_response(&#x27;200 OK&#x27;, [(&#x27;Content-type&#x27;, &#x27;text/plain&#x27;)]) return [titles]if __name__ == &#x27;__main__&#x27;: from eventlet import wsgi wsgi.server(eventlet.listen((&#x27;localhost&#x27;, 9010)), app) 4.7 Port Forwarderforwarder.py 1234567891011121314151617181920212223242526272829&quot;&quot;&quot; This is an incredibly simple port forwarder from port 7000 to 22 onlocalhost. It calls a callback function when the socket is closed, todemonstrate one way that you could start to do interesting things bystarting from a simple framework like this.&quot;&quot;&quot;import eventletdef closed_callback(): print(&quot;called back&quot;)def forward(source, dest, cb=lambda: None): &quot;&quot;&quot;Forwards bytes unidirectionally from source to dest&quot;&quot;&quot; while True: d = source.recv(32384) if d == &#x27;&#x27;: cb() break dest.sendall(d)listener = eventlet.listen((&#x27;localhost&#x27;, 7000))while True: client, addr = listener.accept() server = eventlet.connect((&#x27;localhost&#x27;, 22)) # two unidirectional forwarders make a bidirectional one eventlet.spawn_n(forward, client, server, closed_callback) eventlet.spawn_n(forward, server, client) 4.8 Recursive Web Crawlerrecursive_crawler.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&quot;&quot;&quot;This is a recursive web crawler. Don&#x27;t go pointing this at random sites;it doesn&#x27;t respect robots.txt and it is pretty brutal about how quickly itfetches pages.The code for this is very short; this is perhaps a good indicationthat this is making the most effective use of the primitves at hand.The fetch function does all the work of making http requests,searching for new urls, and dispatching new fetches. The GreenPoolacts as sort of a job coordinator (and concurrency controller ofcourse).&quot;&quot;&quot;from eventlet.green import urllib2import eventletimport re# http://daringfireball.net/2009/11/liberal_regex_for_matching_urlsurl_regex = re.compile(r&#x27;\\b(([\\w-]+://?|www[.])[^\\s()&lt;&gt;]+(?:\\([\\w\\d]+\\)|([^[:punct:]\\s]|/)))&#x27;)def fetch(url, seen, pool): &quot;&quot;&quot;Fetch a url, stick any found urls into the seen set, and dispatch any new ones to the pool.&quot;&quot;&quot; print(&quot;fetching&quot;, url) data = &#x27;&#x27; with eventlet.Timeout(5, False): data = urllib2.urlopen(url).read() for url_match in url_regex.finditer(data): new_url = url_match.group(0) # only send requests to eventlet.net so as not to destroy the internet if new_url not in seen and &#x27;eventlet.net&#x27; in new_url: seen.add(new_url) # while this seems stack-recursive, it&#x27;s actually not: # spawned greenthreads start their own stacks pool.spawn_n(fetch, new_url, seen, pool)def crawl(start_url): &quot;&quot;&quot;Recursively crawl starting from *start_url*. Returns a set of urls that were found.&quot;&quot;&quot; pool = eventlet.GreenPool() seen = set() fetch(start_url, seen, pool) pool.waitall() return seenseen = crawl(&quot;http://eventlet.net&quot;)print(&quot;I saw these urls:&quot;)print(&quot;\\n&quot;.join(seen)) 4.9 Producer Consumer Web Crawlerproducer_consumer.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&quot;&quot;&quot;This is a recursive web crawler. Don&#x27;t go pointing this at random sites;it doesn&#x27;t respect robots.txt and it is pretty brutal about how quickly itfetches pages.This is a kind of &quot;producer/consumer&quot; example; the fetch function producesjobs, and the GreenPool itself is the consumer, farming out work concurrently.It&#x27;s easier to write it this way rather than writing a standard consumer loop;GreenPool handles any exceptions raised and arranges so that there&#x27;s a setnumber of &quot;workers&quot;, so you don&#x27;t have to write that tedious management codeyourself.&quot;&quot;&quot;from eventlet.green import urllib2import eventletimport re# http://daringfireball.net/2009/11/liberal_regex_for_matching_urlsurl_regex = re.compile(r&#x27;\\b(([\\w-]+://?|www[.])[^\\s()&lt;&gt;]+(?:\\([\\w\\d]+\\)|([^[:punct:]\\s]|/)))&#x27;)def fetch(url, outq): &quot;&quot;&quot;Fetch a url and push any urls found into a queue.&quot;&quot;&quot; print(&quot;fetching&quot;, url) data = &#x27;&#x27; with eventlet.Timeout(5, False): data = urllib2.urlopen(url).read() for url_match in url_regex.finditer(data): new_url = url_match.group(0) outq.put(new_url)def producer(start_url): &quot;&quot;&quot;Recursively crawl starting from *start_url*. Returns a set of urls that were found.&quot;&quot;&quot; pool = eventlet.GreenPool() seen = set() q = eventlet.Queue() q.put(start_url) # keep looping if there are new urls, or workers that may produce more urls while True: while not q.empty(): url = q.get() # limit requests to eventlet.net so we don&#x27;t crash all over the internet if url not in seen and &#x27;eventlet.net&#x27; in url: seen.add(url) pool.spawn_n(fetch, url, q) pool.waitall() if q.empty(): break return seenseen = producer(&quot;http://eventlet.net&quot;)print(&quot;I saw these urls:&quot;)print(&quot;\\n&quot;.join(seen)) 4.10 Websocket Server Examplewebsocket.py 12345678910111213141516171819202122232425262728293031323334353637383940414243import eventletfrom eventlet import wsgifrom eventlet import websocketimport six# demo appimport osimport random@websocket.WebSocketWSGIdef handle(ws): &quot;&quot;&quot; This is the websocket handler function. Note that we can dispatch based on path in here, too.&quot;&quot;&quot; if ws.path == &#x27;/echo&#x27;: while True: m = ws.wait() if m is None: break ws.send(m) elif ws.path == &#x27;/data&#x27;: for i in six.moves.range(10000): ws.send(&quot;0 %s %s\\n&quot; % (i, random.random())) eventlet.sleep(0.1)def dispatch(environ, start_response): &quot;&quot;&quot; This resolves to the web page or the websocket depending on the path.&quot;&quot;&quot; if environ[&#x27;PATH_INFO&#x27;] == &#x27;/data&#x27;: return handle(environ, start_response) else: start_response(&#x27;200 OK&#x27;, [(&#x27;content-type&#x27;, &#x27;text/html&#x27;)]) return [open(os.path.join( os.path.dirname(__file__), &#x27;websocket.html&#x27;)).read()]if __name__ == &quot;__main__&quot;: # run an example app from the command line listener = eventlet.listen((&#x27;127.0.0.1&#x27;, 7000)) print(&quot;\\nVisit http://localhost:7000/ in your websocket-capable browser.\\n&quot;) wsgi.server(listener, dispatch) 4.11 Websocket Multi-User Chat Examplewebsocket_chat.py 123456789101112131415161718192021222324252627282930313233343536373839import osimport eventletfrom eventlet import wsgifrom eventlet import websocketPORT = 7000participants = set()@websocket.WebSocketWSGIdef handle(ws): participants.add(ws) try: while True: m = ws.wait() if m is None: break for p in participants: p.send(m) finally: participants.remove(ws)def dispatch(environ, start_response): &quot;&quot;&quot;Resolves to the web page or the websocket depending on the path.&quot;&quot;&quot; if environ[&#x27;PATH_INFO&#x27;] == &#x27;/chat&#x27;: return handle(environ, start_response) else: start_response(&#x27;200 OK&#x27;, [(&#x27;content-type&#x27;, &#x27;text/html&#x27;)]) html_path = os.path.join(os.path.dirname(__file__), &#x27;websocket_chat.html&#x27;) return [open(html_path).read() % &#123;&#x27;port&#x27;: PORT&#125;]if __name__ == &quot;__main__&quot;: # run an example app from the command line listener = eventlet.listen((&#x27;127.0.0.1&#x27;, PORT)) print(&quot;\\nVisit http://localhost:7000/ in your websocket-capable browser.\\n&quot;) wsgi.server(listener, dispatch)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python Web服务部署","slug":"Python Web服务部署","date":"2015-01-20T06:51:25.000Z","updated":"2021-06-22T10:50:49.692Z","comments":true,"path":"2015/01/20/Python Web服务部署/","link":"","permalink":"https://elihe2011.github.io/2015/01/20/Python%20Web%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/","excerpt":"1. uwsgi1.1 安装uwsgi1pip3 install uwsgi","text":"1. uwsgi1.1 安装uwsgi1pip3 install uwsgi 1.2 配置1234567891011121314151617181920212223vi uswgi.ini[uwsgi]uid = rootgid = rootchmod-socket = 777basedir=/usr/local# 项目目录chdir=%(basedir)/django_blog# 指定项目的applicationmodule=django_blog.wsgi:application# virtualenv路径 home=/usr/local/env_django# 启用主进程master=true# 进程数量 processes=2# 指定sock的文件路径socket=/usr/local/django_blog/uwsgi.sock# 清除环境退出vacuum=true# 日志文件(如果使用的是supervisor管理就不需要开启)#daemonize=/var/log/uwsgi.log 1.3 启动uwsgi1uwsgi -ini uwsgi.ini 1.4 supervisord123456789101112131415161718vi /etc/supervisord.conf.d/django.conf[program:django]directory = /usr/local/django_blog ;命令执行目录command = /usr/bin/uwsgi --ini /usr/local/django_blog/uwsgi.iniautostart=trueautorestart=truedirectory=/data/www/lp-service-daily/user=utimestdout_logfile=/var/log/lp-service-daily-strout.logstdout_logfile_maxbytes=100MBstdout_logfile_backups=5stderr_logfile=/var/log/lp-service-daily-stderr.logstderr_logfile_maxbytes=100MBstderr_logfile_backups=5environment=LP_ENV=&quot;development&quot;# supervisorctl reload 1.5 nginx12345678910location / &#123; include /etc/nginx/uwsgi_params; uwsgi_pass unix:///usr/local/django_blog/uwsgi.sock; &#125; location /static &#123; expires 15d; autoindex on; alias /usr/local/django_blog/static/; &#125; 2. gunicorn2.1 Gunicore: Green Unicore, Python WSGI UNIX HTTP Server 来自Ruby的unicorn 使用pre-fork worker模式，简单，轻量级资源消耗，高性能 Gunicore服务器：WSGI APP的容器，使用gevent，兼容各种WEB框架 2.2 总体架构： gunicorn pre-fork worker模型中有一个管理进程以及几个的工作进程。 管理进程:master 工作进程:worker 每个woker子进程都会单独去实例化我们的wsgi app对象。每个worker中的wsgi app对象是相互独立、互不干扰的。 master的事件循环就是接收信号，管理管理worker进程，而worker进程的事件循环就是监听网络事件并处理（如新建连接，断开连接，处理请求发送响应等等），所以真正的连接最终是连到了worker进程上的 gunicorn 会启动一组 worker进程，所有worker进程公用一组listener，在每个worker中为每个listener建立一个wsgi server。每当有HTTP链接到来时，wsgi server创建一个协程来处理该链接，协程处理该链接的时候，先初始化WSGI环境，然后调用用户提供的app对象去处理HTTP请求。 2.3 安装1pip install gunicorn gunicorn [OPTIONS] APP_MODULE 2.4 实例2.4.1 testapp.py12345678910from flask import Flaskapp = Flask(__name__)@app.route(&#x27;/&#x27;)def index(): return &#x27;hello world!&#x27;if __name__ == &#x27;__main__&#x27;: app.debug = True app.run() gunicorn -b 0.0.0.0:8000 testapp:app 2.4.2 与uwsgi一样，增加一个wsgi.py1234567891011import sysimport oscwd = os.path.split(os.path.realpath(__file__))[0]sys.path.append(cwd)print cwdfrom testapp import appif __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=5004) 2.5 使用配置文件12345678910111213vi gunicorn.pybind = &#x27;127.0.0.1:8000&#x27;daemon = &#x27;false&#x27; # 交由supervisor管理workers = 4 # between 2-4 workers per core in the server, (multiprocessing.cpu_count() * 2) + 1threads = 2worker_class = &#x27;gevent&#x27; # sync, eventlet, gevent, tornado, gthread, 默认syncworker_connections = 2000pidfile = &#x27;/var/run/gunicorn.pid&#x27;accesslog = &#x27;/var/log/gunicorn_access.log&#x27;errorlog = &#x27;/var/log/gunicorn_error.log&#x27;loglevel = &#x27;warning&#x27; 123gunicorn -c gunicorn.py wsgi:appcurl -i -X GET http://localhost:8000","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python WSGI","slug":"Python WSGI","date":"2015-01-19T06:47:16.000Z","updated":"2021-06-22T10:50:49.691Z","comments":true,"path":"2015/01/19/Python WSGI/","link":"","permalink":"https://elihe2011.github.io/2015/01/19/Python%20WSGI/","excerpt":"1. WSGI: Web Server Gateway InterfaceWSGI不是服务器，模块，框架，API或者任何软件，只是一种规范，描述web server如何与web application通信的规范(PEP 3333)。 WSGI协议主要包括server和application两部分： WSGI server负责从客户端接收请求，将request转发给application，将application返回的response返回给客户端； WSGI application接收由server转发的request，处理请求，并将处理结果返回给server。application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现server与application，因此可以在WSGI服务器与WSGI应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器。 WSGI协议其实是定义了一种server与application解耦的规范，即可以有多个实现WSGI server的服务器，也可以有多个实现WSGI application的框架，那么就可以选择任意的server和application组合实现自己的web应用。例如uWSGI和Gunicorn都是实现了WSGI server协议的服务","text":"1. WSGI: Web Server Gateway InterfaceWSGI不是服务器，模块，框架，API或者任何软件，只是一种规范，描述web server如何与web application通信的规范(PEP 3333)。 WSGI协议主要包括server和application两部分： WSGI server负责从客户端接收请求，将request转发给application，将application返回的response返回给客户端； WSGI application接收由server转发的request，处理请求，并将处理结果返回给server。application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现server与application，因此可以在WSGI服务器与WSGI应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器。 WSGI协议其实是定义了一种server与application解耦的规范，即可以有多个实现WSGI server的服务器，也可以有多个实现WSGI application的框架，那么就可以选择任意的server和application组合实现自己的web应用。例如uWSGI和Gunicorn都是实现了WSGI server协议的服务 2. WSGI协议的实现以Django为例，分析一下WSGI协议的具体实现过程。 WSGI把来自socket的数据包解析为http格式，然后进而变化为environ变量，这environ变量里面有wsgi本身的信息(比如 host， post，进程模式等)，还有client的header及body信息。start_respnse是一个函调函数，必须要附带两个参数，一个是status(http状态)，response_headers(响应的header头信息)。 2.1 django WSGI applicationWSGI application应该实现为一个可调用对象，例如函数、方法、类(包含call方法)。需要接收两个参数： environment: 字典，包含客户端请求信息及其他信息，可认为是请求上下文 response回掉函数: 将响应的HTTP status, headers返回给server，同时返回响应正文（reponse body) 1234567891011121314151617181920212223242526272829303132333435363738394041class WSGIHandler(base.BaseHandler): initLock = Lock() request_class = WSGIRequest def __call__(self, environ, start_response): # 加载中间件 if self._request_middleware is None: with self.initLock: try: # Check that middleware is still uninitialized. if self._request_middleware is None: self.load_middleware() except: # Unload whatever middleware we got self._request_middleware = None raise set_script_prefix(get_script_name(environ)) # 请求处理之前发送信号 signals.request_started.send(sender=self.__class__, environ=environ) try: request = self.request_class(environ) except UnicodeDecodeError: logger.warning(&#x27;Bad Request (UnicodeDecodeError)&#x27;, exc_info=sys.exc_info(), extra=&#123;&#x27;status_code&#x27;: 400,&#125;) response = http.HttpResponseBadRequest() else: response = self.get_response(request) response._handler_class = self.__class__ status = &#x27;%s %s&#x27; % (response.status_code, response.reason_phrase) response_headers = [(str(k), str(v)) for k, v in response.items()] for c in response.cookies.values(): response_headers.append((str(&#x27;Set-Cookie&#x27;), str(c.output(header=&#x27;&#x27;)))) # server提供的回调方法，将响应的header和status返回给server start_response(force_str(status), response_headers) if getattr(response, &#x27;file_to_stream&#x27;, None) is not None and environ.get(&#x27;wsgi.file_wrapper&#x27;): response = environ[&#x27;wsgi.file_wrapper&#x27;](response.file_to_stream) return response 可以看出application的流程包括: 加载所有中间件，以及执行框架相关的操作，设置当前线程脚本前缀，发送请求开始信号； 处理请求，调用get_response()方法处理当前请求，该方法的的主要逻辑是通过urlconf找到对应的view和callback，按顺序执行各种middleware和callback。 调用由server传入的start_response()方法将响应header与status返回给server。返回响应正文 2.2 django WSGI Server负责获取http请求，将请求传递给WSGI application，由application处理请求后返回response。以Django内建server为例看一下具体实现。 通过runserver运行django项目，在启动时都会调用下面的run方法，创建一个WSGIServer的实例，之后再调用其serve_forever()方法启动服务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475def run(addr, port, wsgi_handler, ipv6=False, threading=False): server_address = (addr, port) if threading: httpd_cls = type(str(&#x27;WSGIServer&#x27;), (socketserver.ThreadingMixIn, WSGIServer), &#123;&#125;) else: httpd_cls = WSGIServer # 这里的wsgi_handler就是WSGIApplication httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6) if threading: httpd.daemon_threads = True httpd.set_app(wsgi_handler) httpd.serve_forever()``` ### 2.3 WSGI server服务器处理流程中关键的类和方法。![image](http://static.zybuluo.com/rainybowe/vqcu9pqtjgwmv3h2b4g6ede0/xiong%20(2).png)- WSGIServer&lt;br&gt;run()方法会创建WSGIServer实例，主要作用是接收客户端请求，将请求传递给application，然后将application返回的response返回给客户端。 - 创建实例时会指定HTTP请求的handler：WSGIRequestHandler类 - 通过set_app和get_app方法设置和获取WSGIApplication实例wsgi_handler - 处理http请求时，调用handler_request方法，会创建WSGIRequestHandler实例处理http请求。 - WSGIServer中get_request方法通过socket接受请求数据- WSGIRequestHandler - 由WSGIServer在调用handle_request时创建实例，传入request、cient_address、WSGIServer三个参数，__init__方法在实例化同时还会调用自身的handle方法 - handle方法会创建ServerHandler实例，然后调用其run方法处理请求- ServerHandler - WSGIRequestHandler在其handle方法中调用run方法，传入self.server.get_app()参数，获取WSGIApplication，然后调用实例(__call__)，获取response，其中会传入start_response回调，用来处理返回的header和status。 - 通过application获取response以后，通过finish_response返回response- WSGIHandler - WSGI协议中的application，接收两个参数，environ字典包含了客户端请求的信息以及其他信息，可以认为是请求上下文，start_response用于发送返回status和header的回调函数 - 虽然上面一个WSGI server涉及到多个类实现以及相互引用，但其实原理还是调用WSGIHandler，传入请求参数以及回调方法start_response()，并将响应返回给客户端。### 2.4 django simple_serverdjango的simple_server.py模块实现了一个简单的HTTP服务器，并给出了一个简单的demo，可以直接运行，运行结果会将请求中涉及到的环境变量在浏览器中展示出来。其中包括上述描述的整个http请求的所有组件:ServerHandler, WSGIServer, WSGIRequestHandler，以及demo_app表示的简易版的WSGIApplication。可以看一下整个流程：```pythonif __name__ == &#x27;__main__&#x27;: # 通过make_server方法创建WSGIServer实例 # 传入建议application，demo_app httpd = make_server(&#x27;&#x27;, 8000, demo_app) sa = httpd.socket.getsockname() print(&quot;Serving HTTP on&quot;, sa[0], &quot;port&quot;, sa[1], &quot;...&quot;) import webbrowser webbrowser.open(&#x27;http://localhost:8000/xyz?abc&#x27;) # 调用WSGIServer的handle_request方法处理http请求 httpd.handle_request() # serve one request, then exit httpd.server_close() def make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): &quot;&quot;&quot;Create a new WSGI server listening on `host` and `port` for `app`&quot;&quot;&quot; server = server_class((host, port), handler_class) server.set_app(app) return server# demo_app可调用对象，接受请求输出结果def demo_app(environ,start_response): from io import StringIO stdout = StringIO() print(&quot;Hello world!&quot;, file=stdout) print(file=stdout) h = sorted(environ.items()) for k,v in h: print(k,&#x27;=&#x27;,repr(v), file=stdout) start_response(&quot;200 OK&quot;, [(&#x27;Content-Type&#x27;,&#x27;text/plain; charset=utf-8&#x27;)]) return [stdout.getvalue().encode(&quot;utf-8&quot;)] demo_app()表示一个简单的WSGI application实现，通过make_server()方法创建一个WSGIServer实例，调用其handle_request()方法，该方法会调用demo_app()处理请求，并最终返回响应。 3. 实例3.1 返回环境变量123456789101112131415161718192021from wsgiref.simple_server import make_serverdef application(environ, start_response): response_body = [ &#x27;%s: %s&#x27; % (key, value) for key, value in sorted(environ.items()) ] response_body = &#x27;\\n&#x27;.join(response_body) status = &#x27;200 OK&#x27; response_headers = [ (&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body))) ] start_response(status, response_headers) return [response_body]httpd = make_server(&#x27;127.0.0.1&#x27;, 8082, application)httpd.serve_forever() 3.2 GETGET方法，environ环境变量中自动新增两个变量： QUERY_STRING: age=10&amp;hobbies=software&amp;hobbies=tunning REQUEST_METHOD: GET 解析： 12345678910111213In [10]: from cgi import parse_qs, escapeIn [11]: QUERY_STRING = &#x27;age=12&amp;hobbies=Game&amp;hobbies=Reading&#x27;In [12]: d = parse_qs(QUERY_STRING) # 解析url参数In [13]: dOut[13]: &#123;&#x27;age&#x27;: [&#x27;12&#x27;], &#x27;hobbies&#x27;: [&#x27;Game&#x27;, &#x27;Reading&#x27;]&#125;In [14]: s = escape(&#x27;&lt;script&gt;alert(123);&lt;/script&gt;&#x27;) # 编译标记性语言In [15]: sOut[15]: &#x27;&amp;lt;script&amp;gt;alert(123);&amp;lt;/script&amp;gt;&#x27; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from wsgiref.simple_server import make_serverfrom cgi import parse_qs, escapehtml = &quot;&quot;&quot;&lt;html&gt;&lt;body&gt; &lt;form method=&quot;get&quot; action=&quot;&quot;&gt; &lt;p&gt; Age: &lt;input type=&quot;text&quot; name=&quot;age&quot; value=&quot;%(age)s&quot;&gt; &lt;/p&gt; &lt;p&gt; Hobbies: &lt;input name=&quot;hobbies&quot; type=&quot;checkbox&quot; value=&quot;software&quot; %(checked-software)s &gt; Software &lt;input name=&quot;hobbies&quot; type=&quot;checkbox&quot; value=&quot;tunning&quot; %(checked-tunning)s &gt; Auto Tunning &lt;/p&gt; &lt;p&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt; &lt;/p&gt; &lt;/form&gt; &lt;p&gt; Age: %(age)s&lt;br&gt; Hobbies: %(hobbies)s &lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot;def application(environ, start_response): d = parse_qs(environ[&#x27;QUERY_STRING&#x27;]) age = d.get(&#x27;age&#x27;, [&#x27;&#x27;])[0] hobbies = d.get(&#x27;hobbies&#x27;, []) age = escape(age) hobbies = [escape(hobby) for hobby in hobbies] response_body = html % &#123; &#x27;checked-software&#x27;: (&#x27;&#x27;, &#x27;checked&#x27;)[&#x27;software&#x27; in hobbies], &#x27;checked-tunning&#x27;: (&#x27;&#x27;, &#x27;checked&#x27;)[&#x27;tunning&#x27; in hobbies], &#x27;age&#x27;: age or &#x27;Empty&#x27;, &#x27;hobbies&#x27;: &#x27;, &#x27;.join(hobbies or [&#x27;No hobbies?&#x27;]) &#125; status = &#x27;200 OK&#x27; response_headers = [ (&#x27;Content-Type&#x27;, &#x27;text/html&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body))) ] start_response(status, response_headers) return response_bodyhttpd = make_server(&#x27;127.0.0.1&#x27;, 8082, application)httpd.serve_forever() 3.3 POST对于POST请求，查询字符串（query string）是放在HTTP请求正文（request body）中的，而不是放在URL中。请求正文在environment字典变量中键wsgi.input对应的值中，这是一个类似file的变量，这个值是一个。The PEP 3333 指出，请求头中CONTENT_LENGTH字段表示正文的大小，但是可能为空、或者不存在，所以读取请求正文时候要用try/except。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768from wsgiref.simple_server import make_serverfrom cgi import parse_qs, escapehtml = &quot;&quot;&quot;&lt;html&gt;&lt;body&gt; &lt;form method=&quot;post&quot; action=&quot;&quot;&gt; &lt;p&gt; Age: &lt;input type=&quot;text&quot; name=&quot;age&quot; value=&quot;%(age)s&quot;&gt; &lt;/p&gt; &lt;p&gt; Hobbies: &lt;input name=&quot;hobbies&quot; type=&quot;checkbox&quot; value=&quot;software&quot; %(checked-software)s &gt; Software &lt;input name=&quot;hobbies&quot; type=&quot;checkbox&quot; value=&quot;tunning&quot; %(checked-tunning)s &gt; Auto Tunning &lt;/p&gt; &lt;p&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt; &lt;/p&gt; &lt;/form&gt; &lt;p&gt; Age: %(age)s&lt;br&gt; Hobbies: %(hobbies)s &lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot;def application(environ, start_response): try: request_body_size = int(environ.get(&#x27;CONTENT_LENGTH&#x27;, 0)) except ValueError: request_body_size = 0 request_body = environ[&#x27;wsgi.input&#x27;].read(request_body_size) d = parse_qs(request_body) age = d.get(&#x27;age&#x27;, [&#x27;&#x27;])[0] hobbies = d.get(&#x27;hobbies&#x27;, []) age = escape(age) hobbies = [escape(hobby) for hobby in hobbies] response_body = html % &#123; &#x27;checked-software&#x27;: (&#x27;&#x27;, &#x27;checked&#x27;)[&#x27;software&#x27; in hobbies], &#x27;checked-tunning&#x27;: (&#x27;&#x27;, &#x27;checked&#x27;)[&#x27;tunning&#x27; in hobbies], &#x27;age&#x27;: age or &#x27;Empty&#x27;, &#x27;hobbies&#x27;: &#x27;, &#x27;.join(hobbies or [&#x27;No hobbies?&#x27;]) &#125; status = &#x27;200 OK&#x27; response_headers = [ (&#x27;Content-Type&#x27;, &#x27;text/html&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body))) ] start_response(status, response_headers) return response_bodyhttpd = make_server(&#x27;127.0.0.1&#x27;, 8082, application)httpd.serve_forever() 4. Middleware中间件位于WSGI server和WSGI application之间 123456789101112131415161718192021222324252627from wsgiref.simple_server import make_serverdef application(environ, start_response): response_body = &#x27;hello world!&#x27; status = &#x27;200 OK&#x27; response_headers = [ (&#x27;Content-Type&#x27;, &#x27;text/html&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body))) ] start_response(status, response_headers) return response_bodyclass Middleware(object): def __init__(self, app): self.wrapper_app = app def __call__(self, environ, start_response): for data in self.wrapper_app(environ, start_response): yield data.upper()app = Middleware(application)httpd = make_server(&#x27;127.0.0.1&#x27;, 8082, app)httpd.serve_forever() 1. ## WSGI: Web Server Gateway InterfaceWeb服务器与应用之间的通信协议接口，确保HTTP请求，能够转换成python应用的一个功能调用。 每个Web应用必须是一个callable对象，并返回一个iterator 123456789101112131415161718192021222324252627def application(environ, start_response): response_body = &#x27;The request method wad %s&#x27; % environ[&#x27;REQUEST_METHOD&#x27;] # HTTP response code and message status = &#x27;200 OK&#x27; # 响应header是一个列表，列表中存放tuple键值对 response_headers = [(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body)))] # 调用服务器程序提供的 start_response start_response(status, response_headers) # 返回必须 iterable return [response_body]class AppClass(object): def __init__(self): pass def __call__(self, environ, start_response): response_body = &#x27;The request method wad %s&#x27; % environ[&#x27;REQUEST_METHOD&#x27;] status = &#x27;200 OK&#x27; response_headers = [(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;)] start_response(status, response_headers) yield response_body 2. WSGI流程图 服务器启动和处理请求： 3. Flask中实现WSGIWerkzeug: 是一个WSGI的工具组件库，提供对HTTP请求和响应的支持，包含HTTP对象封装、缓存、cookie及文件上传等 提供Request和Response类，处理HTTP请求和响应 提供Map和Rule类，处理URL的模式匹配，每个URL模式对应一个Rule实例 使用SharedDataMiddleware对静态内容的访问支持，即static下的资源可以被外部访问 3.1 app.run()核心：调用werkzeug.serving.run_simple1234567891011121314151617181920class Flask(_PackageBoundObject): # ... def run(self, host=None, port=None, debug=None, **options): from werkzeug.serving import run_simple if host is None: host = &#x27;127.0.0.1&#x27; if port is None: server_name = self.config[&#x27;SERVER_NAME&#x27;] if server_name and &#x27;:&#x27; in server_name: port = int(server_name.rsplit(&#x27;:&#x27;, 1)[1]) else: port = 5000 if debug is not None: self.debug = bool(debug) options.setdefault(&#x27;use_reloader&#x27;, self.debug) options.setdefault(&#x27;use_debugger&#x27;, self.debug) try: run_simple(host, port, self, **options) finally: self._got_first_request = False 3.2 run_simple()函数 核心：make_server()函数 1234567891011121314151617def run_simple(hostname, port, application, ...): &quot;&quot;&quot;Start a WSGI application. Optional features include a reloader, multithreading and fork support.&quot;&quot;&quot; # ... def inner(): try: fd = int(os.environ[&#x27;WERKZEUG_SERVER_FD&#x27;]) except (LookupError, ValueError): fd = None srv = make_server(hostname, port, application, ..., fd=fd) if fd is None: log_startup(srv.socket) srv.serve_forever() # ... 3.3 make_server()函数 核心：返回BaseWSGIServer类对象 123456789101112131415161718def make_server(host=None, port=None, app=None, threaded=False, processes=1, request_handler=None, passthrough_errors=False, ssl_context=None, fd=None): &quot;&quot;&quot;Create a new server instance that is either threaded, or forks or just processes one request after another. &quot;&quot;&quot; if threaded and processes &gt; 1: raise ValueError(&quot;cannot have a multithreaded and &quot; &quot;multi process server.&quot;) elif threaded: return ThreadedWSGIServer(host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd) elif processes &gt; 1: return ForkingWSGIServer(host, port, app, processes, request_handler, passthrough_errors, ssl_context, fd=fd) else: return BaseWSGIServer(host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd) 3.4 BaseWSGIServer类 核心： WSGIRequestHandler类：WSGI请求处理 HTTPServer：启动HTTP服务器，开启监听等 1234567891011121314151617181920212223242526272829303132333435363738394041class BaseWSGIServer(HTTPServer, object): &quot;&quot;&quot;Simple single-threaded, single-process WSGI server.&quot;&quot;&quot; multithread = False multiprocess = False request_queue_size = LISTEN_QUEUE def __init__(self, host, port, app, handler=None, passthrough_errors=False, ssl_context=None, fd=None): if handler is None: handler = WSGIRequestHandler self.address_family = select_ip_version(host, port) # ... HTTPServer.__init__(self, (host, int(port)), handler) self.app = app self.passthrough_errors = passthrough_errors self.shutdown_signal = False self.host = host self.port = port # ... def serve_forever(self): self.shutdown_signal = False try: HTTPServer.serve_forever(self) except KeyboardInterrupt: pass finally: self.server_close() def handle_error(self, request, client_address): if self.passthrough_errors: raise return HTTPServer.handle_error(self, request, client_address) def get_request(self): con, info = self.socket.accept() return con, info 3.5 WSGIRequestHandler 核心：run_wsgi，实现WGSI转发。app(environ, start_response)调用Flask的__call__方法，实现WSGI接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113class WSGIRequestHandler(BaseHTTPRequestHandler, object): &quot;&quot;&quot;A request handler that implements WSGI dispatching.&quot;&quot;&quot; def make_environ(self): request_url = url_parse(self.path) def shutdown_server(): self.server.shutdown_signal = True url_scheme = self.server.ssl_context is None and &#x27;http&#x27; or &#x27;https&#x27; path_info = url_unquote(request_url.path) environ = &#123; &#x27;wsgi.version&#x27;: (1, 0), &#x27;wsgi.url_scheme&#x27;: url_scheme, &#x27;wsgi.input&#x27;: self.rfile, &#x27;wsgi.errors&#x27;: sys.stderr, &#x27;wsgi.multithread&#x27;: self.server.multithread, &#x27;wsgi.multiprocess&#x27;: self.server.multiprocess, &#x27;wsgi.run_once&#x27;: False, &#x27;werkzeug.server.shutdown&#x27;: shutdown_server, &#x27;SERVER_SOFTWARE&#x27;: self.server_version, &#x27;REQUEST_METHOD&#x27;: self.command, &#x27;SCRIPT_NAME&#x27;: &#x27;&#x27;, &#x27;PATH_INFO&#x27;: wsgi_encoding_dance(path_info), &#x27;QUERY_STRING&#x27;: wsgi_encoding_dance(request_url.query), &#x27;CONTENT_TYPE&#x27;: self.headers.get(&#x27;Content-Type&#x27;, &#x27;&#x27;), &#x27;CONTENT_LENGTH&#x27;: self.headers.get(&#x27;Content-Length&#x27;, &#x27;&#x27;), &#x27;REMOTE_ADDR&#x27;: self.address_string(), &#x27;REMOTE_PORT&#x27;: self.port_integer(), &#x27;SERVER_NAME&#x27;: self.server.server_address[0], &#x27;SERVER_PORT&#x27;: str(self.server.server_address[1]), &#x27;SERVER_PROTOCOL&#x27;: self.request_version &#125; for key, value in self.headers.items(): key = &#x27;HTTP_&#x27; + key.upper().replace(&#x27;-&#x27;, &#x27;_&#x27;) if key not in (&#x27;HTTP_CONTENT_TYPE&#x27;, &#x27;HTTP_CONTENT_LENGTH&#x27;): environ[key] = value if request_url.scheme and request_url.netloc: environ[&#x27;HTTP_HOST&#x27;] = request_url.netloc return environ def run_wsgi(self): if self.headers.get(&#x27;Expect&#x27;, &#x27;&#x27;).lower().strip() == &#x27;100-continue&#x27;: self.wfile.write(b&#x27;HTTP/1.1 100 Continue\\r\\n\\r\\n&#x27;) self.environ = environ = self.make_environ() headers_set = [] headers_sent = [] def write(data): assert headers_set, &#x27;write() before start_response&#x27; if not headers_sent: status, response_headers = headers_sent[:] = headers_set try: code, msg = status.split(None, 1) except ValueError: code, msg = status, &quot;&quot; self.send_response(int(code), msg) header_keys = set() for key, value in response_headers: self.send_header(key, value) key = key.lower() header_keys.add(key) if &#x27;content-length&#x27; not in header_keys: self.close_connection = True self.send_header(&#x27;Connection&#x27;, &#x27;close&#x27;) if &#x27;server&#x27; not in header_keys: self.send_header(&#x27;Server&#x27;, self.version_string()) if &#x27;date&#x27; not in header_keys: self.send_header(&#x27;Date&#x27;, self.date_time_string()) self.end_headers() assert isinstance(data, bytes), &#x27;applications must write bytes&#x27; self.wfile.write(data) self.wfile.flush() def start_response(status, response_headers, exc_info=None): if exc_info: try: if headers_sent: reraise(*exc_info) finally: exc_info = None elif headers_set: raise AssertionError(&#x27;Headers already set&#x27;) headers_set[:] = [status, response_headers] return write def execute(app): # 调用Flask的__call__方法 application_iter = app(environ, start_response) try: for data in application_iter: write(data) if not headers_sent: write(b&#x27;&#x27;) finally: if hasattr(application_iter, &#x27;close&#x27;): application_iter.close() application_iter = None try: execute(self.server.app) # 实现wsgi接口 except (socket.error, socket.timeout) as e: self.connection_dropped(e, environ) except Exception: # ... # ... 3.6 __call__和wsgi_app实现WGSI应用123456789101112131415161718192021222324class Flask(_PackageBoundObject): # ... def wsgi_app(self, environ, start_response): &quot;&quot;&quot;The actual WSGI application.&quot;&quot;&quot; ctx = self.request_context(environ) # 创建请求上下文 ctx.push() error = None try: try: # 通过flask的路由寻找对应的视图函数进行处理 response = self.full_dispatch_request() except Exception as e: error = e response = self.handle_exception(e) return response(environ, start_response) finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) def __call__(self, environ, start_response): &quot;&quot;&quot;Shortcut for :attr:`wsgi_app`.&quot;&quot;&quot; return self.wsgi_app(environ, start_response) 4. 路由的实现路由的作用：根据http请求的url，找到相关的处理函数 实现：通过werkzeug的Map和Rule类 Map: 提供ImmutableDict来储存URL的Rule实体 Rule: URL与endpoint的一对一的模式匹配 4.1 路由的实现示例12345678910111213141516from werkzeug.exceptions import HTTPExceptionfrom werkzeug.routing import Map, Ruleurl_map = Map([ Rule(&#x27;/&#x27;, endpoint=&#x27;index&#x27;), Rule(&#x27;/about&#x27;, endpoint=&#x27;about&#x27;),])def application(environ, start_response): urls = url_map.bind_to_environ(environ) try: endpoint, args = urls.match() except HTTPException as e: return e(environ, start_response) start_response(&#x27;200 OK&#x27;, [(&#x27;Content-Type&#x27;, &#x27;text/plain&#x27;)]) return [&#x27;Rule pointsto %r with arguments %r&#x27; % (endpoint, args)] 4.2 Flask实现路由。@app.route(‘/‘)1234567891011121314151617181920212223242526272829class Flask(_PackageBoundObject): # ... def route(self, rule, **options): def decorator(f): endpoint = options.pop(&#x27;endpoint&#x27;, None) self.add_url_rule(rule, endpoint, f, **options) return f return decorator @setupmethod def add_url_rule(self, rule, endpoint=None, view_func=None, **options): if endpoint is None: endpoint = _endpoint_from_view_func(view_func) options[&#x27;endpoint&#x27;] = endpoint methods = options.pop(&#x27;methods&#x27;, None) # ... rule = self.url_rule_class(rule, methods=methods, **options) rule.provide_automatic_options = provide_automatic_options self.url_map.add(rule) if view_func is not None: old_func = self.view_functions.get(endpoint) if old_func is not None and old_func != view_func: raise AssertionError(&#x27;View function mapping is overwriting an &#x27; &#x27;existing endpoint function: %s&#x27; % endpoint) self.view_functions[endpoint] = view_func 4.3 处理请求4.3.1 wsgi_app中，调用full_dispatch_request函数12345678910111213141516171819class Flask(): # ... def full_dispatch_request(self): &quot;&quot;&quot;Dispatches the request and on top of that performs request pre and postprocessing as well as HTTP exception catching and error handling. .. versionadded:: 0.7 &quot;&quot;&quot; self.try_trigger_before_first_request_functions() try: request_started.send(self) rv = self.preprocess_request() if rv is None: rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) return self.finalize_request(rv) try_trigger_before_first_request_functions =&gt; @app.before_first_request preprocess_request =&gt; @app.before_request dispatch_request 核心处理函数 finalize_request 组装请求响应 4.3.2 dispatch_request123456789101112131415class Flask(): # ... def dispatch_request(self): req = _request_ctx_stack.top.request if req.routing_exception is not None: self.raise_routing_exception(req) rule = req.url_rule # if we provide automatic options for this URL and the # request came with the OPTIONS method, reply automatically if getattr(rule, &#x27;provide_automatic_options&#x27;, False) \\ and req.method == &#x27;OPTIONS&#x27;: return self.make_default_options_response() # otherwise dispatch to the handler for that endpoint return self.view_functions[rule.endpoint](**req.view_args) 5. WSGI实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130import copyimport osimport reimport socketfrom threading import Threadhtml_dir = &#x27;/Users/eli/Desktop&#x27;def read_file(filename): with open(filename) as f: return f.read()def read_icon(filename): with open(filename, &#x27;rb&#x27;) as f: return f.read()def app(environ, start_response): uri = environ.get(&#x27;uri&#x27;, &#x27;&#x27;) if uri == &#x27;/favicon.ico&#x27;: path = os.path.join(html_dir, &#x27;favicon.ico&#x27;) if os.path.exists(path): status = &#x27;200 OK&#x27; response_body = read_icon(path) else: status = &#x27;404 Not Found&#x27; response_body = &#x27;Icon &lt;favicon.ico&gt; is not found!&#x27; response_headers = [ (&#x27;Content-Type&#x27;, &#x27;image/x-icon&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body))) ] else: if uri in (&#x27;/&#x27;, &#x27;/index&#x27;): html = &#x27;index.html&#x27; else: html = uri.lstrip(&#x27;/&#x27;) path = os.path.join(html_dir, html) if os.path.exists(path): status = &#x27;200 OK&#x27; response_body = read_file(path) else: status = &#x27;404 Not Found&#x27; response_body = &#x27;File &lt;%s&gt; is not found!&#x27; % html response_headers = [ (&#x27;Content-Type&#x27;, &#x27;text/html&#x27;), (&#x27;Content-Length&#x27;, str(len(response_body))) ] start_response(status, response_headers) return response_bodydef app_wrapper(func): def wrapper(*args, **kwargs): if args and isinstance(args[0], dict): for k, v in args[0].items(): if isinstance(v, str): args[0][k] = v.upper() return func(*args, **kwargs) return wrapperclass WSGI(object): def __init__(self, app_, host=&#x27;127.0.0.1&#x27;, port=8000): self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) self.server.bind((host, port)) self.server.listen(5) self.app = app_ environ = dict(os.environ.items()) environ[&#x27;wsgi.version&#x27;] = (1, 0) environ[&#x27;wsgi.multithread&#x27;] = False environ[&#x27;wsgi.multiprocess&#x27;] = True environ[&#x27;wsgi.run_once&#x27;] = True environ[&#x27;wsgi.url_scheme&#x27;] = &#x27;http&#x27; self.environ = environ self.response_header = &#x27;&#x27; def run(self): while True: print(&#x27;waiting......&#x27;) client, (ip, port) = self.server.accept() print(&#x27;connecting %s:%s&#x27; % (ip, port)) Thread(target=self._handler, args=(client, )).run() def start_response(self, status, response_headers, exec_info=None): _ = exec_info response_header = &#x27;HTTP/1.1 &#x27; + status + &#x27;\\r\\n&#x27; for header in response_headers: response_header += &#x27;%s:%s\\r\\n&#x27; % header self.response_header = response_header def _handler(self, client): receive = client.recv(1024) receive_lines = receive.splitlines() print(&#x27;receive_lines&#x27;, receive_lines) uri = &#x27;&#x27; if receive_lines: uri = re.match(r&#x27;\\w+ +(/[^ ]*) &#x27;, receive_lines[0].decode(&#x27;utf-8&#x27;)).group(1) environ = copy.deepcopy(self.environ) environ[&#x27;uri&#x27;] = uri response_start_line = &#x27;&#x27; try: response_body = self.app(environ, self.start_response) except Exception as e: print(e) response_start_line = &#x27;HTTP/1.1 500 Server Internal Error&#x27; response_body = str(e) response_headers = self.response_header # print(response_headers) response = response_start_line + response_headers + &#x27;\\r\\n&#x27; + response_body self.response_header = &#x27;&#x27; print() print(&#x27;+&#x27; * 20) print(response) print(&#x27;+&#x27; * 20) client.send(response.encode(&#x27;utf-8&#x27;)) client.close()if __name__ == &#x27;__main__&#x27;: wsgi = WSGI(app, port=8090) wsgi.run()","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 时间处理","slug":"Python 时间处理","date":"2015-01-18T06:39:59.000Z","updated":"2021-06-22T10:50:49.690Z","comments":true,"path":"2015/01/18/Python 时间处理/","link":"","permalink":"https://elihe2011.github.io/2015/01/18/Python%20%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/","excerpt":"1. datetime1.1 datetime123456789101112from datetime import datetimenow = datetime.now()ts = dt.timestamp()dt = datetime.fromtimestamp(ts)utc_dt = datetime.utcfromtimestamp(ts)dt = datetime(2013, 11, 19, 23, 21, 17)dt = datetime.strptime(&#x27;2017-12-1 21:22:56&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;)fmt = dt.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;)","text":"1. datetime1.1 datetime123456789101112from datetime import datetimenow = datetime.now()ts = dt.timestamp()dt = datetime.fromtimestamp(ts)utc_dt = datetime.utcfromtimestamp(ts)dt = datetime(2013, 11, 19, 23, 21, 17)dt = datetime.strptime(&#x27;2017-12-1 21:22:56&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;)fmt = dt.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;) 1.2 timedelta123from datetime import timedeltayesterday = datetime.now() + timedelta(days=-1) 1.3 timezone1234567from datetime import timezoneutc = datetime.utcnow().replace(tzinfo=timezone.utc) # 强制将该时间设置为utc+0utc8 = utc.astimezone(timezone(timedelta(hours=8)))utc2 = utc8.astimezone(timezone(timedelta(hours=2))) 123dt = datetime.strptime(&#x27;2015-1-21 9:01:30&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;)dt_utc8 = dt.replace(tzinfo=timezone(timedelta(hours=8))) # 使用正确的时区dt_utc5 = dt_utc8.astimezone(timezone(timedelta(hours=5))) 2. time2.1 时间戳12345678ts = time.time() # wall clock secondsstruct_time = time.localtime()struct_time = time.gmtime()ts = time.mktime(time_struct)ts = time.mktime((2013, 11, 18, 16, 0, 0, 0, 322, 0)) # 最后三个必选参数不好确定，尽量不使用time.struct_time(tm_year=2013, tm_mon=11, tm_mday=18, tm_hour=16, tm_min=0, tm_sec=0, tm_wday=0, tm_yday=322, tm_isdst=-1) 2.2 格式化12s = time.strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;, struct_time )struct_time = time.strptime(&#x27;2013-11-18 16:00:00&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;) 2.3 输出可读时间12345time.ctime([timestamp])time.ctime(time.time())time.asctime([time_struct])time.asctime(time.localtime()) 3. date命令12345678date -u UTC datedate -R 显示时区偏移量export TZ=UTC-3date -R # Fri, 13 Jul 2018 06:30:55 +0300export TZ=UTC+5date -R # Thu, 12 Jul 2018 22:31:30 -0500","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 序列化","slug":"Python 序列化","date":"2015-01-17T06:36:08.000Z","updated":"2021-06-22T10:50:49.690Z","comments":true,"path":"2015/01/17/Python 序列化/","link":"","permalink":"https://elihe2011.github.io/2015/01/17/Python%20%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"1.picklepickle.dumps(): 将对象序列化成一个bytes 12d = dict(name=&#x27;Bob&#x27;, age=20, score=88)bytes = pickle.dumps(m)","text":"1.picklepickle.dumps(): 将对象序列化成一个bytes 12d = dict(name=&#x27;Bob&#x27;, age=20, score=88)bytes = pickle.dumps(m) pickle.dump(): 将对象序列化后写入一个file-like Object 123f = open(&#x27;dump.txt&#x27;, &#x27;wb&#x27;)pickle.dump(d, f)f.close() pickle.loads(): 反序列化出对象 1d = pickle.loads(bytes) pickle.load(): 从一个file-like Object中反序列化对象 12f = open(&#x27;dump.txt&#x27;, &#x27;rb&#x27;)d = pickle.load(f) 2. jsonjson.dumps() 导出成json字符串 1j = json.dumps(d) json.dump() 导出到file-like Object json.loads() 从json字符串导入成对象 1d = json.loads(j) json.load() 从file-like Object导入成对象 普通对象的json化 1234567891011121314151617181920212223242526272829class Student: def __init__(self, name, age, score): self.name = name self.age = age self.score = score def __str__(self): return &#x27;&#123;&#125;:&#123;&#125;:&#123;&#125;&#x27;.format(self.name, self.age, self.score)def serialize(s): return &#123;&#x27;name&#x27;: s.name, &#x27;age&#x27;: s.age, &#x27;score&#x27;: s.score&#125;def deserialize(d): return Student(**d)if __name__ == &#x27;__main__&#x27;: import json s = Student(&#x27;alex&#x27;, 21, 98) #j = json.dumps(s, default=serialize) j = json.dumps(s, default=lambda obj: obj.__dict__) print(j) s1 = json.loads(j, object_hook=deserialize) print(s1)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python collections","slug":"Python collections","date":"2015-01-16T01:25:45.000Z","updated":"2021-06-22T10:50:49.689Z","comments":true,"path":"2015/01/16/Python collections/","link":"","permalink":"https://elihe2011.github.io/2015/01/16/Python%20collections/","excerpt":"1. namedtuple1234567from collections import namedtuplePoint = namedtuple(&#x27;Point&#x27;, (&#x27;x&#x27;, &#x27;y&#x27;))p = Point(2, 7)print(p.x)print(isinstance(p, tuple)) # True","text":"1. namedtuple1234567from collections import namedtuplePoint = namedtuple(&#x27;Point&#x27;, (&#x27;x&#x27;, &#x27;y&#x27;))p = Point(2, 7)print(p.x)print(isinstance(p, tuple)) # True 2. deque 双向list1234567891011from collections import dequeq = deque([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])q.append(1)q.appendleft(9)print(q) # deque([9, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, 1])q.pop() # 1q.popleft() # 9print(q) # deque([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]) 3. defaultdict 带默认值的dict123456dd = defaultdict(lambda: &#x27;NA&#x27;)dd[&#x27;key1&#x27;] = &#x27;abc&#x27;print(dd[&#x27;key1&#x27;]) # abcprint(dd[&#x27;key2&#x27;]) # NAprint(dd.get(&#x27;key2&#x27;)) # NA 4. OrderedDict1234from collections import OrderedDictod = OrderedDict([(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 3)])print(list(od.keys())) # [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] 实现FIFO dict 12345678910111213141516171819202122232425262728293031323334from collections import OrderedDictclass LastUpdatedOrderedDict(OrderedDict): def __init__(self, capacity): super(LastUpdatedOrderedDict, self).__init__() self._capacity = capacity def __setitem__(self, key, value): has_key = 1 if key in self else 0 if len(self) - has_key &gt;= self._capacity: last = self.popitem(last=False) # 弹出前面的key-value,last=true 采用LIFI，last=false采用FIFO print(&#x27;remove:&#x27;, last) if has_key: del self[key] # 删除原位置的key print(&#x27;reset:&#x27;, (key, value)) else: print(&#x27;add:&#x27;, (key, value)) super(LastUpdatedOrderedDict, self).__setitem__(key, value)if __name__ == &#x27;__main__&#x27;: lpod = LastUpdatedOrderedDict(5) lpod[&#x27;a&#x27;] = 1 lpod[&#x27;b&#x27;] = 2 lpod[&#x27;c&#x27;] = 3 lpod[&#x27;d&#x27;] = 4 lpod[&#x27;e&#x27;] = 5 lpod[&#x27;a&#x27;] = 6 lpod[&#x27;z&#x27;] = 7 print(lpod) # LastUpdatedOrderedDict([(&#x27;c&#x27;, 3), (&#x27;d&#x27;, 4), (&#x27;e&#x27;, 5), (&#x27;a&#x27;, 6), (&#x27;z&#x27;, 7)]) 5. Counter 计数器12345678from collections import Counterc = Counter()for ch in &#x27;abcccba&#x27;: c[ch] += 1print(c) # Counter(&#123;&#x27;c&#x27;: 3, &#x27;a&#x27;: 2, &#x27;b&#x27;: 2&#125;)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 加密","slug":"Python 加密","date":"2015-01-15T06:31:27.000Z","updated":"2021-06-22T10:50:49.689Z","comments":true,"path":"2015/01/15/Python 加密/","link":"","permalink":"https://elihe2011.github.io/2015/01/15/Python%20%E5%8A%A0%E5%AF%86/","excerpt":"1. md5生成128 bit字节，通常用一个32位的16进制字符串表示 1234567import hashlibmd5 = hashlib.md5()md5.update(&#x27;password&#x27;.encode(&#x27;utf-8&#x27;))print(md5.hexdigest()) # &#x27;5f4dcc3b5aa765d61d8327deb882cf99&#x27;","text":"1. md5生成128 bit字节，通常用一个32位的16进制字符串表示 1234567import hashlibmd5 = hashlib.md5()md5.update(&#x27;password&#x27;.encode(&#x27;utf-8&#x27;))print(md5.hexdigest()) # &#x27;5f4dcc3b5aa765d61d8327deb882cf99&#x27; 2. sha1160 bit字节，通常用一个40位的16进制字符串表示 1234567import hashlibsha1 = hashlib.sha1()sha1.update(&#x27;password&#x27;.encode(&#x27;utf-8&#x27;))print(sha1.hexdigest()) # &#x27;5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8&#x27; 3. sha25612345sha256 = hashlib.sha256()sha256.update(&#x27;password&#x27;.encode(&#x27;utf-8&#x27;))print(sha256.hexdigest() # &#x27;5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8&#x27; 4. hmacHMAC: Keyed-Hashing for Message Authentication。它通过一个标准算法，在计算哈希的过程中，把key混入计算过程中。 123456789import hmacdef hmac_md5(key, message): return hmac.new(key.encode(&#x27;utf-8&#x27;), message.encode(&#x27;utf-8&#x27;), &#x27;MD5&#x27;).hexdigest() key = &#x27;secret&#x27;message = &#x27;Hello, world!&#x27;print(hmac_md5(key, message)) # &#x27;fa4ee7d173f2d97ee79022d1a7355bcf&#x27; 5. base64base64编码: 把3个8位字节（38=24）转化为4个6位的字节（46=24），然后每6位的前面补两个0，形成新的8位, 即1字节。 剩下的字符如果不足3个字节，则用0填充，输出字符使用’=’，因此编码后输出的文本末尾可能会出现1或2个’=’。 新编码的字符，每个最多6位有效位，因此最多需要2^6=64个字符来表示 编码表：A-Za-z0-9+- 123456789import base64s = b&#x27;binary\\x00string&#x27;base64str = base64.b64encode(s)binstr = base64.b64decode(base64str)assert s == binstr","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 内存管理","slug":"Python 内存管理","date":"2015-01-14T03:35:13.000Z","updated":"2021-06-22T10:50:49.688Z","comments":true,"path":"2015/01/14/Python 内存管理/","link":"","permalink":"https://elihe2011.github.io/2015/01/14/Python%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","excerpt":"1. 如何在环状数据结构中管理内存？案例：在python中，GC通过引用计数器来回收垃圾对象，但某些环状结构数据(树，图)，存在对象间的循环引用。比如树的父节点引用子节点，子节点也同时引用父节点。此时同时del引用父子节点，两个对象不能被立即回收如何解决此类的内存管理问题？ 12345678910111213141516class A(object): def __del__(self): print(&#x27;in A.__del__&#x27;) a = A()import syssys.getrefcount(a)a2 = asys.getrefcount(a)del a2sys.getrefcount(a)a = 5 &#x27;in A.__del__&#x27;","text":"1. 如何在环状数据结构中管理内存？案例：在python中，GC通过引用计数器来回收垃圾对象，但某些环状结构数据(树，图)，存在对象间的循环引用。比如树的父节点引用子节点，子节点也同时引用父节点。此时同时del引用父子节点，两个对象不能被立即回收如何解决此类的内存管理问题？ 12345678910111213141516class A(object): def __del__(self): print(&#x27;in A.__del__&#x27;) a = A()import syssys.getrefcount(a)a2 = asys.getrefcount(a)del a2sys.getrefcount(a)a = 5 &#x27;in A.__del__&#x27; 1234567891011121314151617181920class Data(object): def __init__(self, value, owner): self.owner = owner self.value = value def __str__(self): return &quot;%s&#x27;s data, value is %s&quot; % (self.owner, self.value) def __del__(self): print(&#x27;in Data.__del__&#x27;) class Node(object): def __init__(self, value): self.data = Data(value, self) def __del_(self): print(&#x27;in Node.__del_&#x27;) node = Node(100)del node 2. 尝试使用gc强制回收，也不能回收1234import gcgc.collect()input(&#x27;end&#x27;) 3. 弱引用：增加绑定变量，但不增加它的引用计数1234567891011121314151617181920212223242526272829303132333435363738a = A()sys.getrefcount(a) - 1import weakrefa_wref = weakref.ref(a)a2 = a_wref()sys.getrefcount(a) - 1del adel a2a_wref() is None # 引用的对象不存在，若引用返回Noneimport weakrefclass Data(object): def __init__(self, value, owner): self.owner = weakref.ref(owner) self.value = value def __str__(self): return &quot;%s&#x27;s data, value is %s&quot; % (self.owner(), self.value) def __del__(self): print(&#x27;in Data.__del__&#x27;) class Node(object): def __init__(self, value): self.data = Data(value, self) def __del__(self): print(&#x27;in Node.__del__&#x27;) node = Node(100)del nodeinput(&#x27;end&#x27;)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 类和实例","slug":"Python 类和实例","date":"2015-01-13T06:27:38.000Z","updated":"2021-06-22T10:50:49.687Z","comments":true,"path":"2015/01/13/Python 类和实例/","link":"","permalink":"https://elihe2011.github.io/2015/01/13/Python%20%E7%B1%BB%E5%92%8C%E5%AE%9E%E4%BE%8B/","excerpt":"1. 创建和初始化类实例相关方法： __init__(self, *args, **kwargs): 初始化对象，在创建新对象时调用 __del__(self): 释放对象，在删除对象时调用 __new__(cls, *args, **kwargs): 生成实例，先于__init__()前操作1234567891011121314151617### 1.1 单例```pythonclass Singleton: def __new__(cls, *args, **kwargs): if not hasattr(cls, &#x27;instance&#x27;): cls.instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls.instanceif __name__ == &#x27;__main__&#x27;: a = Singleton() b = Singleton() a.x = 1 print(b.x) print(a is b)","text":"1. 创建和初始化类实例相关方法： __init__(self, *args, **kwargs): 初始化对象，在创建新对象时调用 __del__(self): 释放对象，在删除对象时调用 __new__(cls, *args, **kwargs): 生成实例，先于__init__()前操作1234567891011121314151617### 1.1 单例```pythonclass Singleton: def __new__(cls, *args, **kwargs): if not hasattr(cls, &#x27;instance&#x27;): cls.instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls.instanceif __name__ == &#x27;__main__&#x27;: a = Singleton() b = Singleton() a.x = 1 print(b.x) print(a is b) 1.1.1 单例应用实例12345678910111213141516171819202122232425import threadingclass Singleton: __instance = None __lock = threading.Lock() @staticmethod def get_instance(): if Singleton.__instance is None: Singleton.__lock.acquire() if Singleton.__instance is None: Singleton.__instance = object.__new__(Singleton) object.__init__(Singleton.__instance) Singleton.__lock.release() return Singleton.__instanceif __name__ == &#x27;__main__&#x27;: a = Singleton.get_instance() b = Singleton.get_instance() a.x = 1 print(b.x) print(a is b) 2. 类属性和方法2.1 使用property属性1）使用方法 x = property(fget, fset, fdel, doc) 1234567891011121314151617181920class C(object): def __init__(self): self.__x = None def setx(self, x): self.__x = x def getx(self): return self.__x def delx(self): self.__x = None x = property(getx, setx, delx, &#x27;x property doc&#x27;)c = C()c.x = 1print c.xdel c.xprint c.x 2) 使用装饰器 @property, @x.setter, @x.deleter 123456789101112131415161718192021class C(object): def __init__(self): self.__x = None @property def x(self): return self.__x @x.setter def x(self, value): self.__x = value @x.deleter def x(self): self.__x = Nonec = C()c.x = 1print c.xdel c.xprint c.x 2.2 类方法和静态方法 相同点：都可以通过类直接调用 不同点：类方法需要将类作为参数传入，静态方法不需要传入类参数 123456789101112131415161718192021class C(object): name = &#x27;C&#x27; def foo(self): print &#x27;call instance method&#x27; @staticmethod def static_method(): print &#x27;call static method&#x27; @classmethod def class_method(cls): print &#x27;call class method&#x27; print &#x27;class name:&#x27;, cls.name cls.static_method() instance = cls() instance.foo()C.static_method()print &#x27;x&#x27; * 20C.class_method() 2.3 Descriptor: 将某种特殊类型的类的实例指派给另一个类的属性123__get__(self, object, type=None)__set__(self, obj, value)__delete__(self, obj) 123456789101112131415161718class Descriptor(object): def __get__(self, obj, type): print &#x27;get&#x27;, self, obj, type def __set__(self, obj, value): print &#x27;set&#x27;, self, obj, valueclass Demo(object): desc = Descriptor()demo = Demo()demo.desc = &#x27;abc&#x27;print demo.descprint type(demo)type(demo).__dict__[&#x27;desc&#x27;].__get__(demo, type(demo))type(demo).__dict__[&#x27;desc&#x27;].__get__(demo, str) 3. 实例的属性12345678910111213__setattr__(self, name, value)__delattr__(self, name)__getattr__(self, name) 仅对未定义的属性有效，动态返回一个属性__getattribute__(self, name) 对所有属性都有效同时存在，__getattr__不会被调用。除非显示调用它，或者__getattribute__触发AttributeError错误def __getattribute__(self, name): return self.name # 错误，自我无限循环 return object.__getattribute__(self, name) # 正确获取对象属性的顺序：先从self.__dict__(通过__getattribute__)搜索，找不到再通过__getattr__获取 12345678910111213141516171819202122232425262728class Student: def __init__(self, name): self.name = name # 属性找不到再找我 def __getattr__(self, name): if name == &#x27;age&#x27;: return 20 if name == &#x27;name&#x27;: return &#x27;eli&#x27; raise AttributeError # 不允许修改私有属性 def __setattr__(self, name, value): if name == &#x27;id&#x27;: raise AttributeError # self.name = value # 死循环 super(Student, self).__setattr__(name, value)if __name__ == &#x27;__main__&#x27;: s = Student(&#x27;alex&#x27;) print(s.name) # alex print(s.age) # 20 s.score = 90 print(s.score) s.id = 2 # AttributeError 12345678910111213141516class Chain: def __init__(self, path): self._path = path def __getattr__(self, path): return Chain(&#x27;&#123;&#125;/&#123;&#125;&#x27;.format(self._path, path)) def __str__(self): return self._path __repr__ = __str__if __name__ == &#x27;__main__&#x27;: c = Chain(&#x27;/users/status&#x27;) print(c.timeline.list) # /users/status/timeline/list 4. 序列化类123__getitem____setitem____delitem__ 1234567891011121314151617181920212223242526272829class Fib: def __getitem__(self, n): if isinstance(n, (int,)): a, b = 1, 1 for x in range(n): a, b = b, a + b return a elif isinstance(n, slice): start = n.start stop = n.stop if start is None: start = 0 a, b = 1, 1 L = [] for x in range(stop): if x &gt;= start: L.append(a) a, b = b, a + b return Lif __name__ == &#x27;__main__&#x27;: f = Fib() for i in range(10): print(f[i], end=&#x27; &#x27;) print() print(f[2:10]) 123456789101112131415161718192021222324252627282930313233class Sequence: def __init__(self, start=0, step=1): self.start = start self.step = step self._res = &#123;&#125; def __setitem__(self, key, value): self._res[key] = value def __getitem__(self, key): try: return self._res[key] except: return self.start + self.step * key def __delitem__(self, key): try: del self._res[key] except: pass def __len__(self): return len(self._res)if __name__ == &#x27;__main__&#x27;: s = Sequence(1, 2) print(s[3]) s[3] = 100 print(s[3]) del s[3] print(s[3]) 5. 可调用类1__call__ 123456789101112class Student: def __init__(self, name): self.name = name def __call__(self): print(&#x27;i am &#123;&#125;&#x27;.format(self.name))if __name__ == &#x27;__main__&#x27;: s = Student(&#x27;alex&#x27;) if callable(s): s() 6. 可迭代类12345678910111213141516class Fib: def __init__(self): self.a, self.b = 0, 1 def __iter__(self): return self def __next__(self): self.a, self.b = self.b, self.a + self.b if self.a &gt; 1000: raise StopIteration return self.aif __name__ == &#x27;__main__&#x27;: for i in Fib(): print(i, end=&#x27; &#x27;) 7. 类私有属性 _xx: protected，只允许类本身，子类和类的实例访问。 __xx: private，只允许类本身访问。子类和实例均不能访问。 (private name mangling) 但可以通过obj._ClassName__xx方式访问。 __xx__: magic method 8. 可比较类123__eq____lt____gt__ 简化操作：functools.total_ordering，使用total_ordering装饰类 12345678910111213141516171819202122from functools import total_ordering@total_orderingclass Rectangle(object): def __init__(self, w, h): self.w = w self.h = h @property def area(self): return self.w * self.h def __eq__(self, obj): return self.area == obj.area def __lt__(self, obj): return self.area &lt; obj.area a = Rectangle(3, 6)b = Rectangle(4, 5)print(a &gt; b) 12345678910111213141516171819202122232425262728293031323334353637from functools import total_orderingfrom abc import abstractmethod@total_orderingclass Shape(object): def __lt__(self, obj): return self.area &lt; obj.area def __eq__(self, obj): return self.area == obj.area @property @abstractmethod def area(self): pass class Rectangle(Shape): def __init__(self, w, h): self.w = w self.h = h @property def area(self): return self.w * self.h class Circle(Shape): def __init__(self, r): self.r =r @property def area(self): return self.r * self.r * 3.14a = Rectangle(3, 4)b = Circle(2) 9. 实现上下文管理12- __enter__- __exit__: 即使出现异常, 它也会被执行。如果希望屏蔽异常，让该方法返回True 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from telnetlib import Telnetfrom sys import stdin, stdoutfrom collections import dequeclass TelnetClient(object): def __init__(self, addr, port=23): self.addr = addr self.port = port self.tn = None def start(self): # user t = self.tn.read_until(&#x27;login: &#x27;) stdout.write(t) user = stdin.readline() self.tn.write(user) # password t = self.tn.read_until(&#x27;Password: &#x27;) stdout.write(t) password = stdin.readline() self.tn.write(password) t = self.tn.read_until(&#x27;$ &#x27;) stdout.write(t) while True: uinput = stdin.readline() if not uinput: break self.history.append(uinput) self.tn.write(uinput) t = self.tn.read_until(&#x27;$ &#x27;) stdout.write(t[len(uinput) + 1:]) def __enter__(self): self.tn = Telnet(self.addr, self.port) self.history = deque() return self def __exit__(self, exc_type, exc_val, exc_tb): self.tn.close() self.tn = None with open(self.addr + &#x27;_history.txt&#x27;, &#x27;w&#x27;) as f: f.writelines(self.history) with TelnetClient(&#x27;192.168.1.8&#x27;) as client: client.start() 10. 类的继承10.1 类和对象在内存中的如何存储？1) 类及类中的方法只保留一份2) 类的实例，除了封装自己的特有属性外，还保留一个类对象指针，指向类的存储地址 10.2 python2 多重继承的搜寻方式经典类：深度优先。沿着一个继承向上查找新式类: 广度优先。逐个检查父类的siblings上述查找，一旦找到，立即返回 10.3 继承和多态polymorphism：多态，允许子类类型的指针赋值给父类类型(父类对象执行子类) 继承：代码重用 多态：接口重用。为了类在继承和派生时，保证使用“家谱”中任意一个类的实例的某一属性时正确调用 Python不支持多态，也用不到多态。使用一种叫鸭子型的实现。 123456789101112131415161718class Animal(object): def __init__(self, name): self.name = name def talk(self): raise NotImplementedError(&#x27;SubClass must implement abstract method&#x27;)class Cat(Animal): def talk(self): print &#x27;I eat fish.&#x27;class Dog(Animal): def talk(self): print &#x27;I gnaw on a bone.&#x27;animals = [Cat(&#x27;kitty&#x27;), Dog(&#x27;bonny&#x27;)]for animal in animals: animal.talk() 11. 如何在创建大量实例时，节省内存？定义类的slots属性，用它来声明实例属性名字的列表 12345678910111213141516171819202122232425262728293031323334353637383940class Player(object): def __init__(self, uid, name, status=0, level=1): self.uid = uid self.name = name self.status = status self.level = level class Player2(object): __slots__ = [&#x27;uid&#x27;, &#x27;name&#x27;, &#x27;status&#x27;, &#x27;level&#x27;] def __init__(self, uid, name, status=0, level=1): self.uid = uid self.name = name self.status = status self.level = level &gt;&gt;&gt; import sys&gt;&gt;&gt; sys.path.append(r&#x27;c:\\users\\administrator\\desktop&#x27;)&gt;&gt;&gt; from test2 import Player, Player2&gt;&gt;&gt; p1 = Player(1, &#x27;Jack&#x27;)&gt;&gt;&gt; p2 = Player2(1, &#x27;Jack&#x27;)&gt;&gt;&gt; set(dir(p1)) - set(dir(p2))set([&#x27;__dict__&#x27;, &#x27;__weakref__&#x27;])&gt;&gt;&gt; p1.__dict__&#123;&#x27;status&#x27;: 0, &#x27;level&#x27;: 1, &#x27;uid&#x27;: 1, &#x27;name&#x27;: &#x27;Jack&#x27;&#125;&gt;&gt;&gt; p1.x = 123&gt;&gt;&gt; p1.__dict__&#123;&#x27;status&#x27;: 0, &#x27;x&#x27;: 123, &#x27;level&#x27;: 1, &#x27;uid&#x27;: 1, &#x27;name&#x27;: &#x27;Jack&#x27;&#125;&gt;&gt;&gt; p1.__dict__[&#x27;y&#x27;] = 321&gt;&gt;&gt; p1.__dict__&#123;&#x27;status&#x27;: 0, &#x27;uid&#x27;: 1, &#x27;level&#x27;: 1, &#x27;y&#x27;: 321, &#x27;x&#x27;: 123, &#x27;name&#x27;: &#x27;Jack&#x27;&#125;&gt;&gt;&gt; del p1.x&gt;&gt;&gt; sys.getsizeof(p1.__dict__)524&gt;&gt;&gt; p2.x = 10 # 无__dict__, 动态属性不能被添加Traceback (most recent call last): File &quot;&lt;pyshell#13&gt;&quot;, line 1, in &lt;module&gt; p2.x = 10AttributeError: &#x27;Player2&#x27; object has no attribute &#x27;x&#x27; 12. 使用不可变对象修改不可变对象：定义一个不可变类型子类，重写new方法 123456789101112输入：[1, -1, &#x27;abc&#x27;, 6, [&#x27;x&#x27;, &#x27;y&#x27;], 3]输出：(1, 6, 3)class IntTuple(tuple): def __new__(cls, iterable): g = (x for x in iterable if isinstance(x, int) and x &gt; 0) #return super(IntTuple, cls).__new__(cls, g) return super().__new__(cls, g) # 3.x a = [1, -1, &#x27;abc&#x27;, 6, [&#x27;x&#x27;, &#x27;y&#x27;], 3] b = IntTuple(a)print(b) 13. 元类metaclass作用：改变类创建的行为 python中，类本身也是一个对象，简称类对象，有如下特性：可被赋值、复制、作为参数传递、任意增加属性 13.1 类也是对象12345678class C(object): passA = Cobj = A()print obj.__class__obj.name = &#x27;jack&#x27;print hasattr(obj, &#x27;name&#x27;) 13. 2 动态创建类12type(object) -&gt; the object&#x27;s typetype(name, bases, dict) -&gt; a new type 1234C = type(&#x27;MyClass&#x27;, (object,), &#123;&#x27;x&#x27;: 2&#125;)print C.__dict__obj = C()print obj.x 13.3 元类(Meta Class)：类的类，函数type本质就是一个元类123456789MyClass = MetaClass()MyObject = MyClass()name = &#x27;Jack&#x27;print name.__class__print type(name)print name.__class__.__class__print type(type(name)) 元类的本质：就是能够创建类的东西，type即为一个metaclass 13.4 自定义metaclass: 在类定义中使用__metaclass__属性先找本地`metaclass__，找不到再向上找父类的metaclass`,还找不到，则使用type来创建类对象 12345678910111213141516171819202122232425class UpperAttrMetaclass(type): def __new__(cls, name, bases, attrs): uppercase_attrs = &#123;&#125; for key, value in attrs.items(): if not key.startswith(&#x27;__&#x27;): uppercase_attrs[key.upper()] = value else: uppercase_attrs[key] = value #return super(UpperAttrMetaclass, cls).__new__(cls, name, bases, uppercase_attrs) return type.__new__(cls, name, bases, uppercase_attrs)class Foo(metaclass=UpperAttrMetaclass): bar = &#x27;abc&#x27;if __name__ == &#x27;__main__&#x27;: f = Foo() if hasattr(f, &#x27;bar&#x27;): print(&#x27;--bar:&#x27;, end=&#x27; &#x27;) print(f.bar) if hasattr(f, &#x27;BAR&#x27;): print(&#x27;--BAR:&#x27;, end=&#x27; &#x27;) print(f.BAR) 12345678910111213141516class ListMetaclass(type): def __new__(cls, name, bases, attrs): attrs[&#x27;add&#x27;] = lambda self, value: self.append(value) return type.__new__(cls, name, bases, attrs)class MyList(list, metaclass=ListMetaclass): passif __name__ == &#x27;__main__&#x27;: mylist = MyList() mylist.append(1) mylist.add(2) print(mylist) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Field(object): def __init__(self, name, column_type): self.name = name self.column_type = column_type def __str__(self): return &#x27;&lt;%s:%s&gt;&#x27; % (self.__class__.__name__, self.name)class StringField(Field): def __init__(self, name): super(StringField, self).__init__(name, &#x27;varchar(100)&#x27;)class IntegerField(Field): def __init__(self, name): super(IntegerField, self).__init__(name, &#x27;bigint&#x27;)class ModelClassmeta(type): def __new__(cls, name, bases, attrs): if name == &#x27;Model&#x27;: return type.__new__(cls, name, bases, attrs) print(&#x27;Found model %s&#x27; % name) mappings = dict() for k, v in attrs.items(): if isinstance(v, Field): print(&#x27;Found mapping: %s ==&gt; %s&#x27; % (k, v)) mappings[k] = v for k in mappings.keys(): attrs.pop(k) attrs[&#x27;__mappings__&#x27;] = mappings attrs[&#x27;__table__&#x27;] = name.lower() return type.__new__(cls, name, bases, attrs)class Model(dict, metaclass=ModelClassmeta): def __init__(self, **kwargs): super(Model, self).__init__(**kwargs) def __getattr__(self, key): try: return self[key] except: raise AttributeError(&#x27;Model has no atribute %s&#x27; % key) def __setattr__(self, key, value): self[key] = value def save(self): fields = [] params = [] args = [] for k, v in self.__mappings__.items(): fields.append(k) params.append(&#x27;?&#x27;) args.append(getattr(self, k, None)) sql = &#x27;insert into %s (%s) values (%s)&#x27; % (self.__table__, &#x27;,&#x27;.join(fields), &#x27;,&#x27;.join(params)) print(&#x27;SQL: %s&#x27; % sql) print(&#x27;Args: %s&#x27; % str(args))class User(Model): id = IntegerField(&#x27;id&#x27;) name = StringField(&#x27;name&#x27;) email = StringField(&#x27;email&#x27;) password = StringField(&#x27;password&#x27;)if __name__ == &#x27;__main__&#x27;: u = User(id=1, name=&#x27;alex&#x27;, email=&#x27;alex@sina.com&#x27;, password=&#x27;asjaass&#x27;) u.save()","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 字符操作技巧","slug":"Python 字符操作技巧","date":"2015-01-12T02:18:54.000Z","updated":"2021-06-22T10:50:49.687Z","comments":true,"path":"2015/01/12/Python 字符操作技巧/","link":"","permalink":"https://elihe2011.github.io/2015/01/12/Python%20%E5%AD%97%E7%AC%A6%E6%93%8D%E4%BD%9C%E6%8A%80%E5%B7%A7/","excerpt":"0. 字符串处理差别 2.x 3.x 差别 str bytes ‘abc’ –&gt; b’abc’ unicode str u’中文’ –&gt; ‘中文’ 1. 字符串分割123s.split(&#x27;|&#x27;)re.split(&#x27;[,;|]&#x27;, s)","text":"0. 字符串处理差别 2.x 3.x 差别 str bytes ‘abc’ –&gt; b’abc’ unicode str u’中文’ –&gt; ‘中文’ 1. 字符串分割123s.split(&#x27;|&#x27;)re.split(&#x27;[,;|]&#x27;, s) 2. 根据文件后缀修改权限12345678import os, statsh_py_files = [name for name in os.listdir(&#x27;.&#x27;) if name.endswith((&#x27;.sh&#x27;, &#x27;.py&#x27;))]os.stat(&#x27;a.py&#x27;).st_mode # 33204ord(os.stat(&#x27;a.py&#x27;).st_mode) # 0100664os.chmod(&#x27;a.py&#x27;, os.stat(&#x27;a.py&#x27;).st_mode | stat.S_IXUSR) 3. 时间格式转换2018-07-29 20:53:34 ———-&gt; 07/29/2018 20:53:34 1234log = open(&#x27;a.log&#x27;).read()data = re.sub(&#x27;(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&#x27;, r&#x27;\\2/\\3/\\1&#x27;, log)data = re.sub(&#x27;(?P&lt;year&gt;\\d&#123;4&#125;)-(?P&lt;month&gt;\\d&#123;2&#125;)-(?P&lt;day&gt;\\d&#123;2&#125;)&#x27;, r&#x27;\\g&lt;month&gt;/\\g&lt;day&gt;/\\g&lt;year&gt;&#x27;, log) 4. 字符串拼接1) s1 + s22) ‘’.join([s1, s2]) 12l = [&#x27;abc&#x27;, 123, 45, &#x27;xyz&#x27;]&#x27;&#x27;.join((str(x) for x in l)) # 使用生成器解析() 5. 字符串对齐 s.ljust, s.rjust, s.center 12345s = &#x27;abc&#x27;s.ljust(10) # &#x27;abc &#x27;s.ljust(10, &#x27;*&#x27;) # &#x27;abc*******&#x27;s.rjust(10) # &#x27; abc&#x27;s.center(10) # &#x27; abc &#x27; format(s, spec) 123456789101112131415format(s, &#x27;&lt;10&#x27;) # ljustformat(s, &#x27;&gt;10&#x27;) # rjustformat(s, &#x27;^10&#x27;) # centerIn [16]: d = &#123;&#x27;abc&#x27;: 122, &#x27;t&#x27;: 128, &#x27;ra&#x27;: 1221, &#x27;cxsz&#x27;: 832&#125;In [17]: w = max(map(len, d.keys()))In [18]: for k, v in d.items(): ...: print(k.ljust(w), &#x27;:&#x27;, v) ...:abc : 122t : 128ra : 1221cxsz : 832 6. 去除字符串中不需要的字符1) s.strip(), s.lstrip(), s.rstrip() 12345s = &#x27; abc &#x27;s.strip() # &#x27;abc&#x27;s = &#x27;----abc+++&#x27;s.strip(&#x27;-+&#x27;) # &#x27;abc&#x27; 2) s.replace() 12s = &#x27;\\tabc\\t123\\t&#x27;s.replace(&#x27;\\t&#x27;, &#x27;&#x27;) # &#x27;abc123&#x27; 3) re.sub 12s = &#x27;\\tabc\\t123\\nxyz\\n&#x27;re.sub(&#x27;[\\t\\n]&#x27;, &#x27;&#x27;, s) # abc123xyz s.translate(), unicode.translate()123456789101112131415161718s = &#x27;abc1232zyz&#x27;import stringtable = string.maketrans(&#x27;abcxyz&#x27;, &#x27;xyzabc&#x27;)s.translate(table) # &#x27;xyz1232abc&#x27;s = &#x27;\\tabc\\t123\\nxyz\\n&#x27;s.translate(None, &#x27;\\t\\n&#x27;) # abc123xyz&gt;&gt;&gt; u = u&#x27;ní hǎo, chī fàn&#x27;&gt;&gt;&gt; uu&#x27;ni\\u0301 ha\\u030co, chi\\u0304 fa\\u0300n&#x27;&gt;&gt;&gt; u.translate(&#123;0x0301: None&#125;)u&#x27;ni ha\\u030co, chi\\u0304 fa\\u0300n&#x27;&gt;&gt;&gt; u.translate(dict.fromkeys([0x0301, 0x030c, 0x0304, 0x0300]))u&#x27;ni hao, chi fan&#x27;","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 易错知识点总结","slug":"Python 易错知识点总结","date":"2015-01-11T01:38:17.000Z","updated":"2021-06-22T10:50:49.686Z","comments":true,"path":"2015/01/11/Python 易错知识点总结/","link":"","permalink":"https://elihe2011.github.io/2015/01/11/Python%20%E6%98%93%E9%94%99%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","excerpt":"1. UnboundLocalError123456789101112131415a=1def func(): a+=1 # try to modify global variable print aimport random def func(ok): if ok: a = random.random() else: import random # try to modify global variable a = random.randint(1, 10) return a","text":"1. UnboundLocalError123456789101112131415a=1def func(): a+=1 # try to modify global variable print aimport random def func(ok): if ok: a = random.random() else: import random # try to modify global variable a = random.randint(1, 10) return a 2. 以mutable对象作为默认参数产生闭包效应 123456789def foo(a=[]): a.append(1) return afoo() # [1]foo() # [1, 1]foo() # [1, 1, 1] 123456def foo(when=time.time()): return whenfoo() # 1531893020.535466foo() # 1531893020.535466 3. 生成可变对象的序列12345678910111213141516171819a = [[]] * 10id(a[0]) # 4395629000id(a[1]) # 4395629000a[0].append(10)print(a) # [[10], [10], [10], [10], [10], [10], [10], [10], [10], [10]]b = [[] for _ in range(10)]id(b[0]) # 4394449800id(b[1]) # 4395509384b[0].append(10)print(b) # [[10], [], [], [], [], [], [], [], [], []] 4. 在访问列表时删除列表元素(Python 3.x OK)1234567def foo(a): for i, e in enumerate(a): if e % 3 == 0: del a[i] return afoo(list(range(1,10))) # [1, 2, 4, 5, 7, 8] 5. 闭包与lambda12345678910111213def foo(): return [lambda x,i: x*i for i in range(5)]for f in foo(): print(f(2))TypeError Traceback (most recent call last)&lt;ipython-input-40-bbcfd739c3fd&gt; in &lt;module&gt;() 1 for f in foo():----&gt; 2 print(f(2)) 3TypeError: &lt;lambda&gt;() missing 1 required positional argument: &#x27;i&#x27; 修正为： 1234567def foo(): return [lambda x,i=i: x*i for i in range(5)]for f in foo(): print(f(2), end=&#x27;, &#x27;)# 0, 2, 4, 6, 8, python中的属性查找规则，LEGB（local，enclousing，global，bulitin），在上面的例子中，i就是在闭包作用域（enclousing），而Python的闭包是 迟绑定 ， 这意味着闭包中用到的变量的值，是在内部函数被调用时查询得到的。 6. python 2.x 和 python 3.x在python2.7中，range的返回值是一个列表；而在python3.x中，返回的是一个range对象。 map()、filter()、dict.items()在python2.7返回列表，而在3.x中返回迭代器。当然迭代器大多数都是比较好的选择，更加pythonic，但是也有缺点，就是只能遍历一次。 7. 逻辑判断7.1. 空字符串123(&#x27;&#x27;) == &#x27;&#x27; # True(&#x27;&#x27;,) == &#x27;&#x27; # False[&#x27;&#x27;] == &#x27;&#x27; # False 7.2. 等价判断123obj is None # id相同obj == None # 值相等obj1 is obj2 # id(obj1) == id(obj2) 7.3. 比较运行链12a &lt; b &lt; c &lt;=&gt; (a&lt;b) and (b&lt;c)1 in (0,1) == True &lt;=&gt; (1 in (0,1)) and ((0,1) == True) # False 8. 参数类型 形参：聚合位置参数为tuple 实参：分解iterable对象为位置参数 9. 闭包closure内部函数，引用外部函数的参数和局部变量，当返回内部函数时，相关的参数和局部变量都保存在内部函数中。 使用closure注意：返回函数不要引用任何循环变量或后续会发生变化的变量 1234567891011121314151617181920def count(): fs = [] for i in range(3): def f(): return i * i fs.append(f) return fsdef count2(): def f(j): def g(): return j * j return g fs = [] for i in range(3): fs.append(f(i)) return fs 10. global，nonlocal global: 需要在局部环境中修改全局变量 nonlcoal： 内部函数中修改外部函数的变量 11. 特殊变量 _x, __x, __x__ _x: 私有的，不属于API __x: 不可被子类override, 不可直接访问，只能通过a=A(), print(a._A__x)访问 __x__: magic method 12. 多态 静态语言：Java，父类引用指向子类对象 动态语言：Python，鸭子类型，不要求继承关系，一个对象只要“看起来像鸭子，走起来像鸭子”，就可以把它当成鸭子。即一个对象只要有同一类型的方法，即可看成同类123def read_image(fp): if hasattr(fp, &#x27;read&#x27;): return read_data(fp) 13. __slots__限制class的实类新增属性，对class属性无效 14. 命令行1echo a | python -c &quot;import sys; s=sys.stdin.readlines(); print s&quot;","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 模块导入","slug":"Python 模块导入","date":"2015-01-10T03:30:29.000Z","updated":"2021-06-22T10:50:49.686Z","comments":true,"path":"2015/01/10/Python 模块导入/","link":"","permalink":"https://elihe2011.github.io/2015/01/10/Python%20%E6%A8%A1%E5%9D%97%E5%AF%BC%E5%85%A5/","excerpt":"1. 什么是模块一个模块就是一个文件导入就是运行时一个运算 2. 模块导入步骤1) 找到模块文件2) 编译成位码3) 执行模块的代码来创建模块对象","text":"1. 什么是模块一个模块就是一个文件导入就是运行时一个运算 2. 模块导入步骤1) 找到模块文件2) 编译成位码3) 执行模块的代码来创建模块对象 3. 模块搜索顺序1) 程序的主目录2) PYTHONPATH目录3) 标准链接库目录4) 任何.pth文件的内容 4. 模块扩展名.py 源代码.pyc 字节码.dll/.pyd 编译扩展模块 5. 重复导入模块导入只执行一次 a.py 12x = 1y = [1, 2] 1234567from a import x, yx = 2y[0]=9import aprint a.x # 1print a.y # [9, 2] 6. 已安装的模块sys.modules","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 可迭代对象 vs 迭代器 vs 生成器","slug":"Python 可迭代对象 vs 迭代器 vs 生成器","date":"2015-01-09T01:38:17.000Z","updated":"2021-06-22T10:50:49.685Z","comments":true,"path":"2015/01/09/Python 可迭代对象 vs 迭代器 vs 生成器/","link":"","permalink":"https://elihe2011.github.io/2015/01/09/Python%20%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1%20vs%20%E8%BF%AD%E4%BB%A3%E5%99%A8%20vs%20%E7%94%9F%E6%88%90%E5%99%A8/","excerpt":"容易混淆的几个关联概念： 容器(container) 可迭代对象(Iterable) 迭代器(Iterator) 生成器(generator) 生成器表达式 &#123;list, set, dict&#125; 解析式 它们之间的关系如下：","text":"容易混淆的几个关联概念： 容器(container) 可迭代对象(Iterable) 迭代器(Iterator) 生成器(generator) 生成器表达式 &#123;list, set, dict&#125; 解析式 它们之间的关系如下： 1. 容器（container)容器是用来储存元素的一种数据结构，它支持隶属测试，容器将所有数据保存在内存中，在Python中典型的容器有： list， deque, … set，frozesets，… dict, defaultdict, OrderedDict, Counter, … tuple, namedtuple, … str 注意：并非所有的容器都是可迭代对象。 2. 可迭代对象包含：大部分容器、文件对象、管道对象 可迭代对象：实现__iter__或`getitem__`方法 3. 迭代器(Iterators)迭代器：实现__next__方法, (2.X 实现next方法） 3.1 产生无穷的序列123456&gt;&gt;&gt; from itertools import count&gt;&gt;&gt; counter = count(start=13)&gt;&gt;&gt; next(counter)13&gt;&gt;&gt; next（counter)14 3.2 根据有限序列中生成无限序列：12345678910&gt;&gt;&gt; from itertools import cycle&gt;&gt;&gt; colors = cycle([&quot;red&quot;,&quot;white&quot;,&quot;blue&quot;])&gt;&gt;&gt; next(colors)&quot;red&quot;&gt;&gt;&gt; next(colors）&quot;white&quot;&gt;&gt;&gt; next(colors)&quot;blue&quot;&gt;&gt;&gt; next(colors)&quot;red&quot; 3.3 根据无限序列中生成有限序列：123456789&gt;&gt;&gt; from itertools import islice&gt;&gt;&gt; colors = cycle([&#x27;red&#x27;, &#x27;white&#x27;, &#x27;blue&#x27;]) # infinite&gt;&gt;&gt; limited = islice(colors, 0, 4) # finite&gt;&gt;&gt; for x in limited: # so safe to use for-loop on... print(x)redwhitebluered 3.4 生成斐波拉契数的迭代器：12345678910111213141516171819In [14]: class Fib: ...: def __init__(self): ...: self.a = 0 ...: self.b = 1 ...: def __iter__(self): ...: return self ...: def next(self): ...: self.a, self.b = self.b, self.a + self.b ...: return self.aIn [15]: f = Fib()In [16]: next(f)Out[16]: 1In [17]: f = Fib()In [18]: list(islice(f, 0, 10))Out[18]: [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 4. 生成器生成器其实就是一种特殊的迭代器。它使一种更为高级、更为优雅的迭代器。使用生成器让我们可以以一种更加简洁的语法来定义迭代器。让我们先明确以下两点： 任意生成器都是迭代器（反过来不成立）任意生成器，都是一个可以延迟创建值的工厂 g.__iter__() is g # True, 生成器对象实现的iter方法返回自身 生成器常用方法： g.next() &lt;=&gt; g.send(None)g.send(msg)g.throw(Exception, errmsg)g.close() 4.1 斐波那契序列123456789def fib(): a, b = 0, 1 while True: a, b = b, a+b yield af = fib()print(list(islice(f, 0, 10))) # [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 4.2 生成器表达式1234567lazy_squares = (x * x for x in numbers)print(lazy_squares) # &lt;generator object &lt;genexpr&gt; at 0x10d1f5510&gt;next(lazy_squares) # 1list(lazy_squares) # [4, 9, 16, 25, 36] 注意我们第一次调用next()之后，lazy_squares对象的状态已经发生改变，所以后面后面地调用list()方法只会返回部分元素组成的列表。 4.3 查找素数 实例：实现可迭代对象类，它能给出给定范围内的素数 方案：该类的iter方法实现生成器函数，每次yield返回一个素数 123456789101112131415161718192021222324class Prime: def __init__(self, start, end): self.start = start self.end = end def is_prime(self, k): if k &lt; 2: return False for i in range(2, k): if k % i == 0: return False return True def __iter__(self): for x in range(self.start, self.end + 1): if self.is_prime(x): yield x if __name__ == &#x27;__main__&#x27;: for i in Prime(0, 100): print(i, end=&#x27;, &#x27;) 5. 总结 Iterable对象：generator, list, dict, str, set, … Iterator对象：generator, iter(list, dict, str, set…) 为什么list、dict、str等数据类型不是Iterator？Iterator对象表示一个数据流，可以调用next()不断返回下一个数据，直到没有数据抛出StopIteration错误。Iterator的计算时懒性的，只在需要返回下一个数据时才会计算，但list等事先知道序列的长度。 可for循环的对象：Iterable可next()的对象：Iterator for循环本质：不断调用next()函数，直到StopIteration 6.itertools 工具6.1 无限循环器(Infinite Iterators)count(start[, step])cycle(iterable)repeat(obj[, times) 123456789101112131415161718from itertools import count, cycle, repeatfor i in count(3, 2): print(i, end=&#x27;, &#x27;) if i &gt; 15: breakprint()sum = 0for i in cycle([1, 2, 3, 4, 5]): sum += i print(sum, end=&#x27;, &#x27;) if sum &gt; 30: breakprint()for i in repeat(&#x27;x&#x27;, 5): print(i, end=&#x27;, &#x27;) 6.2 序列筛选(Iterators terminating on the shortest sequence)zip_longest(iter1, iter2, …, fillvalue=None)islice(iterable[, start], stop[, step])starmap(func, sequence)filterfalse(func, sequence) 1234567from itertools import zip_longest, starmapa = zip_longest(&#x27;abc&#x27;, [1, 2], fillvalue=0)print(list(a)) # [(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 0)]b = starmap(pow, [(1, 2), (3, 4), (5, 6)])print(list(b)) # [1, 81, 15625] takewhile(predicate, iterable)dropwhile(predicate, iterable) compress(iterable, selectors) 1234567from itertools import takewhile, compressa = takewhile(lambda x: x &lt; 2, [1, 0, 2, -1, 3])print(list(a)) # [1, 0]b = compress(range(5), [0, 1, 1, 0, 1])print(list(b)) # 1, 2, 4 chain(*iterables)chain.from_iterable(iterable) # to chain object groupby(iterable, keyfunc) 12345678from itertools import groupbya = [9, 3, 1, 5, 8, 6, 2]for m, n in groupby(sorted(a), lambda x: x &gt; 5): print(m, list(n))# False [1, 2, 3, 5]# True [6, 8, 9] tee(iterable, n=2) # 复制多份 6.3 组合生成器(Combinatoric Generators)product(*iterable) # Cartesian productpermutations(iterable, len) # 排列， all possible ordingscombinations(iterable, len) # 组合， in sorted order, no repeatcombinations_with_replacement(iterable, len) # in sorted order, with repeat 12345678910111213from itertools import product, permutations, combinations, combinations_with_replacementa = product(&#x27;abc&#x27;, [1, 2])print(list(a)) # [(&#x27;a&#x27;, 1), (&#x27;a&#x27;, 2), (&#x27;b&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 1), (&#x27;c&#x27;, 2)]b = permutations(&#x27;abc&#x27;, 2)print(list(b)) # [(&#x27;a&#x27;, &#x27;b&#x27;), (&#x27;a&#x27;, &#x27;c&#x27;), (&#x27;b&#x27;, &#x27;a&#x27;), (&#x27;b&#x27;, &#x27;c&#x27;), (&#x27;c&#x27;, &#x27;a&#x27;), (&#x27;c&#x27;, &#x27;b&#x27;)]c = combinations(&#x27;abc&#x27;, 2)print(list(c)) # [(&#x27;a&#x27;, &#x27;b&#x27;), (&#x27;a&#x27;, &#x27;c&#x27;), (&#x27;b&#x27;, &#x27;c&#x27;)]d = combinations_with_replacement(&#x27;abc&#x27;, 2)print(list(d)) # [(&#x27;a&#x27;, &#x27;a&#x27;), (&#x27;a&#x27;, &#x27;b&#x27;), (&#x27;a&#x27;, &#x27;c&#x27;), (&#x27;b&#x27;, &#x27;b&#x27;), (&#x27;b&#x27;, &#x27;c&#x27;), (&#x27;c&#x27;, &#x27;c&#x27;)] 7. 扁平化(flatten)列表1python -m timeit -s &#x27;L=[[1, 2, 3], [4, 5, 6], [7], [8, 9]]*99&#x27; &#x27;print [j for i in L for j in i]&#x27; 123456789101112131415161718192021import operatorfrom functools import reducefrom itertools import chaina = [[1, 2], [3, 4], [5, 6]]b1 = chain.from_iterable(a)print(list(b1))b2 = [j for i in a for j in i]print(b2)# 以下三个，子元素必须可执行加法运算b3 = sum(a, [])print(b3)b4 = reduce(lambda x, y: x + y, a)print(b4)b5 = reduce(operator.concat, a)print(b5) 123456a = [1, (2, 3), [4, 5], 7, (8,), [9]]flatten = lambda x: [L2 for L1 in x for L2 in flatten(L1)] \\ if isinstance(x, (list, tuple)) else [x]print(flatten(a))","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[{"name":"iter","slug":"iter","permalink":"https://elihe2011.github.io/tags/iter/"},{"name":"generator","slug":"generator","permalink":"https://elihe2011.github.io/tags/generator/"}]},{"title":"Python 闭包、泛函和装饰器","slug":"Python 闭包泛函和装饰器","date":"2015-01-08T01:38:17.000Z","updated":"2021-06-22T10:50:49.684Z","comments":true,"path":"2015/01/08/Python 闭包泛函和装饰器/","link":"","permalink":"https://elihe2011.github.io/2015/01/08/Python%20%E9%97%AD%E5%8C%85%E6%B3%9B%E5%87%BD%E5%92%8C%E8%A3%85%E9%A5%B0%E5%99%A8/","excerpt":"闭包：返回函数对象，有封闭的变量空间closure 泛函：碧波啊的最外层函数，传入变量var做参数；内层函数传入公共算术因子 装饰器：闭包的最外层函数，传入函数func做参数；内层函数，传入函数func的参数。带参数的装饰器：嵌套多层包装函数","text":"闭包：返回函数对象，有封闭的变量空间closure 泛函：碧波啊的最外层函数，传入变量var做参数；内层函数传入公共算术因子 装饰器：闭包的最外层函数，传入函数func做参数；内层函数，传入函数func的参数。带参数的装饰器：嵌套多层包装函数","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python with异常","slug":"Python with异常","date":"2015-01-07T02:16:00.000Z","updated":"2021-06-22T10:50:49.684Z","comments":true,"path":"2015/01/07/Python with异常/","link":"","permalink":"https://elihe2011.github.io/2015/01/07/Python%20with%E5%BC%82%E5%B8%B8/","excerpt":"当with语句的 enter(self)发生异常, 该异常会在exit(self, *args)中捕获 1. 屏蔽with语句中产生的异常12345678910class Lockit(object): def __enter__(self): pass def __exit__(self, exec_type, exec_val, exec_tb): return True # 直接屏蔽错误 with Lockit(): print &#x27;enter...&#x27; print 1 / 0 print &#x27;exited&#x27;. # 不再执行","text":"当with语句的 enter(self)发生异常, 该异常会在exit(self, *args)中捕获 1. 屏蔽with语句中产生的异常12345678910class Lockit(object): def __enter__(self): pass def __exit__(self, exec_type, exec_val, exec_tb): return True # 直接屏蔽错误 with Lockit(): print &#x27;enter...&#x27; print 1 / 0 print &#x27;exited&#x27;. # 不再执行 2. 忽略with语句中参数的异常123456789101112class Lockit(object): def __enter__(self): pass def __exit__(self, exec_type, exec_val, exec_tb): if exec_type is not None: return False # 不屏蔽错误 return True with Lockit(): print &#x27;enter...&#x27; print 1 / 0 print &#x27;exited&#x27;. # 不再执行 3. 上下文定义本身的异常，无法屏蔽12345678910111213class Foo(object): def __init__(self, a, b): self.a = a self.b = b def __enter__(self): c = self.a / self.b def __exit__(self, exec_type, exec_val, exec_tb): if exec_type is not None: return False return True with Foo(1, 0): pass","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 文件操作","slug":"Python 文件操作","date":"2015-01-06T02:14:31.000Z","updated":"2021-06-22T10:50:49.683Z","comments":true,"path":"2015/01/06/Python 文件操作/","link":"","permalink":"https://elihe2011.github.io/2015/01/06/Python%20%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","excerpt":"1. 文件读写open(file, mode, encoding) mode: r Readonly r+ ReadWrite，从当前位置写入，直接覆盖原有内容 (当前位置只能由seek()改变, read*()引起的位置改变，可导致无法写入) w Writeonly，无法使用read*()方法 w+ ReadWrite，可以使用read*()方法 a Writeonly，无法使用read*()方法 a+ ReadWrite，可以使用read()方法(read()引起的位置改变，可导致无法写入，必须seek(0,2)至文件尾，才可写) b 二进制读写","text":"1. 文件读写open(file, mode, encoding) mode: r Readonly r+ ReadWrite，从当前位置写入，直接覆盖原有内容 (当前位置只能由seek()改变, read*()引起的位置改变，可导致无法写入) w Writeonly，无法使用read*()方法 w+ ReadWrite，可以使用read*()方法 a Writeonly，无法使用read*()方法 a+ ReadWrite，可以使用read()方法(read()引起的位置改变，可导致无法写入，必须seek(0,2)至文件尾，才可写) b 二进制读写 属性： f.closed f.mode f.encoding f.name f.newlines f.softspace 方法： f.read([size]) f.readline() f.readlines() f.next() # 读取下一行 f.write(‘Hello’) f.writelines(L) f.tell() # 文件指针位置 f.seek(offset[, whence]) # 移动文件指针 whence: 0-beginning, 1-current, 2-end f.flush() f.close() f.fileno() f.isatty() f.truncate() 12for line in f: # 高效读取文件，隐式调用next()方法 print line 1.1 读写文件123456f = open(&#x27;py3.txt&#x27;, &#x27;wt&#x27;, encoding=&#x27;utf-8&#x27;)f.write(&#x27;你好，欢迎你&#x27;)f.close()f = open(&#x27;py3.txt&#x27;, &#x27;rt&#x27;, encoding=&#x27;utf-8&#x27;)print(f.read()) # &#x27;你好，欢迎你&#x27; 1.2 创建100M空文件1234f = open(&#x27;100m.txt&#x27;)f.seek(1024*1024*100 - 1)f.write(&#x27;\\x00&#x27;)f.close() 2. 序列化 pickle, cPickle1234567# to file systempickle.dump(obj, file, protocol=0) # 0-ascii, 1,2-binaryobj = pickle.load(file)# to strings = pickle.dumps(obj, protocol=0) # 0-ascii, 1,2-binaryobj = pickle.loads(s)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python functools","slug":"Python functools","date":"2015-01-05T01:38:17.000Z","updated":"2021-06-22T10:50:49.683Z","comments":true,"path":"2015/01/05/Python functools/","link":"","permalink":"https://elihe2011.github.io/2015/01/05/Python%20functools/","excerpt":"1. 偏函数: 简化函数，使调用更简单将一个函数的某些参数传递默认值，使其成为一个新函数int2 = functools.partial(int, base=2) 1234567891011def partial(func, *args, **kwargs): def wrapper(*fargs, **fkwargs): newkwargs = kwargs.copy() newkwargs.update(fkwargs) return func(*(args+fargs), **newkwargs) wrapper.func = func wrapper.args = args wrapper.kwargs = kwargs return wrapper add_1_2(3)","text":"1. 偏函数: 简化函数，使调用更简单将一个函数的某些参数传递默认值，使其成为一个新函数int2 = functools.partial(int, base=2) 1234567891011def partial(func, *args, **kwargs): def wrapper(*fargs, **fkwargs): newkwargs = kwargs.copy() newkwargs.update(fkwargs) return func(*(args+fargs), **newkwargs) wrapper.func = func wrapper.args = args wrapper.kwargs = kwargs return wrapper add_1_2(3)","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 列表扁平化","slug":"Python 列表扁平化","date":"2015-01-04T02:25:11.000Z","updated":"2021-06-22T10:50:49.682Z","comments":true,"path":"2015/01/04/Python 列表扁平化/","link":"","permalink":"https://elihe2011.github.io/2015/01/04/Python%20%E5%88%97%E8%A1%A8%E6%89%81%E5%B9%B3%E5%8C%96/","excerpt":"1. 列表解析列表解析:[expr for iter_var in iterable if cond_expr] 生成器表达式:(expr for iter_var in iterable if cond_expr)","text":"1. 列表解析列表解析:[expr for iter_var in iterable if cond_expr] 生成器表达式:(expr for iter_var in iterable if cond_expr) 2. 排序 对List进行排序1L.sort(cmp=None, key=None, reverse=False) 对iterable对象排序123456789101112131415161718object = sorted(iterable, cmp=None, key=None, reverse=False)cmp: 用于比较函数，比较内容由key值决定key: 由迭代对象元素的属性和函数做关键字，效率高于cmpIn [26]: L = [(&#x27;c&#x27;, 3), (&#x27;b&#x27;, 2), (&#x27;d&#x27;, 4), (&#x27;a&#x27;, 1)]In [27]: sorted(L, cmp=lambda x,y: cmp(x[1],y[1]))Out[27]: [(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 3), (&#x27;d&#x27;, 4)]In [28]: sorted(L, key=lambda x: x[1], reverse=True)Out[28]: [(&#x27;d&#x27;, 4), (&#x27;c&#x27;, 3), (&#x27;b&#x27;, 2), (&#x27;a&#x27;, 1)]In [29]: sorted([-2, 0, 3, 1, -1], key=abs)Out[29]: [0, 1, -1, -2, 3]In [30]: sorted([&#x27;Bye&#x27;, &#x27;hello&#x27;, &#x27;world&#x27;, &#x27;Quit&#x27;], key=str.lower, reverse=True)Out[30]: [&#x27;world&#x27;, &#x27;Quit&#x27;, &#x27;hello&#x27;, &#x27;Bye&#x27;] 3. 字典排序 按key排序： 12for k in sorted(d.keys()): print k, d[k]for k, v in sorted(d.items(), key=lambda x:x[0]): print k, v 按value排序： 12for k, v in sorted(d.items(), key=lambda x:x[1], reverse=True): print k, vfor k, v in sorted(d.items(), lambda x,y: cmp(x[1], y[1])): print k, v 4. 扁平化列表123456789In [22]: a = [[(&#x27;A&#x27;, 1), (&#x27;B&#x27;, 2)], [(&#x27;C&#x27;, 3), (&#x27;D&#x27;, 4)]]In [23]: [x for b in a for x in b]Out[23]: [(&#x27;A&#x27;, 1), (&#x27;B&#x27;, 2), (&#x27;C&#x27;, 3), (&#x27;D&#x27;, 4)]In [33]: import itertoolsIn [34]: list(itertools.chain(*a))Out[34]: [(&#x27;A&#x27;, 1), (&#x27;B&#x27;, 2), (&#x27;C&#x27;, 3), (&#x27;D&#x27;, 4)]","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 内置函数","slug":"Python 内置函数","date":"2015-01-03T01:21:01.000Z","updated":"2021-06-22T10:50:49.681Z","comments":true,"path":"2015/01/03/Python 内置函数/","link":"","permalink":"https://elihe2011.github.io/2015/01/03/Python%20%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/","excerpt":"1. 数值计算abs(x) complex(real,[image]) float(x) *long(x) * int(x,base=10) 12345678910&gt;&gt;&gt; int(&#x27;3&#x27;,base=10)3&gt;&gt;&gt; int(&#x27;a&#x27;,base=16)10&gt;&gt;&gt; int(&#x27;10&#x27;,base=2)2print(0b1110) # int(&#x27;1110&#x27;, 2)print(0o10) # int(&#x27;10&#x27;, 8)print(0x2a) # int(&#x27;2a&#x27;, 16)","text":"1. 数值计算abs(x) complex(real,[image]) float(x) *long(x) * int(x,base=10) 12345678910&gt;&gt;&gt; int(&#x27;3&#x27;,base=10)3&gt;&gt;&gt; int(&#x27;a&#x27;,base=16)10&gt;&gt;&gt; int(&#x27;10&#x27;,base=2)2print(0b1110) # int(&#x27;1110&#x27;, 2)print(0o10) # int(&#x27;10&#x27;, 8)print(0x2a) # int(&#x27;2a&#x27;, 16) round(x[,n]) 返回浮点数精确位 12&gt;&gt;&gt; round(math.pi, 2)3.14 *divmod(a,b) * 12&gt;&gt;&gt; divmod(7, 4)(1, 3) pow(x,y[,z]) 123456&gt;&gt;&gt; pow(2, 10)1024&gt;&gt;&gt; pow(2, 3, 5)3&gt;&gt;&gt; pow(2, 3) % 53 hex(x) oct(x) 12345&gt;&gt;&gt; hex(10)&#x27;0xa&#x27;&gt;&gt;&gt; oct(10)&#x27;0o12&#x27; coerce(x,y) 强制数值类型转换为相同类型，返回一个元组. 1234567&gt;&gt;&gt; coerce(1, 2.3)(1.0, 2.3)&gt;&gt;&gt; c = 1 + 1j&gt;&gt;&gt; d = 2&gt;&gt;&gt; coerce(c, d)((1+1j), (2+0j)) format(value, format_spec) =&gt; value.format 12345678910111213In [12]: s = &#x27;abc&#x27;In [13]: format(s, &#x27;&gt;10&#x27;)Out[13]: &#x27; abc&#x27;In [14]: format(s, &#x27;&lt;10&#x27;)Out[14]: &#x27;abc &#x27;In [15]: format(s, &#x27;^10&#x27;)Out[15]: &#x27; abc &#x27;In [16]: format(12345, &#x27;,&#x27;) # 货币格式Out[16]: &#x27;12,345&#x27; 2. 函数参数filter(func,list) 根据func参数返回的结果来过滤list参数中的项 123&gt;&gt;&gt; a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; filter(lambda x: x%2==0, a) [0, 2, 4, 6, 8] map(func,list,…) 将func运用到list中的每一项上 1234567&gt;&gt;&gt; a = [1, 2, 3, 4]&gt;&gt;&gt; map(lambda x:pow(x,3), a)[1, 8, 27, 64]&gt;&gt;&gt; map(None, [1, 2, 3, 4], [5, 6, 7, 8])[(1, 5), (2, 6), (3, 7), (4, 8)]&gt;&gt;&gt; map(None, [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12])[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)] reduce(func,sequence[,initializer]) 逐个使用sequence元素作为func的参数, 3.x itertools.reduce 12&gt;&gt;&gt; reduce(lambda x,y:x*y, [1,2,3,4,5])120 zip(seq1,…) 每个序列各取一个元素构成元组，再由元组构成新的序列 1234&gt;&gt;&gt; a = [1, 2, 3, 4]&gt;&gt;&gt; b = [5, 6, 7, 8]&gt;&gt;&gt; zip(a, b)[(1, 5), (2, 6), (3, 7), (4, 8)] 3. 序列操作max(iterable[, key, default])max(arg1, arg2, *args[, key])min(s[,args…]) 12&gt;&gt;&gt; max(-1, 0, key=abs)-1 len(s) 返回一序列（字符串、元组或列表）或字典对象的长度 tuple(object)list(sequence) 12&gt;&gt;&gt; list(&#x27;abc&#x27;)[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] range([start,]stop[,step]) 返回数值列表 12&gt;&gt;&gt; range(5, 25, 5)[5, 10, 15, 20] slice([start,]stop,[,step]) 返回序列切片(slice)对象，该对象表示由range(start,stop,step)指定的索引集(本质上为序列号对象的索引集合) 1234&gt;&gt;&gt; s = slice(1,10,2)&gt;&gt;&gt; a = range(-5,10)&gt;&gt;&gt; a[s][-4, -2, 0, 2, 4] 4. 字符串操作cmp(x,y) 比较x和y这两个对象，返回一个整数(-1, 0, 1) chr(i) 返回ASCII码对应的符串 12&gt;&gt;&gt; chr(72)&#x27;H&#x27; ord(c) 返回字符的ASCII或Unicode码 12&gt;&gt;&gt; ord(&#x27;a&#x27;)97 str(object) 返回表示对象的可打印字符串，该字符串不与eval()函数兼容repr(object) 返回对象的字符串表达式。等效于反引号操作(``)，与eval(object)函数产生的值一样 5. 对象操作callable(object) object对象可调用，返回true，否则false, 3.x hasattr(obj, ‘call‘) dir([object]) 返回对象具有的属性 globals() 返回全局命名空间，可修改locals() 返回局部命名空间的拷贝，不可修改vars([object])不带参数，返回值和locals()一致带参数，返回对象的dict id(object) 返回对象唯一标识整数值hash(object) 返回对象的整数散列值 setattr(object,name,value) =&gt; object.name=valuegetattr(object,name[,default]) =&gt; object.namehasattr(object,name)delattr(object, name) =&gt; del object.name isinstance(object ,class)issubclass(class1,class2) type(object) 返回object参数的类型。 12&gt;&gt;&gt; type(lambda x:x)&lt;type &#x27;function&#x27;&gt; 编译执行 eval(expression[,global[,locals]]) 计算字符串表达式值exec(segment) 执行字符串代码片段execfile(file[,globals[,locals]]) 执行python脚本文件 3.x 已删除 123456789101112131415compile(source, filename, mode) 编译source为代码对象filename: 编译时错误标记，无关输出和存储mode:single: 单条语句exec: 多条语句eval: 表达式exec(&#x27;n=2*3&#x27;)print neval(&#x27;x*3 + y*4&#x27;, &#123;&#x27;x&#x27;:1, &#x27;y&#x27;:2&#125;)a = compile(&#x27;print &quot;Hello World!&quot;&#x27;, &#x27;single&#x27;)b = compile(&#x27;for i in range(5): print i&#x27;, &#x27;exec&#x27;)c = compile(&#x27;x*3 + y*4, &#x27;eval&#x27;) 7. 其他函数intern(string) 将string加入到保留字符串的表，返回值为保留的版本号。“保留字符串”通过指针可用，而不是一个纯的字符串；因此允许利用指针比较代替字符串比较来进行字典关键字的查找，这比通常的字符串比较方法功能有所改善。在python名称空间表和用于保留模块、类或实力属性的字典中使用的名字通常被保留用以加速脚本执行。保留字符串定义后不能被作为无用单元收集，所以必须注意在大字典关键字集上使用保留字符串将大大增加内存需求，即使字典关键字应急超出了作用域。3.x sys.intern reload(module) 将以前导入过的模块再加载一次。重新加载(reload)包括最初导入模块是应用的分析过程和初始化过程。这样就允许在不退出解释器的情况重新加载已更改的python模块。 buffer(object[,offset[,size]]) 为支持缓存调用接口的object对象创建一个新缓存。这样的对象包括字符串、数组和缓存。该新缓存通过使用从offset参数值开始知道该对象末尾的存储片段或从offset参数值开始直到size参数给出的尺寸为长度的存储片段来引用object对象。如果没给出任何选项参数，缓存区域就覆盖整个序列，最终得到的缓存对象是object对象数据的只读拷贝。缓存对象用于给某个对象类型创建一个更友好的接口。比如，字符串对象类型通用缓存对象而变得可用，允许逐个字节地访问字符串中的信息。 open(filename[,mode[,bufsize]]) 通过使用mode和缓存bufsize类型来打开filename标识的文件|模式 |含义||————|————||r | readonly ||w | writeonly ||a | append 打开用于附加(打开期间，文件位置自动移到文件末尾)||r+ | 打开用于更新(读和写)||w+ | 截断(或清空)文件，接着打开文件用于读写||a+ | 打开文件用于读和写，并自动改变当前为止到文件尾||b | 仅对windows，dos和其他一些操作系统有效，对Unix、MacOS和BeOS则不管选项为何值，以二进制模式对待所有文件| bufsize值 说明 &gt;1 使用大小近似为bufsize字符长度的缓存 &lt;0 使用系统默认","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 异常处理","slug":"Python 异常处理","date":"2015-01-02T02:04:45.000Z","updated":"2021-06-22T10:50:49.681Z","comments":true,"path":"2015/01/02/Python 异常处理/","link":"","permalink":"https://elihe2011.github.io/2015/01/02/Python%20%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","excerpt":"1. 异常流程12345678try: try_suiteexcept Exception [, resean]: except_suiteelse: else_suitefinally: finally_suit","text":"1. 异常流程12345678try: try_suiteexcept Exception [, resean]: except_suiteelse: else_suitefinally: finally_suit 流程： try-&gt;异常-&gt;except-&gt;finally try-&gt;无异常-&gt;else-&gt;finally 用法 语句 说明 try: 执行代码块 except: 捕获所有异常 except name: 捕获特定异常 except name, value: 捕获特定异常及其实例 except(name1, name2): 捕获一组异常 except(name1, name2)， value: 捕获一组异常及其实例 else: 未引发异常时执行 finally: 总是执行 捕获异常 except IOError, e: except IOError as e: except IOError, (errno, errmsg): 打印异常 print e print e.args # 实例参数 抛出异常参数 raise Exception(3, ‘error’) raise Exception, (3, ‘error’) 2. 实例读取文件：12345678910111213141516171819for arg in sys.argv[1:]: f = None try: f = open(arg) s = f.readline() i = int(s.strip()) except IOError, (errno, errmsg): print &quot;I/O error(%s): %s&quot; % (errno, errmsg) except ValueError: print &quot;Could not convert data to an integer.&quot; except: print &quot;Unexpected error:&quot;, sys.exe_info()[0] raise else: print &quot;The first line of %s is %d&quot; % (arg, i) finally: if f is not None: f.close() print &quot;Done.&quot; 3.主动抛出异常123456789try: raise Exception(&#x27;err1&#x27;, &#x27;err2&#x27;)except Exception, e: print e.args print e # output(&#x27;err1&#x27;, &#x27;err2&#x27;)(&#x27;err1&#x27;, &#x27;err2&#x27;) # __str__ 123456789101112&gt;&gt;&gt; try: raise NameError(&#x27;Haha&#x27;)except NameError: print &#x27;An exception flew by!&#x27; raiseAn exception flew by!Traceback (most recent call last): File &quot;&lt;pyshell#8&gt;&quot;, line 2, in &lt;module&gt; raise NameError(&#x27;Haha&#x27;)NameError: Haha 4. 自定义异常123456789101112class MyError(Exception): def __init__(self, value): self.value = value def __str__(self): return repr(self.value)try: raise MyError(2*2)except MyError as e: ## except MyError, e print &#x27;my exception occurred value:&#x27;, e.value print &#x27;my exception occurred value:&#x27;, e 5. 异常家族1234567891011graph LRBaseException--&gt;SystemExitBaseException--&gt;KeyboardInterruptBaseException--&gt;GeneratorExitBaseException--&gt;ExceptionException--&gt;WarningException--&gt;StandardErrorException--&gt;StopIterationWarning--&gt;RuntimeWarning 1234567891011121314graph LRStandardError--&gt;AssertionErrorStandardError--&gt;ArithmeticErrorArithmeticError--&gt;ZeroDivisionErrorStandardError--&gt;EnvironmentErrorEnvironmentError--&gt;IOErrorStandardError--&gt;ImportErrorStandardError--&gt;NameErrorStandardError--&gt;AttributeErrorStandardError--&gt;RuntimeErrorStandardError--&gt;SyntaxErrorStandardError--&gt;SystemErrorStandardError--&gt;TypeErrorStandardError--&gt;ValueError 6. Assert1assert False,&#x27;error...&#x27;","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[]},{"title":"Python 字符编码","slug":"Python 字符编码","date":"2015-01-01T01:38:17.000Z","updated":"2021-06-22T10:50:49.680Z","comments":true,"path":"2015/01/01/Python 字符编码/","link":"","permalink":"https://elihe2011.github.io/2015/01/01/Python%20%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","excerpt":"1. 编码类型 ASCII: American Standard Code for Information Interchange, 单字节，最大256个，但实际只用7bit(\\080以下)，即最大127 MBCS: Multiple-Byte Character Set DBCS: Double Bytes Code Set，两字节汉字和一字节英文字符同时存在，如果字节值大于127,认为是双字节汉字 GB2312: 对ASCII的中文扩展 GBK: 对GB2312的扩展，新增2W多汉字，包含繁体字 GB18030: 对GBK的扩展，新增少数民族语言字符 CP936: IBM的Code Page, GBK为第936页 Unicode UCS/UNICODE: Universal Multiple-Octet Coded Character Set，所有字符采用2个字节来标识 UCS-4: 采用4个字节来标识一个字符 UTF: UCS Transfer Format UTF8: 每次传输8bit UTF16: 每次传输16bit BOM: Byte Order Mark。网络传输数据高低位解析方式: BOM_UTF8 ‘\\xef\\xbb\\xbf’ BOM_UTF16_LE ‘\\xff\\xfe’ BOM_UTF16_BE ‘\\xfe\\xff’ UNICODE和UTF-8转换： Unicode UTF-8 0000 - 007F 0xxxxxxx 0080 - 07FF 110xxxxx 10xxxxxx 0800 - FFFF 1110xxxx 10xxxxxx 10xxxxxx","text":"1. 编码类型 ASCII: American Standard Code for Information Interchange, 单字节，最大256个，但实际只用7bit(\\080以下)，即最大127 MBCS: Multiple-Byte Character Set DBCS: Double Bytes Code Set，两字节汉字和一字节英文字符同时存在，如果字节值大于127,认为是双字节汉字 GB2312: 对ASCII的中文扩展 GBK: 对GB2312的扩展，新增2W多汉字，包含繁体字 GB18030: 对GBK的扩展，新增少数民族语言字符 CP936: IBM的Code Page, GBK为第936页 Unicode UCS/UNICODE: Universal Multiple-Octet Coded Character Set，所有字符采用2个字节来标识 UCS-4: 采用4个字节来标识一个字符 UTF: UCS Transfer Format UTF8: 每次传输8bit UTF16: 每次传输16bit BOM: Byte Order Mark。网络传输数据高低位解析方式: BOM_UTF8 ‘\\xef\\xbb\\xbf’ BOM_UTF16_LE ‘\\xff\\xfe’ BOM_UTF16_BE ‘\\xfe\\xff’ UNICODE和UTF-8转换： Unicode UTF-8 0000 - 007F 0xxxxxxx 0080 - 07FF 110xxxxx 10xxxxxx 0800 - FFFF 1110xxxx 10xxxxxx 10xxxxxx 编码示例： Unicode: 0110 1100 0100 1001 三字节模板: 0110 110001 001001 UTF-8: 1110-0110 10-110001 10-001001 16进制编码: E6B189 中文字符占用的字节数： utf-8: 3bytes gbk: 2bytes unicode: 1char (2bytes) 2. 操作系统相关编码123456789101112131415sys.getdefaultencoding() # 2.x: ascii, 3.x: utf-8[m for m in dir(sys) if &#x27;encoding&#x27; in m] # [&#x27;getdefaultencoding&#x27;, &#x27;getfilesystemencoding&#x27;]# 重设系统默认编码reload(sys)[m for m in dir(sys) if &#x27;encoding&#x27; in m] # [&#x27;getdefaultencoding&#x27;, &#x27;getfilesystemencoding&#x27;, &#x27;setdefaultencoding&#x27;]sys.setdefaultencoding(&#x27;utf-8&#x27;)sys.getfilesystemencoding() # WIN: mbcs, MacOS: utf-8sys.stdin.encodingsys.stdout.encodinglocale.getdefaultlocale() # (&#x27;zh_CN&#x27;, &#x27;UTF-8&#x27;)locale.getlocale() # (&#x27;zh_CN&#x27;, &#x27;UTF-8&#x27;)locale.setlocale(locale.LC_ALL, &#x27;en_US.UTF-8&#x27;) 123456&gt;&gt;&gt; a = unicode(&#x27;汉&#x27;, encoding=&#x27;gb2312&#x27;) # encoding必须是sys.stdin.encoding一致&gt;&gt;&gt; au&#x27;\\u6c49&#x27;&gt;&gt;&gt; b = a.encode(&#x27;utf-8&#x27;)&gt;&gt;&gt; b&#x27;\\xe6\\xb1\\x89&#x27; 3. python 2.x编码问题123456789101112131415&gt;&gt;&gt; s1 = &#x27;汉&#x27;&gt;&gt;&gt; s2 = u&#x27;汉&#x27;&gt;&gt;&gt; s3 = s1.decode(&#x27;utf-8&#x27;).encode(&#x27;gbk&#x27;)&gt;&gt;&gt; s1&#x27;\\xe6\\xb1\\x89&#x27;&gt;&gt;&gt; s2u&#x27;\\u6c49&#x27;&gt;&gt;&gt; s3&#x27;\\xba\\xba&#x27;&gt;&gt;&gt; len(s1) # 系统默认，utf-8, 3bytes3&gt;&gt;&gt; len(s2) # unicode, 2bytes1&gt;&gt;&gt; len(s3) # gbk, 1char2 若头部声明coding=utf-8, a = ‘中文’ 其编码为utf-8 4. str和unicode str —&gt; decode —&gt; unicode unicode —&gt; encode —&gt; str 12345s = &#x27;中文&#x27; # stru = u&#x27;中文&#x27; # unicodeu = unicode(s, encoding=&#x27;utf-8&#x27;) # unicodeu = s.decode(&#x27;utf-8&#x27;) # unicodes = u.encode(‘utf8’) # str 5. json 字符编码1234567891011js = json.loads(&#x27;&#123;&quot;haha&quot;:&quot;哈哈&quot;&#125;&#x27;, encoding=&#x27;gbk&#x27;)print jsprint js.dumps(js, ensure_ascii=False)print str # 直接printprint obj # 先__str__或__repr__，然后printa = &#123;&#125;a[0] = &#x27;中国&#x27;print aprint a[0] 6. unicode_escape &amp; string_escape6.1 string_escape: 对二进制字节流，逐个字节转义，并对每个字节以16进制输出。123456&gt;&gt;&gt; &#x27;中&#x27;&#x27;\\xe4\\xb8\\xad&#x27;&gt;&gt;&gt; &#x27;中&#x27;.encode(&#x27;string_escape&#x27;)&#x27;\\\\xe4\\\\xb8\\\\xad&#x27;&gt;&gt;&gt; u&#x27;中&#x27;.encode(&#x27;gbk&#x27;).encode(&#x27;string_escape&#x27;)&#x27;\\\\xd6\\\\xd0&#x27; 6.2 unicode_escape: 对unicode字节流，按两个字节转义，并以16进制输出1234&gt;&gt;&gt; u&#x27;中&#x27;u&#x27;\\u4e2d&#x27;&gt;&gt;&gt; u&#x27;中&#x27;.encode(&#x27;unicode_escape&#x27;)&#x27;\\\\u4e2d&#x27; unicode &lt;–&gt; utf-8/gbk &lt;–&gt; string_escapeunicode &lt;–&gt; unicode_escape 6.3 unicode与ascii转换1234567891011&gt;&gt;&gt; uni = u&#x27;\\u4e2d\\u6587&#x27;&gt;&gt;&gt; print(uni)中文&gt;&gt;&gt; asc = uni.encode(&#x27;unicode_escape&#x27;) # 转义&gt;&gt;&gt; asc&#x27;\\\\u4e2d\\\\u6587&#x27;&gt;&gt;&gt; print(asc)\\u4e2d\\u6587&gt;&gt;&gt; uni = asc.decode(&#x27;unicode_escape&#x27;)&gt;&gt;&gt; uniu&#x27;\\u4e2d\\u6587&#x27; 6.4 Latin-1123456789101112131415&gt;&gt;&gt; s = &#x27;z\\xe9ro&#x27;&gt;&gt;&gt; s&#x27;z\\xe9ro&#x27;&gt;&gt;&gt; s.decode(&#x27;unicode_escape&#x27;)u&#x27;z\\xe9ro&#x27;&gt;&gt;&gt; s.decode(&#x27;latin-1&#x27;)u&#x27;z\\xe9ro&#x27;&gt;&gt;&gt; s.decode(&#x27;iso8859-1&#x27;)u&#x27;z\\xe9ro&#x27;&gt;&gt;&gt; print(s.decode(&#x27;unicode_escape&#x27;))zéro&gt;&gt;&gt; print(s.decode(&#x27;iso8859-1&#x27;))zéro&gt;&gt;&gt; print(s.decode(&#x27;latin-1&#x27;))zéro 6.5 直接存储unicode的内置编码12345678910&gt;&gt;&gt; s = u&#x27;中文&#x27;.encode(&#x27;unicode_escape&#x27;)&gt;&gt;&gt; s&#x27;\\\\u4e2d\\\\u6587&#x27;&gt;&gt;&gt; len(s)12&gt;&gt;&gt; s1 = s.decode(&#x27;unicode_escape&#x27;)&gt;&gt;&gt; s1u&#x27;\\u4e2d\\u6587&#x27;&gt;&gt;&gt; len(s1)2 6.6 直接存储utf8的内置编码12345678910&gt;&gt;&gt; s = &#x27;中文&#x27;.encode(&#x27;string_escape&#x27;)&gt;&gt;&gt; s&#x27;\\\\xe4\\\\xb8\\\\xad\\\\xe6\\\\x96\\\\x87&#x27;&gt;&gt;&gt; len(s)24&gt;&gt;&gt; s1 = s.decode(&#x27;string_escape&#x27;)&gt;&gt;&gt; s1&#x27;\\xe4\\xb8\\xad\\xe6\\x96\\x87&#x27;&gt;&gt;&gt; len(s1)6 7. 关于读文件：如果文件中存储的内容是”\\x41\\x42\\x43\\xe4\\xb8\\xad” 那么python程序去读到的是字符串其实是：”\\x41\\x42\\x43\\xe4\\xb8\\xad” 12In [57]: len(&quot;\\\\x41\\\\x42\\\\x43\\\\xe4\\\\xb8\\\\xad&quot;)Out[57]: 24 也就是说，读到的内容，需要先decode(“string-escape”)，然后再decode(“utf-8”) 8. 总结 编码：将人类可识别的字符，转换为机器可识别的字节码 Unicode: 真正的字符串， 解决字符与二进制的对应关系，主要用在内存中，但它太大，不适合网络传输 ASCII、UTF-8、GBK等编码表示的字节串，用来传输和保存数据。（translating a Unicode string into a sequence of bytes） UTF(Unicode Transfermation Format): 解决存储和网络传输问题 UTF-8: 使用1、2、3、4个字节表示所有字符。英文1个，欧洲语系2个，东亚3个 UTF-16: 使用2、4个字节表示所有字符 UTF-32: 使用4个字节表示所有字符 Python2.x &amp; Python3.x的编码差异: Py2: 字符串(str)更应该称为字节串(bytes) Py3: str==unicode 编码解码函数： s.encode(encoding): unicode –&gt; ascii, utf-8, gbk s.decode(encoding): ascii, utf-8, gbk –&gt; unicode 字节流和字符流： 字节流：处理1byte的字节，操作字节和字节数组，如音频、视频等 字符流：处理2bytes的unicode字符，可操作字符、字符数组或字符串 python2中，有basestring、str、bytes、unicode四种类型, 其中str == bytes ,basestring = (str,unicode) python3中，有str和bytes类型","categories":[{"name":"Python","slug":"Python","permalink":"https://elihe2011.github.io/categories/Python/"}],"tags":[{"name":"unicode","slug":"unicode","permalink":"https://elihe2011.github.io/tags/unicode/"}]}]}